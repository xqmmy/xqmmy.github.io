<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">

    <!--[if lt IE 9]>
        <style>body {display: none; background: none !important} </style>
        <meta http-equiv="Refresh" Content="0; url=//outdatedbrowser.com/" />
    <![endif]-->

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="format-detection" content="telephone=no">
<meta name="author" content="MingmingYe">


    
    


<meta property="og:type" content="website">
<meta property="og:title" content="Stay hungry, Stay foolish.">
<meta property="og:url" content="http://mmyblog.cn/index.html">
<meta property="og:site_name" content="Stay hungry, Stay foolish.">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Stay hungry, Stay foolish.">

<link rel="apple-touch-icon" href="/apple-touch-icon.png">


    <link rel="alternate" href="/atom.xml" title="Stay hungry, Stay foolish." type="application/atom+xml">



    <link rel="shortcut icon" href="/favicon.png">



    <link href="//cdn.bootcss.com/animate.css/3.5.1/animate.min.css" rel="stylesheet">



    <link href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet">



    <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
    <link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-minimal.css" rel="stylesheet">


<link rel="stylesheet" href="/css/style.css">


    <style> .article { opacity: 0;} </style>


<link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">


<title>Stay hungry, Stay foolish.</title>

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

<script>
    var yiliaConfig = {
        fancybox: true,
        animate: true,
        isHome: true,
        isPost: false,
        isArchive: false,
        isTag: false,
        isCategory: false,
        fancybox_js: "//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js",
        scrollreveal: "//cdn.bootcss.com/scrollReveal.js/3.1.4/scrollreveal.min.js",
        search: true
    }
</script>


    <script>
        yiliaConfig.jquery_ui = [true, "//cdn.bootcss.com/jqueryui/1.10.4/jquery-ui.min.js", "//cdn.bootcss.com/jqueryui/1.10.4/css/jquery-ui.min.css"];
    </script>



    <script> yiliaConfig.rootUrl = "\/";</script>






</head></html>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            <img src="/img/deep.png" class="animated zoomIn">
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">MingmingYe</a></h1>
        </hgroup>

        
        <p class="header-subtitle">当你的才华撑不起你的野心时，只有静下心来好好学习！纵使命运注定是个打酱油的，也要打一瓶与别人不一样的酱油！</p>
        

        
            <form id="search-form">
            <input type="text" id="local-search-input" name="q" placeholder="search..." class="search form-control" autocomplete="off" autocorrect="off" searchonload="false" />
            <i class="fa fa-times" onclick="resetSearch()"></i>
            </form>
            <div id="local-search-result"></div>
            <p class='no-result'>No results found <i class='fa fa-spinner fa-pulse'></i></p>
        


        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/">主页</a></li>
                        
                            <li><a href="/archives/">所有文章</a></li>
                        
                            <li><a href="/tags/">标签云</a></li>
                        
                            <li><a href="/about/">关于我</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" href="mailto:878759487@qq.com" title="Email"></a>
                            
                                <a class="fa GitHub" href="#" title="GitHub"></a>
                            
                                <a class="fa RSS" href="/atom.xml" title="RSS"></a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/AUC/">AUC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LR/">LR</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ROC/">ROC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mumpy/">mumpy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pandas/">pandas</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pyspark/">pyspark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/seaborn/">seaborn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/softmax/">softmax</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/优化方法/">优化方法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/微积分/">微积分</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习/">机器学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/概率/">概率</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/算法/">算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/线性代数/">线性代数</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/统计/">统计</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/面试/">面试</a></li></ul>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a class="main-nav-link switch-friends-link" href="https://hexo.io">Hexo</a>
                    
                      <a class="main-nav-link switch-friends-link" href="https://pages.github.com/">GitHub</a>
                    
                      <a class="main-nav-link switch-friends-link" href="http://mmyblog.cn/">mmy</a>
                    
                    </div>
                </section>
                

                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">MingmingYe</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                <img src="/img/deep.png" class="animated zoomIn">
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页">MingmingYe</a></h1>
            </hgroup>
            
            <p class="header-subtitle">当你的才华撑不起你的野心时，只有静下心来好好学习！纵使命运注定是个打酱油的，也要打一瓶与别人不一样的酱油！</p>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/">主页</a></li>
                
                    <li><a href="/archives/">所有文章</a></li>
                
                    <li><a href="/tags/">标签云</a></li>
                
                    <li><a href="/about/">关于我</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" target="_blank" href="mailto:878759487@qq.com" title="Email"></a>
                            
                                <a class="fa GitHub" target="_blank" href="#" title="GitHub"></a>
                            
                                <a class="fa RSS" target="_blank" href="/atom.xml" title="RSS"></a>
                            
                        </ul>
            </nav>
        </header>                
    </div>
    <link class="menu-list" tags="标签" friends="友情链接" about="关于我"/>
</nav>
      <div class="body-wrap">
  
    <article id="post-机器学习逻辑回归与softmax" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/08/29/机器学习逻辑回归与softmax/" class="article-date">
      <time datetime="2019-08-29T08:39:02.000Z" itemprop="datePublished">2019-08-29</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/08/29/机器学习逻辑回归与softmax/">机器学习逻辑回归与softmax</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="机器学习逻辑回归与softmax"><a href="#机器学习逻辑回归与softmax" class="headerlink" title="机器学习逻辑回归与softmax"></a>机器学习逻辑回归与softmax</h1><h2 id="机器学习中的线性模型"><a href="#机器学习中的线性模型" class="headerlink" title="机器学习中的线性模型"></a>机器学习中的线性模型</h2><p>谈及线性模型，其实我们很早就已经与它打过交道，还记得高中数学必修3课本中那个顽皮的“最小二乘法”吗？这就是线性模型的经典算法之一：根据给定的（x，y）点对，求出一条与这些点拟合效果最好的直线y=ax+b，之前我们利用下面的公式便可以计算出拟合直线的系数a,b（3.1中给出了具体的计算过程），从而对于一个新的x，可以预测它所对应的y值。前面我们提到：在机器学习的术语中，当预测值为连续值时，称为“回归问题”，离散值时为“分类问题”。本篇先从线性回归任务开始，接着讨论分类和多分类问题。</p>
<p><img src="https://i.loli.net/2018/10/17/5bc722b068e48.png" alt="1.png"></p>
<h3 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h3><p>线性回归问题就是试图学到一个线性模型尽可能准确地预测新样本的输出值，例如：通过历年的人口数据预测2017年人口数量。在这类问题中，往往我们会先得到一系列的有标记数据，例如：2000–&gt;13亿…2016–&gt;15亿，这时输入的属性只有一个，即年份；也有输入多属性的情形，假设我们预测一个人的收入，这时输入的属性值就不止一个了，例如：（学历，年龄，性别，颜值，身高，体重）–&gt;15k。</p>
<p>有时这些输入的属性值并不能直接被我们的学习模型所用，需要进行相应的处理，对于连续值的属性，一般都可以被学习器所用，有时会根据具体的情形作相应的预处理，例如：归一化等；对于离散值的属性，可作下面的处理：</p>
<ul>
<li><p>若属性值之间存在“序关系”，则可以将其转化为连续值，例如：身高属性分为“高”“中等”“矮”，可转化为数值：{1， 0.5， 0}。</p>
</li>
<li><p>若属性值之间不存在“序关系”，则通常将其转化为向量的形式，例如：性别属性分为“男”“女”，可转化为二维向量：{（1，0），（0，1）}。</p>
</li>
</ul>
<p>（1）当输入属性只有一个的时候，就是最简单的情形，也就是我们高中时最熟悉的“最小二乘法”（Euclidean distance），首先计算出每个样本预测值与真实值之间的误差并求和，通过最小化均方误差MSE，使用求偏导等于零的方法计算出拟合直线y=wx+b的两个参数w和b，计算过程如下图所示：</p>
<p><img src="https://i.loli.net/2018/10/17/5bc722b0ccec4.png" alt="2.png"></p>
<p>（2）当输入属性有多个的时候，例如对于一个样本有d个属性{（x1,x2…xd）,y}，则y=wx+b需要写成：</p>
<p><img src="https://i.loli.net/2018/10/17/5bc72567b8bcd.png" alt="0.png"></p>
<p>通常对于多元问题，常常使用矩阵的形式来表示数据。在本问题中，将具有m个样本的数据集表示成矩阵X，将系数w与b合并成一个列向量，这样每个样本的预测值以及所有样本的均方误差最小化就可以写成下面的形式：</p>
<p><img src="https://i.loli.net/2018/10/17/5bc722b0ad8f7.png" alt="3.png"></p>
<p><img src="https://i.loli.net/2018/10/17/5bc722b0af652.png" alt="4.png"></p>
<p><img src="https://i.loli.net/2018/10/17/5bc722b090543.png" alt="5.png"></p>
<p><img src="/blog_picture/line04.jpg" alt="avatar"></p>
<p><img src="/blog_picture/line05.jpg" alt="avatar"></p>
<p><img src="/blog_picture/line06.jpg" alt="avatar"></p>
<p><img src="/blog_picture/line07.jpg" alt="avatar"></p>
<h3 id="最小二乘法"><a href="#最小二乘法" class="headerlink" title="最小二乘法"></a>最小二乘法</h3><p>同样地，我们使用最小二乘法对w和b进行估计，令均方误差的求导等于0，需要注意的是，当一个矩阵的行列式不等于0时，我们才可能对其求逆，因此对于下式，我们需要考虑矩阵（X的转置*X）的行列式是否为0，若不为0，则可以求出其解，若为0，则需要使用其它的方法进行计算，书中提到了引入正则化，此处不进行深入。</p>
<p><img src="https://i.loli.net/2018/10/17/5bc722b0cde33.png" alt="6.png"></p>
<p>然而现实任务中当特征数量大于样本数时，XTX不满秩，此时θ有多个解；而且当数据量大时，求矩阵的逆非常耗时；对于不可逆矩阵（特征之间不相互独立），这种正规方程方法是不能用的。所以，还可以采用梯度下降法，利用迭代的方式求解θ。</p>
<h3 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h3><p>梯度下降法是按下面的流程进行的：<br>1）首先对θ赋值，这个值可以是随机的，也可以让θ是一个全零的向量。<br>2）改变θ的值，使得θ按梯度下降的方向进行减少。</p>
<p><img src="/blog_picture/line01.jpg" alt="avatar"></p>
<p>对于只有两维属性的样本，J(θ)即J(θ0,θ1)的等高线图</p>
<p><img src="/blog_picture/line02.jpg" alt="avatar"></p>
<p><img src="/blog_picture/line03.jpg" alt="avatar"></p>
<p>迭代更新的方式有多种</p>
<ul>
<li>批量梯度下降（batch gradient descent），也就是是梯度下降法最原始的形式，对全部的训练数据求得误差后再对θ<br>进行更新，优点是每步都趋向全局最优解；缺点是对于大量数据，由于每步要计算整体数据，训练过程慢；</li>
<li>随机梯度下降（stochastic gradient descent），每一步随机选择一个样本对θ<br>进行更新，优点是训练速度快；缺点是每次的前进方向不好确定，容易陷入局部最优；</li>
<li>微型批量梯度下降（mini-batch gradient descent），每步选择一小批数据进行批量梯度下降更新θ<br>，属于批量梯度下降和随机梯度下降的一种折中，非常适合并行处理。</li>
</ul>
<p>另一方面，有时像上面这种原始的线性回归可能并不能满足需求，例如：y值并不是线性变化，而是在指数尺度上变化。这时我们可以采用线性模型来逼近y的衍生物，例如lny，这时衍生的线性模型如下所示，实际上就是相当于将指数曲线投影在一条直线上，如下图所示：</p>
<p><img src="https://i.loli.net/2018/10/17/5bc722b103cbf.png" alt="7.png"></p>
<p>更一般地，考虑所有y的衍生物的情形，就得到了“广义的线性模型”（generalized linear model），其中，g（*）称为联系函数（link function）。</p>
<p><img src="https://i.loli.net/2018/10/17/5bc722b0a2841.png" alt="8.png"></p>
<h3 id="对数几率回归"><a href="#对数几率回归" class="headerlink" title="对数几率回归"></a>对数几率回归</h3><p>回归就是通过输入的属性值得到一个预测值，利用上述广义线性模型的特征，是否可以通过一个联系函数，将预测值转化为离散值从而进行分类呢？线性几率回归正是研究这样的问题。对数几率引入了一个对数几率函数（logistic function）,将预测值投影到0-1之间，从而将线性回归问题转化为二分类问题。</p>
<p><img src="https://i.loli.net/2018/10/17/5bc722b0c7748.png" alt="9.png"></p>
<p><img src="https://i.loli.net/2018/10/17/5bc722b0a655d.png" alt="10.png"></p>
<p>若将y看做样本为正例的概率，（1-y）看做样本为反例的概率，则上式实际上使用线性回归模型的预测结果器逼近真实标记的对数几率。因此这个模型称为“对数几率回归”（logistic regression），也有一些书籍称之为“逻辑回归”。下面使用最大似然估计的方法来计算出w和b两个参数的取值，下面只列出求解的思路，不列出具体的计算过程。</p>
<p><img src="https://i.loli.net/2018/10/17/5bc723b824f0c.png" alt="11.png"></p>
<p><img src="https://i.loli.net/2018/10/17/5bc723b817961.png" alt="12.png"></p>
<h3 id="线性判别分析"><a href="#线性判别分析" class="headerlink" title="线性判别分析"></a>线性判别分析</h3><p>线性判别分析（Linear Discriminant Analysis，简称LDA）,其基本思想是：将训练样本投影到一条直线上，使得同类的样例尽可能近，不同类的样例尽可能远。如图所示：</p>
<p><img src="https://i.loli.net/2018/10/17/5bc723b863ebb.png" alt="13.png"><img src="https://i.loli.net/2018/10/17/5bc723b85bfa9.png" alt="14.png"></p>
<p>想让同类样本点的投影点尽可能接近，不同类样本点投影之间尽可能远，即：让各类的协方差之和尽可能小，不用类之间中心的距离尽可能大。基于这样的考虑，LDA定义了两个散度矩阵。</p>
<ul>
<li>类内散度矩阵（within-class scatter matrix）</li>
</ul>
<p><img src="https://i.loli.net/2018/10/17/5bc723b8156e1.png" alt="15.png"></p>
<ul>
<li>类间散度矩阵(between-class scaltter matrix)</li>
</ul>
<p><img src="https://i.loli.net/2018/10/17/5bc723b7e9db3.png" alt="16.png"></p>
<p>因此得到了LDA的最大化目标：“广义瑞利商”（generalized Rayleigh quotient）。</p>
<p><img src="https://i.loli.net/2018/10/17/5bc723b7e8a61.png" alt="17.png"></p>
<p>从而分类问题转化为最优化求解w的问题，当求解出w后，对新的样本进行分类时，只需将该样本点投影到这条直线上，根据与各个类别的中心值进行比较，从而判定出新样本与哪个类别距离最近。求解w的方法如下所示，使用的方法为λ乘子。</p>
<p><img src="https://i.loli.net/2018/10/17/5bc723b83d5e0.png" alt="18.png"></p>
<p>若将w看做一个投影矩阵，类似PCA的思想，则LDA可将样本投影到N-1维空间（N为类簇数），投影的过程使用了类别信息（标记信息），因此LDA也常被视为一种经典的监督降维技术。    </p>
<h3 id="回归与欠-过拟合"><a href="#回归与欠-过拟合" class="headerlink" title="回归与欠/过拟合"></a>回归与欠/过拟合</h3><p><img src="/blog_picture/line08.jpg" alt="avatar">    </p>
<h3 id="线性回归与正则化"><a href="#线性回归与正则化" class="headerlink" title="线性回归与正则化"></a>线性回归与正则化</h3><p><img src="/blog_picture/line09.jpg" alt="avatar">     </p>
<h3 id="多分类学习"><a href="#多分类学习" class="headerlink" title="多分类学习"></a>多分类学习</h3><p>现实中我们经常遇到不只两个类别的分类问题，即多分类问题，在这种情形下，我们常常运用“拆分”的策略，通过多个二分类学习器来解决多分类问题，即将多分类问题拆解为多个二分类问题，训练出多个二分类学习器，最后将多个分类结果进行集成得出结论。最为经典的拆分策略有三种：“一对一”（OvO）、“一对其余”（OvR）和“多对多”（MvM），核心思想与示意图如下所示。</p>
<ul>
<li><p>OvO：给定数据集D，假定其中有N个真实类别，将这N个类别进行两两配对（一个正类/一个反类），从而产生N（N-1）/2个二分类学习器，在测试阶段，将新样本放入所有的二分类学习器中测试，得出N（N-1）个结果，最终通过投票产生最终的分类结果。</p>
</li>
<li><p>OvM：给定数据集D，假定其中有N个真实类别，每次取出一个类作为正类，剩余的所有类别作为一个新的反类，从而产生N个二分类学习器，在测试阶段，得出N个结果，若仅有一个学习器预测为正类，则对应的类标作为最终分类结果。</p>
</li>
<li><p>MvM：给定数据集D，假定其中有N个真实类别，每次取若干个类作为正类，若干个类作为反类（通过ECOC码给出，编码），若进行了M次划分，则生成了M个二分类学习器，在测试阶段（解码），得出M个结果组成一个新的码，最终通过计算海明/欧式距离选择距离最小的类别作为最终分类结果。</p>
</li>
</ul>
<p><img src="https://i.loli.net/2018/10/17/5bc723b862bfb.png" alt="19.png"></p>
<p><img src="https://i.loli.net/2018/10/17/5bc723b8300d5.png" alt="20.png"></p>
<h3 id="类别不平衡问题"><a href="#类别不平衡问题" class="headerlink" title="类别不平衡问题"></a>类别不平衡问题</h3><p>类别不平衡（class-imbanlance）就是指分类问题中不同类别的训练样本相差悬殊的情况，例如正例有900个，而反例只有100个，这个时候我们就需要进行相应的处理来平衡这个问题。常见的做法有三种：</p>
<ol>
<li>在训练样本较多的类别中进行“欠采样”（undersampling）,比如从正例中采出100个，常见的算法有：EasyEnsemble。</li>
<li>在训练样本较少的类别中进行“过采样”（oversampling）,例如通过对反例中的数据进行插值，来产生额外的反例，常见的算法有SMOTE。</li>
<li>直接基于原数据集进行学习，对预测值进行“再缩放”处理。其中再缩放也是代价敏感学习的基础。<img src="https://i.loli.net/2018/10/17/5bc726fe87ae2.png" alt="21.png"></li>
</ol>
<h3 id="LR应用经验"><a href="#LR应用经验" class="headerlink" title="LR应用经验"></a>LR应用经验</h3><p>LR实现简单高效易解释，计算速度快，易并行，在大规模数据情况下非常适用，更适合于应对数值型和标称型数据，主要适合解决线性可分的问题，但容易欠拟合，大多数情况下需要手动进行特征工程，构建组合特征，分类精度不高。</p>
<p>LR直接对分类可能性进行建模，无需事先假设数据分布，这样就避免了假设分布不准确所带来的问题<br>LR能以概率的形式输出，而非知识0，1判定，对许多利用概率辅助决策的任务很有用<br>对率函数任意阶可导，具有很好的数学性质，许多现有的数值优化算法都可以用来求最优解，训练速度快<br>适用情景：LR是很多分类算法的基础组件，它的好处是输出值自然地落在0到1之间，并且有概率意义。因为它本质上是一个线性的分类器，所以处理不好特征之间相关的情况。虽然效果一般，却胜在模型清晰，背后的概率学经得住推敲。它拟合出来的参数就代表了每一个特征(feature)对结果的影响。也是一个理解数据的好工具。</p>
<p>应用上： </p>
<ul>
<li>CTR预估，推荐系统的learning to rank，各种分类场景 </li>
<li>某搜索引擎厂的广告CTR预估基线版是LR </li>
<li>某电商搜索排序基线版是LR </li>
<li>某新闻app排序基线版是LR</li>
</ul>
<p>大规模工业实时数据，需要可解释性的金融数据，需要快速部署低耗时数据<br>LR就是简单，可解释，速度快，消耗资源少，分布式性能好</p>
<p>ADMM-LR:用ADMM求解LogisticRegression的优化方法称作ADMM_LR。ADMM算法是一种求解约束问题的最优化方法，它适用广泛。相比于SGD，ADMM在精度要求不高的情况下，在少数迭代轮数时就达到一个合理的精度，但是收敛到很精确的解则需要很多次迭代。</p>
<p><img src="/blog_picture/line10.jpg" alt="avatar">   </p>
<p><img src="/blog_picture/line11.jpg" alt="avatar">   </p>
<p><img src="/blog_picture/line12.jpg" alt="avatar">   </p>
<h2 id="LR多分类推广-Softmax回归"><a href="#LR多分类推广-Softmax回归" class="headerlink" title="LR多分类推广 - Softmax回归"></a>LR多分类推广 - Softmax回归</h2><p>LR是一个传统的二分类模型，它也可以用于多分类任务，其基本思想是：将多分类任务拆分成若干个二分类任务，然后对每个二分类任务训练一个模型，最后将多个模型的结果进行集成以获得最终的分类结果。一般来说，可以采取的拆分策略有：</p>
<h3 id="one-vs-one策略"><a href="#one-vs-one策略" class="headerlink" title="one vs one策略"></a>one vs one策略</h3><p>　　假设我们有N个类别，该策略基本思想就是不同类别两两之间训练一个分类器，这时我们一共会训练出<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171104175530607-1392543504.png" alt="img">种不同的分类器。在预测时，我们将样本提交给所有的分类器，一共会获得N(N-1)个结果，最终结果通过<strong>投票</strong>产生。</p>
<h3 id="one-vs-all策略"><a href="#one-vs-all策略" class="headerlink" title="one vs all策略"></a>one vs all策略</h3><p>　　该策略基本思想就是将第i种类型的所有样本作为正例，将剩下的所有样本作为负例，进行训练得到一个分类器。这样我们就一共可以得到N个分类器。在预测时，我们将样本提交给所有的分类器，一共会获得N个结果，我们<strong>选择其中概率值最大</strong>的那个作为最终分类结果。 <img src="https://images2017.cnblogs.com/blog/1251096/201710/1251096-20171021171313943-1199609768.png" alt="img"></p>
<h2 id="softmax回归"><a href="#softmax回归" class="headerlink" title="softmax回归"></a>softmax回归</h2><p>　　softmax是LR在多分类的推广。与LR一样，同属于广义线性模型。什么是Softmax函数？假设我们有一个数组A，<img src="https://images2017.cnblogs.com/blog/1251096/201710/1251096-20171021164616881-992414484.png" alt="img">表示的是数组A中的第i个元素，那么这个元素的Softmax值就是</p>
<p>　　　　　　　　　　　　<img src="https://images2017.cnblogs.com/blog/1251096/201710/1251096-20171021165228865-866731732.png" alt="img"></p>
<p>也就是说，是该元素的指数，与所有元素指数和的比值。那么 softmax回归模型的假设函数又是怎么样的呢？</p>
<p>　　　　　　　　　　<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171105100956795-1587348606.png" alt="img"></p>
<p>由上式很明显可以得出，假设函数的分母其实就是对概率分布进行了归一化，使得所有类别的概率之和为1；也可以看出LR其实就是K=2时的Softmax。在参数获得上，我们可以采用one vs all策略获得K个不同的训练数据集进行训练，进而针对每一类别都会得到一组参数向量<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171105102153701-629755133.png" alt="img">。当测试样本特征向量<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171105102416560-1451219507.png" alt="img">输入时，我们先用假设函数针对每一个类别<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171105102622045-1005416234.png" alt="img">估算出概率值<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171105102706623-369597312.png" alt="img">。因此我们的假设函数将要输出一个K维的向量（向量元素和为1）来表示K个类别的估计概率，我们选择其中得分最大的类别作为该输入的预测类别。Softmax看起来和one vs all 的LR很像，它们最大的不同在与Softmax得到的K个类别的得分和为1，而one vs all的LR并不是。</p>
<h3 id="softmax的代价函数"><a href="#softmax的代价函数" class="headerlink" title="softmax的代价函数"></a>softmax的代价函数</h3><p>　　类似于LR，其似然函数我们采用对数似然，故：</p>
<p>　　　　<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171105113747779-692061991.png" alt="img"></p>
<p>加入<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171104162333248-539020480.png" alt="img">正则项的损失函数为：</p>
<p>　　　　<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171105114132232-517057992.png" alt="img"></p>
<p>此处的<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171105110553560-1026190635.png" alt="img">为符号函数。对于其参数的求解过程，我们依然采用梯度下降法。</p>
<h3 id="softmax的梯度的求解"><a href="#softmax的梯度的求解" class="headerlink" title="softmax的梯度的求解"></a>softmax的梯度的求解</h3><p>　　正则化项的求导很简单，就等于<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171105120226607-495282914.png" alt="img">，下面我们主要讨论没有加正则项的损失函数的梯度求解，即</p>
<p>　　　　　　<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171105113747779-692061991.png" alt="img"></p>
<p>的导数（梯度）。为了使得求解过程看起来简便、易于理解，我们仅仅只对于一个样本（x,y）情况（SGD）进行讨论，</p>
<p>　　　　<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171105161912482-1607069737.png" alt="img"></p>
<p>此时，我们令</p>
<p>　　　　<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171105162625888-1575402902.png" alt="img"></p>
<p>可以得到</p>
<p>　　　　<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171105163457810-492161690.png" alt="img"></p>
<p>故：</p>
<p><img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171105170233232-810575386.png" alt="img"></p>
<p>所以，正则化之后的损失函数的梯度为</p>
<p>　　　　<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171105171748341-1281292385.png" alt="img"></p>
<p>然后通过梯度下降法最小化 <img src="http://ufldl.stanford.edu/wiki/images/math/c/e/0/ce027336c1cb3c0cd461406c81369ebf.png" alt="\textstyle J(\theta)">，我们就能实现一个可用的 softmax 回归模型了。</p>
<h3 id="多分类LR与Softmax回归"><a href="#多分类LR与Softmax回归" class="headerlink" title="多分类LR与Softmax回归"></a>多分类LR与Softmax回归</h3><p>　　有了多分类的处理方法，那么我们什么时候该用多分类LR？什么时候要用softmax呢？</p>
<p>总的来说，若待分类的<strong>类别互斥</strong>，我们就使用Softmax方法；若待分类的<strong>类别有相交</strong>，我们则要选用多分类LR，然后投票表决。</p>
<h2 id="Softmax分类器"><a href="#Softmax分类器" class="headerlink" title="Softmax分类器"></a>Softmax分类器</h2><p>SVM是最常用的两个分类器之一，而另一个就是<strong>Softmax分类器，</strong>它的损失函数与SVM的损失函数不同。对于学习过二元逻辑回归分类器的读者来说，Softmax分类器就可以理解为逻辑回归分类器面对多个分类的一般化归纳。SVM将输出<img src="https://www.zhihu.com/equation?tex=f%28x_i%2CW%29" alt="[公式]">作为每个分类的评分（因为无定标，所以难以直接解释）。与SVM不同，Softmax的输出（归一化的分类概率）更加直观，并且从概率上可以解释，这一点后文会讨论。在Softmax分类器中，函数映射<img src="https://www.zhihu.com/equation?tex=f%28x_i%3BW%29%3DWx_i" alt="[公式]">保持不变，但将这些评分值视为每个分类的未归一化的对数概率，并且将<em>折叶损失（hinge loss）</em>替换为<strong>交叉熵损失</strong>（<strong>cross-entropy loss）</strong>。公式如下：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cdisplaystyle+Li%3D-log%28%5Cfrac%7Be%5E%7Bf_%7By_i%7D%7D%7D%7B%5Csum_je%5E%7Bf_j%7D%7D%29" alt="[公式]"> 或等价的 <img src="https://www.zhihu.com/equation?tex=L_i%3D-f_%7By_i%7D%2Blog%28%5Csum_je%5E%7Bf_j%7D%29" alt="[公式]"></p>
<p>在上式中，使用<img src="https://www.zhihu.com/equation?tex=f_j" alt="[公式]">来表示分类评分向量<img src="https://www.zhihu.com/equation?tex=f" alt="[公式]">中的第j个元素。和之前一样，整个数据集的损失值是数据集中所有样本数据的损失值<img src="https://www.zhihu.com/equation?tex=L_i" alt="[公式]">的均值与正则化损失<img src="https://www.zhihu.com/equation?tex=R%28W%29" alt="[公式]">之和。其中函数<img src="https://www.zhihu.com/equation?tex=f_j%28z%29%3D%5Cfrac%7Be%5E%7Bz_j%7D%7D%7B%5Csum_ke%5E%7Bz_k%7D%7D" alt="[公式]">被称作<strong>softmax 函数</strong>：其输入值是一个向量，向量中元素为任意实数的评分值（<img src="https://www.zhihu.com/equation?tex=z" alt="[公式]">中的），函数对其进行压缩，输出一个向量，其中每个元素值在0到1之间，且所有元素之和为1。所以，包含softmax函数的完整交叉熵损失看起唬人，实际上还是比较容易理解的。</p>
<p><strong>信息理论视角</strong>：在“真实”分布<img src="https://www.zhihu.com/equation?tex=p" alt="[公式]">和估计分布<img src="https://www.zhihu.com/equation?tex=q" alt="[公式]">之间的<em>交叉熵</em>定义如下：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cdisplaystyle+H%28p%2Cq%29%3D-%5Csum_xp%28x%29+logq%28x%29" alt="[公式]"></p>
<p><strong>*译者注</strong>：Kullback-Leibler差异（Kullback-Leibler Divergence）也叫做相对熵（Relative Entropy），它衡量的是相同事件空间里的两个概率分布的差异情况。*</p>
<p><strong>概率论解释</strong>：先看下面的公式：</p>
<p><img src="https://www.zhihu.com/equation?tex=P%28y_i%7Cx_i%2CW%29%3D%5Cfrac%7Be%5E%7Bf_%7By_i%7D%7D%7D%7B%5Csum_je%5E%7Bf_j%7D%7D" alt="[公式]"></p>
<p><strong>实操事项：数值稳定。</strong>编程实现softmax函数计算的时候，中间项<img src="https://www.zhihu.com/equation?tex=e%5E%7Bf_%7By_i%7D%7D" alt="[公式]">和<img src="https://www.zhihu.com/equation?tex=%5Csum_j+e%5E%7Bf_j%7D" alt="[公式]">因为存在指数函数，所以数值可能非常大。除以大数值可能导致数值计算的不稳定，所以学会使用归一化技巧非常重要。如果在分式的分子和分母都乘以一个常数<img src="https://www.zhihu.com/equation?tex=C" alt="[公式]">，并把它变换到求和之中，就能得到一个从数学上等价的公式：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cfrac%7Be%5E%7Bf_%7By_i%7D%7D%7D%7B%5Csum_je%5E%7Bf_j%7D%7D%3D%5Cfrac%7BCe%5E%7Bf_%7By_i%7D%7D%7D%7BC%5Csum_je%5E%7Bf_j%7D%7D%3D%5Cfrac%7Be%5E%7Bf_%7By_i%7D%2BlogC%7D%7D%7B%5Csum_je%5E%7Bf_j%2BlogC%7D%7D" alt="[公式]"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">f = np.array([<span class="number">123</span>, <span class="number">456</span>, <span class="number">789</span>]) <span class="comment"># 例子中有3个分类，每个评分的数值都很大</span></span><br><span class="line">p = np.exp(f) / np.sum(np.exp(f)) <span class="comment"># 不妙：数值问题，可能导致数值爆炸</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 那么将f中的值平移到最大值为0：</span></span><br><span class="line">f -= np.max(f) <span class="comment"># f becomes [-666, -333, 0]</span></span><br><span class="line">p = np.exp(f) / np.sum(np.exp(f)) <span class="comment"># 现在OK了，将给出正确结果</span></span><br></pre></td></tr></table></figure>

<p><strong>让人迷惑的命名规则</strong>：精确地说，SVM分类器使用的是<em>折叶损失（hinge loss）</em>，有时候又被称为<em>最大边界损失（max-margin loss）</em>。Softmax分类器使用的是<em>交叉熵损失（corss-entropy loss）</em>。Softmax分类器的命名是从<em>softmax函数</em>那里得来的，softmax函数将原始分类评分变成正的归一化数值，所有数值和为1，这样处理后交叉熵损失才能应用。注意从技术上说“softmax损失（softmax loss）”是没有意义的，因为softmax只是一个压缩数值的函数。但是在这个说法常常被用来做简称。</p>
<h2 id="SVM和Softmax的比较"><a href="#SVM和Softmax的比较" class="headerlink" title="SVM和Softmax的比较"></a>SVM和Softmax的比较</h2><p>下图有助于区分这 Softmax和SVM这两种分类器：</p>
<p>————————————————————————————————————————</p>
<p><img src="https://pic1.zhimg.com/80/a90ce9e0ff533f3efee4747305382064_hd.png" alt="img"></p>
<p>针对一个数据点，SVM和Softmax分类器的不同处理方式的例子。两个分类器都计算了同样的分值向量<strong>f</strong>（本节中是通过矩阵乘来实现）。不同之处在于对<strong>f</strong>中分值的解释：SVM分类器将它们看做是分类评分，它的损失函数鼓励正确的分类（本例中是蓝色的类别2）的分值比其他分类的分值高出至少一个边界值。Softmax分类器将这些数值看做是每个分类没有归一化的<strong>对数概率</strong>，鼓励正确分类的归一化的对数概率变高，其余的变低。SVM的最终的损失值是1.58，Softmax的最终的损失值是0.452，但要注意这两个数值没有可比性。只在给定同样数据，在同样的分类器的损失值计算中，它们才有意义。</p>
<p>————————————————————————————————————————</p>
<p><strong>Softmax分类器为每个分类提供了“可能性”</strong>：SVM的计算是无标定的，而且难以针对所有分类的评分值给出直观解释。Softmax分类器则不同，它允许我们计算出对于所有分类标签的可能性。举个例子，针对给出的图像，SVM分类器可能给你的是一个[12.5, 0.6, -23.0]对应分类“猫”，“狗”，“船”。而softmax分类器可以计算出这三个标签的”可能性“是[0.9, 0.09, 0.01]，这就让你能看出对于不同分类准确性的把握。为什么我们要在”可能性“上面打引号呢？这是因为可能性分布的集中或离散程度是由正则化参数λ直接决定的，λ是你能直接控制的一个输入参数。举个例子，假设3个分类的原始分数是[1, -2, 0]，那么softmax函数就会计算：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5B1%2C-2%2C0%5D%5Cto%5Be%5E1%2Ce%5E%7B-2%7D%2Ce%5E0%5D%3D%5B2.71%2C0.14%2C1%5D%5Cto%5B0.7%2C0.04%2C0.26%5D" alt="[公式]"></p>
<p>现在，如果正则化参数λ更大，那么权重W就会被惩罚的更多，然后他的权重数值就会更小。这样算出来的分数也会更小，假设小了一半吧[0.5, -1, 0]，那么softmax函数的计算就是：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5B0.5%2C-1%2C0%5D%5Cto%5Be%5E%7B0.5%7D%2Ce%5E%7B-1%7D%2Ce%5E0%5D%3D%5B1.65%2C0.73%2C1%5D%5Cto%5B0.55%2C0.12%2C0.33%5D" alt="[公式]"></p>
<p>现在看起来，概率的分布就更加分散了。还有，随着正则化参数λ不断增强，权重数值会越来越小，最后输出的概率会接近于均匀分布。这就是说，softmax分类器算出来的概率最好是看成一种对于分类正确性的自信。和SVM一样，数字间相互比较得出的大小顺序是可以解释的，但其绝对值则难以直观解释<strong>。</strong></p>
<p><strong>在实际使用中，SVM和Softmax经常是相似的</strong>：通常说来，两种分类器的表现差别很小，不同的人对于哪个分类器更好有不同的看法。相对于Softmax分类器，SVM更加“局部目标化（local objective）”，这既可以看做是一个特性，也可以看做是一个劣势。考虑一个评分是[10, -2, 3]的数据，其中第一个分类是正确的。那么一个SVM（<img src="https://www.zhihu.com/equation?tex=%5CDelta+%3D1" alt="[公式]">）会看到正确分类相较于不正确分类，已经得到了比边界值还要高的分数，它就会认为损失值是0。SVM对于数字个体的细节是不关心的：如果分数是[10, -100, -100]或者[10, 9, 9]，对于SVM来说没设么不同，只要满足超过边界值等于1，那么损失值就等于0。</p>
<p>对于softmax分类器，情况则不同。对于[10, 9, 9]来说，计算出的损失值就远远高于[10, -100, -100]的。换句话来说，softmax分类器对于分数是永远不会满意的：正确分类总能得到更高的可能性，错误分类总能得到更低的可能性，损失值总是能够更小。但是，SVM只要边界值被满足了就满意了，不会超过限制去细微地操作具体分数。这可以被看做是SVM的一种特性。举例说来，一个汽车的分类器应该把他的大量精力放在如何分辨小轿车和大卡车上，而不应该纠结于如何与青蛙进行区分，因为区分青蛙得到的评分已经足够低了。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LR/">LR</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/softmax/">softmax</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-机器学习基本概念" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/08/23/机器学习基本概念/" class="article-date">
      <time datetime="2019-08-23T09:01:11.000Z" itemprop="datePublished">2019-08-23</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/08/23/机器学习基本概念/">机器学习基本概念</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h2 id="机器学习基本概念"><a href="#机器学习基本概念" class="headerlink" title="机器学习基本概念"></a>机器学习基本概念</h2><p><strong>1  机器学习</strong></p>
<p><strong>1.1 机器学习的定义</strong></p>
<p>正如我们根据过去的经验来判断明天的天气，吃货们希望从购买经验中挑选一个好瓜，那能不能让计算机帮助人类来实现这个呢？机器学习正是这样的一门学科，人的“经验”对应计算机中的“数据”，让计算机来学习这些经验数据，生成一个算法模型，在面对新的情况中，计算机便能作出有效的判断，这便是机器学习。</p>
<p>另一本经典教材的作者Mitchell给出了一个形式化的定义，假设：</p>
<ul>
<li>P：计算机程序在某任务类T上的性能。</li>
<li>T：计算机程序希望实现的任务类。</li>
<li>E：表示经验，即历史的数据集。</li>
</ul>
<p>若该计算机程序通过利用经验E在任务T上获得了性能P的改善，则称该程序对E进行了学习。</p>
<p><strong>1.2 机器学习的一些基本术语</strong><br><img src="../img/ml_concepts.png" alt><br>假设我们收集了一批西瓜的数据，例如：（色泽=青绿;根蒂=蜷缩;敲声=浊响)， (色泽=乌黑;根蒂=稍蜷;敲声=沉闷)， (色泽=浅自;根蒂=硬挺;敲声=清脆)……每对括号内是一个西瓜的记录，定义：     </p>
<ul>
<li><p>所有记录的集合为：数据集。</p>
</li>
<li><p>每一条记录为：一个实例（instance）或样本（sample）。</p>
</li>
<li><p>例如：色泽或敲声，单个的特点为特征（feature）或属性（attribute）。</p>
</li>
<li><p>对于一条记录，如果在坐标轴上表示，每个西瓜都可以用坐标轴中的一个点表示，一个点也是一个向量，例如（青绿，蜷缩，浊响），即每个西瓜为：一个特征向量（feature vector）。</p>
</li>
<li><p>一个样本的特征数为：维数（dimensionality），该西瓜的例子维数为3，当维数非常大时，也就是现在说的“维数灾难”。</p>
<p> 计算机程序学习经验数据生成算法模型的过程中，每一条记录称为一个“训练样本”，同时在训练好模型后，我们希望使用新的样本来测试模型的效果，则每一个新的样本称为一个“测试样本”。定义：    </p>
</li>
<li><p>所有训练样本的集合为：训练集（trainning set），[特殊]。</p>
</li>
<li><p>所有测试样本的集合为：测试集（test set），[一般]。  </p>
</li>
<li><p>机器学习出来的模型适用于新样本的能力为：泛化能力（generalization），即从特殊到一般。</p>
<p> 西瓜的例子中，我们是想计算机通过学习西瓜的特征数据，训练出一个决策模型，来判断一个新的西瓜是否是好瓜。可以得知我们预测的是：西瓜是好是坏，即好瓜与差瓜两种，是离散值。同样地，也有通过历年的人口数据，来预测未来的人口数量，人口数量则是连续值。定义：    </p>
</li>
<li><p>预测值为离散值的问题为：分类（classification）。</p>
</li>
<li><p>预测值为连续值的问题为：回归（regression）。</p>
<p> 我们预测西瓜是否是好瓜的过程中，很明显对于训练集中的西瓜，我们事先已经知道了该瓜是否是好瓜，学习器通过学习这些好瓜或差瓜的特征，从而总结出规律，即训练集中的西瓜我们都做了标记，称为标记信息。但也有没有标记信息的情形，例如：我们想将一堆西瓜根据特征分成两个小堆，使得某一堆的西瓜尽可能相似，即都是好瓜或差瓜，对于这种问题，我们事先并不知道西瓜的好坏，样本没有标记信息。定义：    </p>
</li>
<li><p>训练数据有标记信息的学习任务为：监督学习（supervised learning），容易知道上面所描述的分类和回归都是监督学习的范畴。</p>
</li>
<li><p>训练数据没有标记信息的学习任务为：无监督学习（unsupervised learning），常见的有聚类和关联规则。</p>
</li>
</ul>
<p><strong>2  模型的评估与选择</strong></p>
<p><strong>2.1 误差与过拟合</strong></p>
<p>我们将学习器对样本的实际预测结果与样本的真实值之间的差异成为：误差（error）。定义：    </p>
<ul>
<li>在训练集上的误差称为训练误差（training error）或经验误差（empirical error）。</li>
<li>在测试集上的误差称为测试误差（test error）。</li>
<li>学习器在所有新样本上的误差称为泛化误差（generalization error）。</li>
</ul>
<p>显然，我们希望得到的是在新样本上表现得很好的学习器，即泛化误差小的学习器。因此，我们应该让学习器尽可能地从训练集中学出普适性的“一般特征”，这样在遇到新样本时才能做出正确的判别。然而，当学习器把训练集学得“太好”的时候，即把一些训练样本的自身特点当做了普遍特征；同时也有学习能力不足的情况，即训练集的基本特征都没有学习出来。我们定义：</p>
<ul>
<li>学习能力过强，以至于把训练样本所包含的不太一般的特性都学到了，称为：过拟合（overfitting）。</li>
<li>学习能太差，训练样本的一般性质尚未学好，称为：欠拟合（underfitting）。</li>
</ul>
<p>可以得知：在过拟合问题中，训练误差十分小，但测试误差教大；在欠拟合问题中，训练误差和测试误差都比较大。目前，欠拟合问题比较容易克服，例如增加迭代次数等，但过拟合问题还没有十分好的解决方案，过拟合是机器学习面临的关键障碍。</p>
<p><img src="https://i.loli.net/2018/10/17/5bc7181172996.png" alt></p>
<p><strong>2.2 评估方法</strong></p>
<p>在现实任务中，我们往往有多种算法可供选择，那么我们应该选择哪一个算法才是最适合的呢？如上所述，我们希望得到的是泛化误差小的学习器，理想的解决方案是对模型的泛化误差进行评估，然后选择泛化误差最小的那个学习器。但是，泛化误差指的是模型在所有新样本上的适用能力，我们无法直接获得泛化误差。</p>
<p>因此，通常我们采用一个“测试集”来测试学习器对新样本的判别能力，然后以“测试集”上的“测试误差”作为“泛化误差”的近似。显然：我们选取的测试集应尽可能与训练集互斥，下面用一个小故事来解释why：</p>
<p>假设老师出了10 道习题供同学们练习，考试时老师又用同样的这10道题作为试题，可能有的童鞋只会做这10 道题却能得高分，很明显：这个考试成绩并不能有效地反映出真实水平。回到我们的问题上来，我们希望得到泛化性能好的模型，好比希望同学们课程学得好并获得了对所学知识”举一反三”的能力；训练样本相当于给同学们练习的习题，测试过程则相当于考试。显然，若测试样本被用作训练了，则得到的将是过于”乐观”的估计结果。</p>
<p><strong>2.3 训练集与测试集的划分方法</strong></p>
<p>如上所述：我们希望用一个“测试集”的“测试误差”来作为“泛化误差”的近似，因此我们需要对初始数据集进行有效划分，划分出互斥的“训练集”和“测试集”。下面介绍几种常用的划分方法：</p>
<p><strong>2.3.1 留出法</strong></p>
<p>将数据集D划分为两个互斥的集合，一个作为训练集S，一个作为测试集T，满足D=S∪T且S∩T=∅，常见的划分为：大约2/3-4/5的样本用作训练，剩下的用作测试。需要注意的是：训练/测试集的划分要尽可能保持数据分布的一致性，以避免由于分布的差异引入额外的偏差，常见的做法是采取分层抽样。同时，由于划分的随机性，单次的留出法结果往往不够稳定，一般要采用若干次随机划分，重复实验取平均值的做法。</p>
<p><strong>2.3.2 交叉验证法</strong></p>
<p>将数据集D划分为k个大小相同的互斥子集，满足D=D1∪D2∪…∪Dk，Di∩Dj=∅（i≠j），同样地尽可能保持数据分布的一致性，即采用分层抽样的方法获得这些子集。交叉验证法的思想是：每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集，这样就有K种训练集/测试集划分的情况，从而可进行k次训练和测试，最终返回k次测试结果的均值。交叉验证法也称“k折交叉验证”，k最常用的取值是10，下图给出了10折交叉验证的示意图。</p>
<p><img src="https://i.loli.net/2018/10/17/5bc718115d224.png" alt></p>
<p>与留出法类似，将数据集D划分为K个子集的过程具有随机性，因此K折交叉验证通常也要重复p次，称为p次k折交叉验证，常见的是10次10折交叉验证，即进行了100次训练/测试。特殊地当划分的k个子集的每个子集中只有一个样本时，称为“留一法”，显然，留一法的评估结果比较准确，但对计算机的消耗也是巨大的。</p>
<p><strong>2.3.3 自助法</strong></p>
<p>我们希望评估的是用整个D训练出的模型。但在留出法和交叉验证法中，由于保留了一部分样本用于测试，因此实际评估的模型所使用的训练集比D小，这必然会引入一些因训练样本规模不同而导致的估计偏差。留一法受训练样本规模变化的影响较小，但计算复杂度又太高了。“自助法”正是解决了这样的问题。</p>
<p>自助法的基本思想是：给定包含m个样本的数据集D，每次随机从D 中挑选一个样本，将其拷贝放入D’，然后再将该样本放回初始数据集D 中，使得该样本在下次采样时仍有可能被采到。重复执行m 次，就可以得到了包含m个样本的数据集D’。可以得知在m次采样中，样本始终不被采到的概率取极限为：</p>
<p><img src="https://i.loli.net/2018/10/17/5bc71811246dd.png" alt></p>
<p>这样，通过自助采样，初始样本集D中大约有36.8%的样本没有出现在D’中，于是可以将D’作为训练集，D-D’作为测试集。自助法在数据集较小，难以有效划分训练集/测试集时很有用，但由于自助法产生的数据集（随机抽样）改变了初始数据集的分布，因此引入了估计偏差。在初始数据集足够时，留出法和交叉验证法更加常用。</p>
<p><strong>2.4 调参</strong></p>
<p>大多数学习算法都有些参数(parameter) 需要设定，参数配置不同，学得模型的性能往往有显著差别，这就是通常所说的”参数调节”或简称”调参” (parameter tuning)。</p>
<p>学习算法的很多参数是在实数范围内取值，因此，对每种参数取值都训练出模型来是不可行的。常用的做法是：对每个参数选定一个范围和步长λ，这样使得学习的过程变得可行。例如：假定算法有3 个参数，每个参数仅考虑5 个候选值，这样对每一组训练/测试集就有5<em>5</em>5= 125 个模型需考察，由此可见：拿下一个参数（即经验值）对于算法人员来说是有多么的happy。</p>
<p>最后需要注意的是：当选定好模型和调参完成后，我们需要使用初始的数据集D重新训练模型，即让最初划分出来用于评估的测试集也被模型学习，增强模型的学习效果。用上面考试的例子来比喻：就像高中时大家每次考试完，要将考卷的题目消化掉（大多数题目都还是之前没有见过的吧？），这样即使考差了也能开心的玩耍了~。</p>
<p><strong>3  机器学习评估与度量指标</strong></p>
<p>这里的内容主要包括：性能度量、比较检验和偏差与方差。在上一个notebook中，我们解决了评估学习器泛化性能的方法，即用测试集的“测试误差”作为“泛化误差”的近似，当我们划分好训练/测试集后，那如何计算“测试误差”呢？这就是性能度量，例如：均方差，错误率等，即“测试误差”的一个评价标准。有了评估方法和性能度量，就可以计算出学习器的“测试误差”，但由于“测试误差”受到很多因素的影响，例如：算法随机性或测试集本身的选择，那如何对两个或多个学习器的性能度量结果做比较呢？这就是比较检验。最后偏差与方差是解释学习器泛化性能的一种重要工具。</p>
<p><strong>3.1 性能度量</strong></p>
<p>性能度量（performance measure）是衡量模型泛化能力的评价标准，在对比不同模型的能力时，使用不同的性能度量往往会导致不同的评判结果。本节除2.5.1外，其它主要介绍分类模型的性能度量。</p>
<p><strong>3.1.1 最常见的性能度量</strong></p>
<p>在回归任务中，即预测连续值的问题，最常用的性能度量是“均方误差”（mean squared error）,很多的经典算法都是采用了MSE作为评价函数，想必大家都十分熟悉。</p>
<p><img src="https://i.loli.net/2018/10/17/5bc71daf76276.png" alt="1.png"></p>
<p>在分类任务中，即预测离散值的问题，最常用的是错误率和精度，错误率是分类错误的样本数占样本总数的比例，精度则是分类正确的样本数占样本总数的比例，易知：错误率+精度=1。</p>
<p><img src="https://i.loli.net/2018/10/17/5bc71daf4c704.png" alt="2.png"></p>
<p><img src="https://i.loli.net/2018/10/17/5bc71daf6fb84.png" alt="3.png"></p>
<p><strong>3.1.2 查准率/查全率/F1</strong></p>
<p>错误率和精度虽然常用，但不能满足所有的需求，例如：在推荐系统中，我们只关心推送给用户的内容用户是否感兴趣（即查准率），或者说所有用户感兴趣的内容我们推送出来了多少（即查全率）。因此，使用查准/查全率更适合描述这类问题。对于二分类问题，分类结果混淆矩阵与查准/查全率定义如下：</p>
<p><img src="https://i.loli.net/2018/10/17/5bc71daf885a4.png" alt="4.png"></p>
<p>初次接触时，FN与FP很难正确的理解，按照惯性思维容易把FN理解成：False-&gt;Negtive，即将错的预测为错的，这样FN和TN就反了，后来找到一张图，描述得很详细，为方便理解，把这张图也贴在了下边：</p>
<p><img src="https://i.loli.net/2018/10/17/5bc71daf871a6.png" alt="5.png"></p>
<p>正如天下没有免费的午餐，查准率和查全率是一对矛盾的度量。例如我们想让推送的内容尽可能用户全都感兴趣，那只能推送我们把握高的内容，这样就漏掉了一些用户感兴趣的内容，查全率就低了；如果想让用户感兴趣的内容都被推送，那只有将所有内容都推送上，宁可错杀一千，不可放过一个，这样查准率就很低了。</p>
<p>“P-R曲线”正是描述查准/查全率变化的曲线，P-R曲线定义如下：根据学习器的预测结果（一般为一个实值或概率）对测试样本进行排序，将最可能是“正例”的样本排在前面，最不可能是“正例”的排在后面，按此顺序逐个把样本作为“正例”进行预测，每次计算出当前的P值和R值，如下图所示：</p>
<p><img src="https://i.loli.net/2018/10/17/5bc71dafc4411.png" alt="6.png"></p>
<p>P-R曲线如何评估呢？若一个学习器A的P-R曲线被另一个学习器B的P-R曲线完全包住，则称：B的性能优于A。若A和B的曲线发生了交叉，则谁的曲线下的面积大，谁的性能更优。但一般来说，曲线下的面积是很难进行估算的，所以衍生出了“平衡点”（Break-Event Point，简称BEP），即当P=R时的取值，平衡点的取值越高，性能更优。</p>
<p>P和R指标有时会出现矛盾的情况，这样就需要综合考虑他们，最常见的方法就是F-Measure，又称F-Score。F-Measure是P和R的加权调和平均，即：</p>
<p><img src="https://i.loli.net/2018/10/17/5bc71daf40ff6.png" alt="7.png"></p>
<p><img src="https://i.loli.net/2018/10/17/5bc71daf75407.png" alt="8.png"></p>
<p>特别地，当β=1时，也就是常见的F1度量，是P和R的调和平均，当F1较高时，模型的性能越好。</p>
<p><img src="https://i.loli.net/2018/10/17/5bc71daf20885.png" alt="9.png"></p>
<p><img src="https://i.loli.net/2018/10/17/5bc71daf4b90a.png" alt="10.png"></p>
<p>有时候我们会有多个二分类混淆矩阵，例如：多次训练或者在多个数据集上训练，那么估算全局性能的方法有两种，分为宏观和微观。简单理解，宏观就是先算出每个混淆矩阵的P值和R值，然后取得平均P值macro-P和平均R值macro-R，在算出Fβ或F1，而微观则是计算出混淆矩阵的平均TP、FP、TN、FN，接着进行计算P、R，进而求出Fβ或F1。</p>
<p><img src="https://i.loli.net/2018/10/17/5bc71ed70230e.png" alt="11.png"></p>
<p><strong>3.1.3 ROC与AUC</strong></p>
<p>如上所述：学习器对测试样本的评估结果一般为一个实值或概率，设定一个阈值，大于阈值为正例，小于阈值为负例，因此这个实值的好坏直接决定了学习器的泛化性能，若将这些实值排序，则排序的好坏决定了学习器的性能高低。ROC曲线正是从这个角度出发来研究学习器的泛化性能，ROC曲线与P-R曲线十分类似，都是按照排序的顺序逐一按照正例预测，不同的是ROC曲线以“真正例率”（True Positive Rate，简称TPR）为横轴，纵轴为“假正例率”（False Positive Rate，简称FPR），ROC偏重研究基于测试样本评估值的排序好坏。</p>
<p><img src="https://i.loli.net/2018/10/17/5bc71ed6bee91.png" alt="12.png"></p>
<p><img src="https://i.loli.net/2018/10/17/5bc71ed75cefe.png" alt="13.png"></p>
<p>简单分析图像，可以得知：当FN=0时，TN也必须0，反之也成立，我们可以画一个队列，试着使用不同的截断点（即阈值）去分割队列，来分析曲线的形状，（0,0）表示将所有的样本预测为负例，（1,1）则表示将所有的样本预测为正例，（0,1）表示正例全部出现在负例之前的理想情况，（1,0）则表示负例全部出现在正例之前的最差情况。限于篇幅，这里不再论述。</p>
<p>现实中的任务通常都是有限个测试样本，因此只能绘制出近似ROC曲线。绘制方法：首先根据测试样本的评估值对测试样本排序，接着按照以下规则进行绘制。</p>
<p><img src="https://i.loli.net/2018/10/17/5bc71ed740a24.png" alt="14.png"></p>
<p>同样地，进行模型的性能比较时，若一个学习器A的ROC曲线被另一个学习器B的ROC曲线完全包住，则称B的性能优于A。若A和B的曲线发生了交叉，则谁的曲线下的面积大，谁的性能更优。ROC曲线下的面积定义为AUC（Area Uder ROC Curve），不同于P-R的是，这里的AUC是可估算的，即AOC曲线下每一个小矩形的面积之和。易知：AUC越大，证明排序的质量越好，AUC为1时，证明所有正例排在了负例的前面，AUC为0时，所有的负例排在了正例的前面。</p>
<p><img src="https://i.loli.net/2018/10/17/5bc71ed6e2c57.png" alt="15.png"></p>
<p><strong>3.1.4 代价敏感错误率与代价曲线</strong></p>
<p>上面的方法中，将学习器的犯错同等对待，但在现实生活中，将正例预测成假例与将假例预测成正例的代价常常是不一样的，例如：将无疾病–&gt;有疾病只是增多了检查，但有疾病–&gt;无疾病却是增加了生命危险。以二分类为例，由此引入了“代价矩阵”（cost matrix）。</p>
<p><img src="https://i.loli.net/2018/10/17/5bc71ed6ed582.png" alt="16.png"></p>
<p>在非均等错误代价下，我们希望的是最小化“总体代价”，这样“代价敏感”的错误率（2.5.1节介绍）为：</p>
<p><img src="https://i.loli.net/2018/10/17/5bc71ed70bebe.png" alt="17.png"></p>
<p>同样对于ROC曲线，在非均等错误代价下，演变成了“代价曲线”，代价曲线横轴是取值在[0,1]之间的正例概率代价，式中p表示正例的概率，纵轴是取值为[0,1]的归一化代价。</p>
<p><img src="https://i.loli.net/2018/10/17/5bc71ed6e952e.png" alt="18.png"></p>
<p><img src="https://i.loli.net/2018/10/17/5bc71ed6eee7b.png" alt="19.png"></p>
<p>代价曲线的绘制很简单：设ROC曲线上一点的坐标为(TPR，FPR) ，则可相应计算出FNR，然后在代价平面上绘制一条从(0，FPR) 到(1，FNR) 的线段，线段下的面积即表示了该条件下的期望总体代价；如此将ROC 曲线土的每个点转化为代价平面上的一条线段，然后取所有线段的下界，围成的面积即为在所有条件下学习器的期望总体代价，如图所示：</p>
<p><img src="https://i.loli.net/2018/10/17/5bc71ed716e0d.png" alt="20.png"></p>
<p><strong>4  机器学习指标ROC与AUC</strong></p>
<p>AUC是一种模型分类指标，且仅仅是二分类模型的评价指标。AUC是Area Under Curve的简称，那么Curve就是ROC（Receiver Operating Characteristic），翻译为”接受者操作特性曲线”。</p>
<h3 id="ROC"><a href="#ROC" class="headerlink" title="ROC"></a>ROC</h3><p>曲线由两个变量TPR和FPR组成，这个组合以FPR对TPR，即是以代价(costs)对收益(benefits)。</p>
<ul>
<li><p>x轴为假阳性率（FPR）：在所有的负样本中，分类器预测错误的比例</p>
<p>$$FPR = \frac {FP}{FP+TN}$$</p>
</li>
<li><p>y轴为真阳性率（TPR）：在所有的正样本中，分类器预测正确的比例（等于Recall）</p>
<p>$$TPR = \frac {TP}{TP+FN}$$</p>
</li>
</ul>
<p>为了更好地理解ROC曲线，我们使用具体的实例来说明：</p>
<p>如在医学诊断中,判断有病的样本。那么尽量把有病的揪出来是主要任务，也就是第一个指标TPR，要越高越好。而把没病的样本误诊为有病的，也就是第二个指标FPR，要越低越好。</p>
<p>不难发现,这两个指标之间是相互制约的。如果某个医生对于有病的症状比较敏感，稍微的小症状都判断为有病,那么他的第一个指标应该会很高，但是第二个指标也就相应地变高。最极端的情况下,他把所有的样本都看做有病,那么第一个指标达到1,第二个指标也为1。</p>
<p>我们以FPR为横轴,TPR为纵轴,得到如下ROC空间。</p>
<img src="/blog_picture/1.7.png" width="60%">

<p>我们可以看出，左上角的点(TPR=1，FPR=0)，为完美分类，也就是这个医生医术高明，诊断全对。点A(TPR&gt;FPR),医生A的判断大体是正确的。中线上的点B(TPR=FPR),也就是医生B全都是蒙的，蒙对一半，蒙错一半；下半平面的点C(TPR&lt;FPR)，这个医生说你有病，那么你很可能没有病，医生C的话我们要反着听，为真庸医。上图中一个阈值，得到一个点。现在我们需要一个独立于阈值的评价指标来衡量这个医生的医术如何，也就是遍历所有的阈值,得到ROC曲线。</p>
<p>假设如下就是某个医生的诊断统计图，直线代表阈值。通过改变不同的阈值$1.0 \rightarrow 0$，从而绘制出ROC曲线。下图为未得病人群（蓝色）和得病人群（红色）的模型输出概率分布图（横坐标表示模型输出概率，纵坐标表示概率对应的人群的数量）。阈值为1时，不管你什么症状，医生均未诊断出疾病（预测值都为N），此时FPR=TPR=0，位于左下。阈值为0时，不管你什么症状，医生都诊断结果都是得病（预测值都为P），此时FPR=TPR=1，位于右上。</p>
<img src="/blog_picture/1.8.png" width="50%">


<p>曲线距离左上角越近,证明分类器效果越好。</p>
<img src="/blog_picture/1.9.png" width="60%">

<p>如上，是三条ROC曲线，在0.23处取一条直线。那么，在同样的低FPR=0.23的情况下，红色分类器得到更高的PTR。也就表明，ROC越往左上，分类器效果越好。我们用一个标量值AUC来量化它。</p>
<h3 id="AUC"><a href="#AUC" class="headerlink" title="AUC"></a>AUC</h3><p><strong>AUC定义：</strong></p>
<p>AUC值为ROC曲线所覆盖的区域面积，显然，AUC越大，分类器分类效果越好。</p>
<p>AUC = 1，是完美分类器。绝大多数预测的场合，不存在完美分类器。</p>
<p>0.5 &lt; AUC &lt; 1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。</p>
<p>AUC = 0.5，跟随机猜测一样（例：丢铜板），模型没有预测价值。</p>
<p>AUC &lt; 0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测。</p>
<p>注：对于AUC小于0.5的模型，我们可以考虑取反（模型预测为positive，那我们就取negtive），这样就可以保证模型的性能不可能比随机猜测差。</p>
<p>以下为ROC曲线和AUC值的实例：</p>
<img src="/blog_picture/1.12.png" width="70%">

<p><strong>AUC的物理意义</strong></p>
<p>AUC的物理意义正样本的预测结果大于负样本的预测结果的概率。所以AUC反应的是分类器对样本的排序能力。  </p>
<p>另外值得注意的是，AUC对样本类别是否均衡并不敏感，这也是不均衡样本通常用AUC评价分类器性能的一个原因。</p>
<p>下面从一个小例子解释AUC的含义：小明一家四口，小明5岁，姐姐10岁，爸爸35岁，妈妈33岁建立一个逻辑回归分类器，来预测小明家人为成年人概率，假设分类器已经对小明的家人做过预测，得到每个人为成人的概率。</p>
<ol>
<li>AUC更多的是关注对计算概率的排序，关注的是概率值的相对大小，与阈值和概率值的绝对大小没有关系</li>
</ol>
<p>例子中并不关注小明是不是成人，而关注的是，预测为成人的概率的排序。</p>
<p><strong>问题⑪：</strong>以下为三种模型的输出结果，求三种模型的AUC。</p>
<table>
<thead>
<tr>
<th></th>
<th>小明</th>
<th>姐姐</th>
<th>妈妈</th>
<th>爸爸</th>
</tr>
</thead>
<tbody><tr>
<td>a</td>
<td>0.12</td>
<td>0.35</td>
<td>0.76</td>
<td>0.85</td>
</tr>
<tr>
<td>b</td>
<td>0.12</td>
<td>0.35</td>
<td>0.44</td>
<td>0.49</td>
</tr>
<tr>
<td>c</td>
<td>0.52</td>
<td>0.65</td>
<td>0.76</td>
<td>0.85</td>
</tr>
</tbody></table>
<p>AUC只与概率的相对大小（概率排序）有关，和绝对大小没关系。由于三个模型概率排序的前两位都是未成年人（小明，姐姐），后两位都是成年人（妈妈，爸爸），因此三个模型的AUC都等于。</p>
<ol>
<li><p>AUC只关注正负样本之间的排序，并不关心正样本内部，或者负样本内部的排序。这也体现了AUC的本质：任意个正样本的概率都大于负样本的概率的能力  </p>
<p>例子中AUC只需要保证（小明和姐姐）（爸爸和妈妈），小明和姐姐在前2个排序，爸爸和妈妈在后2个排序，而不会考虑小明和姐姐谁在前，或者爸爸和妈妈谁在前。</p>
<p><strong>问题⑫：</strong>以下已经对分类器输出概率从小到大进行了排列，哪些情况的AUC等于1， 情况的AUC为0（其中背景色表示True value，红色表示成年人，蓝色表示未成年人）。</p>
<img src="/blog_picture/1.10.png" width="70%">

<p>D 模型, E模型和F模型的AUC值为1，C模型的AUC值为0（爸妈为成年人的概率小于小明和姐姐，显然这个模型预测反了）。</p>
</li>
</ol>
<p><strong>AUC的计算：</strong></p>
<ul>
<li><p>法1：AUC为ROC曲线下的面积，那我们直接计算面积可得。面积为一个个小的梯形面积（曲线）之和。计算的精度与阈值的精度有关。</p>
</li>
<li><p>法2：根据AUC的物理意义，我们计算正样本预测结果大于负样本预测结果的概率。取n1*n0(n1为正样本数，n0为负样本数)个二元组，比较score（预测结果），最后得到AUC。时间复杂度为O(N*M)。</p>
</li>
<li><p>法3：我们首先把所有样本按照score排序，依次用rank表示他们，如最大score的样本，rank=n (n=n0+n1，其中n0为负样本个数，n1为正样本个数)，其次为n-1。那么对于正样本中rank最大的样本，rank_max，有n1-1个其他正样本比他score小,那么就有(rank_max-1)-(n1-1)个负样本比他score小。其次为(rank_second-1)-(n1-2)。最后我们得到正样本大于负样本的概率为</p>
<p><img src="/blog_picture/auc.jpg" alt="avatar"></p>
</li>
</ul>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AUC/">AUC</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ROC/">ROC</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-简洁版机器学习速查表" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/08/23/简洁版机器学习速查表/" class="article-date">
      <time datetime="2019-08-23T08:47:20.000Z" itemprop="datePublished">2019-08-23</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/08/23/简洁版机器学习速查表/">简洁版机器学习速查表</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p><img src="/blog_picture/ml_1.jpg" alt="avatar"><br><img src="/blog_picture/ml_2.jpg" alt="avatar"><br><img src="/blog_picture/ml_3.jpg" alt="avatar"><br><img src="/blog_picture/ml_4.jpg" alt="avatar"><br><img src="/blog_picture/ml_5.jpg" alt="avatar"></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-CS229版机器学习速查表" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/08/23/CS229版机器学习速查表/" class="article-date">
      <time datetime="2019-08-23T08:41:33.000Z" itemprop="datePublished">2019-08-23</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/08/23/CS229版机器学习速查表/">CS229版机器学习速查表</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p><img src="/blog_picture/0001.jpg" alt="avatar"><br><img src="/blog_picture/0002.jpg" alt="avatar"><br><img src="/blog_picture/0003.jpg" alt="avatar"><br><img src="/blog_picture/0004.jpg" alt="avatar"><br><img src="/blog_picture/0005.jpg" alt="avatar"><br><img src="/blog_picture/0006.jpg" alt="avatar"><br><img src="/blog_picture/0007.jpg" alt="avatar"><br><img src="/blog_picture/0008.jpg" alt="avatar"><br><img src="/blog_picture/0009.jpg" alt="avatar"><br><img src="/blog_picture/0010.jpg" alt="avatar"><br><img src="/blog_picture/0011.jpg" alt="avatar"><br><img src="/blog_picture/0012.jpg" alt="avatar"><br><img src="/blog_picture/0013.jpg" alt="avatar"><br><img src="/blog_picture/0014.jpg" alt="avatar"><br><img src="/blog_picture/0015.jpg" alt="avatar"><br><img src="/blog_picture/0016.jpg" alt="avatar"></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-葫芦书学习笔记" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/08/08/葫芦书学习笔记/" class="article-date">
      <time datetime="2019-08-08T09:13:57.000Z" itemprop="datePublished">2019-08-08</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/08/08/葫芦书学习笔记/">葫芦书学习笔记</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="1-为什么需要对数值类型的特征做归一化处理？"><a href="#1-为什么需要对数值类型的特征做归一化处理？" class="headerlink" title="1.为什么需要对数值类型的特征做归一化处理？"></a>1.为什么需要对数值类型的特征做归一化处理？</h1><ul>
<li>为了方便后续进行梯度下降的时候加速收敛</li>
<li>归一化通常主要分为两种：min-max(线性函数归一化)，Z-Score(零均值归一化)</li>
<li>需要进行归一化的模型：线性回归，LR，SVM，神经网络等</li>
<li>决策树模型不适用归一化处理，因为决策树在进行节点分裂时主要依据数据集D关于特征x的信息增益比，而信息增益比和特征是否进行归一化无关，因为归一化并不改变样本在特征x上的信息增益。</li>
</ul>
<h1 id="2-􏳉􏴔􏳓在数据进行预处理时，应该怎样处理类别型特征？"><a href="#2-􏳉􏴔􏳓在数据进行预处理时，应该怎样处理类别型特征？" class="headerlink" title="2.􏳉􏴔􏳓在数据进行预处理时，应该怎样处理类别型特征？"></a>2.􏳉􏴔􏳓在数据进行预处理时，应该怎样处理类别型特征？</h1><ul>
<li>类别型特征原始输入形式通常是字符串形式、除了决策树等少量模型能直接处理字符串形式的输入，对于LR、SVM等模型来说，类别型特征必须经过处理转换成数值型特征才能正确工作</li>
<li>序号编码(ordinal)：类别间具有大小关系</li>
<li>独热编码(one-hot)：类别间没有大小关系，特征的每个值作为一列。维度过高可能导致维度灾难，产生过拟合问题。</li>
<li>二进制编码：先用序号编码给每个类别赋予一个类别ID，然后将ID转为二进制编码作为结果。</li>
</ul>
<h1 id="3-什么是组合特征？如何处理高维组合特征-解决高维组合特征维度过高的问题-？"><a href="#3-什么是组合特征？如何处理高维组合特征-解决高维组合特征维度过高的问题-？" class="headerlink" title="3.什么是组合特征？如何处理高维组合特征(解决高维组合特征维度过高的问题)？"></a>3.什么是组合特征？如何处理高维组合特征(解决高维组合特征维度过高的问题)？</h1><ul>
<li>可以将M * N矩阵分解为M * K和K * N两个矩阵相乘的形式，这样参数从M * N降到 K * (M+N)</li>
<li>为了提高复杂关系的拟合能力，在特征工程中经常会把一阶离散特征两两组合，构成高阶组合特征。</li>
</ul>
<p>#4.怎样有效的找到组合特征？</p>
<ul>
<li>基于决策树的特征组合寻找。（原始输入构建决策树可以采用梯度提升决策树即每次都在之前构建的决策树的残差上构建下一课决策树）</li>
</ul>
<h1 id="5-有哪些文本模型？他们各有什么优缺点？"><a href="#5-有哪些文本模型？他们各有什么优缺点？" class="headerlink" title="5.有哪些文本模型？他们各有什么优缺点？"></a>5.有哪些文本模型？他们各有什么优缺点？</h1><ul>
<li>词袋模型(bag of words)：最基础的文本表示模型是词袋模型。顾名思义，就是将每篇文章看成一袋子词，并忽略每个词出现的顺序。将整段文本以词为单位切分开，然后每篇文章可以表示成一个长向量，向量中的每一维代表一个单词，而该维对应得权重则则反映了这个词在原文章的重要程度。但是词袋忽略了由几个词组成一个意思这种情况（“如NBA吐槽大会”这种，分解成了NBA和吐槽大会，结果匹配了很多李诞这样和NBA完全不相关的物料）</li>
<li>N-gram模型：词袋模型的改进，N-gram将连续出现的N个词组成的词组也作为一维放到向量表示中去。但是N-gram不能识别两个不同的词有相同的主题</li>
<li>TF-TDF：TF-IDF(t,d) = TF(t,d)*IDF(t)其中，TF(t,d)为单词t在文档d中出现的频率，IDF(t) = log(文章总数/(包含单词t的文章总数+1)) ，IDF公式可理解为如果一个词出现的文章数越多那么说明它越是一个通用词，通用词对文档内容贡献度比较小</li>
<li>主题模型：主题模型用于从文本库发现有代表性的主题（得到每个主题上面词的分布特性），并且能够计算出每篇文章的主题分布。</li>
<li>词嵌入与深度学习模型：词嵌入是一类将词向量化的模型的统称，核心思想是将每个词都映射成低维空间（通常50-300维)上的一个稠密向量。K维空间中的每一维都可以看作是一个隐含的主题，只不过不像主题模型中的主题那么直观。由于词嵌入将每个词映射成一个K维的向量，如果一篇文章有N个词，就可以用一个N*K维的矩阵来表示这篇文档，但是这样表示过去底层。在实际应用中，如果仅仅把这个矩阵作为源文本的表示特征输入到机器学习模型中，通常很难得到满意的结果。因此，还需要在此基础上加工出更高层的特征。在传统的浅层机器学习模型中，一个好的特征工程往往可以带来算法效果的显著提示。深度学习模型正好为我们提供了一种自动 的进行特征工程的方式，模型中的每个隐层都可以认为对应着不同抽象层次的特征。卷积神经网络和循环神经网络的结构在文本表示中取得很好的效果，主要是由于他们能够更好的对文本进行建模，抽取出更高层的语义特征。。与全链接网络结构相比，卷积神经网络和RNN一方面很好的抓住了文本的特征，另一方面又减少了网络学习中待学习的参数，提高了训练速度，并且降低了过拟合的风险。</li>
</ul>
<h1 id="6-Word2Vec是如何工作的？它和LDA有什么区别与联系？"><a href="#6-Word2Vec是如何工作的？它和LDA有什么区别与联系？" class="headerlink" title="6.Word2Vec是如何工作的？它和LDA有什么区别与联系？"></a>6.Word2Vec是如何工作的？它和LDA有什么区别与联系？</h1><ul>
<li>word2vec实际上一种浅层的神经网络模型，它有两种网络结构，分别是CBOW(continues bag of words)和Skip-gram</li>
<li>CBOW的目标是根据上下文出现的词语来预测当前词的生成概率；skip-gram是根据当前词来预测上下文中各词的生成概率。</li>
<li>word2vec是google开发的一种词向量嵌入的模型，主要分为CBOW和skip-gram两种，最后得到得词向量是dense vector。</li>
<li>LDA是一种生成模型，最后可以得到文档与主题，主题与词之间的概率分布。</li>
</ul>
<h1 id="7-在图像分类任务中，训练数据不足会带来什么问题？如何缓解数据量不足带来的问题？"><a href="#7-在图像分类任务中，训练数据不足会带来什么问题？如何缓解数据量不足带来的问题？" class="headerlink" title="7.在图像分类任务中，训练数据不足会带来什么问题？如何缓解数据量不足带来的问题？"></a>7.在图像分类任务中，训练数据不足会带来什么问题？如何缓解数据量不足带来的问题？</h1><ul>
<li>训练数据不足主要表现在过拟合方面。</li>
<li>两类处理方法：一是基于模型的方法，主要是采用降低过拟合风险的措施包括简化模型(非线性简化为线性)、添加约束项以缩小假设空间、集成学习、Dropout超参数等。二是基于数据的的方法，主要是通过数据扩充</li>
</ul>
<h1 id="8-准确率的局限性"><a href="#8-准确率的局限性" class="headerlink" title="8.准确率的局限性"></a>8.准确率的局限性</h1><ul>
<li>不同类别的样本比例非常不均匀时，占比大的类别往往成为影响准确率的最主要因素</li>
</ul>
<h1 id="9-精确率与召回率的权衡"><a href="#9-精确率与召回率的权衡" class="headerlink" title="9.精确率与召回率的权衡"></a>9.精确率与召回率的权衡</h1><ul>
<li>只用某个点对应的精确率和召回率不能全面地衡量模型的性能，只有通过P-R曲线的整体表现，才能够对模型进行更为全面的评估</li>
</ul>
<h1 id="10-平方根误差的意外"><a href="#10-平方根误差的意外" class="headerlink" title="10.平方根误差的意外"></a>10.平方根误差的意外</h1><ul>
<li>一般情况下，RMSE能够很好的反映回归模型预测值与真实值的偏离程度。但在实际问题中，如果存在个别偏离程度非常大的离群点时，即使离群点数量非常少，也会让RMSE指标变得很差。</li>
<li>解决方法：一，在数据预处理时过滤这些噪声点。二，如果不认为这些离群点是噪声的话就要进一步提高模型的预测能力，将离群点产生的机制建模进去。三，找一个更合适的指标来评估该模型。</li>
</ul>
<h1 id="11-什么是ROC曲线"><a href="#11-什么是ROC曲线" class="headerlink" title="11.什么是ROC曲线"></a>11.什么是ROC曲线</h1><ul>
<li>ROC􏵻􏵲􏰋曲线是Receiver Operating Characteristic Curve􏰊􏵱􏲒􏰢􏱟的简称，中文名为“受试者工作特征曲线”。ROC曲线的横坐标为假阳性率FPR；纵坐标为真阳性率TPR。</li>
</ul>
<p>#12.如果绘制ROC􏵻􏵲􏰋曲线</p>
<ul>
<li>ROC􏵻􏵲􏰋曲线是通过不断移动分类器的“截断点”来生成曲线上一组关键点的。</li>
<li>首先根据样本标签统计出正负样本的数量，假设正样本数量为p，负样本数量为n；接下来，把横轴的刻度间隔设置为1/n,纵轴的刻度间隔设置为1/p；再根据模型输出的预测概率对样本进行排序依次遍历样本，同时从零点开始绘制ROC􏵻􏵲􏰋曲线，每遇到一个正样本就沿纵轴方向绘制一个刻度间隔的曲线，每遇到一个负样本就沿着横轴方向绘制一个刻度间隔的曲线，直到遍历完所有样本，曲线最终停在（1，1）这个点，整个ROC曲线绘制完成。</li>
</ul>
<h1 id="13-如何计算AUC"><a href="#13-如何计算AUC" class="headerlink" title="13.如何计算AUC"></a>13.如何计算AUC</h1><ul>
<li>沿着ROC横轴做积分。</li>
</ul>
<h1 id="14-ROC曲线相比P-R曲线有什么特点"><a href="#14-ROC曲线相比P-R曲线有什么特点" class="headerlink" title="14.ROC曲线相比P-R曲线有什么特点"></a>14.ROC曲线相比P-R曲线有什么特点</h1><ul>
<li>当正负样本的分布发生变化时，ROC曲线的形状能够基本保持不变，而P-R曲线的形状一般会发生较剧烈变化。</li>
<li>ROC曲线能够尽量降低不同测试集带来的干扰，更加客观地衡量模型本身的性能。ROC曲线的适用范围更广，适用于排序、推荐、广告。选择ROC曲线还是P-R曲线因实际问题而异，如果希望更多的看到模型在特定数据集上的表现，P-R曲线能够更直观地反映其性能。</li>
</ul>
<h1 id="15-结合你的学习和研究经历，探讨为什么在一些场景中要使用余弦相似度而不是欧氏距离"><a href="#15-结合你的学习和研究经历，探讨为什么在一些场景中要使用余弦相似度而不是欧氏距离" class="headerlink" title="15.结合你的学习和研究经历，探讨为什么在一些场景中要使用余弦相似度而不是欧氏距离"></a>15.结合你的学习和研究经历，探讨为什么在一些场景中要使用余弦相似度而不是欧氏距离</h1><ul>
<li>当一对文本相似度的长度差距很大、但内容相近时，如果采用词频或词向量作为特征，它们在特征空间中的欧式距离通常很大；而余弦相似度，它们之间的夹角可能很小，因而相似度更高。此外，在文本、图像、视频等领域，研究的对象的特征维度往往很高，余弦相似度在高维情况下依然保持“ 相同为1，正交是为0，相反时为-1”的性质，而欧式距离的数值则受维度的影响，范围不固定，并且含义也比较模糊。</li>
<li>在一些场景中，例如Word2Vec中，其向量的模长是经过归一化的，此时欧式距离与余弦距离有着单调的关系。此场景下余弦相似度和欧式距离的结果是相同的</li>
<li>欧式距离体现数值上的绝对差异，余弦距离体现方向上的相对差异。分析两个不同用户对于不同视频的偏好，更关注相对差异，显然应当用余弦距离。分析用户活跃度，以登陆次数和平均观看时长作为特征，余弦距离为认为(1,10)􏱤(10,100)两个用户距离很近；但显然这两个用户活跃度是有着极大的差异的，此时更关注数值绝对差异，应当使用欧式距离。</li>
</ul>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a><a class="article-category-link" href="/categories/机器学习/面试/">面试</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/算法/">算法</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/面试/">面试</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-数学基础知识整理" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/08/06/数学基础知识整理/" class="article-date">
      <time datetime="2019-08-06T01:02:41.000Z" itemprop="datePublished">2019-08-06</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/08/06/数学基础知识整理/">数学基础知识整理</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>##线性代数</p>
<h4 id="线性相关与线性无关"><a href="#线性相关与线性无关" class="headerlink" title="线性相关与线性无关"></a>线性相关与线性无关</h4><ul>
<li><img src="/blog_picture/linear.jpg" alt="avatar"></li>
</ul>
<p>线性相关的判定：根据观察，利用定义即可判断。</p>
<p>线性相关的判断定理：</p>
<ul>
<li><p><img src="/blog_picture/2.jpg" alt="avatar"></p>
</li>
<li><p><img src="/blog_picture/3.jpg" alt="avatar"></p>
</li>
</ul>
<h4 id="矩阵的秩"><a href="#矩阵的秩" class="headerlink" title="矩阵的秩"></a>矩阵的秩</h4><p>一个向量组A的秩是A的线性无关的向量的个数</p>
<p>如果把一个向量组看成一个矩阵，则向量组的秩就是矩阵的秩</p>
<ul>
<li><p><img src="/blog_picture/4.jpg" alt="avatar"></p>
</li>
<li><p><img src="/blog_picture/5.jpg" alt="avatar"></p>
</li>
</ul>
<h4 id="向量的范数"><a href="#向量的范数" class="headerlink" title="向量的范数"></a>向量的范数</h4><ul>
<li><img src="/blog_picture/6.jpg" alt="avatar"></li>
</ul>
<p>####常用的向量范数</p>
<p>1-范数 $||x||<em>1=\sum</em>{i=1}^{n}|x|$</p>
<p>2-范数  $||x||<em>2=\sqrt{\sum</em>{i=1}^{n}{x_i}^2}$欧式范数</p>
<p>无穷范数   $||x||_n=max|x_i|$</p>
<h4 id="矩阵的范数"><a href="#矩阵的范数" class="headerlink" title="矩阵的范数"></a>矩阵的范数</h4><p><img src="/blog_picture/8.jpg" alt="avatar"></p>
<p>####常用的矩阵范数</p>
<p><img src="/blog_picture/9.jpg" alt="avatar"></p>
<p><img src="/blog_picture/10.jpg" alt="avatar"></p>
<p>范数的作用：机器学习的分类问题中，使用范数可以判断两个特征向量和矩阵的相似性</p>
<p>####矩阵的迹</p>
<p><img src="/blog_picture/11.jpg" alt="avatar"></p>
<h4 id="线性变换及其矩阵表示"><a href="#线性变换及其矩阵表示" class="headerlink" title="线性变换及其矩阵表示"></a>线性变换及其矩阵表示</h4><p><img src="/blog_picture/12.jpg" alt="avatar"></p>
<h4 id="特征值、特征向量"><a href="#特征值、特征向量" class="headerlink" title="特征值、特征向量"></a>特征值、特征向量</h4><p><img src="/blog_picture/13.jpg" alt="avatar"></p>
<p>####特征值的性质</p>
<p><img src="/blog_picture/14.jpg" alt="avatar"></p>
<p>####特征值和特征向量的求法</p>
<p><img src="/blog_picture/15.jpg" alt="avatar"></p>
<p><img src="/blog_picture/16.jpg" alt="avatar"></p>
<p>特征值和特征向量在机器学习中的应用：• 主成分分析• 流行学习• LDA</p>
<h4 id="正交投影"><a href="#正交投影" class="headerlink" title="正交投影"></a>正交投影</h4><p>在线性代数和泛函分析中，投影是从向量空间映射到自身的一种线性变换。具体来说，正交投影是指像空间U和零空间W相互正交子空间的投影</p>
<p>从解方程角度看，A x = b 可能无解，因为对任意 的 x , Ax 总是在A的列子空间里，若 向量 b 不在 列空间里，则方程无解。但是我们可以将 b 利用正 交投影矩阵投影到 A 的列子空间里得到正交投影 y， 然后求解A x = y，寻找一个最佳近似解 x。</p>
<p><img src="/blog_picture/17.jpg" alt="avatar"></p>
<h4 id="二次型"><a href="#二次型" class="headerlink" title="二次型"></a>二次型</h4><p><img src="/blog_picture/18.jpg" alt="avatar"></p>
<p><img src="/blog_picture/19.jpg" alt="avatar"></p>
<p>二次型补充知识点</p>
<p><img src="/blog_picture/20.jpg" alt="avatar"></p>
<h4 id="矩阵的QR分解"><a href="#矩阵的QR分解" class="headerlink" title="矩阵的QR分解"></a>矩阵的QR分解</h4><p><img src="/blog_picture/21.jpg" alt="avatar"></p>
<h4 id="SVD奇异值分解"><a href="#SVD奇异值分解" class="headerlink" title="SVD奇异值分解"></a>SVD奇异值分解</h4><p><img src="/blog_picture/22.jpg" alt="avatar"></p>
<p>##微积分</p>
<h4 id="集合的定义"><a href="#集合的定义" class="headerlink" title="集合的定义"></a>集合的定义</h4><p><img src="/blog_picture/23.jpg" alt="avatar"></p>
<p>####集合的表示方法</p>
<p><img src="/blog_picture/24.jpg" alt="avatar"></p>
<p>####集合的分类</p>
<p><img src="/blog_picture/25.jpg" alt="avatar"></p>
<h4 id="集合运算"><a href="#集合运算" class="headerlink" title="集合运算"></a>集合运算</h4><p><img src="/blog_picture/26.jpg" alt="avatar"></p>
<h4 id="Venn图"><a href="#Venn图" class="headerlink" title="Venn图"></a>Venn图</h4><p>表示集合的另一种形式</p>
<p><img src="/blog_picture/27.jpg" alt="avatar"></p>
<h4 id="函数定义"><a href="#函数定义" class="headerlink" title="函数定义"></a>函数定义</h4><p><img src="/blog_picture/28.jpg" alt="avatar"></p>
<h4 id="领域的定义"><a href="#领域的定义" class="headerlink" title="领域的定义"></a>领域的定义</h4><p><img src="/blog_picture/29.jpg" alt="avatar"></p>
<p>####函数的极限性质</p>
<h5 id="四则运算"><a href="#四则运算" class="headerlink" title="四则运算"></a>四则运算</h5><p><img src="/blog_picture/30.jpg" alt="avatar"></p>
<p>#####复合函数的极限</p>
<p><img src="/blog_picture/31.jpg" alt="avatar"></p>
<p>#####保号性</p>
<p><img src="/blog_picture/32.jpg" alt="avatar"></p>
<p>#####夹逼定理</p>
<p><img src="/blog_picture/33.jpg" alt="avatar"></p>
<p>#####洛必达法则</p>
<p><img src="/blog_picture/34.jpg" alt="avatar"></p>
<p>####函数的连续性</p>
<p><img src="/blog_picture/35.jpg" alt="avatar"></p>
<p>####间断的定义</p>
<p><img src="/blog_picture/36.jpg" alt="avatar"></p>
<p><img src="/blog_picture/37.jpg" alt="avatar"></p>
<h4 id="函数的导数"><a href="#函数的导数" class="headerlink" title="函数的导数"></a>函数的导数</h4><p><img src="/blog_picture/38.jpg" alt="avatar"></p>
<p>####导数的常用公式</p>
<p><img src="/blog_picture/39.jpg" alt="avatar"></p>
<h4 id="导数的性质"><a href="#导数的性质" class="headerlink" title="导数的性质"></a>导数的性质</h4><p>#####四则运算</p>
<p><img src="/blog_picture/40.jpg" alt="avatar"></p>
<p>#####复合函数求导</p>
<p><img src="/blog_picture/41.jpg" alt="avatar"></p>
<h5 id="导数作用"><a href="#导数作用" class="headerlink" title="导数作用"></a>导数作用</h5><p>链式求导法则:神经网络反向传播基础 </p>
<p>梯度下降法:最简单的优化方法</p>
<h4 id="函数的微分"><a href="#函数的微分" class="headerlink" title="函数的微分"></a>函数的微分</h4><p><img src="/blog_picture/42.jpg" alt="avatar"></p>
<h4 id="原函数"><a href="#原函数" class="headerlink" title="原函数"></a>原函数</h4><p><img src="/blog_picture/43.jpg" alt="avatar"></p>
<h4 id="不定积分"><a href="#不定积分" class="headerlink" title="不定积分"></a>不定积分</h4><p><img src="/blog_picture/44.jpg" alt="avatar"></p>
<p><img src="/blog_picture/45.jpg" alt="avatar"></p>
<p><img src="/blog_picture/46.jpg" alt="avatar"></p>
<p>####不定积分性质</p>
<p><img src="/blog_picture/47.jpg" alt="avatar"></p>
<p>####不定积分的基本公式</p>
<p><img src="/blog_picture/48.jpg" alt="avatar"></p>
<h4 id="定积分"><a href="#定积分" class="headerlink" title="定积分"></a>定积分</h4><p><img src="/blog_picture/49.jpg" alt="avatar"></p>
<p><img src="/blog_picture/50.jpg" alt="avatar"></p>
<p><img src="/blog_picture/51.jpg" alt="avatar"></p>
<p><img src="/blog_picture/52.jpg" alt="avatar"></p>
<p><img src="/blog_picture/53.jpg" alt="avatar"></p>
<p>####定积分的性质</p>
<p><img src="/blog_picture/54.jpg" alt="avatar"></p>
<p>牛顿-莱布尼兹公式</p>
<p><img src="/blog_picture/55.jpg" alt="avatar"></p>
<p><img src="/blog_picture/56.jpg" alt="avatar"></p>
<p>####二重积分</p>
<p><img src="/blog_picture/57.jpg" alt="avatar"></p>
<p><img src="/blog_picture/58.jpg" alt="avatar"></p>
<p><img src="/blog_picture/59.jpg" alt="avatar"></p>
<p><img src="/blog_picture/60.jpg" alt="avatar"></p>
<p>####导数</p>
<p><img src="/blog_picture/61.jpg" alt="avatar"></p>
<p>#####标量关于标量X的求导</p>
<p><img src="/blog_picture/62.jpg" alt="avatar"></p>
<p>#####向量关于标量X的求导</p>
<p><img src="/blog_picture/63.jpg" alt="avatar"></p>
<p>####矩阵关于标量X的求导</p>
<p><img src="/blog_picture/64.jpg" alt="avatar"></p>
<p>####标量关于向量x的导数</p>
<p><img src="/blog_picture/65.jpg" alt="avatar"></p>
<p>####向量关于向量x的导数</p>
<p><img src="/blog_picture/66.jpg" alt="avatar"></p>
<p>####矩阵关于向量 x 的导数</p>
<p><img src="/blog_picture/67.jpg" alt="avatar"></p>
<p>####标量关于矩阵的导数</p>
<p><img src="/blog_picture/68.jpg" alt="avatar"></p>
<p>####向量关于矩阵的导数</p>
<p><img src="/blog_picture/69.jpg" alt="avatar"></p>
<h4 id="矩阵关于矩阵的导数"><a href="#矩阵关于矩阵的导数" class="headerlink" title="矩阵关于矩阵的导数"></a>矩阵关于矩阵的导数</h4><p><img src="/blog_picture/70.jpg" alt="avatar"></p>
<p>####分子布局法与分母局部法区别</p>
<p><img src="/blog_picture/71.jpg" alt="avatar"></p>
<p>####Hessian矩阵</p>
<p><img src="/blog_picture/72.jpg" alt="avatar"></p>
<p><img src="/blog_picture/73.jpg" alt="avatar"></p>
<p>##概率论基础</p>
<p>####概率论基础</p>
<p>概率论与数理统计是研究什么的?</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">随机现象:不确定性与统计规律性 </span><br><span class="line">概率论:从数量上研究随机现象的统计规律性的科学</span><br><span class="line">数理统计:从应用角度研究处理随机性数据，建立有效的统计方法，进行统计推理</span><br></pre></td></tr></table></figure>

<p>随机试验</p>
<p>在概率论中，将具有下述三个特点的试验称为<strong>随机试验</strong>，简称试验。 随机试验常用E表示</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.试验的可重复性 —— 在相同条件下可重复进行;</span><br><span class="line">2.一次试验结果的随机性 —— 一次试验的可能结果不止一个，且试验之前无法确定具体是哪种结果出现; </span><br><span class="line">3.全部试验结果的可知性 —— 所有可能的结果是预先可知的，且每次试验有且仅有一个结果出现。</span><br></pre></td></tr></table></figure>

<p>####样本空间与样本点</p>
<p><img src="/blog_picture/74.jpg" alt="avatar"></p>
<p>####随机事件</p>
<p><img src="/blog_picture/75.jpg" alt="avatar"></p>
<p>####事件的性质与运算</p>
<p>事件的本质是集合，集合的一切性质和运算都适用与事件</p>
<p>####频率与概率</p>
<p><img src="/blog_picture/76.jpg" alt="avatar"></p>
<h4 id="概率的性质"><a href="#概率的性质" class="headerlink" title="概率的性质"></a>概率的性质</h4><p><img src="/blog_picture/77.jpg" alt="avatar"></p>
<h4 id="古典概型"><a href="#古典概型" class="headerlink" title="古典概型"></a>古典概型</h4><p><img src="/blog_picture/78.jpg" alt="avatar"></p>
<p><img src="/blog_picture/79.jpg" alt="avatar"></p>
<h4 id="几何概型"><a href="#几何概型" class="headerlink" title="几何概型"></a>几何概型</h4><p><img src="/blog_picture/80.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565069627088.jpg" alt="avatar"></p>
<h4 id="条件概率"><a href="#条件概率" class="headerlink" title="条件概率"></a>条件概率</h4><p><img src="/blog_picture/1565069696978.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565069726956.jpg" alt="avatar"></p>
<p>####条件概率的几何意义</p>
<p><img src="/blog_picture/1565069854934.jpg" alt="avatar"></p>
<p>####加法公式</p>
<p><img src="/blog_picture/1565069969698.jpg" alt="avatar"></p>
<p>####乘法公式</p>
<p><img src="/blog_picture/1565070039368.jpg" alt="avatar"></p>
<p>####排列组合</p>
<p><img src="/blog_picture/1565070090722.jpg" alt="avatar"></p>
<p>####全概率公式</p>
<p><img src="/blog_picture/1565070149616.jpg" alt="avatar"></p>
<p>####离散分布 vs 连续分布</p>
<p><img src="/blog_picture/1565070338442.jpg" alt="avatar"></p>
<p>####伯努利分布</p>
<p><img src="/blog_picture/1565070378085.jpg" alt="avatar"></p>
<p>####二项分布</p>
<p><img src="/blog_picture/1565070413168.jpg" alt="avatar"></p>
<p>####期望</p>
<p><img src="/blog_picture/1565070571975.jpg" alt="avatar"></p>
<h5 id="期望的性质"><a href="#期望的性质" class="headerlink" title="期望的性质"></a>期望的性质</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">1、E (C ) = C</span><br><span class="line">2、E (aX ) = a E (X )</span><br><span class="line">3、E (X + Y ) = E (X ) + E (Y )</span><br><span class="line">4、当X ,Y 相互独立时，E (X Y ) = E (X )E (Y )</span><br></pre></td></tr></table></figure>

<h5 id="期望的数学含义"><a href="#期望的数学含义" class="headerlink" title="期望的数学含义"></a>期望的数学含义</h5><p>反应了数据的平均取值情况</p>
<p>####方差</p>
<p><img src="/blog_picture/1565070731625.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565070796641.jpg" alt="avatar"></p>
<p>####数据归一化</p>
<p><img src="/blog_picture/1565070856261.jpg" alt="avatar"></p>
<p>####高斯分布</p>
<p><img src="/blog_picture/1565070907312.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565070933026.jpg" alt="avatar"></p>
<p>####分布函数</p>
<p><img src="/blog_picture/1565071005463.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565071040441.jpg" alt="avatar"></p>
<p>####均匀分布</p>
<p><img src="/blog_picture/1565071087634.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565071126393.jpg" alt="avatar"></p>
<p>####指数分布</p>
<p><img src="/blog_picture/1565071160548.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565071258034.jpg" alt="avatar"></p>
<p>####二维随机变量</p>
<p><img src="/blog_picture/1565071336855.jpg" alt="avatar"></p>
<p>####联合分布函数</p>
<p><img src="/blog_picture/1565071371964.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565071397963.jpg" alt="avatar"></p>
<p>####联合分布列</p>
<p><img src="/blog_picture/1565071449242.jpg" alt="avatar"></p>
<p>####二维连续型随机变量及其密度函数</p>
<p><img src="/blog_picture/1565071492637.jpg" alt="avatar"></p>
<p>####联合密度性质</p>
<p><img src="/blog_picture/1565071532659.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565071741870.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565071745834.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565071749581.jpg" alt="avatar"></p>
<p>####边缘分布</p>
<p><img src="/blog_picture/1565071827339.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565071830825.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565072132127.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565072287072.jpg" alt="avatar"></p>
<p>####多维分布</p>
<p>在机器学习中，一个 样本有多个特征，研究多个特征的概率分布与统计情况</p>
<p>####二维随机变量</p>
<p><img src="/blog_picture/1565072474902.jpg" alt="avatar"></p>
<p>####为什么需要协方差?</p>
<p><img src="/blog_picture/1565072501064.jpg" alt="avatar"></p>
<p>####协方差</p>
<p><img src="/blog_picture/1565072546171.jpg" alt="avatar"></p>
<p>####协方差的性质</p>
<p><img src="/blog_picture/1565072627923.jpg" alt="avatar"></p>
<p>####协方差矩阵</p>
<p><img src="/blog_picture/1565072672838.jpg" alt="avatar"></p>
<h4 id="主成分分析法"><a href="#主成分分析法" class="headerlink" title="主成分分析法"></a>主成分分析法</h4><p>#####PCA的意义</p>
<p><img src="/blog_picture/1565072734381.jpg" alt="avatar"></p>
<p>#####PCA的数学模型</p>
<p><img src="/blog_picture/1565072773199.jpg" alt="avatar"></p>
<p>####PCA推导</p>
<p><img src="/blog_picture/1565072881626.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565072885469.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565072888797.jpg" alt="avatar"></p>
<p>####PCA实施</p>
<p><img src="/blog_picture/1565072955696.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565072959543.jpg" alt="avatar"></p>
<h2 id="概率论与信息论"><a href="#概率论与信息论" class="headerlink" title="概率论与信息论"></a>概率论与信息论</h2><p>####切比雪夫不等式</p>
<p><img src="/blog_picture/1565073174283.jpg" alt="avatar"></p>
<p>####中心极限定理</p>
<p><img src="/blog_picture/1565073177541.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565073180613.jpg" alt="avatar"></p>
<p>####关于正态分布计算的补充</p>
<p><img src="/blog_picture/1565073253138.jpg" alt="avatar"></p>
<p>####矩的概念</p>
<p><img src="/blog_picture/1565073324278.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565073327543.jpg" alt="avatar"></p>
<p>####矩估计</p>
<p><img src="/blog_picture/1565073407133.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565073410261.jpg" alt="avatar"></p>
<p>####极大似然估计的思想</p>
<p><img src="/blog_picture/1565073555795.jpg" alt="avatar"></p>
<p>####极大似然估计</p>
<p><img src="/blog_picture/1565073575910.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565073579745.jpg" alt="avatar"></p>
<p>####极大似然估计求法</p>
<p><img src="/blog_picture/1565073673751.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565073677603.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565073681686.jpg" alt="avatar"></p>
<h4 id="MLE在机器学习中的应用"><a href="#MLE在机器学习中的应用" class="headerlink" title="MLE在机器学习中的应用"></a>MLE在机器学习中的应用</h4><p>参数估计 逻辑回归的参数估计</p>
<h4 id="最大后验估MAP"><a href="#最大后验估MAP" class="headerlink" title="最大后验估MAP"></a>最大后验估MAP</h4><p>####先验信息</p>
<p><img src="/blog_picture/1565073949228.jpg" alt="avatar"></p>
<p>####先验分布</p>
<p><img src="/blog_picture/1565073979451.jpg" alt="avatar"></p>
<p>####如何利用先验信息?</p>
<p>在样本少的情况下，如何 加入先验信息? 后验概率</p>
<p>####后验概率</p>
<p><img src="/blog_picture/1565074058577.jpg" alt="avatar"></p>
<p>####最大后验估计</p>
<p><img src="/blog_picture/1565074072524.jpg" alt="avatar"></p>
<p>####贝叶斯法则</p>
<p><img src="/blog_picture/1565074197261.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565074201110.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565074204451.jpg" alt="avatar"></p>
<p>####贝叶斯意义</p>
<p><img src="/blog_picture/1565074264162.jpg" alt="avatar"></p>
<p>####贝叶斯公式的密度函数形式</p>
<p><img src="/blog_picture/1565074294912.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565074306035.jpg" alt="avatar"></p>
<p>####共轭分布</p>
<p><img src="/blog_picture/1565074406347.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565074410909.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565074415028.jpg" alt="avatar"></p>
<p>####如何度量信息的多少?</p>
<p><img src="/blog_picture/1565074557282.jpg" alt="avatar"></p>
<p>####自信息量</p>
<p><img src="/blog_picture/1565074568602.jpg" alt="avatar"></p>
<p>####信息熵</p>
<p><img src="/blog_picture/1565074580286.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565074642251.jpg" alt="avatar"></p>
<p>####交叉熵</p>
<p><img src="/blog_picture/1565074679965.jpg" alt="avatar"></p>
<p>####交叉熵在机器学习中的应用</p>
<p>交叉熵损失函数   衡量两个随机变量之间的相似度</p>
<p>####互信息</p>
<p><img src="/blog_picture/1565074818018.jpg" alt="avatar"></p>
<p>####KL散度</p>
<p><img src="/blog_picture/1565074821449.jpg" alt="avatar"></p>
<p>####KL散度的性质</p>
<p><img src="/blog_picture/1565074832615.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565074846596.jpg" alt="avatar"></p>
<p>##优化方法</p>
<h4 id="优化方法"><a href="#优化方法" class="headerlink" title="优化方法"></a>优化方法</h4><p>所谓最优化问题，指在某些约束条件下，决定某些可选择的变量应该取何值，使所选定的目标函数达到最优的问题。即运用最新科技手段和处理方法，使系统达到总体最优，从而为系统提出 设计、施工、管理、运行的最优方案。</p>
<p>为什么要用优化算法?</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">求导找函数的最小(大)值不行吗?</span><br><span class="line">考虑:1、多元函数</span><br><span class="line">2、局部最大最小值</span><br></pre></td></tr></table></figure>

<p>####线性规划</p>
<p><img src="/blog_picture/1565076518810.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565076541128.jpg" alt="avatar"></p>
<h4 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h4><p><img src="/blog_picture/1565076888078.jpg" alt="avatar"></p>
<h4 id="一维函数梯度"><a href="#一维函数梯度" class="headerlink" title="一维函数梯度"></a>一维函数梯度</h4><p><img src="/blog_picture/1565077155760.jpg" alt="avatar"></p>
<p>####梯度下降法</p>
<p><img src="/blog_picture/1565077206152.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565077232963.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565077254742.jpg" alt="avatar"></p>
<p>####梯度法的迭代过程</p>
<p><img src="/blog_picture/1565077296818.jpg" alt="avatar"></p>
<p>####批量梯度下降BGD</p>
<p><img src="/blog_picture/1565077637320.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565077674463.jpg" alt="avatar"></p>
<p>####随机梯度下降SGD</p>
<p><img src="/blog_picture/1565078179419.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565078182517.jpg" alt="avatar"></p>
<p>####小批量梯度下降法MBGD</p>
<p><img src="/blog_picture/1565078253357.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565078257221.jpg" alt="avatar"></p>
<h4 id="牛顿法"><a href="#牛顿法" class="headerlink" title="牛顿法"></a>牛顿法</h4><p>求解无约束极值问题得最古老算法之一，已发展成为一类算法:Newton型方法。<br>在局部，用一个二次函数近似代替目标函数 f(x)，然后用近似函数的极小 点作为f(x) 的近似极小点。</p>
<p><img src="/blog_picture/1565078413953.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565078417533.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565078421199.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565078424695.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565078428776.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565078432769.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565078436246.jpg" alt="avatar"></p>
<h4 id="拟牛顿法"><a href="#拟牛顿法" class="headerlink" title="拟牛顿法"></a>拟牛顿法</h4><p>拟牛顿法的本质思想是改善牛顿法每次需要求解复杂的Hessian矩阵的逆矩阵的缺陷，它使用 正定矩阵来近似Hessian矩阵的逆，从而简化了运算的复杂度。 拟牛顿法和最速下降法一样只要求每一步迭代时知道目标函数的梯度。通过测量梯度的变化， 构造一个目标函数的模型使之足以产生超线性收敛性。 这类方法大大优于最速下降法，尤其对于困难的问题。另外，因为拟牛顿法不需要二阶导数的 信息，所以有时比牛顿法更为有效。</p>
<p><strong>用不包含二阶导数的矩阵近似<em>Hesse*</em></strong>矩阵的*</p>
<p><img src="/blog_picture/1565078600068.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565078603177.jpg" alt="avatar"></p>
<p>####常用的拟牛顿法</p>
<p><img src="/blog_picture/1565078654456.jpg" alt="avatar"></p>
<h4 id="共轭方向法"><a href="#共轭方向法" class="headerlink" title="共轭方向法"></a>共轭方向法</h4><p><strong>共轭方向法</strong>是介于最速下降法与牛顿法之间的一类方法。</p>
<p>它仅需利用一阶导数信息，但克服了最速下降法收敛慢的缺点，又避免了存储和 计算牛顿法所需要的二阶导数信息。</p>
<p><img src="/blog_picture/1565078732264.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565078735596.jpg" alt="avatar"></p>
<p>####共轭方向法的几何意义</p>
<p><img src="/blog_picture/1565078861764.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565078864870.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565078867892.jpg" alt="avatar"></p>
<h4 id="共轭梯度法"><a href="#共轭梯度法" class="headerlink" title="共轭梯度法"></a>共轭梯度法</h4><p>⚫ <strong>共轭梯度法</strong>(conjugate gradient method, CG)是以共轭方向(conjugate direction)作为 搜索方向的一类算法。</p>
<p>⚫ CG法是由Hesteness和Stiefel于1952年为求解线性方程组而提出的。后来用于求解无约束最优 化问题，它是一种重要的数学优化方法。这种方法具有<strong>二次终止性</strong></p>
<p>CG的基本思想是把共轭性与最速下降法相结合，利用已知迭代点的梯度方向 构造一组共轭方向，并沿着此组方向进行搜索，求出目标函数的极小点。</p>
<p><strong>什么是二次终止性?</strong></p>
<p>如果某算法用于求解目标函数为二次函数的无约束问题时，只需要经过有限迭代就能 达到最优解，则该算法具有二次终止性。<br>共轭梯度法就有二次终止性</p>
<p><img src="/blog_picture/1565078980017.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565079002662.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565079045462.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565079049180.jpg" alt="avatar"></p>
<p>####动量梯度下降法法Momentum</p>
<p><img src="/blog_picture/1565079107750.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565079110804.jpg" alt="avatar"></p>
<p>####均方根优化法RMSp</p>
<p><img src="/blog_picture/1565079198345.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565079201526.jpg" alt="avatar"></p>
<p>####自适应矩估计法Adam</p>
<p><img src="/blog_picture/1565079255381.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565079258315.jpg" alt="avatar"></p>
<p>####学习率衰减</p>
<p><img src="/blog_picture/1565079349701.jpg" alt="avatar"></p>
<p><img src="/blog_picture/1565079353025.jpg" alt="avatar"></p>
<p>####早停</p>
<p><img src="/blog_picture/1565079408798.jpg" alt="avatar"></p>
<p><strong>核心思想:</strong></p>
<p>如果训练数轮后准确率(损失函数)没有上升(下降)，就停止训练</p>
<p><strong>应用场景:</strong></p>
<p>大批量数据，训练时间长</p>
<p>####局部最优值</p>
<p><img src="/blog_picture/1565079488243.jpg" alt="avatar"></p>
<p>####鞍点问题</p>
<p><img src="/blog_picture/1565079501278.jpg" alt="avatar"></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/优化方法/">优化方法</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/微积分/">微积分</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/概率/">概率</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/线性代数/">线性代数</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/统计/">统计</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-大数据基础" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/07/24/大数据基础/" class="article-date">
      <time datetime="2019-07-23T23:46:26.000Z" itemprop="datePublished">2019-07-24</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/07/24/大数据基础/">大数据基础</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="pyspark-RDD基础"><a href="#pyspark-RDD基础" class="headerlink" title="pyspark-RDD基础"></a>pyspark-RDD基础</h1><h3 id="spark"><a href="#spark" class="headerlink" title="spark"></a>spark</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pyspark是spark的python API,允许python调用spark编程模型</span><br></pre></td></tr></table></figure>

<h3 id="初始化spark"><a href="#初始化spark" class="headerlink" title="初始化spark"></a>初始化spark</h3><h4 id="SparkContext"><a href="#SparkContext" class="headerlink" title="SparkContext"></a>SparkContext</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line">sc = SparkContext(master=<span class="string">'local[2]'</span>)</span><br></pre></td></tr></table></figure>

<h4 id="核查SparkContext"><a href="#核查SparkContext" class="headerlink" title="核查SparkContext"></a>核查SparkContext</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sc.version									获取SparkContext的版本</span><br><span class="line">sc.pythonVer								获取python版本</span><br><span class="line">sc.master										要连接的Master URL</span><br><span class="line">str(sc.sparkHome)						spark工作节点的安装路径</span><br><span class="line">str(sc.sparkUser())					获取SparkContext的spark用户名</span><br><span class="line">sc.appName									返回应用名称</span><br><span class="line">sc.applicationId						返回应用程序ID</span><br><span class="line">sc.defaultParallelism				返回默认并行级别</span><br><span class="line">sc.defaultMinPatitions			RDD默认最小分区数</span><br></pre></td></tr></table></figure>

<h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf,SparkContext</span><br><span class="line">conf = (SparkConf().setMaster(<span class="string">"local"</span>).setAppName(<span class="string">"my APP"</span>).set(<span class="string">"spark.executor.memory"</span>,<span class="string">"1g"</span>))</span><br><span class="line">sc = SparkContext(conf=conf)</span><br></pre></td></tr></table></figure>

<h4 id="使用shell"><a href="#使用shell" class="headerlink" title="使用shell"></a>使用shell</h4><p>pyspark shell已经为SparkContext创建了名为sc的变量</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-shell --master local[2]</span><br><span class="line">./bin/pyspark --master local[4] --py-files code.py</span><br></pre></td></tr></table></figure>

<p>用—master参数设定Context连接到哪个Master服务器，通过传递逗号分隔列表至—py-files添加Python.zip、egg或.py文件到Runtime路径</p>
<h3 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h3><h4 id="并行集合"><a href="#并行集合" class="headerlink" title="并行集合"></a>并行集合</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rdd = sc.parallelize([(<span class="string">'a'</span>,<span class="number">7</span>),(<span class="string">'a'</span>,<span class="number">2</span>),(<span class="string">'b'</span>,<span class="number">2</span>)])</span><br><span class="line">rdd2 = sc.parallelize([(<span class="string">'a'</span>,<span class="number">2</span>),(<span class="string">'d'</span>,<span class="number">1</span>),(<span class="string">'b'</span>,<span class="number">1</span>)])</span><br><span class="line">rdd3 = sc.parallelize(range(<span class="number">100</span>))</span><br><span class="line">rdd4 = sc.parallelize([(<span class="string">"a"</span>,[<span class="string">"x"</span>,<span class="string">"y"</span>,<span class="string">"z"</span>]),(<span class="string">"b"</span>,[<span class="string">"p"</span>,<span class="string">"r"</span>])])</span><br></pre></td></tr></table></figure>

<h4 id="外部数据"><a href="#外部数据" class="headerlink" title="外部数据"></a>外部数据</h4><p>使用textFile()函数从HDFS、本地文件或其它支持hadoop的文件系统里读取文件，或使用wholeTextFiles()函数读取目录下所有文本文件</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">textFile = sc.textFile(<span class="string">'a.txt'</span>)</span><br><span class="line">textFile2 = sc.wholeTextFiles(/aa)</span><br></pre></td></tr></table></figure>

<h3 id="提取RDD信息"><a href="#提取RDD信息" class="headerlink" title="提取RDD信息"></a>提取RDD信息</h3><h4 id="基础信息"><a href="#基础信息" class="headerlink" title="基础信息"></a>基础信息</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">rdd.getNumPatitions()								列出分区数</span><br><span class="line">rdd.count()													计算RDD的实例数量</span><br><span class="line">rdd.countByKey()										按键计算RDD实例数量</span><br><span class="line">defaultdict(&lt;type <span class="string">'int'</span>&gt;,(<span class="string">'a'</span>:<span class="number">2</span>,<span class="string">'b'</span>:<span class="number">1</span>))</span><br><span class="line">rdd.countByValue()							按值计算RDD实例数量</span><br><span class="line">defaultdict(&lt;type <span class="string">'int'</span>&gt;,((<span class="string">'b'</span>,<span class="number">2</span>):<span class="number">1</span>,(<span class="string">'a'</span>,<span class="number">2</span>):<span class="number">1</span>,(<span class="string">'a'</span>,<span class="number">7</span>):<span class="number">1</span>))</span><br><span class="line">rdd.collectAsMap()							以字典的形式返回键值</span><br><span class="line">(<span class="string">'a'</span>:<span class="number">2</span>,<span class="string">'b'</span>:<span class="number">2</span>)</span><br><span class="line">rdd.sum()									汇总RDD元素</span><br><span class="line"><span class="number">4959</span></span><br><span class="line">sc.parallelize([]).isEmpty()				检查RDD是否为空</span><br></pre></td></tr></table></figure>

<h4 id="汇总"><a href="#汇总" class="headerlink" title="汇总"></a>汇总</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">rdd.max()					RDD元素的最大值</span><br><span class="line">rdd.min()					RDD元素的最小值</span><br><span class="line">rdd.mean()					RDD元素的平均值</span><br><span class="line">rdd.stdev()					RDD元素的标准差</span><br><span class="line">rdd.variance()				RDD元素的方差</span><br><span class="line">rdd.histogram(<span class="number">3</span>)			分箱（bin）生成直方图</span><br><span class="line">rdd.stats()					综合统计包括：计数、平均值、标准差、最大值和最小值</span><br></pre></td></tr></table></figure>

<h4 id="应用函数"><a href="#应用函数" class="headerlink" title="应用函数"></a>应用函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rdd.map(<span class="keyword">lambda</span> x:x+(x[<span class="number">1</span>],x[<span class="number">0</span>])).collect()		对每个RDD元素执行函数</span><br><span class="line">rdd.flatMap(<span class="keyword">lambda</span> x:x+(x[<span class="number">1</span>],x[<span class="number">0</span>]))				对每个RDD元素执行函数，并拉平结果</span><br><span class="line">rdd.collect()</span><br><span class="line">rdd.flatMapValues(<span class="keyword">lambda</span> x:x).collect()			不改变键，对rdd的每个键值对执行flatMap函数</span><br></pre></td></tr></table></figure>

<h4 id="选择数据"><a href="#选择数据" class="headerlink" title="选择数据"></a>选择数据</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">获取</span><br><span class="line">rdd.collect()							返回包含所以RDD元素的列表</span><br><span class="line">rdd.take(<span class="number">4</span>)								提取前<span class="number">4</span>个RDD元素</span><br><span class="line">rdd.first()								提取第一个RDD元素</span><br><span class="line">rdd.top(<span class="number">2</span>)								提取前两个RDD元素</span><br><span class="line">抽样</span><br><span class="line">rdd.sample(<span class="literal">False</span>,<span class="number">0.15</span>,<span class="number">81</span>)				返回RDD的采样子集</span><br><span class="line">筛选</span><br><span class="line">rdd.filter(<span class="keyword">lambda</span> x:<span class="string">'a'</span> <span class="keyword">in</span> x)			筛选RDD</span><br><span class="line">rdd.distinct()							返回RDD里的唯一值</span><br><span class="line">rdd.keys()								返回RDD键值对里的键</span><br></pre></td></tr></table></figure>

<h4 id="迭代"><a href="#迭代" class="headerlink" title="迭代"></a>迭代</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">g</span><span class="params">(x)</span>:</span>print(x)     </span><br><span class="line">rdd.foreach(g)</span><br></pre></td></tr></table></figure>

<h4 id="改变数据形状"><a href="#改变数据形状" class="headerlink" title="改变数据形状"></a>改变数据形状</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">规约</span><br><span class="line">rdd.reduceByKey(<span class="keyword">lambda</span> x,y:x+y)				合并每个键的值</span><br><span class="line">rdd.reduce(<span class="keyword">lambda</span> x,y:x+y)					合并RDD的值</span><br><span class="line">分组</span><br><span class="line">rdd.groupBy(<span class="keyword">lambda</span> x:x%<span class="number">2</span>).mapValues(list)	返回RDD的分组值</span><br><span class="line">rdd.groupByKey().mapValues(list)			按键分组RDD</span><br><span class="line">集合</span><br><span class="line">seqOp = (<span class="keyword">lambda</span> x,y:(x[<span class="number">0</span>]+y,x[<span class="number">1</span>]+<span class="number">1</span>))</span><br><span class="line">combOP = (<span class="keyword">lambda</span> x,y:(x[<span class="number">0</span>]+y[<span class="number">0</span>],x[<span class="number">1</span>]+y[<span class="number">1</span>]))</span><br><span class="line">rdd.aggregate((<span class="number">0</span>,<span class="number">0</span>),seqOp,combOP)		 	汇总每个分区里的RDD元素，并输出结果</span><br><span class="line">rdd.aggregeteByKey((<span class="number">0</span>,<span class="number">0</span>),seqOp,combOP)		汇总每个RDD的键的值</span><br><span class="line">rdd.fold(<span class="number">0</span>,add)								汇总每个分区里的RDD元素，并输出结果</span><br><span class="line">rdd.foldByKey(<span class="number">0</span>,add)						合并每个键的值</span><br><span class="line">rdd,keyBy(<span class="keyword">lambda</span> x:x+x)						通过执行函数，创建RDD元素的元组</span><br></pre></td></tr></table></figure>

<h4 id="数学运算"><a href="#数学运算" class="headerlink" title="数学运算"></a>数学运算</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rdd.subtract(rdd2)							返回RDD2里没有匹配键的rdd的兼职对</span><br><span class="line">rdd2.subtractByKey(rdd)						返回rdd2里的每个（键、值）对，rdd中，没有匹配的键</span><br><span class="line">rdd.cartesian(rdd2)							返回rdd和rdd2的笛卡尔积</span><br></pre></td></tr></table></figure>

<h4 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rdd.sortBy(lambda x:x[1])					按给定函数排序RDD</span><br><span class="line">rdd.sortByKey()								按键排序RDD的键值对</span><br></pre></td></tr></table></figure>

<h4 id="重分区"><a href="#重分区" class="headerlink" title="重分区"></a>重分区</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rdd.repartition(4)							新建一个含4个分区的RDD</span><br><span class="line">rdd.coalesce(1)								将RDD中的分区数缩减为1个</span><br></pre></td></tr></table></figure>

<h4 id="保存"><a href="#保存" class="headerlink" title="保存"></a>保存</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rdd.saveAsTextFile(&quot;rdd.txt&quot;)</span><br><span class="line">rdd.saveAsHadoopFile(&quot;hdfs://namenodehost/parent/child&quot;,&apos;org.apache.hadoop.mapred.TextOutputFormat&apos;)</span><br></pre></td></tr></table></figure>

<h4 id="终止SparkContext"><a href="#终止SparkContext" class="headerlink" title="终止SparkContext"></a>终止SparkContext</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sc.stop()</span><br></pre></td></tr></table></figure>

<h4 id="执行程序"><a href="#执行程序" class="headerlink" title="执行程序"></a>执行程序</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-submit examples/src/main/python/pi.py</span><br></pre></td></tr></table></figure>

<h1 id="Pyspark-sql"><a href="#Pyspark-sql" class="headerlink" title="Pyspark_sql"></a>Pyspark_sql</h1><h4 id="Pyspark与Spark-SQL"><a href="#Pyspark与Spark-SQL" class="headerlink" title="Pyspark与Spark SQL"></a>Pyspark与Spark SQL</h4><p>Spark SQL是Apache Spark处理结构化数据的模块</p>
<h4 id="初始化SparkSession"><a href="#初始化SparkSession" class="headerlink" title="初始化SparkSession"></a>初始化SparkSession</h4><p>SparkSession用于创建数据框，将数据框注册为表，执行SQL查询，缓存表及读取Parquet文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import SparkSession</span><br><span class="line">spark = SparkSession.builder.appName(&quot;my app&quot;).config(&quot;spark.some.config.option&quot;,&quot;some-value&quot;).getOrCreate()</span><br></pre></td></tr></table></figure>

<h4 id="创建数据框"><a href="#创建数据框" class="headerlink" title="创建数据框"></a>创建数据框</h4><h5 id="从RDD创建"><a href="#从RDD创建" class="headerlink" title="从RDD创建"></a>从RDD创建</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql.types import *</span><br><span class="line">推断Schema</span><br><span class="line">sc = spark.sparkContext</span><br><span class="line">lines = sc.textFile(&quot;people.txt&quot;)</span><br><span class="line">parts = lines.map(lambda l:l.split(&quot;,&quot;))</span><br><span class="line">people = parts.map(lambda p:Row(name=p[0],age=int(p[1])))</span><br><span class="line">peopledf = spark.createDataFrame(people)</span><br><span class="line">指定Schema</span><br><span class="line">people = parts.map(lambda p:Row(name=p[0],age=int(p[1].strip())))</span><br><span class="line">schemaString = &quot;name age&quot;</span><br><span class="line">fields = [StructField(field_name,StringType(),True) for field_name in schemaString.split()]</span><br><span class="line">schema = StructType(fields)</span><br><span class="line">spark.createDataFrame(people,schema).show()</span><br></pre></td></tr></table></figure>

<h5 id="从spark数据源创建"><a href="#从spark数据源创建" class="headerlink" title="从spark数据源创建"></a>从spark数据源创建</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">json</span><br><span class="line">df = spark.read.json(<span class="string">"customer.json"</span>)</span><br><span class="line">df.show()</span><br><span class="line">df2 = spark.read.load(<span class="string">"people.json"</span>,format = <span class="string">"json"</span>)</span><br><span class="line">Parquet文件</span><br><span class="line">df3 = spark.read.load(<span class="string">"users.parquet"</span>)</span><br><span class="line">文本文件</span><br><span class="line">df4 = spark.read.text(<span class="string">"people.txt"</span>)</span><br></pre></td></tr></table></figure>

<h5 id="查阅数据信息"><a href="#查阅数据信息" class="headerlink" title="查阅数据信息"></a>查阅数据信息</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">df.dtypes						返回df的列名与数据类型</span><br><span class="line">df.show()						显示df内容</span><br><span class="line">df.head()						返回前n行数据</span><br><span class="line">df.first()						返回第一行数据</span><br><span class="line">df.take(2)						返回前两行数据</span><br><span class="line">df.schema						返回df的schema</span><br><span class="line">df.describe().show()			汇总统计数据</span><br><span class="line">df.columns						返回df列名</span><br><span class="line">df.count()						返回df的行数</span><br><span class="line">df.distinct().count()			返回df中不重复的行数</span><br><span class="line">df.printSchema()				返回df的Schema</span><br><span class="line">df.explain()					返回逻辑与实体方案</span><br></pre></td></tr></table></figure>

<h5 id="重复值"><a href="#重复值" class="headerlink" title="重复值"></a>重复值</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df = df.dropDuplicates()</span><br></pre></td></tr></table></figure>

<h5 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> functions <span class="keyword">as</span> F</span><br><span class="line">Select</span><br><span class="line">df.select(<span class="string">"firstName"</span>).show()					显示firstName列的所有条目</span><br><span class="line">df.select(<span class="string">"firstName"</span>,<span class="string">"lastName"</span>.show())					</span><br><span class="line">df.select(<span class="string">"firstName"</span>,<span class="string">"age"</span>,\</span><br><span class="line">          explode(<span class="string">"phoneNumber"</span>)\				显示firstName、age的所有条目和类型</span><br><span class="line">          .alias(<span class="string">"contactInfo"</span>))\</span><br><span class="line">			.select(<span class="string">"ContactInfo.type"</span>,<span class="string">"firstName"</span>,<span class="string">"age"</span>)</span><br><span class="line">df.select(df[<span class="string">"firstName"</span>],df[<span class="string">"age"</span>]+<span class="number">1</span>).show()	显示firstName和age列的所有记录添加</span><br><span class="line">df.select(df[<span class="string">"age"</span>]&gt;<span class="number">24</span>).show()					显示所有小于<span class="number">24</span>的记录</span><br><span class="line">When</span><br><span class="line">df.select(<span class="string">"firstName"</span>,F.when(df.age&gt;<span class="number">30</span>,<span class="number">1</span>))\		显示firstName，且大于<span class="number">30</span>岁显示<span class="number">1</span>，小于<span class="number">30</span>显示<span class="number">0</span></span><br><span class="line">				.otherwise(<span class="number">0</span>).show()</span><br><span class="line">df[df.firstName.isin(<span class="string">"Jane"</span>,<span class="string">"Boris"</span>)].collect()	显示符合特定条件的firstName列的记录</span><br><span class="line">Like	</span><br><span class="line">df.select(<span class="string">"firstName"</span>,df.lastName,\				显示lastName列中包含Smith的firstName列的记录</span><br><span class="line">          like(<span class="string">"Smith"</span>)).show()</span><br><span class="line">Startswith-Endwith</span><br><span class="line">df.select(<span class="string">"firstName"</span>,df.lastName.\				显示lastName列中以Sm开头的firstName列的记录	</span><br><span class="line">          startswith(<span class="string">"Sm"</span>)).show()</span><br><span class="line">df.select(df.lastName.endswith(<span class="string">"th"</span>)).show()	显示以th结尾的lastName</span><br><span class="line">Substring</span><br><span class="line">df.select(df.firstName.substr(<span class="number">1</span>,<span class="number">3</span>).alias(<span class="string">"name"</span>))返回firstName的子字符串</span><br><span class="line">Between</span><br><span class="line">df.select(df.age.between(<span class="number">22</span>,<span class="number">24</span>)).show()			显示介于<span class="number">22</span>到<span class="number">24</span>直接的age列的所有记录</span><br></pre></td></tr></table></figure>

<h4 id="添加、修改、删除列"><a href="#添加、修改、删除列" class="headerlink" title="添加、修改、删除列"></a>添加、修改、删除列</h4><h5 id="添加列"><a href="#添加列" class="headerlink" title="添加列"></a>添加列</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df = df.withColumn(<span class="string">'city'</span>,df.address.city) \</span><br><span class="line">       .withColumn(<span class="string">'postalCode'</span>,df.address.postalCode) \</span><br><span class="line">    .withColumn(<span class="string">'state'</span>,df.address.state) \</span><br><span class="line">    .withColumn(<span class="string">'streetAddress'</span>,df.address.streetAddress) \</span><br><span class="line">    .withColumn(<span class="string">'telePhoneNumber'</span>,explode(df.phoneNumber.number)) \</span><br><span class="line">    .withColumn(<span class="string">'telePhoneType'</span>,explode(df.phoneNumber.type)) \</span><br></pre></td></tr></table></figure>

<h5 id="修改列"><a href="#修改列" class="headerlink" title="修改列"></a>修改列</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df = df.withColumnRenamed(<span class="string">'telePhoneNumber'</span>,<span class="string">'phoneNumber'</span>)</span><br></pre></td></tr></table></figure>

<h5 id="删除列"><a href="#删除列" class="headerlink" title="删除列"></a>删除列</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = df.drop(&quot;address&quot;,&quot;phoneNumber&quot;)</span><br><span class="line">df = df.drop(df.address).drop(df.phoneNumber)</span><br></pre></td></tr></table></figure>

<h5 id="分组"><a href="#分组" class="headerlink" title="分组"></a>分组</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.groupBy(<span class="string">"age"</span>).count().show()		按age列分组，统计每组人数</span><br></pre></td></tr></table></figure>

<h5 id="筛选"><a href="#筛选" class="headerlink" title="筛选"></a>筛选</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.filter(df[<span class="string">"age"</span>]&gt;<span class="number">24</span>).show()			按age列筛选，保留年龄大于<span class="number">24</span>岁的</span><br></pre></td></tr></table></figure>

<h5 id="排序-1"><a href="#排序-1" class="headerlink" title="排序"></a>排序</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">peopledf.sort(peopledf.age.desc()).collect()</span><br><span class="line">df.sort(&quot;age&quot;,ascending=False).collect()</span><br><span class="line">df.orderBy([&quot;age&quot;,&quot;city&quot;],ascending=[0,1]).collect()</span><br></pre></td></tr></table></figure>

<h5 id="替换缺失值"><a href="#替换缺失值" class="headerlink" title="替换缺失值"></a>替换缺失值</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df.na.fill(<span class="number">50</span>).show()				用一个值替换空值</span><br><span class="line">df.na.drop().show()					去除df中为空值的行</span><br><span class="line">df.na.replace(<span class="number">10</span>,<span class="number">20</span>).show()			用一个值去替换另一个值</span><br></pre></td></tr></table></figure>

<h5 id="重分区-1"><a href="#重分区-1" class="headerlink" title="重分区"></a>重分区</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.repartition(<span class="number">10</span>).rdd.getNumPartitions()	将df拆分为<span class="number">10</span>个分区</span><br><span class="line">df.coalesce(<span class="number">1</span>).rdd.getNumPartitions()		将df合并为<span class="number">1</span>个分区</span><br></pre></td></tr></table></figure>

<h4 id="运行SQL查询"><a href="#运行SQL查询" class="headerlink" title="运行SQL查询"></a>运行SQL查询</h4><h5 id="将数据框注册为视图"><a href="#将数据框注册为视图" class="headerlink" title="将数据框注册为视图"></a>将数据框注册为视图</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">peopledf.createGlobalTempView(<span class="string">"people"</span>)</span><br><span class="line">df.createTempView(<span class="string">"customer"</span>)</span><br><span class="line">df.createOrReplaceTempView(<span class="string">"customer"</span>)</span><br></pre></td></tr></table></figure>

<h5 id="查询视图"><a href="#查询视图" class="headerlink" title="查询视图"></a>查询视图</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = spark.sql(<span class="string">"select * from customer"</span>).show()</span><br><span class="line">peopledf = spark.sql(<span class="string">"select * from global_temp.people"</span>).show()</span><br></pre></td></tr></table></figure>

<h4 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h4><h5 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rdd1 = df.rdd		将df转为rdd</span><br><span class="line">df.toJSON().first()	将df转为rdd字符串</span><br><span class="line">df.toPandas()		将df的内容转为Pandas的数据框</span><br></pre></td></tr></table></figure>

<h5 id="保存至文件"><a href="#保存至文件" class="headerlink" title="保存至文件"></a>保存至文件</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.select(<span class="string">"firstName"</span>,<span class="string">"city"</span>).write.save(<span class="string">"nameAndCity.parquet"</span>)</span><br><span class="line">df.select(<span class="string">"firstName"</span>,<span class="string">"age"</span>).write.save(<span class="string">"nameAndAges.json"</span>,format=<span class="string">"json"</span>)</span><br></pre></td></tr></table></figure>

<h5 id="终止SparkSession"><a href="#终止SparkSession" class="headerlink" title="终止SparkSession"></a>终止SparkSession</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark.stop()</span><br></pre></td></tr></table></figure>


      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/pyspark/">pyspark</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-数据分析常用工具总结" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/07/22/数据分析常用工具总结/" class="article-date">
      <time datetime="2019-07-21T23:46:36.000Z" itemprop="datePublished">2019-07-22</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/07/22/数据分析常用工具总结/">数据分析常用工具总结</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="numpy"><a href="#numpy" class="headerlink" title="numpy"></a>numpy</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">1. 优点:向量化数据操作比for循环,速度大大加强，numpy array比list好的地方在于切片</span><br><span class="line">2. array属性</span><br><span class="line">    np.random.random((2,2)) # 0-1随机数</span><br><span class="line">    np.random.randint(1,10,(3,3)) # 随机整数</span><br><span class="line">    array.shape, array.dtype # numpy两个属性</span><br><span class="line">    array.astype(np.float64) # 类型转换</span><br><span class="line">3. array切片操作</span><br><span class="line">    a[0,1] # 第一个维度为0,第二个维度1,第三个维度全选,类似于a[0,1,:]</span><br><span class="line">    a[a&gt;2] # boolean indexing, 利用broadcasting进行判断, 之后可以作为index进行数据的提取</span><br><span class="line">    a[a&gt;2]=0 # 也可以对满足条件的元素进行赋值</span><br><span class="line">4. array数学运算</span><br><span class="line">    broadcasting, 对不匹配的数据在高维上进行扩展,在取最小公倍数</span><br><span class="line">    np.sum(array) # 统计运算</span><br><span class="line">    np.dot # 矩阵乘法,点乘</span><br><span class="line">    np.multiply  # 逐个元素乘法,对应相乘</span><br></pre></td></tr></table></figure>

<p>#pandas</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">基于Numpy构建，利用它的高级数据结构和操作工具，可使数据分析工作变得更加便捷高效。</span><br><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br></pre></td></tr></table></figure>

<h2 id="基本数据结构"><a href="#基本数据结构" class="headerlink" title="基本数据结构"></a>基本数据结构</h2><h3 id="Series"><a href="#Series" class="headerlink" title="Series"></a>Series</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">1. 基本概念</span><br><span class="line">    pd.__version__ # 查看版本</span><br><span class="line">    pd.Series # 可以使用不同类型,和list区别在于有index, 可以指定index</span><br><span class="line"></span><br><span class="line">2. Series构建</span><br><span class="line">    pd.Series([1,2,3], index=[&apos;a&apos;, &apos;b&apos;, &apos;c&apos;])</span><br><span class="line">    pd.Series(&#123;...&#125;, name=&quot;xxx&quot;) # 通过对dictionary进行构建pandas, 给Series赋予名字</span><br><span class="line"></span><br><span class="line">3. 切片</span><br><span class="line">    aseries[[1,4,3]]; aseries[1:]; aseries[:-1]  # 数字下标切片,即使index不是数字也ok</span><br><span class="line"></span><br><span class="line">4. 运算规则</span><br><span class="line">    series的相加是根据index对应相加的</span><br><span class="line"></span><br><span class="line">5. 取值</span><br><span class="line">    数学运算也是broadcasting方式</span><br><span class="line">    &apos;xxx&apos; in aseries # 判断xxx是否在aseries的index中</span><br><span class="line">    aseries.get(&apos;xxx&apos;, 0) # 类似于字典</span><br><span class="line">    aseries[aseries&lt;20] # boolean index也可以</span><br><span class="line">    aseries.median() # 除去缺失值之后进行统计运算</span><br><span class="line">    aseries[&apos;xxx&apos;] = 1000 # 对aseries[&apos;xxx&apos;]重新赋值</span><br><span class="line">    np.square(aseries) # 对每个运算进行计算平方</span><br></pre></td></tr></table></figure>

<h3 id="DataFrame"><a href="#DataFrame" class="headerlink" title="DataFrame"></a>DataFrame</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">1. 基本概念</span><br><span class="line">    一组Series集合在一起</span><br><span class="line"></span><br><span class="line">2. DataFrame的构建</span><br><span class="line">    - pd.DataFrame(&#123;&apos;a&apos;:[1,2,3], &apos;b&apos;:[1,4,3]&#125;, columns = [&apos;b&apos;, &apos;a&apos;], index = [&apos;one&apos;, &apos;two&apos;, &apos;three&apos;]) # 构建DF, 指定列名以及index名</span><br><span class="line">    - pd.DataFrame([&#123;&apos;a&apos;:100,&apos;b&apos;:200&#125;, &#123;&apos;a&apos;:200, &apos;b&apos;:300&#125;], index=[&apos;one&apos;, &apos;two&apos;]) # 按照一行一行构建DF</span><br><span class="line">    - pd.DataFrame(&#123;&apos;a&apos;:seriesa, &apos;b&apos;:seriesb&#125; # 记住按照index对齐, 缺失值直接Nan填充</span><br><span class="line"></span><br><span class="line">3. 元素的提取以及增加及逻辑操作及转置</span><br><span class="line">    - aDF[&apos;xxx&apos;]/aDF.xxx # 取出来的是一个Series</span><br><span class="line">    - aDF[[&apos;xxx&apos;]] # 取出来的是一个DF</span><br><span class="line">    - aDF.loc([&apos;a&apos;,&apos;b&apos;],[&apos;c&apos;,&apos;d&apos;]) # 取对应的数据</span><br><span class="line">    - aDF.loc[:, &apos;newcol&apos;] = 2000 # 如果没有newcol那么就新加一列</span><br><span class="line">    - aDF.loc[(aDF[&apos;a&apos;]&gt;10) &amp; (aDF[&apos;b&apos;]&lt;100), :] # 也可以给条件进行筛选,&amp; | ~进行逻辑运算</span><br><span class="line">    - aDF.T # 进行转置</span><br><span class="line">4. 数据读入以及基本信息以及删除</span><br><span class="line">    - pd.read_csv(path, sep=&apos;\t&apos;, index_col=&apos;&apos;/int, usecols=[...], header=0, parse_dates=[0]/[&apos;Date&apos;]) # 读文件，第一列作为日期型，日期型处理参照: http://hshsh.me/post/2016-04-12-python-pandas-notes-01/</span><br><span class="line">    - aDF.to_csv(&apos;xxx.csv&apos;, sep=&apos;\t&apos;, index=True, header=True) # 写文件</span><br><span class="line">    - aDF.describe(include=[np.float64...]) / aDF.info() # 对数据进行统计，查看缺失值</span><br><span class="line">    - aDF.shape</span><br><span class="line">    - aDF.isnull() # 判断是是否为空</span><br><span class="line">    - aDF[aDF[&apos;xxx&apos;].isnull(), :] = 10 # 对空值赋值</span><br><span class="line">    - aDF.notnull() # 查看是否有值</span><br><span class="line">    - aDF.drop([&apos;one&apos;, &apos;two&apos;], axis=0) # 对index为one和two的两行进行删除, axis=1删除列</span><br><span class="line"></span><br><span class="line">5. 数据分组聚合</span><br><span class="line">    - aDF.groupby(&apos;name&apos;, sort=False).sum() # 对DF进行聚合操作,同时对相应聚合的列进行排序,然后计算其他值的和</span><br><span class="line">    - groupbyname=aDF.groupby(&apos;name&apos;); groupbyname.groups; len(groupbyname) # 得到对应的各个组别包含的index, 并且可以获取对应的group长度</span><br><span class="line">    - aDF.groupby(&apos;name&apos;).agg([np.sum, np.mean, np.std]) # 对不同类别的数据进行各类运算, 每个name对应三列分别是分组之后np.sum, np.mean, np.std计算</span><br><span class="line">    - aDF.groupby(&apos;name&apos;).agg([&apos;sum&apos;, &apos;median&apos;, &apos;mean&apos;]) # 和上面的作用相同</span><br><span class="line">    - aDF.groupby(&apos;name&apos;).agg([&apos;a&apos;:np.sum, &apos;b&apos;:median, &apos;c&apos;:np.mean]) # 对不同列进行不同操作</span><br><span class="line">    - aDF.groupby([&apos;name&apos;, &apos;year&apos;]).sum()/mean()/median()/describe() # 多组分类</span><br><span class="line">    - aDF.groupby([&apos;name&apos;, &apos;year&apos;]).size() # 多组分类, 每一组有多少个记录</span><br><span class="line">    - 提取group类别名称以及类别对应的数据行</span><br><span class="line">        for name,group in groupbyname:</span><br><span class="line">            print(name) # 类别名称</span><br><span class="line">            print(group) # 名称对应的数据行</span><br><span class="line">        groupbyname.get_group(&apos;jason&apos;) # 可以得到对应组别的数据行,DF格式</span><br><span class="line">6. transform/apply/filter 数据变换</span><br><span class="line">    transfrom可以对分组进行变换, apply对整个DF进行分类,filter对分组进行判断</span><br><span class="line">    - aDF[&apos;Date&apos;].dt.dayofweek # 可以得到对应的日期中的第几天</span><br><span class="line">    - aDF.groupby(aDF.index.year).mean() # 可以对相应的日期型的年进行分组聚合</span><br><span class="line">    - aDF.groupby(aDF.index.year).transform(lambda x: (x-x.mean())/x.std()) # 对每一年的数据求均值以及标准差,并对每个数据进行操作,之所以没以每年为单位进行展示主要是跟function有关,因为之前的是mean之类的</span><br><span class="line">    - aDF.groupby(aDF.index.year).apply(lambda x: (x-x.mean())/x.std()) # 可以起到相同的效果</span><br><span class="line">    - aDF.loc[:,&apos;new&apos;] = aDF[&apos;xxx&apos;].apply(afunc) # 可以对xxx这一列进行操作按照afunc进行操作,然后创建新的列</span><br><span class="line">    - aSer = pd.Series([1,1,2,2,2,3,3,4,5,5]); sSer.groupby(sSer).filter(lambda x:x.sum()&gt;4) # 对ser进行过滤,留下那些和大于4的类别</span><br><span class="line"></span><br><span class="line">7. 表格的拼接与合并(concat/append/merge/join)</span><br><span class="line">    - df1.append(df2, sort=False, ignore_index=True) # 追加在行上,同时忽略原先df1和df2的index,合并为新的index</span><br><span class="line">    - df1.append([df2, df3])  # 也可以追加两个DF, 参考: https://zhuanlan.zhihu.com/p/38184619</span><br><span class="line">    - pd.concat([df1.set_index(&apos;a&apos;), df2.set_index(&apos;a&apos;)], sort=False, axis=1, join=&apos;inner&apos;) # 和上述利用merge在a字段上进行内连接的效果类似,因为concat是基于index进行连接的,merge可以不基于index,指定字段</span><br><span class="line">    - pd.concat([df1, df2, df3], keys=[&apos;a&apos;, &apos;b&apos;, &apos;c&apos;], axis=0, join=&apos;outer&apos;, sort=False) #列对齐的方式对行进行拼接,缺少值则补充为None,可以对拼接的每个df进行key的命名,axis=1的时候行对齐列拼接; join指定连接方式,outer表示外连接,inner表示内连接,sort是否对合并的数据进行排序</span><br><span class="line">    - merge # 基于某个字段进行连接,之前的append和concat都是在行上或者列上进行连接的,merge类似于SQL里面的连接,可以指定某个字段或某几个字段,体现在on上,on接list就是多个字段为key</span><br><span class="line">    - pd.merge(df1, df4, on=&apos;city&apos;, how=&apos;outer&apos;/&apos;inner&apos;/&apos;left&apos;/&apos;right&apos;) # 基于两个表中的city字段进行表格的连接,把其他的列进行combine到一起,不指定on的话就会找字段相同的那个进行拼接,注意concat是基于index进行拼接的</span><br><span class="line">    - pd.merge(df1, df2, how=&apos;inner&apos;, left_index=True, right_on=&apos;id&apos;) # 对数据进行merge,左表以index作为连接关键字,右表用id作为关键字</span><br><span class="line">8. 链家Case study流程</span><br><span class="line">    - pd.to_datetime() # 日期类型转换</span><br><span class="line">    - df.drop(droplist, inplace=True, axis=1) # 删除一些列</span><br><span class="line">    - aDF.describe(include=&apos;all&apos;) # 字符串变量也会同时统计</span><br><span class="line">    - aDF.sort_values(by = &apos;xxx&apos;).tail() # 找出更新最晚的20套,但是有可能同一天超过20套</span><br><span class="line">    - 如果对数据进行处理发现转换未果可能是因为数据有缺失,做异常处理,缺失值作为Nan</span><br><span class="line">    - aDF.nsmallest(columns=&apos;age&apos;, n=20) # 取出年龄最小的20个数据</span><br><span class="line">    - groupby().agg() 之后一般会使用reset_index() 对数据进行归置然后再进行操作,ascending=False</span><br><span class="line">    - adf.value_counts(normalize=True) # 默认是按照value进行排序的</span><br><span class="line">    - aDF.apply(lambda x: &apos;xxx&apos; in x) # 筛选出xxx在某列的值中与否,返回Ture, False，正则表达式的字符串匹配</span><br><span class="line">    - 可以定义正则表达式对文本信息进行提取</span><br><span class="line">        def get_info(s, pattern, n):</span><br><span class="line">            result = re.search(pattern, s)</span><br><span class="line">            if result:</span><br><span class="line">                return result.group(n)</span><br><span class="line">            else:</span><br><span class="line">                return &apos;&apos;</span><br><span class="line">    - .astype(int) # 转换pd类型</span><br><span class="line">    - help(pd.Series.value_counts) # 打印帮助文档</span><br></pre></td></tr></table></figure>

<h1 id="python绘图"><a href="#python绘图" class="headerlink" title="python绘图"></a>python绘图</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line">1. pandas 绘图</span><br><span class="line">    - pd.date_range(&apos;2018/12/28&apos;, periods=10) # 产生日期格式, 以2018/12/28为起始产生以天为单位的日期时间list</span><br><span class="line">    - pandas绘图需要把横坐标作为index,之后再画图</span><br><span class="line">    - 折线图绘制需要注意各列幅度，否则数值不明显</span><br><span class="line">    - df.plot.bar() # barplot, stacked=True, 堆叠</span><br><span class="line">    - df.plot.barh() # 绘制水平的barplot</span><br><span class="line">    - df.plot.hist(bins = 20) # 绘制直方图,单维度</span><br><span class="line">    - df.plot.box() # 对每列去看一些分布outlier</span><br><span class="line">    - df.plot.area # 堆叠区域图</span><br><span class="line">    - df.plot.scatter(x=&apos;a&apos;, y=&apos;b&apos;) # 散点图</span><br><span class="line">    - df.plot.pie(subplots=True) # 绘制带图例的饼图</span><br><span class="line">    </span><br><span class="line">2. matplotlib 绘图</span><br><span class="line">    - plt.rcParams[&apos;figure.figsize&apos;] = (12,8) / plt.figure(figsize=(12,8)) # 设置画布大小</span><br><span class="line">    - ax = plt.plot(x,y,color=&apos;green&apos;, linewidth=&apos;-&apos;, marker=&apos;./*/x&apos;, label=r&apos;$y=cos&#123;x&#125;$&apos;/r&apos;$y=sin&#123;x&#125;$&apos;/r&apos;$y=\sqrt&#123;x&#125;$&apos;) # 绘图</span><br><span class="line">    - ax.spines[&apos;right&apos;].set_color(&apos;none&apos;) # 去掉右边的边框</span><br><span class="line">    - ax.xaxis.set_ticks_position(&apos;bottem&apos;) # ??????????????</span><br><span class="line">    - plt.xticks([2,4,6], [r&apos;a&apos;,r&apos;b&apos;,r&apos;c&apos;]) # 设置坐标轴刻度</span><br><span class="line">    - ax.spines[&apos;bottem&apos;].set_position(&apos;data&apos;, 0)  # 设置坐标轴从0开始</span><br><span class="line">    - plt.xlim(1,3) # 设置坐标位置</span><br><span class="line">    - plt.title() # 标题</span><br><span class="line">    - plt.xlabel(r&apos;xxx&apos;, fontsize=18, labelpad=12.5) # 绘制label, r值的是不转义的,$$值的是markdown格式</span><br><span class="line">    - plt.text(0.8, 0.9, r&apos;$$&apos;, color=&apos;k&apos;, fontsize=15) # 进行注解</span><br><span class="line">    - plt.scatter([8], [8], 50, color=&apos;m&apos;) # 在某个位置,点有多大,颜色是什么</span><br><span class="line">    - plt.annotate(r&apos;$xxx$&apos;, xy=(8,8), xytext=(8.2, 8.2), fontsize=16, color=&apos;m&apos;, arrowprops=dict(arrowstyle=&apos;-&gt;&apos;, connectionstyle=&apos;arc3, rad=0.1&apos;, color=&apos;m&apos;)) # 对某个点进行注解, 进行加箭头等等</span><br><span class="line">    - plt.grid(True) # 网格线 </span><br><span class="line">    - plt.plot(x, y) # xy应为np array,如果是pandas那么可以通过values进行取值转换</span><br><span class="line">3. matplotlib 绘图case</span><br><span class="line">    - 文件解压</span><br><span class="line">        x = zipfile.ZipFile(xxx, &apos;r&apos;) # 解压文件夹</span><br><span class="line">        x.extractall(&apos;xxxdir&apos;) # 解压到某个文件夹下</span><br><span class="line">        x.close() # 记得关闭</span><br><span class="line">    - matplotlib.rc(&apos;figure&apos;, figsize=(14,7)) # 设置一下图片尺寸</span><br><span class="line">    - matplotlib.rc(&apos;font&apos;, size=14) # 设置字体</span><br><span class="line">    - matplotlib.rc(&apos;axes.spines&apos;, top=False, right=False) # 设置边线</span><br><span class="line">    - matplotlib.rc(&apos;axes&apos;, grid=False) # 设置网格</span><br><span class="line">    - matplotlib.rc(&apos;axes&apos;, facecolor=&apos;white&apos;) # 设置颜色</span><br><span class="line">    - fig,ax含义</span><br><span class="line">        fig,ax = plt.subplots() # 创建绘图对象之后对ax进行操作，相当于先fig=plt.figure()再ax=fig.add_subplot(1,1,1)</span><br><span class="line">        https://blog.csdn.net/htuhxf/article/details/82986440</span><br><span class="line">    - ax.fill_between(x, low, upper, alpha=) # 对回归进行置信度绘制</span><br><span class="line">    - ax2 = ax1.twinx() # 共享同一个x轴</span><br><span class="line">    - ax2.spines[&apos;right&apos;].set_visible(True) # 对右侧坐标轴进行设置,得到相应的图</span><br><span class="line">    - 图的使用</span><br><span class="line">        关联分析:散点图,曲线图,置信区间曲线图,双坐标曲线图</span><br><span class="line">        分布分析:堆叠直方图, 密度图</span><br><span class="line">        组间分析:柱状图(带errorbar),boxplot,这个需要多看看,</span><br><span class="line">        </span><br><span class="line"> 4. seaborn 绘图</span><br><span class="line">    - 引入seaborn的同时也要引入matplotlib因为,是底层</span><br><span class="line">    - 颜色设置</span><br><span class="line">        sns.set(color_codes=True) # 一些集成的颜色</span><br><span class="line">        https://seaborn.pydata.org/tutorial/color_palettes.html</span><br><span class="line">    - sns.displot(x, kde=True, bins=20, rug=True, fit=stats.gamma) # histgram加密度线,样本分布情况, 拟合某些分布fit</span><br><span class="line">    - sns.kdeplot # 类似于上面的,kde是每个样本用正态分布画,如果样本多,高度就高,之后再做归一化</span><br><span class="line">    - sns.jointplot(x,y,data) # 绘制带有histgram以及散点图的图，两个变量</span><br><span class="line">    - sns.pairplot(df) # 直接绘制各个列之间的散点图以及对应的histgram，多个变量</span><br><span class="line">    - scatter plot的密度版</span><br><span class="line">        with sns.axes_style(&apos;ticks&apos;):</span><br><span class="line">            sns.jointplot(x,y,data, kind=&apos;hex&apos;/&apos;kde&apos;,color=&apos;m&apos;) #相当于对点很多的时候,六角箱图就能体现出点的多少,kde是等高线,密度联合分布</span><br><span class="line">    - 多图绘制1</span><br><span class="line">        g = sns.PairGrik(df) # 各个列混合,产出n*n个格子</span><br><span class="line">        g.map_diag(sns.kdeplot) # 对角线绘制</span><br><span class="line">        g.map_offdiag(sns.kdeplot, cmap=&apos;Blues_d&apos;, n_levels=20) # 绘制对角线是kde密度图其他为等高线的图</span><br><span class="line">    - 多图绘制2</span><br><span class="line">        g = FaceGrid(row=[..],aspect=1.5, data=)</span><br><span class="line">        g.map(sns.boxplot, x, y, hue, hue_order=[], ...)</span><br><span class="line">    - 多图绘制3</span><br><span class="line">        g = sns.PairGrid(data, x_vars=[], y_vars=[], aspect=0.5, size=3.5)</span><br><span class="line">        g.map(sns.violinplot, palette=&apos;bright&apos;) # x_vars数量*y_vars数量个子图，然后每个子图都绘制violinplot</span><br><span class="line">    - 关联分析 sns.lmplot</span><br><span class="line">        · sns.lmplot(x, y, data) # 散点图+线性回归,95%置信区间,适用于连续值</span><br><span class="line">        · sns.lmplot(x, y, data, x_jitter=0.08) # 左右抖动, 点如果离得近,会把点左右抖动开,适用于离散值</span><br><span class="line">        · sns.lmplot(x, y, data, x_estimator=np.mean, ci=95, scatter_kws=&#123;&apos;s&apos;:80&#125;, order=2, robust=True) # 对于离散值还可以这样操作,先求均值和95置信区间,之后再进行拟合, scatter_kws对点进行操作,order是说对数据点进行二次方的分布,而不是线性分布,robust打开的作用是踢除异常点,然后再进行绘制图</span><br><span class="line">        · sns.lmplot(x, y, data, x_estimator=np.mean, ci=95, scatter_kws=&#123;&apos;s&apos;:80&#125;, order=1, robust=True, logistic=True) # 相当于是说对二值化的数据进行logistic回归拟合,sigmoid拟合</span><br><span class="line">        · sns.lmplot(x, y, data, hue, col, row, col_wrap, aspect=0.5) # 散点图.线性回归,95%置信区间,适用于连续值,hue进行分组类似于pandas里面的groupby, hue变量一定是个离散变量, col也可以加一个变量,可以把图分成多列,row可以多行,如果row,col以及hue都指定,那么相当于在pandas里面groupby三个内容,col_wrap用于之指定每个col中的绘图数量</span><br><span class="line">    - sns.residplot() # 残差图</span><br><span class="line">    - sns.barplot(x,y,hue,ci=None)  # 是否打开置信区间</span><br><span class="line">    - sns.stripplot(x, y, data, jitter =True) # 基于x为离散数据的,类似于散点图的boxplot</span><br><span class="line">    - sns.swarmplot(x, y, data) #  蜂群图，类似于小提琴图的点版</span><br><span class="line">    - sns.boxplot()</span><br><span class="line">    - sns.violinplot(bw) # 属于kde以及boxplot的组合，既看了单变量分布，也看了各变量之间的差异</span><br><span class="line">    - sns.violinplot(split=True， hue， inner=&apos;stick&apos;) # split将hue为两个类型的进行拼接绘制小提琴图，stick，每个样本绘制竖线</span><br><span class="line">    - sns.countplot(x, data) # 绘制离散变量数量分布，类似于value_counts()，类似于barplot但是使用的统计量是数量</span><br><span class="line">    - sns.pointplot(x, y, hue) # 查看离散变量x以及hue在离散变量y上的差别，使用均值，画点</span><br><span class="line">    - sns.factorplot(x, y, hue, col, data, kind=&apos;swarm&apos;) # 是一种泛化的绘图函数</span><br><span class="line">    - a.savefig(&apos;xx&apos;) # 进行图片存储 plt函数</span><br></pre></td></tr></table></figure>


      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/mumpy/">mumpy</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/pandas/">pandas</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/seaborn/">seaborn</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-python基础知识整理" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/07/20/python基础知识整理/" class="article-date">
      <time datetime="2019-07-20T06:17:41.000Z" itemprop="datePublished">2019-07-20</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/07/20/python基础知识整理/">python基础知识整理</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>#Canda环境安装以及包管理</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">清华镜像下载https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/</span><br><span class="line">命令行启动jupyter notebook或点击快捷图标方式启动</span><br><span class="line">conda list <span class="comment"># 查看所在环境的安装的包</span></span><br><span class="line">conda upgrade --all <span class="comment"># 对包进行更新</span></span><br><span class="line">spyder <span class="comment"># 启动anaconda中的IDE</span></span><br><span class="line">conda install numpy pandas <span class="comment"># 在某个环境下能够安装某些Python包</span></span><br><span class="line">conda install numpy=<span class="number">1.10</span> <span class="comment"># 安装特定版本的包</span></span><br><span class="line">conda remove &lt; package_name &gt; <span class="comment"># 删除包</span></span><br><span class="line">conda env list <span class="comment"># 列出当前机器上创建的虚拟环境</span></span><br><span class="line">conda create -n env1 python=<span class="number">2.7</span> <span class="comment"># 创建一个名为env1的环境然后在其中安装python2.7</span></span><br><span class="line">conda create -n env1 numpy <span class="comment"># 创建一个名为env1的环境然后在其中安装numpy</span></span><br><span class="line">source activate env1 <span class="comment"># 进入env1虚拟环境，在window上不用加source</span></span><br><span class="line">source deactivate <span class="comment"># 离开环境</span></span><br><span class="line">conda install -n py27 ipykernel <span class="comment"># 在虚拟环境py27下安装ipykernel</span></span><br><span class="line">python -m ipykernel install --user --name py27 --display-name <span class="string">"python2"</span> <span class="comment"># 在py27环境内安装ipykernel并在菜单里命名为python2</span></span><br><span class="line">conda env remove -n py27 <span class="comment"># 移除py27的虚拟环境</span></span><br><span class="line">conda install jupyter notebook <span class="comment"># 在conda环境中安装jupyter notebook</span></span><br><span class="line">%matplotlib <span class="comment"># jupyter notebook中已交互式方式实现matplotlib的绘图</span></span><br><span class="line">%matplotlib inline <span class="comment"># 不跳出，直接内嵌在web中</span></span><br></pre></td></tr></table></figure>

<h1 id="jupyter-notebook常用配置"><a href="#jupyter-notebook常用配置" class="headerlink" title="jupyter notebook常用配置"></a>jupyter notebook常用配置</h1><h2 id="notebook中的magic开关"><a href="#notebook中的magic开关" class="headerlink" title="notebook中的magic开关"></a>notebook中的magic开关</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">为实现一些快捷操作，提升效率。notebook中提供magic开关，能极大的优化使用notebook的体验。</span><br><span class="line">magic开关分为两大类：%line magic &amp; %%cell magic</span><br></pre></td></tr></table></figure>

<p>​        </p>
<h2 id="magic开关总览"><a href="#magic开关总览" class="headerlink" title="magic开关总览"></a>magic开关总览</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">%quickref<span class="comment"># 所有magic命令 </span></span><br><span class="line">%lsmagic<span class="comment"># 打印所有magic命令</span></span><br><span class="line"></span><br><span class="line">%config ZMQInteractiveShell.ast_node_interactivity=<span class="string">'all'</span>/<span class="string">'last_expr'</span></span><br><span class="line">%pprint <span class="comment"># 打印所有结果,保证每次执行都输出,默认只输出最后一个内容</span></span><br><span class="line">%config ZMQInteractiveShell可以查看可选择的输出类型</span><br><span class="line">或者执行这个命令保证多输出</span><br><span class="line"><span class="keyword">from</span> IPython.core.interactiveshell <span class="keyword">import</span> InteractiveShell</span><br><span class="line">InteractiveShell.ast_node_interactivity = <span class="string">'all'</span>/<span class="string">'last_expr'</span></span><br><span class="line"></span><br><span class="line"> %%整个cell magic</span><br><span class="line"> %%writefile test.py <span class="comment"># 将cell中的命令写入文件test.py</span></span><br><span class="line"> %%timeit代码计时</span><br><span class="line"> %%bash <span class="comment"># 在cell内可以执行bash命令</span></span><br><span class="line"> %%writefile xx.py <span class="comment"># 把整个cell中的内容输入到xx.py中,如果新加内容可以%%writefile -a xx.py</span></span><br><span class="line"></span><br><span class="line"> %line magic命令</span><br><span class="line"> %matplotline inline <span class="comment"># 在jupyter内打印图片</span></span><br><span class="line"> %run utils.ipynb <span class="comment"># 执行本地的utils.ipynb文件,进行配置</span></span><br><span class="line"></span><br><span class="line"> line magic和cell magic区别就在于line magic只在一行有效,cell magic在多行都有效</span><br><span class="line"> 具体参考:https://gispark.readthedocs.io/zh_CN/latest/pystart/jupyter_magics.html</span><br></pre></td></tr></table></figure>

<h2 id="Jupyter-notebook扩展"><a href="#Jupyter-notebook扩展" class="headerlink" title="Jupyter notebook扩展"></a>Jupyter notebook扩展</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">jupyter_contrib_nbextensions</span><br><span class="line">直接安装官网conda命令安装即可</span><br><span class="line">conda install jupyter notebook</span><br><span class="line">conda install -c conda-forge jupyter_contrib_nbextensions </span><br><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple autopep8 </span><br><span class="line">pip安装加速镜像:https://www.cnblogs.com/microman/p/6107879.html</span><br><span class="line">jupyter 使用参考资料:https://zhuanlan.zhihu.com/p/33105153</span><br><span class="line">jupyter extension 参考资料:https://zhuanlan.zhihu.com/p/52890101</span><br></pre></td></tr></table></figure>

<h3 id="jupyter-使用linux命令"><a href="#jupyter-使用linux命令" class="headerlink" title="jupyter 使用linux命令"></a>jupyter 使用linux命令</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!head -n 5 xx.txt # 直接通过jupyter行使linux命令</span><br></pre></td></tr></table></figure>

<h1 id="python"><a href="#python" class="headerlink" title="python"></a>python</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">python语言是一种面向对象、动态数据类型的解释型语言</span><br><span class="line">1.运行方式</span><br><span class="line">    解释运行:直接py脚本运行</span><br><span class="line">    交互运行:jupyter输入一个输出一个</span><br><span class="line"></span><br><span class="line">2.命名规则:</span><br><span class="line">    常量大写，下划线隔开单词</span><br><span class="line">    类用驼峰命名</span><br><span class="line">     del xx 删除变量xx</span><br><span class="line"></span><br><span class="line">3.操作优先级：</span><br><span class="line">    函数调用，寻址，下标</span><br><span class="line">    幂运算</span><br><span class="line">    翻转运算符</span><br><span class="line">    正负号</span><br><span class="line">    * / %</span><br><span class="line">    - + </span><br><span class="line">4.赋值</span><br><span class="line">    多重赋值:a=b=10相当于a=10,b=10</span><br><span class="line">    多元赋值 a,b,c = 1,2,3</span><br><span class="line">    交换赋值 a,b = b,a # 指针</span><br><span class="line"></span><br><span class="line">5.解包(需要拓展 参考:https://zhuanlan.zhihu.com/p/33896402?utm_source=wechat_session&amp;utm_medium=social&amp;s_r=0)</span><br><span class="line">    l1 = [1,2,3,4,5,&apos;6&apos;]; a,b,*c,d = l1</span><br><span class="line">    l1=[1,2,3,4];b=&apos;sdaad&apos;;[*l1,*b]</span><br><span class="line">    b,=[[3,4,5]] # 逗号解包 </span><br><span class="line"></span><br><span class="line">6.python进制及基本类型</span><br><span class="line">    bin() 二进制</span><br><span class="line">    oct() 八进制</span><br><span class="line">    hex() 十六进制</span><br><span class="line"></span><br><span class="line">    float(&apos;inf&apos;) 正无穷</span><br></pre></td></tr></table></figure>

<h2 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#行内注释</span><br><span class="line">&quot;&quot;&quot; &quot;&quot;&quot;多行注释</span><br><span class="line">？内省，显示对象的通用信息</span><br><span class="line">？？内省，显示出大部分函数的源代码</span><br><span class="line">help()显示一个对象的帮助文档</span><br><span class="line">%timeit 魔法命令，计算语句的平均执行时间</span><br><span class="line">type（x）查看变量x的数据类型</span><br><span class="line">in(x) 将变量x的数据类型转换为整型</span><br><span class="line">isinstance(x,float)检测变量x是否为浮点型，返回一个布尔型数值</span><br></pre></td></tr></table></figure>

<p>##字符串</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">s=u&quot; &quot;定义Unicode字符串</span><br><span class="line">s=r&quot; &quot;定义原始字符串，避免字符串中的字符串转义，在正则表达式中经常使用到</span><br><span class="line">len(s)返回s字符串的字数</span><br><span class="line">s.lower()字母全部转为小写</span><br><span class="line">s.upper()字母全部转为大写</span><br><span class="line">s.capitalize()将字符串s中的首个字符转换为大写，其余部分转换为小写</span><br><span class="line">s.replace(&apos;k&apos;,&apos;l&apos;)使用字符&quot;l&quot;替换掉s中所有的字符&quot;k&quot;,返回结果是cooldata</span><br><span class="line">s.strip()去掉s最前面和最后面的空格</span><br><span class="line">s.split(&quot;\t&quot;)使用制表符&quot;\t&quot;分割字符串</span><br><span class="line">&apos;%s is No.%d&apos;%(s,1)格式化</span><br><span class="line">&apos;&#123;&#125; is No.&#123;&#125;&apos;.format(s,1)格式化</span><br></pre></td></tr></table></figure>

<h2 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">list()空列表</span><br><span class="line">l[-1]返回列表的最后一个元素</span><br><span class="line">l[1:3]返回列表的第二个和第三个元素</span><br><span class="line">len(l)返回列表长度</span><br><span class="line">l[::-1]将列表进行逆序排列</span><br><span class="line">l.reverse()将列表进行逆序排列</span><br><span class="line">l.insert(1,&quot;b&quot;)在指定的索引位置插入&apos;b&apos;</span><br><span class="line">l.append()在列表末尾添加元素</span><br><span class="line">l.extend()等价于&quot;1+L&quot;，将列表L中的元素依次添加到1的末尾</span><br><span class="line">l.remove()删除列表中的某个元素</span><br><span class="line">l.pop()等价于del l[]，删除列表中对应索引位置的元素</span><br><span class="line">&quot; &quot;.join([&apos;&apos;c,&apos;o&apos;,&apos;o&apos;,&apos;k&apos;])将列表中的各个字符串元素用空格连接起来并转换为字符串，返回结果为cook</span><br></pre></td></tr></table></figure>

<h2 id="条件判断和循环语句"><a href="#条件判断和循环语句" class="headerlink" title="条件判断和循环语句"></a>条件判断和循环语句</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">if condition1:</span><br><span class="line">		statement1</span><br><span class="line">elif condition2:</span><br><span class="line">		statement2</span><br><span class="line">else:</span><br><span class="line">		statement3</span><br><span class="line">		</span><br><span class="line">for item in sequence:</span><br><span class="line">		statement</span><br><span class="line">		</span><br><span class="line">while condition:</span><br><span class="line">		statement</span><br><span class="line">		</span><br><span class="line">range(5)产生一个从0到5且间隔为1的整数列表[0，1，2，3，4]</span><br><span class="line">break从最内层for循环或while循环中跳出</span><br><span class="line">continue继续执行下一次循环</span><br><span class="line">pass占位符</span><br></pre></td></tr></table></figure>

<h2 id="enumerate（）and-zip（）"><a href="#enumerate（）and-zip（）" class="headerlink" title="enumerate（）and zip（）"></a>enumerate（）and zip（）</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">for i,item in emumerate(l)在每一次循环时取出索引号和相应的值分别赋给和item</span><br><span class="line">s=&#123;item**2 for item in l&#125;集合推导式，对l中的每一个元素取平方得到的新集合</span><br><span class="line">D=&#123;key:value for key,value in zip(l,k)&#125;字典推导式，通过zip()函数将两个列表l和k中的元素组成键对并形成字典</span><br><span class="line">enumerate(list/set, start=0) # 遍历元素，start指定从哪个数字作为开始下标</span><br><span class="line">c = list(zip(a,b))</span><br><span class="line">c = set(zip(a,b))</span><br><span class="line">c = dict(zip(a,b))</span><br><span class="line">list(zip(*c)) # 解压</span><br></pre></td></tr></table></figure>

<h2 id="推导式"><a href="#推导式" class="headerlink" title="推导式"></a>推导式</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">L=[item**2 for item in l]列表推导式，对l中每一个元素取平方得到新的列表</span><br><span class="line">S=&#123;item**2 for item in l&#125;集合推导式，对l中的每一个元素取平方得到新的集合</span><br><span class="line">D=&#123;key:value for key,value in zip(l,k)&#125;字典推导式，通过zip()函数将两个列表l和k中的元素组成键值对并形成字典</span><br><span class="line">[i for i in range(30) if 1%2==0] # 取0-29之间偶数</span><br><span class="line">[function(i) for i in range(30) if 1%2==0] # function可以自己定义</span><br><span class="line">[ x**2 if x%2 ==0 else x**3 for x in range(10)] # 两个条件</span><br></pre></td></tr></table></figure>

<h2 id="文件读写"><a href="#文件读写" class="headerlink" title="文件读写"></a>文件读写</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">读取文件</span><br><span class="line">f=open(filename,mode)返回一个文件对象f，读文件&quot;mode=r&quot;,写文件&quot;mode=w&quot;</span><br><span class="line">f.read(size)返回包含前size个字符的字符串</span><br><span class="line">f.readline()每次读取一行，返回该行字符串</span><br><span class="line">f.readlines()返回包含每个文件内容的列表，列表的元素为文件的每一行内容所构成的字符串</span><br><span class="line">f.close()关闭文件并释放它所占用的系统资源</span><br><span class="line">with open(&quot;aa.txt&quot;,&quot;r&quot;) as f:</span><br><span class="line">		content = f.readlines()</span><br><span class="line">在with主体块语句执行完后，自动关闭文件并释放占用的系统资源</span><br><span class="line">import csv</span><br><span class="line">f=open(&quot;aa.csv&quot;,&quot;r&quot;)</span><br><span class="line">csvreader = csv.reader(f)</span><br><span class="line">content_list=list(csvreader)</span><br><span class="line">读取csv文件，并把数据存储为一个嵌套列表(列表的元素扔是一个对象)content_list</span><br><span class="line"></span><br><span class="line">写入文件</span><br><span class="line">f.write(s)</span><br><span class="line">print(s,file=f)</span><br><span class="line">两种等价的方式，将字符串s写入文件对象f中</span><br></pre></td></tr></table></figure>

<h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def sum(a,b=1)</span><br><span class="line">		return a+b</span><br><span class="line">def sum(*args,**kwargs)不定长参数，*args接收包含多个位置参数的元组，**kwargs接收包含多个关键字参数的字典。</span><br><span class="line">obj.methodname一个方法是一个&quot;属于&quot;对象并被命名为obj.methodname的函数</span><br></pre></td></tr></table></figure>

<h2 id="map-和lambda"><a href="#map-和lambda" class="headerlink" title="map()和lambda()"></a>map()和lambda()</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">map(func,sequence)将函数依次作用在序列的每个元素上，把结果作为一个新的序列返回。</span><br><span class="line">lambda a,b:a+b匿名函数，正常函数定义的语法糖</span><br><span class="line">lambda [参数列表]:表达式</span><br><span class="line">例如: sum = lambda x,y:x+y # 可以有多个参数,返回只能有一个式子</span><br><span class="line">可以作为一个函数的参数赋给另外一个参数</span><br><span class="line">当然普通函数也可以作为参数传入</span><br><span class="line">a = [&#123;&apos;name&apos;:&apos;ss&apos;,&apos;age&apos;:10&#125;,&#123;&apos;name&apos;:&apos;yy&apos;,&apos;age&apos;:7&#125;,&#123;&apos;name&apos;:&apos;zz&apos;,&apos;age&apos;:15&#125;] # 将匿名函数作为参数传入第三方函数的参数</span><br><span class="line">a.sort(key=lambda x:x[&apos;age&apos;]) # sort方法需要传入一个key，这个key可以作为排序依据，lambda可以提取每个元素，并对元素排列</span><br><span class="line">a.sort(key=lambda x:x[&apos;age&apos;]， reverse=True) # 降序</span><br></pre></td></tr></table></figure>

<h2 id="包模块"><a href="#包模块" class="headerlink" title="包模块"></a>包模块</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">包是一个文件夹</span><br><span class="line">模块是不同的python文件</span><br><span class="line">import package.module.func()</span><br><span class="line">import package1.module1, package2.module1 # 多个模块调用</span><br><span class="line">import package1.module1 as p1m1 # 对模块进行重命名使用</span><br><span class="line">from package.module import func1 # 调用某个包某个模块的某个函数</span><br><span class="line">import sys;sys.path # 搜索模块路径，包含当前文件夹</span><br><span class="line">package.module.__file__ # 可以确定当前的模块所在的路径</span><br><span class="line">__init__.py  #在包被加载的时候，会被执行。在一个包下面可以有也可以没有__init__.py</span><br><span class="line">from package import * # 引用包下面所有的模块都加载，自动搜索是不会发生的，</span><br><span class="line">    需要我们在__init__.py下进行定义才可以实现,定义的内容是__all__=[&quot;module1&quot;,&quot;module2&quot;],</span><br><span class="line">    将package下的module1和module2都加载进来</span><br><span class="line">    如果想直接加载某个函数，在__init__.py里面加入from .module1 import func1, __all__=[&quot;func1&quot;]</span><br><span class="line">    这样修改完之后，可以直接from package import *，然后直接调用func1即可，不用带package.module</span><br><span class="line">    restart kernel</span><br><span class="line">如果想要直接引用包,如：import package,这样的话，需要一定要有__init__.py，否则会在打印package.__file__的时候报错。</span><br><span class="line">注意import package和from package import *效果相同</span><br></pre></td></tr></table></figure>

<h2 id="Counter"><a href="#Counter" class="headerlink" title="Counter"></a>Counter</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">字典的继承类</span><br><span class="line">set dict list tuple 作为key</span><br><span class="line">from collection import Counter # 导入</span><br><span class="line">cnt = Counter()</span><br><span class="line">for i in [1,1,2,2,2,3]:</span><br><span class="line">    cnt[i] += 1</span><br><span class="line">print cnt</span><br><span class="line">如果用key的话会报错先做第一次初始化才行</span><br><span class="line">cnt2 = Counter(alist)  #可以统计每个元素出现的次数（字符串，set,list,）</span><br><span class="line">Counter(cat=4,dogs=8,abc=-1) # 初始化counter次数，或者用dictionary构建</span><br><span class="line">Counter(&#123;&apos;cat&apos;:4,&apos;dogs&apos;:8,&apos;abc&apos;:-1&#125;)</span><br><span class="line">Counter返回一个字典，如果缺失的话会返回0</span><br><span class="line">del cnt2[&apos;xx&apos;]</span><br><span class="line">.values()</span><br><span class="line">list(cnt),set(cnt),dict(cnt) # 前两个只返回key</span><br><span class="line">cnt.most_common()[0] # 对出现次数排序</span><br><span class="line">cnt.clear()</span><br><span class="line">cnt1+cnt2 # 对于key相同的value做加法，如果为0则不保留</span><br><span class="line">cnt1-cnt2 # 对于key相同的value做减法</span><br><span class="line">&amp; # 求key相同value的最小值</span><br><span class="line">| # 求key相同value的最大值</span><br></pre></td></tr></table></figure>

<h2 id="random"><a href="#random" class="headerlink" title="random"></a>random</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import random #引入</span><br><span class="line">random.random() # 0-1</span><br><span class="line">random.uniform(1,10) # 包含1，10的浮点数</span><br><span class="line">random.randint(1,10)  # 包含1，10的整数</span><br><span class="line">random.randrange(0,20,3) # 0-20能被3整除的数</span><br><span class="line">random.choice([1,2,3]) # 随机取元素</span><br><span class="line">random.choice(&quot;qwdwq&quot;) # 随机取元素</span><br><span class="line">random.shuffle([12,3,1,4,2,3]) # 混洗</span><br><span class="line">random.sample([1,2,3,4,5], 3) # 从前面的list中选3个</span><br></pre></td></tr></table></figure>

<h2 id="编码和解码"><a href="#编码和解码" class="headerlink" title="编码和解码"></a>编码和解码</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import chardet</span><br><span class="line">chardet.detect(s)</span><br><span class="line">检测字符串的编码方式</span><br></pre></td></tr></table></figure>

<h2 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">try:</span><br><span class="line">		statement</span><br><span class="line">except:</span><br><span class="line">		pass</span><br><span class="line"></span><br><span class="line">try:</span><br><span class="line">		statement</span><br><span class="line">except Exception as e:</span><br><span class="line">		print(e)</span><br><span class="line"></span><br><span class="line">try:</span><br><span class="line">		statement</span><br><span class="line">except (Exception1,Exception2) as e:</span><br><span class="line">		statement1</span><br><span class="line">else:</span><br><span class="line">		statement2</span><br><span class="line">finally:</span><br><span class="line">		statement3#无论对错都运行</span><br><span class="line">抛出异常</span><br><span class="line">raise Exception(&apos;Oops！&apos;)</span><br><span class="line">assert statement,e#若继续运行代码、否则抛出e的错误提示信息</span><br></pre></td></tr></table></figure>

<h2 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line">raw_s=r&apos;\d&#123;17&#125;[\d|x]|\d&#123;15&#125;&apos;</span><br><span class="line">pattern=re.compile(raw_s)</span><br><span class="line">re.search(pattern,s)</span><br><span class="line">用于匹配身份证号</span><br><span class="line">首先使用原始字符串定义正则表达式；然后编译原始字符为正则表达式Pattern对象；最后对整个字符串s进行模式搜索，如果模式匹配，则返回MatchObject的实例，如果该字符串没有模式匹配，则返回弄none</span><br><span class="line">re.search(r&apos;\d&#123;17&#125;[\d|x]|\d&#123;15&#125;&apos;,s)将Pattern编译过程与搜索过程合二为一</span><br><span class="line">re.match(pattern,s)从字符串s的起始位置匹配一个模式，如果匹配不成功返回None</span><br><span class="line">re.findall(pattern,s)返回一个包含所有满足条件的字串列表</span><br><span class="line">re.sub(pattern,repl,s)使用替换字符串repl替换匹配到的字符串</span><br><span class="line">re.split(pattern,s)利用满足匹配模式的字符串将字符串s分隔开，并返回一个列表</span><br><span class="line"></span><br><span class="line">1.正则表达式的match与search区别</span><br><span class="line">    https://segmentfault.com/a/1190000006736033</span><br><span class="line"></span><br><span class="line">2.贪婪匹配与非贪婪匹配的区别</span><br><span class="line">    https://segmentfault.com/a/1190000002640851</span><br><span class="line">    https://blog.csdn.net/lxcnn/article/details/4756030</span><br><span class="line"></span><br><span class="line">3. 练习网站</span><br><span class="line">    https://alf.nu/RegexGolf 一个正则表达式练习网站</span><br><span class="line">    https://regexr.com/ 验证网站</span><br><span class="line"></span><br><span class="line">4. 单字符匹配</span><br><span class="line">    . # 匹配出点换行符之外的任意字符</span><br><span class="line">    \. # 匹配单个.字符</span><br><span class="line">    [abd] # 匹配a/b/d单个字符</span><br><span class="line">    \d # 匹配数字, 相当于[1,2,3,4,5,6,7,8,9]</span><br><span class="line">    \D # 所有非字符</span><br><span class="line">    \s # 空白符,空格 tab等等</span><br><span class="line">    \S # 所有非空格</span><br><span class="line">    \w # a-z,A-Z,0-9,_</span><br><span class="line">    \W # 除了 a-z,A-Z,0-9</span><br><span class="line"></span><br><span class="line">5. 数量词用来多匹配</span><br><span class="line">    m&#123;2&#125; # 表示匹配两个m</span><br><span class="line">    m&#123;2,4&#125; # 表示匹配2/3/4个m,贪婪匹配</span><br><span class="line">    m* # 0个或者更多个,贪婪匹配</span><br><span class="line">    m+ # 1个或者更多个,贪婪匹配</span><br><span class="line">    m? # 0个或者1个</span><br><span class="line">    ^xx # 文本开头是xx进行匹配</span><br><span class="line">    xxx$ # 对结尾进行匹配</span><br><span class="line">    (re)su(lt) # group</span><br><span class="line"></span><br><span class="line">6. python中的正则表达式步骤</span><br><span class="line">    写一个文本pattern</span><br><span class="line">    进行匹配</span><br><span class="line">    对匹配的文本进行后续操作</span><br><span class="line">    例子:</span><br><span class="line">        import re</span><br><span class="line">        pattern = re.compile(r&apos;hello.*\!&apos;) # hello后面有若干个字符串直到有!</span><br><span class="line">        match = pattern.match(&apos;hello, xxx! how are you?&apos;) # 对文本进行匹配</span><br><span class="line">        if match: # 是否匹配</span><br><span class="line">            print match.group() # 如果匹配上了返回相应的匹配到的部分</span><br><span class="line"></span><br><span class="line">7. 使用实例</span><br><span class="line">    import re</span><br><span class="line">    re.compile(r&quot;&quot;&quot;</span><br><span class="line">    \d+ # 数字部分</span><br><span class="line">    \. # 小数点</span><br><span class="line">    \d # 小数部分</span><br><span class="line">    &quot;&quot;&quot;, re.X)</span><br><span class="line">    这种模式下可以写注解</span><br><span class="line">    re.compile(r&quot;\d+\.\d&quot;) # 与这个模式结果一样</span><br><span class="line"></span><br><span class="line">8.一些命令</span><br><span class="line">    match # 一次匹配结果,从头匹配,开头没有就匹配不上了</span><br><span class="line">    search # 所有匹配到的</span><br><span class="line">    findall # search返回第一个匹配的结果,findall会返回所有的结果</span><br><span class="line">    m=re.match()</span><br><span class="line">    m.string # 匹配的字符串</span><br><span class="line">    m.group(1,2) # 匹配1和2处字符串</span><br><span class="line"></span><br><span class="line">9. 替换和分割</span><br><span class="line">     split也可以使用正则表达式进行分割</span><br><span class="line">        p = re.compile(r&apos;\d+&apos;)</span><br><span class="line">        p.split(&apos;adwdwad1dawwd23dwadw&apos;) # 字符串复杂分割</span><br><span class="line">    sub # 用来替换</span><br><span class="line">        p = re.compile(r&apos;(\w+) (\w+)&apos;)</span><br><span class="line">        p.sub(r&apos;\2 \1&apos;, s) # 匹配字符串并且在匹配到的字符串处进行前后颠倒 </span><br><span class="line">    subn # 和sub类似,只不过除了返回替换的远足之外,还返回相应的替换次数,可以p.subn(afunc, s), afunc可以自己定义</span><br></pre></td></tr></table></figure>

<h2 id="日期处理"><a href="#日期处理" class="headerlink" title="日期处理"></a>日期处理</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from datetime import datetimes</span><br><span class="line">format=&quot;%Y-%m-%d %H:%M:%S&quot;指定日期格式</span><br><span class="line">date_s=datetime.striptime(s,format)</span><br><span class="line">date_s.year</span><br><span class="line">date_s.month</span><br><span class="line">date_s.now()</span><br></pre></td></tr></table></figure>


      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/">python</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
  
</div>
      <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
<footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                <i class="fa fa-copyright"></i> 
                2019 MingmingYe
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank" title="快速、简洁且高效的博客框架">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="简而不减 Hexo 双栏博客主题  v3.5">Yelee</a> by MOxFIVE <i class="fa fa-heart animated infinite pulse"></i>
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" title="本站到访数"><i class="fa fa-user" aria-hidden="true"></i><span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>| </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit"  title="本页阅读量"><i class="fa fa-eye animated infinite pulse" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>

    </div>
    
<script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.2.0/require.min.js"></script>

    <script>
        $(document).ready(function() {
            var iPad = window.navigator.userAgent.indexOf('iPad');
            if (iPad > -1 || $(".left-col").css("display") === "none") {
                var bgColorList = ["#9db3f4", "#414141", "#e5a859", "#f5dfc6", "#c084a0", "#847e72", "#cd8390", "#996731"];
                var bgColor = Math.ceil(Math.random() * (bgColorList.length - 1));
                $("body").css({"background-color": bgColorList[bgColor], "background-size": "cover"});
            }
            else {
                var backgroundnum = 5;
                var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
                $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
            }
        })
    </script>





    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<div class="scroll" id="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" onclick="load$hide();" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    // Open in New Window
    
        var oOpenInNew = {
            
            
            
            
            
            
             archives: ".archive-article-title", 
             miniArchives: "a.post-list-link", 
            
             friends: "#js-friends a", 
             socail: ".social a" 
        }
        for (var x in oOpenInNew) {
            $(oOpenInNew[x]).attr("target", "_blank");
        }
    
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>
</body>
</html>