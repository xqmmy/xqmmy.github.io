<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">

    <!--[if lt IE 9]>
        <style>body {display: none; background: none !important} </style>
        <meta http-equiv="Refresh" Content="0; url=//outdatedbrowser.com/" />
    <![endif]-->

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="format-detection" content="telephone=no">
<meta name="author" content="MingmingYe">


    
    


<meta property="og:type" content="website">
<meta property="og:title" content="Stay hungry, Stay foolish.">
<meta property="og:url" content="http://mmyblog.cn/index.html">
<meta property="og:site_name" content="Stay hungry, Stay foolish.">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Stay hungry, Stay foolish.">

<link rel="apple-touch-icon" href="/apple-touch-icon.png">


    <link rel="alternate" href="/atom.xml" title="Stay hungry, Stay foolish." type="application/atom+xml">



    <link rel="shortcut icon" href="/favicon.png">



    <link href="//cdn.bootcss.com/animate.css/3.5.1/animate.min.css" rel="stylesheet">



    <link href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet">



    <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
    <link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-minimal.css" rel="stylesheet">


<link rel="stylesheet" href="/css/style.css">


    <style> .article { opacity: 0;} </style>


<link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">


<title>Stay hungry, Stay foolish.</title>

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

<script>
    var yiliaConfig = {
        fancybox: true,
        animate: true,
        isHome: true,
        isPost: false,
        isArchive: false,
        isTag: false,
        isCategory: false,
        fancybox_js: "//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js",
        scrollreveal: "//cdn.bootcss.com/scrollReveal.js/3.1.4/scrollreveal.min.js",
        search: true
    }
</script>


    <script>
        yiliaConfig.jquery_ui = [true, "//cdn.bootcss.com/jqueryui/1.10.4/jquery-ui.min.js", "//cdn.bootcss.com/jqueryui/1.10.4/css/jquery-ui.min.css"];
    </script>



    <script> yiliaConfig.rootUrl = "\/";</script>






</head></html>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            <img src="/img/deep.png" class="animated zoomIn">
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">MingmingYe</a></h1>
        </hgroup>

        
        <p class="header-subtitle">å½“ä½ çš„æ‰åæ’‘ä¸èµ·ä½ çš„é‡å¿ƒæ—¶ï¼Œåªæœ‰é™ä¸‹å¿ƒæ¥å¥½å¥½å­¦ä¹ ï¼çºµä½¿å‘½è¿æ³¨å®šæ˜¯ä¸ªæ‰“é…±æ²¹çš„ï¼Œä¹Ÿè¦æ‰“ä¸€ç“¶ä¸åˆ«äººä¸ä¸€æ ·çš„é…±æ²¹ï¼</p>
        

        
            <form id="search-form">
            <input type="text" id="local-search-input" name="q" placeholder="search..." class="search form-control" autocomplete="off" autocorrect="off" searchonload="false" />
            <i class="fa fa-times" onclick="resetSearch()"></i>
            </form>
            <div id="local-search-result"></div>
            <p class='no-result'>No results found <i class='fa fa-spinner fa-pulse'></i></p>
        


        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>èœå•</li>
                        <li>æ ‡ç­¾</li>
                        
                        <li>å‹æƒ…é“¾æ¥</li>
                        
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/">ä¸»é¡µ</a></li>
                        
                            <li><a href="/archives/">æ‰€æœ‰æ–‡ç« </a></li>
                        
                            <li><a href="/tags/">æ ‡ç­¾äº‘</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" href="mailto:878759487@qq.com" title="Email"></a>
                            
                                <a class="fa GitHub" href="#" title="GitHub"></a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/AUC/">AUC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Attention/">Attention</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BERT/">BERT</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BLUE/">BLUE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Beam-search/">Beam search</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN/">CNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CRF/">CRF</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ConvNet/">ConvNet</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ELMo/">ELMo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GPT/">GPT</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GRU/">GRU</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Gradient-Clipping/">Gradient Clipping</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LR/">LR</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LSTM/">LSTM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linear/">Linear</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Parsing/">Parsing</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PyTorch/">PyTorch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/QA/">QA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RNN/">RNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RNN-LSTM/">RNN/LSTM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ROC/">ROC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Recursive-Neural-Networks/">Recursive Neural Networks</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SQuAD-BiDAF/">SQuAD-BiDAF</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SVM/">SVM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Seq2Seq/">Seq2Seq</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TorchText/">TorchText</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Transformer/">Transformer</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Transformer-XL/">Transformer-XL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/XLNet/">XLNet</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/boosting/">boosting</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cbow/">cbow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hierarchical-softmax/">hierarchical softmax</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/inference/">inference</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/jiaba/">jiaba</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/jieba/">jieba</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mumpy/">mumpy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/negative-sampling/">negative sampling</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pandas/">pandas</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pyspark/">pyspark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/seaborn/">seaborn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/skip-gram/">skip-gram</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/softmax/">softmax</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/word-embedding/">word-embedding</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/wxBot/">wxBot</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ä¸­æ–‡åˆ†è¯/">ä¸­æ–‡åˆ†è¯</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ä¼˜åŒ–æ–¹æ³•/">ä¼˜åŒ–æ–¹æ³•</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/å†³ç­–æ ‘/">å†³ç­–æ ‘</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/å›¾ç¥ç»ç½‘ç»œ/">å›¾ç¥ç»ç½‘ç»œ</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/å¾®ç§¯åˆ†/">å¾®ç§¯åˆ†</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/æœ´ç´ è´å¶æ–¯/">æœ´ç´ è´å¶æ–¯</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/æœºå™¨å­¦ä¹ /">æœºå™¨å­¦ä¹ </a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/æ¦‚ç‡/">æ¦‚ç‡</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/æ¨¡å‹è°ƒä¼˜/">æ¨¡å‹è°ƒä¼˜</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/æ­£åˆ™è¡¨è¾¾å¼/">æ­£åˆ™è¡¨è¾¾å¼</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/æ·±åº¦å­¦ä¹ é€ŸæŸ¥è¡¨/">æ·±åº¦å­¦ä¹ é€ŸæŸ¥è¡¨</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ç‰¹å¾å·¥ç¨‹/">ç‰¹å¾å·¥ç¨‹</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ç®—æ³•/">ç®—æ³•</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/çº¿æ€§ä»£æ•°/">çº¿æ€§ä»£æ•°</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ç»Ÿè®¡/">ç»Ÿè®¡</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/èŠå¤©æœºå™¨äºº/">èŠå¤©æœºå™¨äºº</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/èšç±»/">èšç±»</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/è¯­è¨€æ¨¡å‹/">è¯­è¨€æ¨¡å‹</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/è´å¶æ–¯åˆ†ç±»å™¨/">è´å¶æ–¯åˆ†ç±»å™¨</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/é™ç»´/">é™ç»´</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/é›†æˆå­¦ä¹ /">é›†æˆå­¦ä¹ </a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/é¢è¯•/">é¢è¯•</a></li></ul>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a class="main-nav-link switch-friends-link" href="https://hexo.io">Hexo</a>
                    
                      <a class="main-nav-link switch-friends-link" href="https://pages.github.com/">GitHub</a>
                    
                      <a class="main-nav-link switch-friends-link" href="http://mmyblog.cn/">mmy</a>
                    
                    </div>
                </section>
                

                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="å›åˆ°ä¸»é¡µ">MingmingYe</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                <img src="/img/deep.png" class="animated zoomIn">
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="å›åˆ°ä¸»é¡µ">MingmingYe</a></h1>
            </hgroup>
            
            <p class="header-subtitle">å½“ä½ çš„æ‰åæ’‘ä¸èµ·ä½ çš„é‡å¿ƒæ—¶ï¼Œåªæœ‰é™ä¸‹å¿ƒæ¥å¥½å¥½å­¦ä¹ ï¼çºµä½¿å‘½è¿æ³¨å®šæ˜¯ä¸ªæ‰“é…±æ²¹çš„ï¼Œä¹Ÿè¦æ‰“ä¸€ç“¶ä¸åˆ«äººä¸ä¸€æ ·çš„é…±æ²¹ï¼</p>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/">ä¸»é¡µ</a></li>
                
                    <li><a href="/archives/">æ‰€æœ‰æ–‡ç« </a></li>
                
                    <li><a href="/tags/">æ ‡ç­¾äº‘</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" target="_blank" href="mailto:878759487@qq.com" title="Email"></a>
                            
                                <a class="fa GitHub" target="_blank" href="#" title="GitHub"></a>
                            
                        </ul>
            </nav>
        </header>                
    </div>
    <link class="menu-list" tags="æ ‡ç­¾" friends="å‹æƒ…é“¾æ¥" about="å…³äºæˆ‘"/>
</nav>
      <div class="body-wrap">
  
    <article id="post-æ‰©å±•å†…å®¹" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/06/09/æ‰©å±•å†…å®¹/" class="article-date">
      <time datetime="2020-06-09T00:51:03.000Z" itemprop="datePublished">2020-06-09</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/06/09/æ‰©å±•å†…å®¹/">æ‰©å±•å†…å®¹</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h3 id="ç»“æ„åŒ–é¢„æµ‹"><a href="#ç»“æ„åŒ–é¢„æµ‹" class="headerlink" title="ç»“æ„åŒ–é¢„æµ‹"></a><a href="https://shimo.im/docs/t9hjVGDx33vyTDjD" target="_blank" rel="noopener">ç»“æ„åŒ–é¢„æµ‹</a></h3><ul>
<li>éšé©¬å°”ç§‘å¤«æ¨¡å‹ <a href="http://www.cs.columbia.edu/~mcollins/hmms-spring2013.pdf" target="_blank" rel="noopener">http://www.cs.columbia.edu/~mcollins/hmms-spring2013.pdf</a></li>
<li>æœ€å¤§ç†µä¸è¯æ€§æ ‡æ³¨</li>
<li>æ¡ä»¶éšæœºåœº</li>
</ul>
<h3 id="ä¸­æ–‡åˆ†è¯-Chinese-Word-Segmentation"><a href="#ä¸­æ–‡åˆ†è¯-Chinese-Word-Segmentation" class="headerlink" title="ä¸­æ–‡åˆ†è¯ Chinese Word Segmentation"></a>ä¸­æ–‡åˆ†è¯ Chinese Word Segmentation</h3><ul>
<li><a href="https://www.aclweb.org/anthology/D18-1529.pdf" target="_blank" rel="noopener">https://www.aclweb.org/anthology/D18-1529.pdf</a></li>
</ul>
<h3 id="Parsingä¸Recursive-Neural-Networks"><a href="#Parsingä¸Recursive-Neural-Networks" class="headerlink" title="Parsingä¸Recursive Neural Networks"></a>Parsingä¸Recursive Neural Networks</h3><ul>
<li><a href="http://web.stanford.edu/class/cs224n/slides/cs224n-2020-lecture18-TreeRNNs.pdf" target="_blank" rel="noopener">http://web.stanford.edu/class/cs224n/slides/cs224n-2020-lecture18-TreeRNNs.pdf</a></li>
<li><a href="http://web.stanford.edu/class/cs224n/slides/cs224n-2020-lecture05-dep-parsing.pdf" target="_blank" rel="noopener">http://web.stanford.edu/class/cs224n/slides/cs224n-2020-lecture05-dep-parsing.pdf</a></li>
</ul>
<h3 id="å›¾ç¥ç»ç½‘ç»œ"><a href="#å›¾ç¥ç»ç½‘ç»œ" class="headerlink" title="å›¾ç¥ç»ç½‘ç»œ"></a>å›¾ç¥ç»ç½‘ç»œ</h3><ul>
<li>GCN: <a href="https://arxiv.org/pdf/1609.02907.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1609.02907.pdf</a></li>
<li>GCN for relational graph: <a href="https://arxiv.org/pdf/1703.06103.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1703.06103.pdf</a></li>
</ul>
<h3 id="Data-to-Text-æ–‡æœ¬ç”Ÿæˆ"><a href="#Data-to-Text-æ–‡æœ¬ç”Ÿæˆ" class="headerlink" title="Data to Text æ–‡æœ¬ç”Ÿæˆ"></a>Data to Text æ–‡æœ¬ç”Ÿæˆ</h3><ul>
<li>GCNç”Ÿæˆæ–‡æœ¬ <a href="https://arxiv.org/pdf/1810.09995v1.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1810.09995v1.pdf</a></li>
</ul>
<h3 id="çŸ¥è¯†å›¾è°±ç›¸å…³é—®é¢˜"><a href="#çŸ¥è¯†å›¾è°±ç›¸å…³é—®é¢˜" class="headerlink" title="çŸ¥è¯†å›¾è°±ç›¸å…³é—®é¢˜"></a><a href="https://shimo.im/docs/9pwCHPwXxcGHRrxh" target="_blank" rel="noopener">çŸ¥è¯†å›¾è°±ç›¸å…³é—®é¢˜</a></h3>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/NLP/">NLP</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Parsing/">Parsing</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Recursive-Neural-Networks/">Recursive Neural Networks</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ä¸­æ–‡åˆ†è¯/">ä¸­æ–‡åˆ†è¯</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/å›¾ç¥ç»ç½‘ç»œ/">å›¾ç¥ç»ç½‘ç»œ</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
  
</article>










  
    <article id="post-XLNet" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/06/09/XLNet/" class="article-date">
      <time datetime="2020-06-09T00:33:08.000Z" itemprop="datePublished">2020-06-09</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/06/09/XLNet/">XLNet</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h2 id="Transformer-XL-Attentive-Language-Models-Beyond-a-Fixed-Length-Context"><a href="#Transformer-XL-Attentive-Language-Models-Beyond-a-Fixed-Length-Context" class="headerlink" title="Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context"></a>Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context</h2><p><a href="https://arxiv.org/pdf/1901.02860.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1901.02860.pdf</a></p>
<p>ç›¸è¾ƒäºä¼ ç»Ÿtransformer decoderï¼Œå¼•å…¥ä¸¤ä¸ªæ–°æ¨¡å—</p>
<ul>
<li>segment-level recurrence mechanism</li>
</ul>
<p><img src="https://uploader.shimo.im/f/DpNe30kuahkbOeW5.png!thumbnail" alt="img"></p>
<ul>
<li><p>a novel positional encoding scheme</p>
</li>
<li><p>è€ƒè™‘æˆ‘ä»¬åœ¨attentionæœºåˆ¶ä¸­å¦‚ä½•ä½¿ç”¨positional encoding</p>
</li>
</ul>
<p>(E_{x_i}^T+U_i^T)W_q^TW_kE_{x_j}U_j</p>
<p><img src="https://uploader.shimo.im/f/5zNU9yZQtQMClNiY.png!thumbnail" alt="img"></p>
<ul>
<li><p>Rä»–ä»¬é‡‡ç”¨çš„æ˜¯transformerå½“ä¸­çš„positional encoding</p>
</li>
<li><p>uå’Œvæ˜¯éœ€è¦è®­ç»ƒçš„æ¨¡å‹å‚æ•°</p>
</li>
</ul>
<p>æœ€ç»ˆTransformer XLæ¨¡å‹</p>
<p><img src="https://uploader.shimo.im/f/Nm1uk49MIjUys1aK.png!thumbnail" alt="img"></p>
<p>ä»£ç </p>
<p><a href="https://github.com/kimiyoung/transformer-xl" target="_blank" rel="noopener">https://github.com/kimiyoung/transformer-xl</a></p>
<h2 id="XLNet-Generalized-Autoregressive-Pretraining-for-Language-Understanding"><a href="#XLNet-Generalized-Autoregressive-Pretraining-for-Language-Understanding" class="headerlink" title="XLNet: Generalized Autoregressive Pretraining for Language Understanding"></a>XLNet: Generalized Autoregressive Pretraining for Language Understanding</h2><p><a href="https://arxiv.org/pdf/1906.08237.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1906.08237.pdf</a></p>
<p>èƒŒæ™¯çŸ¥è¯†</p>
<ul>
<li><p>è‡ªå›å½’è¯­è¨€æ¨¡å‹ï¼ˆAutoregressive Language Modelï¼‰ï¼šé‡‡ç”¨ä»å·¦å¾€å³æˆ–ä»å³å¾€å·¦çš„è¯­è¨€æ¨¡å‹ï¼Œæ ¹æ®ä¸Šæ–‡é¢„æµ‹ä¸‹æ–‡ã€‚</p>
</li>
<li><p>ç¼ºç‚¹ï¼šåªåˆ©ç”¨äº†é¢„æµ‹å•è¯å·¦è¾¹æˆ–å³è¾¹çš„ä¿¡æ¯ï¼Œæ— æ³•åŒæ—¶åˆ©ç”¨ä¸¤è¾¹çš„ä¿¡æ¯ã€‚ELMoåœ¨ä¸€å®šç¨‹åº¦ä¸Šè§£å†³äº†è¿™ä¸ªé—®é¢˜ã€‚</p>
</li>
<li><p><img src="https://uploader.shimo.im/f/cpfGbeRfzf8c1ga8.png!thumbnail" alt="img"></p>
</li>
<li><p>è‡ªç¼–ç æ¨¡å‹ï¼ˆDenoising Auto Encoder, DAEï¼‰ï¼šåœ¨è¾“å…¥ä¸­éšæœºmaskä¸€äº›å•è¯ï¼Œåˆ©ç”¨ä¸Šä¸‹æ–‡æ¥é¢„æµ‹è¢«maskæ‰çš„å•è¯ã€‚BERTé‡‡ç”¨äº†è¿™ä¸€æ€è·¯ã€‚</p>
</li>
<li><p><img src="https://uploader.shimo.im/f/za1FnG3zHdsbm5gD.png!thumbnail" alt="img"></p>
</li>
</ul>
<p>ä¸¤ä¸ªæ¨¡å‹çš„é—®é¢˜</p>
<p><img src="https://uploader.shimo.im/f/A1rO6rAR1nAQqqvu.png!thumbnail" alt="img"></p>
<p>XLNetçš„ç›®æ ‡æ˜¯èåˆä»¥ä¸Šä¸¤ç§æ¨¡å‹çš„ä¼˜ç‚¹ï¼Œè§£å†³å®ƒä»¬å„è‡ªå­˜åœ¨çš„é—®é¢˜ã€‚</p>
<p>XLNetæ¨¡å‹ï¼šPermutation Language Modeling</p>
<p><img src="https://uploader.shimo.im/f/LdaKeEgG8XwH3iNj.png!thumbnail" alt="img"></p>
<p>Two-Stream Self-Attention</p>
<p><img src="https://uploader.shimo.im/f/TdQVsxOeYMoakBW0.png!thumbnail" alt="img"></p>
<p><img src="https://uploader.shimo.im/f/iLMqF1WinQI6wOsW.png!thumbnail" alt="img"></p>
<p>å‚è€ƒèµ„æ–™</p>
<p><a href="https://zhuanlan.zhihu.com/p/70257427" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/70257427</a></p>
<p>ä»£ç </p>
<p><a href="https://github.com/zihangdai/xlnet" target="_blank" rel="noopener">https://github.com/zihangdai/xlnet</a></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/NLP/">NLP</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/word-embedding/">word-embedding</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
  
</article>










  
    <article id="post-PyTorch" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/06/08/PyTorch/" class="article-date">
      <time datetime="2020-06-08T11:12:06.000Z" itemprop="datePublished">2020-06-08</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/06/08/PyTorch/">PyTorch</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="ä»€ä¹ˆæ˜¯PyTorch"><a href="#ä»€ä¹ˆæ˜¯PyTorch" class="headerlink" title="ä»€ä¹ˆæ˜¯PyTorch?"></a>ä»€ä¹ˆæ˜¯PyTorch?</h1><p>PyTorchæ˜¯ä¸€ä¸ªåŸºäºPythonçš„ç§‘å­¦è®¡ç®—åº“ï¼Œå®ƒæœ‰ä»¥ä¸‹ç‰¹ç‚¹:</p>
<ul>
<li>ç±»ä¼¼äºNumPyï¼Œä½†æ˜¯å®ƒå¯ä»¥ä½¿ç”¨GPU</li>
<li>å¯ä»¥ç”¨å®ƒå®šä¹‰æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå¯ä»¥çµæ´»åœ°è¿›è¡Œæ·±åº¦å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒå’Œä½¿ç”¨</li>
</ul>
<h2 id="Tensors"><a href="#Tensors" class="headerlink" title="Tensors"></a>Tensors</h2><p>Tensorç±»ä¼¼ä¸NumPyçš„ndarrayï¼Œå”¯ä¸€çš„åŒºåˆ«æ˜¯Tensorå¯ä»¥åœ¨GPUä¸ŠåŠ é€Ÿè¿ç®—ã€‚</p>
<p>In [2]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br></pre></td></tr></table></figure>

<p>æ„é€ ä¸€ä¸ªæœªåˆå§‹åŒ–çš„5x3çŸ©é˜µ:</p>
<p>In [4]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.empty(5,3)</span><br><span class="line">x</span><br></pre></td></tr></table></figure>

<p>Out[4]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 0.0000e+00, -8.5899e+09,  0.0000e+00],</span><br><span class="line">        [-8.5899e+09,         nan,  0.0000e+00],</span><br><span class="line">        [ 2.7002e-06,  1.8119e+02,  1.2141e+01],</span><br><span class="line">        [ 7.8503e+02,  6.7504e-07,  6.5200e-10],</span><br><span class="line">        [ 2.9537e-06,  1.7186e-04,         nan]])</span><br></pre></td></tr></table></figure>

<p>æ„å»ºä¸€ä¸ªéšæœºåˆå§‹åŒ–çš„çŸ©é˜µ:</p>
<p>In [5]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.rand(5,3)</span><br><span class="line">x</span><br></pre></td></tr></table></figure>

<p>Out[5]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0.4628, 0.7432, 0.9785],</span><br><span class="line">        [0.2068, 0.4441, 0.9176],</span><br><span class="line">        [0.1027, 0.5275, 0.3884],</span><br><span class="line">        [0.9380, 0.2113, 0.2839],</span><br><span class="line">        [0.0094, 0.4001, 0.6483]])</span><br></pre></td></tr></table></figure>

<p>æ„å»ºä¸€ä¸ªå…¨éƒ¨ä¸º0ï¼Œç±»å‹ä¸ºlongçš„çŸ©é˜µ:</p>
<p>In [8]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.zeros(5,3,dtype=torch.long)</span><br><span class="line">x</span><br></pre></td></tr></table></figure>

<p>Out[8]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0, 0, 0],</span><br><span class="line">        [0, 0, 0],</span><br><span class="line">        [0, 0, 0],</span><br><span class="line">        [0, 0, 0],</span><br><span class="line">        [0, 0, 0]])</span><br></pre></td></tr></table></figure>

<p>In [11]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.zeros(5,3).long()</span><br><span class="line">x.dtype</span><br></pre></td></tr></table></figure>

<p>Out[11]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.int64</span><br></pre></td></tr></table></figure>

<p>ä»æ•°æ®ç›´æ¥ç›´æ¥æ„å»ºtensor:</p>
<p>In [12]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([5.5,3])</span><br><span class="line">x</span><br></pre></td></tr></table></figure>

<p>Out[12]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([5.5000, 3.0000])</span><br></pre></td></tr></table></figure>

<p>ä¹Ÿå¯ä»¥ä»ä¸€ä¸ªå·²æœ‰çš„tensoræ„å»ºä¸€ä¸ªtensorã€‚è¿™äº›æ–¹æ³•ä¼šé‡ç”¨åŸæ¥tensorçš„ç‰¹å¾ï¼Œä¾‹å¦‚ï¼Œæ•°æ®ç±»å‹ï¼Œé™¤éæä¾›æ–°çš„æ•°æ®ã€‚</p>
<p>In [16]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = x.new_ones(5,3, dtype=torch.double)</span><br><span class="line">x</span><br></pre></td></tr></table></figure>

<p>Out[16]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[1., 1., 1.],</span><br><span class="line">        [1., 1., 1.],</span><br><span class="line">        [1., 1., 1.],</span><br><span class="line">        [1., 1., 1.],</span><br><span class="line">        [1., 1., 1.]], dtype=torch.float64)</span><br></pre></td></tr></table></figure>

<p>In [17]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn_like(x, dtype=torch.float)</span><br><span class="line">x</span><br></pre></td></tr></table></figure>

<p>Out[17]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 0.2411, -0.3961, -0.9206],</span><br><span class="line">        [-0.0508,  0.2653,  0.4685],</span><br><span class="line">        [ 0.5368, -0.3606, -0.0073],</span><br><span class="line">        [ 0.3383,  0.6826,  1.7368],</span><br><span class="line">        [-0.0811, -0.6957, -0.4566]])</span><br></pre></td></tr></table></figure>

<p>å¾—åˆ°tensorçš„å½¢çŠ¶:</p>
<p>In [20]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x.shape</span><br></pre></td></tr></table></figure>

<p>Out[20]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([5, 3])</span><br></pre></td></tr></table></figure>

<h4 id="æ³¨æ„"><a href="#æ³¨æ„" class="headerlink" title="æ³¨æ„"></a>æ³¨æ„</h4><p><code>torch.Size</code> è¿”å›çš„æ˜¯ä¸€ä¸ªtuple</p>
<p>Operations</p>
<p>æœ‰å¾ˆå¤šç§tensorè¿ç®—ã€‚æˆ‘ä»¬å…ˆä»‹ç»åŠ æ³•è¿ç®—ã€‚</p>
<p>In [21]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y = torch.rand(5,3)</span><br><span class="line">y</span><br></pre></td></tr></table></figure>

<p>Out[21]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0.9456, 0.3996, 0.1981],</span><br><span class="line">        [0.8728, 0.7097, 0.3721],</span><br><span class="line">        [0.7489, 0.9502, 0.6241],</span><br><span class="line">        [0.5176, 0.0200, 0.5130],</span><br><span class="line">        [0.3552, 0.2710, 0.7392]])</span><br></pre></td></tr></table></figure>

<p>In [23]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x + y</span><br></pre></td></tr></table></figure>

<p>Out[23]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 1.1866,  0.0035, -0.7225],</span><br><span class="line">        [ 0.8220,  0.9750,  0.8406],</span><br><span class="line">        [ 1.2857,  0.5896,  0.6168],</span><br><span class="line">        [ 0.8559,  0.7026,  2.2498],</span><br><span class="line">        [ 0.2741, -0.4248,  0.2826]])</span><br></pre></td></tr></table></figure>

<p>å¦ä¸€ç§ç€åŠ æ³•çš„å†™æ³•</p>
<p>In [24]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.add(x, y)</span><br></pre></td></tr></table></figure>

<p>Out[24]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 1.1866,  0.0035, -0.7225],</span><br><span class="line">        [ 0.8220,  0.9750,  0.8406],</span><br><span class="line">        [ 1.2857,  0.5896,  0.6168],</span><br><span class="line">        [ 0.8559,  0.7026,  2.2498],</span><br><span class="line">        [ 0.2741, -0.4248,  0.2826]])</span><br></pre></td></tr></table></figure>

<p>åŠ æ³•ï¼šæŠŠè¾“å‡ºä½œä¸ºä¸€ä¸ªå˜é‡</p>
<p>In [26]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">result = torch.empty(5,3)</span><br><span class="line">torch.add(x, y, out=result)</span><br><span class="line"># result = x + y</span><br><span class="line">result</span><br></pre></td></tr></table></figure>

<p>Out[26]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 1.1866,  0.0035, -0.7225],</span><br><span class="line">        [ 0.8220,  0.9750,  0.8406],</span><br><span class="line">        [ 1.2857,  0.5896,  0.6168],</span><br><span class="line">        [ 0.8559,  0.7026,  2.2498],</span><br><span class="line">        [ 0.2741, -0.4248,  0.2826]])</span><br></pre></td></tr></table></figure>

<p>in-placeåŠ æ³•</p>
<p>In [28]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y.add_(x)</span><br><span class="line">y</span><br></pre></td></tr></table></figure>

<p>Out[28]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 1.1866,  0.0035, -0.7225],</span><br><span class="line">        [ 0.8220,  0.9750,  0.8406],</span><br><span class="line">        [ 1.2857,  0.5896,  0.6168],</span><br><span class="line">        [ 0.8559,  0.7026,  2.2498],</span><br><span class="line">        [ 0.2741, -0.4248,  0.2826]])</span><br></pre></td></tr></table></figure>

<h4 id="æ³¨æ„-1"><a href="#æ³¨æ„-1" class="headerlink" title="æ³¨æ„"></a>æ³¨æ„</h4><p>ä»»ä½•in-placeçš„è¿ç®—éƒ½ä¼šä»¥<code>_</code>ç»“å°¾ã€‚ ä¸¾ä¾‹æ¥è¯´ï¼š<code>x.copy_(y)</code>, <code>x.t_()</code>, ä¼šæ”¹å˜ <code>x</code>ã€‚</p>
<p>å„ç§ç±»ä¼¼NumPyçš„indexingéƒ½å¯ä»¥åœ¨PyTorch tensorä¸Šé¢ä½¿ç”¨ã€‚</p>
<p>In [31]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x[1:, 1:]</span><br></pre></td></tr></table></figure>

<p>Out[31]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 0.2653,  0.4685],</span><br><span class="line">        [-0.3606, -0.0073],</span><br><span class="line">        [ 0.6826,  1.7368],</span><br><span class="line">        [-0.6957, -0.4566]])</span><br></pre></td></tr></table></figure>

<p>Resizing: å¦‚æœä½ å¸Œæœ›resize/reshapeä¸€ä¸ªtensorï¼Œå¯ä»¥ä½¿ç”¨<code>torch.view</code>ï¼š</p>
<p>In [39]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(4,4)</span><br><span class="line">y = x.view(16)</span><br><span class="line">z = x.view(-1,8)</span><br><span class="line">z</span><br></pre></td></tr></table></figure>

<p>Out[39]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([[-0.5683,  1.3885, -2.0829, -0.7613, -1.9115,  0.3732, -0.2055, -1.2300],</span><br><span class="line">        [-0.2612, -0.4682, -1.0596,  0.7447,  0.7603, -0.4281,  0.5495,  0.1025]])</span><br></pre></td></tr></table></figure>

<p>å¦‚æœä½ æœ‰ä¸€ä¸ªåªæœ‰ä¸€ä¸ªå…ƒç´ çš„tensorï¼Œä½¿ç”¨<code>.item()</code>æ–¹æ³•å¯ä»¥æŠŠé‡Œé¢çš„valueå˜æˆPythonæ•°å€¼ã€‚</p>
<p>In [40]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(1)</span><br><span class="line">x</span><br></pre></td></tr></table></figure>

<p>Out[40]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([-1.1493])</span><br></pre></td></tr></table></figure>

<p>In [44]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x.item()</span><br></pre></td></tr></table></figure>

<p>Out[44]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-1.1493233442306519</span><br></pre></td></tr></table></figure>

<p>In [48]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">z.transpose(1,0)</span><br></pre></td></tr></table></figure>

<p>Out[48]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tensor([[-0.5683, -0.2612],</span><br><span class="line">        [ 1.3885, -0.4682],</span><br><span class="line">        [-2.0829, -1.0596],</span><br><span class="line">        [-0.7613,  0.7447],</span><br><span class="line">        [-1.9115,  0.7603],</span><br><span class="line">        [ 0.3732, -0.4281],</span><br><span class="line">        [-0.2055,  0.5495],</span><br><span class="line">        [-1.2300,  0.1025]])</span><br></pre></td></tr></table></figure>

<p><strong>æ›´å¤šé˜…è¯»</strong></p>
<p>å„ç§Tensor operations, åŒ…æ‹¬transposing, indexing, slicing, mathematical operations, linear algebra, random numbersåœ¨<code>&lt;https://pytorch.org/docs/torch&gt;</code>.</p>
<h2 id="Numpyå’ŒTensorä¹‹é—´çš„è½¬åŒ–"><a href="#Numpyå’ŒTensorä¹‹é—´çš„è½¬åŒ–" class="headerlink" title="Numpyå’ŒTensorä¹‹é—´çš„è½¬åŒ–"></a>Numpyå’ŒTensorä¹‹é—´çš„è½¬åŒ–</h2><p>åœ¨Torch Tensorå’ŒNumPy arrayä¹‹é—´ç›¸äº’è½¬åŒ–éå¸¸å®¹æ˜“ã€‚</p>
<p>Torch Tensorå’ŒNumPy arrayä¼šå…±äº«å†…å­˜ï¼Œæ‰€ä»¥æ”¹å˜å…¶ä¸­ä¸€é¡¹ä¹Ÿä¼šæ”¹å˜å¦ä¸€é¡¹ã€‚</p>
<p>æŠŠTorch Tensorè½¬å˜æˆNumPy Array</p>
<p>In [49]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = torch.ones(5)</span><br><span class="line">a</span><br></pre></td></tr></table></figure>

<p>Out[49]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([1., 1., 1., 1., 1.])</span><br></pre></td></tr></table></figure>

<p>In [50]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">b = a.numpy()</span><br><span class="line">b</span><br></pre></td></tr></table></figure>

<p>Out[50]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([1., 1., 1., 1., 1.], dtype=float32)</span><br></pre></td></tr></table></figure>

<p>æ”¹å˜numpy arrayé‡Œé¢çš„å€¼ã€‚</p>
<p>In [51]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">b[1] = 2</span><br><span class="line">b</span><br></pre></td></tr></table></figure>

<p>Out[51]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([1., 2., 1., 1., 1.], dtype=float32)</span><br></pre></td></tr></table></figure>

<p>In [52]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a</span><br></pre></td></tr></table></figure>

<p>Out[52]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([1., 2., 1., 1., 1.])</span><br></pre></td></tr></table></figure>

<p>æŠŠNumPy ndarrayè½¬æˆTorch Tensor</p>
<p>In [54]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br></pre></td></tr></table></figure>

<p>In [55]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = np.ones(5)</span><br><span class="line">b = torch.from_numpy(a)</span><br><span class="line">np.add(a, 1, out=a)</span><br><span class="line">print(a)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[2. 2. 2. 2. 2.]</span><br></pre></td></tr></table></figure>

<p>In [56]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">b</span><br></pre></td></tr></table></figure>

<p>Out[56]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([2., 2., 2., 2., 2.], dtype=torch.float64)</span><br></pre></td></tr></table></figure>

<p>æ‰€æœ‰CPUä¸Šçš„Tensoréƒ½æ”¯æŒè½¬æˆnumpyæˆ–è€…ä»numpyè½¬æˆTensorã€‚</p>
<h2 id="CUDA-Tensors"><a href="#CUDA-Tensors" class="headerlink" title="CUDA Tensors"></a>CUDA Tensors</h2><p>ä½¿ç”¨<code>.to</code>æ–¹æ³•ï¼ŒTensorå¯ä»¥è¢«ç§»åŠ¨åˆ°åˆ«çš„deviceä¸Šã€‚</p>
<p>In [60]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    device = torch.device(<span class="string">"cuda"</span>)</span><br><span class="line">    y = torch.ones_like(x, device=device)</span><br><span class="line">    x = x.to(device)</span><br><span class="line">    z = x + y</span><br><span class="line">    print(z)</span><br><span class="line">    print(z.to(<span class="string">"cpu"</span>, torch.double))</span><br></pre></td></tr></table></figure>

<p>Out[60]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">False</span><br></pre></td></tr></table></figure>

<p>In [ ]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y.to(<span class="string">"cpu"</span>).data.numpy()</span><br><span class="line">y.cpu().data.numpy()</span><br></pre></td></tr></table></figure>

<p>In [ ]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = model.cuda()</span><br></pre></td></tr></table></figure>

<h2 id="çƒ­èº«-ç”¨numpyå®ç°ä¸¤å±‚ç¥ç»ç½‘ç»œ"><a href="#çƒ­èº«-ç”¨numpyå®ç°ä¸¤å±‚ç¥ç»ç½‘ç»œ" class="headerlink" title="çƒ­èº«: ç”¨numpyå®ç°ä¸¤å±‚ç¥ç»ç½‘ç»œ"></a>çƒ­èº«: ç”¨numpyå®ç°ä¸¤å±‚ç¥ç»ç½‘ç»œ</h2><p>ä¸€ä¸ªå…¨è¿æ¥ReLUç¥ç»ç½‘ç»œï¼Œä¸€ä¸ªéšè—å±‚ï¼Œæ²¡æœ‰biasã€‚ç”¨æ¥ä»xé¢„æµ‹yï¼Œä½¿ç”¨L2 Lossã€‚</p>
<ul>
<li>â„=ğ‘Š1ğ‘‹h=W1X</li>
<li>ğ‘=ğ‘šğ‘ğ‘¥(0,â„)a=max(0,h)</li>
<li>ğ‘¦â„ğ‘ğ‘¡=ğ‘Š2ğ‘yhat=W2a</li>
</ul>
<p>è¿™ä¸€å®ç°å®Œå…¨ä½¿ç”¨numpyæ¥è®¡ç®—å‰å‘ç¥ç»ç½‘ç»œï¼Œlossï¼Œå’Œåå‘ä¼ æ’­ã€‚</p>
<ul>
<li>forward pass</li>
<li>loss</li>
<li>backward pass</li>
</ul>
<p>numpy ndarrayæ˜¯ä¸€ä¸ªæ™®é€šçš„nç»´arrayã€‚å®ƒä¸çŸ¥é“ä»»ä½•å…³äºæ·±åº¦å­¦ä¹ æˆ–è€…æ¢¯åº¦(gradient)çš„çŸ¥è¯†ï¼Œä¹Ÿä¸çŸ¥é“è®¡ç®—å›¾(computation graph)ï¼Œåªæ˜¯ä¸€ç§ç”¨æ¥è®¡ç®—æ•°å­¦è¿ç®—çš„æ•°æ®ç»“æ„ã€‚</p>
<p>In [ ]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># éšæœºåˆ›å»ºä¸€äº›è®­ç»ƒæ•°æ®</span></span><br><span class="line">x = np.random.randn(N, D_in)</span><br><span class="line">y = np.random.randn(N, D_out)</span><br><span class="line"></span><br><span class="line">w1 = np.random.randn(D_in, H)</span><br><span class="line">w2 = np.random.randn(H, D_out)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass</span></span><br><span class="line">    h = x.dot(w1) <span class="comment"># N * H</span></span><br><span class="line">    h_relu = np.maximum(h, <span class="number">0</span>) <span class="comment"># N * H</span></span><br><span class="line">    y_pred = h_relu.dot(w2) <span class="comment"># N * D_out</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute loss</span></span><br><span class="line">    loss = np.square(y_pred - y).sum()</span><br><span class="line">    print(it, loss)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Backward pass</span></span><br><span class="line">    <span class="comment"># compute the gradient</span></span><br><span class="line">    grad_y_pred = <span class="number">2.0</span> * (y_pred - y)</span><br><span class="line">    grad_w2 = h_relu.T.dot(grad_y_pred)</span><br><span class="line">    grad_h_relu = grad_y_pred.dot(w2.T)</span><br><span class="line">    grad_h = grad_h_relu.copy()</span><br><span class="line">    grad_h[h&lt;<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    grad_w1 = x.T.dot(grad_h)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># update weights of w1 and w2</span></span><br><span class="line">    w1 -= learning_rate * grad_w1</span><br><span class="line">    w2 -= learning_rate * grad_w2</span><br></pre></td></tr></table></figure>

<h2 id="PyTorch-Tensors"><a href="#PyTorch-Tensors" class="headerlink" title="PyTorch: Tensors"></a>PyTorch: Tensors</h2><p>è¿™æ¬¡æˆ‘ä»¬ä½¿ç”¨PyTorch tensorsæ¥åˆ›å»ºå‰å‘ç¥ç»ç½‘ç»œï¼Œè®¡ç®—æŸå¤±ï¼Œä»¥åŠåå‘ä¼ æ’­ã€‚</p>
<p>ä¸€ä¸ªPyTorch Tensorå¾ˆåƒä¸€ä¸ªnumpyçš„ndarrayã€‚ä½†æ˜¯å®ƒå’Œnumpy ndarrayæœ€å¤§çš„åŒºåˆ«æ˜¯ï¼ŒPyTorch Tensorå¯ä»¥åœ¨CPUæˆ–è€…GPUä¸Šè¿ç®—ã€‚å¦‚æœæƒ³è¦åœ¨GPUä¸Šè¿ç®—ï¼Œå°±éœ€è¦æŠŠTensoræ¢æˆcudaç±»å‹ã€‚</p>
<p>In [ ]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># éšæœºåˆ›å»ºä¸€äº›è®­ç»ƒæ•°æ®</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line">w1 = torch.randn(D_in, H)</span><br><span class="line">w2 = torch.randn(H, D_out)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass</span></span><br><span class="line">    h = x.mm(w1) <span class="comment"># N * H</span></span><br><span class="line">    h_relu = h.clamp(min=<span class="number">0</span>) <span class="comment"># N * H</span></span><br><span class="line">    y_pred = h_relu.mm(w2) <span class="comment"># N * D_out</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute loss</span></span><br><span class="line">    loss = (y_pred - y).pow(<span class="number">2</span>).sum().item()</span><br><span class="line">    print(it, loss)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Backward pass</span></span><br><span class="line">    <span class="comment"># compute the gradient</span></span><br><span class="line">    grad_y_pred = <span class="number">2.0</span> * (y_pred - y)</span><br><span class="line">    grad_w2 = h_relu.t().mm(grad_y_pred)</span><br><span class="line">    grad_h_relu = grad_y_pred.mm(w2.t())</span><br><span class="line">    grad_h = grad_h_relu.clone()</span><br><span class="line">    grad_h[h&lt;<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    grad_w1 = x.t().mm(grad_h)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># update weights of w1 and w2</span></span><br><span class="line">    w1 -= learning_rate * grad_w1</span><br><span class="line">    w2 -= learning_rate * grad_w2</span><br></pre></td></tr></table></figure>

<p>ç®€å•çš„autograd</p>
<p>In [72]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor(<span class="number">1.</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">w = torch.tensor(<span class="number">2.</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">b = torch.tensor(<span class="number">3.</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">y = w*x + b <span class="comment"># y = 2*1+3</span></span><br><span class="line"></span><br><span class="line">y.backward()</span><br><span class="line"></span><br><span class="line"><span class="comment"># dy / dw = x</span></span><br><span class="line">print(w.grad)</span><br><span class="line">print(x.grad)</span><br><span class="line">print(b.grad)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor(1.)</span><br><span class="line">tensor(2.)</span><br><span class="line">tensor(1.)</span><br></pre></td></tr></table></figure>

<h2 id="PyTorch-Tensorå’Œautograd"><a href="#PyTorch-Tensorå’Œautograd" class="headerlink" title="PyTorch: Tensorå’Œautograd"></a>PyTorch: Tensorå’Œautograd</h2><p>PyTorchçš„ä¸€ä¸ªé‡è¦åŠŸèƒ½å°±æ˜¯autogradï¼Œä¹Ÿå°±æ˜¯è¯´åªè¦å®šä¹‰äº†forward pass(å‰å‘ç¥ç»ç½‘ç»œ)ï¼Œè®¡ç®—äº†lossä¹‹åï¼ŒPyTorchå¯ä»¥è‡ªåŠ¨æ±‚å¯¼è®¡ç®—æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¢¯åº¦ã€‚</p>
<p>ä¸€ä¸ªPyTorchçš„Tensorè¡¨ç¤ºè®¡ç®—å›¾ä¸­çš„ä¸€ä¸ªèŠ‚ç‚¹ã€‚å¦‚æœ<code>x</code>æ˜¯ä¸€ä¸ªTensorå¹¶ä¸”<code>x.requires_grad=True</code>é‚£ä¹ˆ<code>x.grad</code>æ˜¯å¦ä¸€ä¸ªå‚¨å­˜ç€<code>x</code>å½“å‰æ¢¯åº¦(ç›¸å¯¹äºä¸€ä¸ªscalarï¼Œå¸¸å¸¸æ˜¯loss)çš„å‘é‡ã€‚</p>
<p>In [ ]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># éšæœºåˆ›å»ºä¸€äº›è®­ç»ƒæ•°æ®</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line">w1 = torch.randn(D_in, H, requires_grad=<span class="literal">True</span>)</span><br><span class="line">w2 = torch.randn(H, D_out, requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass</span></span><br><span class="line">    y_pred = x.mm(w1).clamp(min=<span class="number">0</span>).mm(w2)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute loss</span></span><br><span class="line">    loss = (y_pred - y).pow(<span class="number">2</span>).sum() <span class="comment"># computation graph</span></span><br><span class="line">    print(it, loss.item())</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Backward pass</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># update weights of w1 and w2</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        w1 -= learning_rate * w1.grad</span><br><span class="line">        w2 -= learning_rate * w2.grad</span><br><span class="line">        w1.grad.zero_()</span><br><span class="line">        w2.grad.zero_()</span><br></pre></td></tr></table></figure>

<h2 id="PyTorch-nn"><a href="#PyTorch-nn" class="headerlink" title="PyTorch: nn"></a>PyTorch: nn</h2><p>è¿™æ¬¡æˆ‘ä»¬ä½¿ç”¨PyTorchä¸­nnè¿™ä¸ªåº“æ¥æ„å»ºç½‘ç»œã€‚ ç”¨PyTorch autogradæ¥æ„å»ºè®¡ç®—å›¾å’Œè®¡ç®—gradientsï¼Œ ç„¶åPyTorchä¼šå¸®æˆ‘ä»¬è‡ªåŠ¨è®¡ç®—gradientã€‚</p>
<p>In [ ]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># éšæœºåˆ›å»ºä¸€äº›è®­ç»ƒæ•°æ®</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line">model = torch.nn.Sequential(</span><br><span class="line">    torch.nn.Linear(D_in, H, bias=<span class="literal">False</span>), <span class="comment"># w_1 * x + b_1</span></span><br><span class="line">    torch.nn.ReLU(),</span><br><span class="line">    torch.nn.Linear(H, D_out, bias=<span class="literal">False</span>),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">torch.nn.init.normal_(model[<span class="number">0</span>].weight)</span><br><span class="line">torch.nn.init.normal_(model[<span class="number">2</span>].weight)</span><br><span class="line"></span><br><span class="line"><span class="comment"># model = model.cuda()</span></span><br><span class="line"></span><br><span class="line">loss_fn = nn.MSELoss(reduction=<span class="string">'sum'</span>)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass</span></span><br><span class="line">    y_pred = model(x) <span class="comment"># model.forward() </span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute loss</span></span><br><span class="line">    loss = loss_fn(y_pred, y) <span class="comment"># computation graph</span></span><br><span class="line">    print(it, loss.item())</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Backward pass</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># update weights of w1 and w2</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> model.parameters(): <span class="comment"># param (tensor, grad)</span></span><br><span class="line">            param -= learning_rate * param.grad</span><br><span class="line">            </span><br><span class="line">    model.zero_grad()</span><br></pre></td></tr></table></figure>

<p>In [113]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model[0].weight</span><br></pre></td></tr></table></figure>

<p>Out[113]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Parameter containing:</span><br><span class="line">tensor([[-0.0218,  0.0212,  0.0243,  ...,  0.0230,  0.0247,  0.0168],</span><br><span class="line">        [-0.0144,  0.0177, -0.0221,  ...,  0.0161,  0.0098, -0.0172],</span><br><span class="line">        [ 0.0086, -0.0122, -0.0298,  ..., -0.0236, -0.0187,  0.0295],</span><br><span class="line">        ...,</span><br><span class="line">        [ 0.0266, -0.0008, -0.0141,  ...,  0.0018,  0.0319, -0.0129],</span><br><span class="line">        [ 0.0296, -0.0005,  0.0115,  ...,  0.0141, -0.0088, -0.0106],</span><br><span class="line">        [ 0.0289, -0.0077,  0.0239,  ..., -0.0166, -0.0156, -0.0235]],</span><br><span class="line">       requires_grad=True)</span><br></pre></td></tr></table></figure>

<h2 id="PyTorch-optim"><a href="#PyTorch-optim" class="headerlink" title="PyTorch: optim"></a>PyTorch: optim</h2><p>è¿™ä¸€æ¬¡æˆ‘ä»¬ä¸å†æ‰‹åŠ¨æ›´æ–°æ¨¡å‹çš„weights,è€Œæ˜¯ä½¿ç”¨optimè¿™ä¸ªåŒ…æ¥å¸®åŠ©æˆ‘ä»¬æ›´æ–°å‚æ•°ã€‚ optimè¿™ä¸ªpackageæä¾›äº†å„ç§ä¸åŒçš„æ¨¡å‹ä¼˜åŒ–æ–¹æ³•ï¼ŒåŒ…æ‹¬SGD+momentum, RMSProp, Adamç­‰ç­‰ã€‚</p>
<p>In [ ]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># éšæœºåˆ›å»ºä¸€äº›è®­ç»ƒæ•°æ®</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line">model = torch.nn.Sequential(</span><br><span class="line">    torch.nn.Linear(D_in, H, bias=<span class="literal">False</span>), <span class="comment"># w_1 * x + b_1</span></span><br><span class="line">    torch.nn.ReLU(),</span><br><span class="line">    torch.nn.Linear(H, D_out, bias=<span class="literal">False</span>),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">torch.nn.init.normal_(model[<span class="number">0</span>].weight)</span><br><span class="line">torch.nn.init.normal_(model[<span class="number">2</span>].weight)</span><br><span class="line"></span><br><span class="line"><span class="comment"># model = model.cuda()</span></span><br><span class="line"></span><br><span class="line">loss_fn = nn.MSELoss(reduction=<span class="string">'sum'</span>)</span><br><span class="line"><span class="comment"># learning_rate = 1e-4</span></span><br><span class="line"><span class="comment"># optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)</span></span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass</span></span><br><span class="line">    y_pred = model(x) <span class="comment"># model.forward() </span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute loss</span></span><br><span class="line">    loss = loss_fn(y_pred, y) <span class="comment"># computation graph</span></span><br><span class="line">    print(it, loss.item())</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    <span class="comment"># Backward pass</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># update model parameters</span></span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure>

<h2 id="PyTorch-è‡ªå®šä¹‰-nn-Modules"><a href="#PyTorch-è‡ªå®šä¹‰-nn-Modules" class="headerlink" title="PyTorch: è‡ªå®šä¹‰ nn Modules"></a>PyTorch: è‡ªå®šä¹‰ nn Modules</h2><p>æˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸€ä¸ªæ¨¡å‹ï¼Œè¿™ä¸ªæ¨¡å‹ç»§æ‰¿è‡ªnn.Moduleç±»ã€‚å¦‚æœéœ€è¦å®šä¹‰ä¸€ä¸ªæ¯”Sequentialæ¨¡å‹æ›´åŠ å¤æ‚çš„æ¨¡å‹ï¼Œå°±éœ€è¦å®šä¹‰nn.Moduleæ¨¡å‹ã€‚</p>
<p>In [ ]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># éšæœºåˆ›å»ºä¸€äº›è®­ç»ƒæ•°æ®</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TwoLayerNet</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, D_in, H, D_out)</span>:</span></span><br><span class="line">        super(TwoLayerNet, self).__init__()</span><br><span class="line">        <span class="comment"># define the model architecture</span></span><br><span class="line">        self.linear1 = torch.nn.Linear(D_in, H, bias=<span class="literal">False</span>)</span><br><span class="line">        self.linear2 = torch.nn.Linear(H, D_out, bias=<span class="literal">False</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        y_pred = self.linear2(self.linear1(x).clamp(min=<span class="number">0</span>))</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br><span class="line">model = TwoLayerNet(D_in, H, D_out)</span><br><span class="line">loss_fn = nn.MSELoss(reduction=<span class="string">'sum'</span>)</span><br><span class="line">learning_rate = <span class="number">1e-4</span></span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass</span></span><br><span class="line">    y_pred = model(x) <span class="comment"># model.forward() </span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute loss</span></span><br><span class="line">    loss = loss_fn(y_pred, y) <span class="comment"># computation graph</span></span><br><span class="line">    print(it, loss.item())</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    <span class="comment"># Backward pass</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># update model parameters</span></span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure>

<p>In [ ]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/æœºå™¨å­¦ä¹ /">æœºå™¨å­¦ä¹ </a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/PyTorch/">PyTorch</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
  
</article>










  
    <article id="post-æœ´ç´ è´å¶æ–¯" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/06/08/æœ´ç´ è´å¶æ–¯/" class="article-date">
      <time datetime="2020-06-08T10:24:41.000Z" itemprop="datePublished">2020-06-08</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/06/08/æœ´ç´ è´å¶æ–¯/">æœ´ç´ è´å¶æ–¯</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="æœ´ç´ è´å¶æ–¯"><a href="#æœ´ç´ è´å¶æ–¯" class="headerlink" title="æœ´ç´ è´å¶æ–¯"></a>æœ´ç´ è´å¶æ–¯</h1><h2 id="1-å¼•è¨€"><a href="#1-å¼•è¨€" class="headerlink" title="1. å¼•è¨€"></a>1. å¼•è¨€</h2><p>è´å¶æ–¯æ–¹æ³•æ˜¯ä¸€ä¸ªå†å²æ‚ ä¹…ï¼Œæœ‰ç€åšå®çš„ç†è®ºåŸºç¡€çš„æ–¹æ³•ï¼ŒåŒæ—¶å¤„ç†å¾ˆå¤šé—®é¢˜æ—¶ç›´æ¥è€Œåˆé«˜æ•ˆï¼Œå¾ˆå¤šé«˜çº§è‡ªç„¶è¯­è¨€å¤„ç†æ¨¡å‹ä¹Ÿå¯ä»¥ä»å®ƒæ¼”åŒ–è€Œæ¥ã€‚å› æ­¤ï¼Œå­¦ä¹ è´å¶æ–¯æ–¹æ³•ï¼Œæ˜¯ç ”ç©¶è‡ªç„¶è¯­è¨€å¤„ç†é—®é¢˜çš„ä¸€ä¸ªéå¸¸å¥½çš„åˆ‡å…¥å£ã€‚</p>
<h2 id="2-è´å¶æ–¯å…¬å¼"><a href="#2-è´å¶æ–¯å…¬å¼" class="headerlink" title="2. è´å¶æ–¯å…¬å¼"></a>2. è´å¶æ–¯å…¬å¼</h2><p>è´å¶æ–¯å…¬å¼å°±ä¸€è¡Œï¼š</p>
<blockquote>
<p>$$<br>P(Y|X)=P(X|Y)P(Y)/P(X)<br>$$</p>
</blockquote>
<p>è€Œå®ƒå…¶å®æ˜¯ç”±ä»¥ä¸‹çš„è”åˆæ¦‚ç‡å…¬å¼æ¨å¯¼å‡ºæ¥ï¼š<br>$$<br>P(Y,X)=P(Y|X)P(X)=P(X|Y)P(Y)<br>$$<br>å…¶ä¸­P(Y)å«åšå…ˆéªŒæ¦‚ç‡ï¼ŒP(Y|X)å«åšåéªŒæ¦‚ç‡ï¼ŒP(Y,X)å«åšè”åˆæ¦‚ç‡ã€‚</p>
<p>æ²¡äº†ï¼Œè´å¶æ–¯æœ€æ ¸å¿ƒçš„å…¬å¼å°±è¿™ä¹ˆäº›ã€‚</p>
<h2 id="3-ç”¨æœºå™¨å­¦ä¹ çš„è§†è§’ç†è§£è´å¶æ–¯å…¬å¼"><a href="#3-ç”¨æœºå™¨å­¦ä¹ çš„è§†è§’ç†è§£è´å¶æ–¯å…¬å¼" class="headerlink" title="3. ç”¨æœºå™¨å­¦ä¹ çš„è§†è§’ç†è§£è´å¶æ–¯å…¬å¼"></a>3. ç”¨æœºå™¨å­¦ä¹ çš„è§†è§’ç†è§£è´å¶æ–¯å…¬å¼</h2><p>åœ¨æœºå™¨å­¦ä¹ çš„è§†è§’ä¸‹ï¼Œæˆ‘ä»¬æŠŠXç†è§£æˆ<strong>â€œå…·æœ‰æŸç‰¹å¾â€</strong>ï¼ŒæŠŠYç†è§£æˆ<strong>â€œç±»åˆ«æ ‡ç­¾â€</strong>(ä¸€èˆ¬æœºå™¨å­¦ä¹ ä¸ºé¢˜ä¸­éƒ½æ˜¯<code>X=&gt;ç‰¹å¾</code>, <code>Y=&gt;ç»“æœ</code>å¯¹å§)ã€‚åœ¨æœ€ç®€å•çš„äºŒåˆ†ç±»é—®é¢˜(<code>æ˜¯</code>ä¸<code>å¦</code>åˆ¤å®š)ä¸‹ï¼Œæˆ‘ä»¬å°†Yç†è§£æˆ<strong>â€œå±äºæŸç±»</strong>â€çš„æ ‡ç­¾ã€‚äºæ˜¯è´å¶æ–¯å…¬å¼å°±å˜å½¢æˆäº†ä¸‹é¢çš„æ ·å­:</p>
<blockquote>
<p>P(â€œå±äºæŸç±»â€|â€œå…·æœ‰æŸç‰¹å¾â€)=P(â€œå…·æœ‰æŸç‰¹å¾â€|â€œå±äºæŸç±»â€)P(â€œå±äºæŸç±»â€)P(â€œå…·æœ‰æŸç‰¹å¾â€)</p>
</blockquote>
<p>æˆ‘ä»¬ç®€åŒ–è§£é‡Šä¸€ä¸‹ä¸Šè¿°å…¬å¼ï¼š</p>
<blockquote>
<p>P(â€œå±äºæŸç±»â€|â€œå…·æœ‰æŸç‰¹å¾â€)=åœ¨å·²çŸ¥æŸæ ·æœ¬â€œå…·æœ‰æŸç‰¹å¾â€çš„æ¡ä»¶ä¸‹ï¼Œè¯¥æ ·æœ¬â€œå±äºæŸç±»â€çš„æ¦‚ç‡ã€‚æ‰€ä»¥å«åš<strong>ã€åéªŒæ¦‚ç‡ã€</strong>ã€‚<br>P(â€œå…·æœ‰æŸç‰¹å¾â€|â€œå±äºæŸç±»â€)=åœ¨å·²çŸ¥æŸæ ·æœ¬â€œå±äºæŸç±»â€çš„æ¡ä»¶ä¸‹ï¼Œè¯¥æ ·æœ¬â€œå…·æœ‰æŸç‰¹å¾â€çš„æ¦‚ç‡ã€‚<br>P(â€œå±äºæŸç±»â€)=ï¼ˆåœ¨æœªçŸ¥æŸæ ·æœ¬å…·æœ‰è¯¥â€œå…·æœ‰æŸç‰¹å¾â€çš„æ¡ä»¶ä¸‹ï¼Œï¼‰è¯¥æ ·æœ¬â€œå±äºæŸç±»â€çš„æ¦‚ç‡ã€‚æ‰€ä»¥å«åš<strong>ã€å…ˆéªŒæ¦‚ç‡ã€</strong>ã€‚<br>P(â€œå…·æœ‰æŸç‰¹å¾â€)=(åœ¨æœªçŸ¥æŸæ ·æœ¬â€œå±äºæŸç±»â€çš„æ¡ä»¶ä¸‹ï¼Œ)è¯¥æ ·æœ¬â€œå…·æœ‰æŸç‰¹å¾â€çš„æ¦‚ç‡ã€‚</p>
</blockquote>
<p>è€Œæˆ‘ä»¬äºŒåˆ†ç±»é—®é¢˜çš„æœ€ç»ˆç›®çš„å°±æ˜¯è¦<strong>åˆ¤æ–­P(â€œå±äºæŸç±»â€|â€œå…·æœ‰æŸç‰¹å¾â€)æ˜¯å¦å¤§äº1/2</strong>å°±å¤Ÿäº†ã€‚è´å¶æ–¯æ–¹æ³•æŠŠè®¡ç®—<strong>â€œå…·æœ‰æŸç‰¹å¾çš„æ¡ä»¶ä¸‹å±äºæŸç±»â€</strong>çš„æ¦‚ç‡è½¬æ¢æˆéœ€è¦è®¡ç®—<strong>â€œå±äºæŸç±»çš„æ¡ä»¶ä¸‹å…·æœ‰æŸç‰¹å¾â€</strong>çš„æ¦‚ç‡ï¼Œè€Œåè€…è·å–æ–¹æ³•å°±ç®€å•å¤šäº†ï¼Œæˆ‘ä»¬åªéœ€è¦æ‰¾åˆ°ä¸€äº›åŒ…å«å·²çŸ¥ç‰¹å¾æ ‡ç­¾çš„æ ·æœ¬ï¼Œå³å¯è¿›è¡Œè®­ç»ƒã€‚è€Œæ ·æœ¬çš„ç±»åˆ«æ ‡ç­¾éƒ½æ˜¯æ˜ç¡®çš„ï¼Œæ‰€ä»¥è´å¶æ–¯æ–¹æ³•åœ¨æœºå™¨å­¦ä¹ é‡Œå±äºæœ‰ç›‘ç£å­¦ä¹ æ–¹æ³•ã€‚</p>
<p>è¿™é‡Œå†è¡¥å……ä¸€ä¸‹ï¼Œä¸€èˆ¬<strong>ã€å…ˆéªŒæ¦‚ç‡ã€ã€ã€åéªŒæ¦‚ç‡ã€æ˜¯ç›¸å¯¹</strong>å‡ºç°çš„ï¼Œæ¯”å¦‚P(Y)ä¸P(Y|X)æ˜¯å…³äºYçš„å…ˆéªŒæ¦‚ç‡ä¸åéªŒæ¦‚ç‡ï¼ŒP(X)ä¸P(X|Y)æ˜¯å…³äºXçš„å…ˆéªŒæ¦‚ç‡ä¸åéªŒæ¦‚ç‡ã€‚</p>
<h2 id="4-åƒåœ¾é‚®ä»¶è¯†åˆ«"><a href="#4-åƒåœ¾é‚®ä»¶è¯†åˆ«" class="headerlink" title="4. åƒåœ¾é‚®ä»¶è¯†åˆ«"></a>4. åƒåœ¾é‚®ä»¶è¯†åˆ«</h2><p>ä¸¾ä¸ªä¾‹å­å¥½å•¦ï¼Œæˆ‘ä»¬ç°åœ¨è¦å¯¹é‚®ä»¶è¿›è¡Œåˆ†ç±»ï¼Œè¯†åˆ«åƒåœ¾é‚®ä»¶å’Œæ™®é€šé‚®ä»¶ï¼Œå¦‚æœæˆ‘ä»¬é€‰æ‹©ä½¿ç”¨æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ï¼Œé‚£ç›®æ ‡å°±æ˜¯<strong>åˆ¤æ–­P(â€œåƒåœ¾é‚®ä»¶â€|â€œå…·æœ‰æŸç‰¹å¾â€)æ˜¯å¦å¤§äº1/2</strong>ã€‚ç°åœ¨å‡è®¾æˆ‘ä»¬æœ‰åƒåœ¾é‚®ä»¶å’Œæ­£å¸¸é‚®ä»¶å„1ä¸‡å°ä½œä¸ºè®­ç»ƒé›†ã€‚éœ€è¦åˆ¤æ–­ä»¥ä¸‹è¿™ä¸ªé‚®ä»¶æ˜¯å¦å±äºåƒåœ¾é‚®ä»¶ï¼š</p>
<blockquote>
<p>â€œæˆ‘å¸å¯åŠç†æ­£è§„å‘ç¥¨ï¼ˆä¿çœŸï¼‰17%å¢å€¼ç¨å‘ç¥¨ç‚¹æ•°ä¼˜æƒ ï¼â€</p>
</blockquote>
<p>ä¹Ÿå°±æ˜¯<strong>åˆ¤æ–­æ¦‚ç‡P(â€œåƒåœ¾é‚®ä»¶â€|â€œæˆ‘å¸å¯åŠç†æ­£è§„å‘ç¥¨ï¼ˆä¿çœŸï¼‰17%å¢å€¼ç¨å‘ç¥¨ç‚¹æ•°ä¼˜æƒ ï¼â€)æ˜¯å¦å¤§äº1/2</strong>ã€‚</p>
<p>å’³å’³ï¼Œæœ‰æœ¨æœ‰å‘ç°ï¼Œè½¬æ¢æˆçš„è¿™ä¸ªæ¦‚ç‡ï¼Œè®¡ç®—çš„æ–¹æ³•ï¼šå°±æ˜¯å†™ä¸ªè®¡æ•°å™¨ï¼Œç„¶å+1 +1 +1ç»Ÿè®¡å‡ºæ‰€æœ‰åƒåœ¾é‚®ä»¶å’Œæ­£å¸¸é‚®ä»¶ä¸­å‡ºç°è¿™å¥è¯çš„æ¬¡æ•°å•Šï¼ï¼ï¼å¥½ï¼Œå…·ä½“ç‚¹è¯´ï¼š</p>
<blockquote>
<p>P(â€œåƒåœ¾é‚®ä»¶â€|â€œæˆ‘å¸å¯åŠç†æ­£è§„å‘ç¥¨ï¼ˆä¿çœŸï¼‰17%å¢å€¼ç¨å‘ç¥¨ç‚¹æ•°ä¼˜æƒ ï¼â€) =åƒåœ¾é‚®ä»¶ä¸­å‡ºç°è¿™å¥è¯çš„æ¬¡æ•°åƒåœ¾é‚®ä»¶ä¸­å‡ºç°è¿™å¥è¯çš„æ¬¡æ•°+æ­£å¸¸é‚®ä»¶ä¸­å‡ºç°è¿™å¥è¯çš„æ¬¡æ•°</p>
</blockquote>
<h2 id="5-åˆ†è¯"><a href="#5-åˆ†è¯" class="headerlink" title="5. åˆ†è¯"></a>5. åˆ†è¯</h2><p>ä¸€ä¸ªå¾ˆæ‚²å“€ä½†æ˜¯å¾ˆç°å®çš„ç»“è®ºï¼š <strong>è®­ç»ƒé›†æ˜¯æœ‰é™çš„ï¼Œè€Œå¥å­çš„å¯èƒ½æ€§åˆ™æ˜¯æ— é™çš„ã€‚æ‰€ä»¥è¦†ç›–æ‰€æœ‰å¥å­å¯èƒ½æ€§çš„è®­ç»ƒé›†æ˜¯ä¸å­˜åœ¨çš„ã€‚</strong></p>
<p>æ‰€ä»¥è§£å†³æ–¹æ³•æ˜¯ï¼Ÿ <strong>å¥å­çš„å¯èƒ½æ€§æ— é™ï¼Œä½†æ˜¯è¯è¯­å°±é‚£ä¹ˆäº›ï¼ï¼</strong>æ±‰è¯­å¸¸ç”¨å­—2500ä¸ªï¼Œå¸¸ç”¨è¯è¯­ä¹Ÿå°±56000ä¸ª(ä½ ç»ˆäºæ˜ç™½å°å­¦è¯­æ–‡è€å¸ˆçš„ç”¨å¿ƒè‰¯è‹¦äº†)ã€‚æŒ‰äººä»¬çš„ç»éªŒç†è§£ï¼Œä¸¤å¥è¯æ„æ€ç›¸è¿‘å¹¶ä¸å¼ºæ±‚éå¾—æ¯ä¸ªå­—ã€è¯è¯­éƒ½ä¸€æ ·ã€‚æ¯”å¦‚<strong>â€œæˆ‘å¸å¯åŠç†æ­£è§„å‘ç¥¨ï¼Œ17%å¢å€¼ç¨å‘ç¥¨ç‚¹æ•°ä¼˜æƒ ï¼â€</strong>ï¼Œè¿™å¥è¯å°±æ¯”ä¹‹å‰é‚£å¥è¯å°‘äº†<strong>â€œï¼ˆä¿çœŸï¼‰â€</strong>è¿™ä¸ªè¯ï¼Œä½†æ˜¯æ„æ€åŸºæœ¬ä¸€æ ·ã€‚å¦‚æœæŠŠè¿™äº›æƒ…å†µä¹Ÿè€ƒè™‘è¿›æ¥ï¼Œé‚£æ ·æœ¬æ•°é‡å°±ä¼šå¢åŠ ï¼Œè¿™å°±æ–¹ä¾¿æˆ‘ä»¬è®¡ç®—äº†ã€‚</p>
<p>äºæ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥ä¸æ‹¿å¥å­ä½œä¸ºç‰¹å¾ï¼Œè€Œæ˜¯æ‹¿å¥å­é‡Œé¢çš„è¯è¯­ï¼ˆç»„åˆï¼‰ä½œä¸ºç‰¹å¾å»è€ƒè™‘ã€‚æ¯”å¦‚<strong>â€œæ­£è§„å‘ç¥¨â€</strong>å¯ä»¥ä½œä¸ºä¸€ä¸ªå•ç‹¬çš„è¯è¯­ï¼Œ<strong>â€œå¢å€¼ç¨â€</strong>ä¹Ÿå¯ä»¥ä½œä¸ºä¸€ä¸ªå•ç‹¬çš„è¯è¯­ç­‰ç­‰ã€‚</p>
<blockquote>
<p>å¥å­<strong>â€œæˆ‘å¸å¯åŠç†æ­£è§„å‘ç¥¨ï¼Œ17%å¢å€¼ç¨å‘ç¥¨ç‚¹æ•°ä¼˜æƒ ï¼â€å°±å¯ä»¥å˜æˆï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€,â€œä¿çœŸâ€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œç‚¹æ•°â€,â€œä¼˜æƒ â€)ï¼‰</strong>ã€‚</p>
</blockquote>
<p>äºæ˜¯ä½ æ¥è§¦åˆ°äº†ä¸­æ–‡NLPä¸­ï¼Œæœ€æœ€æœ€é‡è¦çš„æŠ€æœ¯ä¹‹ä¸€ï¼š<strong>åˆ†è¯</strong>ï¼ï¼ï¼ä¹Ÿå°±æ˜¯<strong>æŠŠä¸€æ•´å¥è¯æ‹†åˆ†æˆæ›´ç»†ç²’åº¦çš„è¯è¯­æ¥è¿›è¡Œè¡¨ç¤º</strong>ã€‚å¦å¤–ï¼Œåˆ†è¯ä¹‹å<strong>å»é™¤æ ‡ç‚¹ç¬¦å·ã€æ•°å­—ç”šè‡³æ— å…³æˆåˆ†(åœç”¨è¯)æ˜¯ç‰¹å¾é¢„å¤„ç†ä¸­çš„ä¸€é¡¹æŠ€æœ¯</strong>ã€‚</p>
<p><strong>ä¸­æ–‡åˆ†è¯æ˜¯ä¸€ä¸ªä¸“é—¨çš„æŠ€æœ¯é¢†åŸŸ(æˆ‘ä¸ä¼šå‘Šè¯‰ä½ æŸæœç´¢å¼•æ“å‚ç ç –å·¥æœ‰ä¸“é—¨åšåˆ†è¯çš„ï¼ï¼ï¼)ï¼Œä¸Šè¿‡ä¹‹å‰è¯¾ç¨‹çš„åŒå­¦éƒ½çŸ¥é“pythonæœ‰ä¸€ä¸ªéå¸¸æ–¹ä¾¿çš„åˆ†è¯å·¥å…·jiebaï¼Œå‡å®šæˆ‘ä»¬å·²ç»å®Œæˆåˆ†è¯å·¥ä½œï¼š</strong></p>
<p>æˆ‘ä»¬è§‚å¯Ÿï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€,â€œä¿çœŸâ€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œç‚¹æ•°â€,â€œä¼˜æƒ â€)ï¼Œ<strong>è¿™å¯ä»¥ç†è§£æˆä¸€ä¸ªå‘é‡ï¼šå‘é‡çš„æ¯ä¸€ç»´åº¦éƒ½è¡¨ç¤ºç€è¯¥ç‰¹å¾è¯åœ¨æ–‡æœ¬ä¸­çš„ç‰¹å®šä½ç½®å­˜åœ¨ã€‚è¿™ç§å°†ç‰¹å¾æ‹†åˆ†æˆæ›´å°çš„å•å…ƒï¼Œä¾æ®è¿™äº›æ›´çµæ´»ã€æ›´ç»†ç²’åº¦çš„ç‰¹å¾è¿›è¡Œåˆ¤æ–­çš„æ€ç»´æ–¹å¼ï¼Œåœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸æœºå™¨å­¦ä¹ ä¸­éƒ½æ˜¯éå¸¸å¸¸è§åˆæœ‰æ•ˆçš„ã€‚</strong></p>
<p>å› æ­¤è´å¶æ–¯å…¬å¼å°±å˜æˆäº†ï¼š</p>
<blockquote>
<p>P(â€œåƒåœ¾é‚®ä»¶â€|ï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€,â€œä¿çœŸâ€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œç‚¹æ•°â€,â€œä¼˜æƒ â€)ï¼‰ =P(ï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€,â€œä¿çœŸâ€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œç‚¹æ•°â€,â€œä¼˜æƒ â€)|â€åƒåœ¾é‚®ä»¶â€ï¼‰P(â€œåƒåœ¾é‚®ä»¶â€)P(ï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€,â€œä¿çœŸâ€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œç‚¹æ•°â€,â€œä¼˜æƒ â€))</p>
<p>P(â€œæ­£å¸¸é‚®ä»¶â€|ï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€,â€œä¿çœŸâ€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œç‚¹æ•°â€,â€œä¼˜æƒ â€)ï¼‰ =P(ï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€,â€œä¿çœŸâ€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œç‚¹æ•°â€,â€œä¼˜æƒ â€)|â€æ­£å¸¸é‚®ä»¶â€ï¼‰P(â€œæ­£å¸¸é‚®ä»¶â€)P(ï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€,â€œä¿çœŸâ€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œç‚¹æ•°â€,â€œä¼˜æƒ â€))</p>
</blockquote>
<h2 id="6-æ¡ä»¶ç‹¬ç«‹å‡è®¾"><a href="#6-æ¡ä»¶ç‹¬ç«‹å‡è®¾" class="headerlink" title="6. æ¡ä»¶ç‹¬ç«‹å‡è®¾"></a>6. æ¡ä»¶ç‹¬ç«‹å‡è®¾</h2><p>ä¸‹é¢æˆ‘ä»¬é©¬ä¸Šä¼šçœ‹åˆ°ä¸€ä¸ªéå¸¸ç®€å•ç²—æš´çš„å‡è®¾ã€‚</p>
<p>æ¦‚ç‡P(ï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€,â€œä¿çœŸâ€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œç‚¹æ•°â€,â€œä¼˜æƒ â€)|â€åƒåœ¾é‚®ä»¶â€ï¼‰ä¾æ—§ä¸å¤Ÿå¥½æ±‚ï¼Œæˆ‘ä»¬å¼•è¿›ä¸€ä¸ª<strong>å¾ˆæœ´ç´ çš„è¿‘ä¼¼</strong>ã€‚ä¸ºäº†è®©å…¬å¼æ˜¾å¾—æ›´åŠ ç´§å‡‘ï¼Œæˆ‘ä»¬ä»¤å­—æ¯Sè¡¨ç¤ºâ€œåƒåœ¾é‚®ä»¶â€,ä»¤å­—æ¯Hè¡¨ç¤ºâ€œæ­£å¸¸é‚®ä»¶â€ã€‚è¿‘ä¼¼å…¬å¼å¦‚ä¸‹ï¼š</p>
<blockquote>
<p>P(ï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€,â€œä¿çœŸâ€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œç‚¹æ•°â€,â€œä¼˜æƒ â€)|Sï¼‰<br>=P(â€œæˆ‘â€|Sï¼‰Ã—P(â€œå¸â€|Sï¼‰Ã—P(â€œå¯â€|Sï¼‰Ã—P(â€œåŠç†â€|Sï¼‰Ã—P(â€œæ­£è§„å‘ç¥¨â€|Sï¼‰ Ã—P(â€œä¿çœŸâ€|Sï¼‰Ã—P(â€œå¢å€¼ç¨â€|Sï¼‰Ã—P(â€œå‘ç¥¨â€|Sï¼‰Ã—P(â€œç‚¹æ•°â€|Sï¼‰Ã—P(â€œä¼˜æƒ â€|S)</p>
</blockquote>
<p>è¿™å°±æ˜¯ä¼ è¯´ä¸­çš„<strong>æ¡ä»¶ç‹¬ç«‹å‡è®¾</strong>ã€‚åŸºäºâ€œæ­£å¸¸é‚®ä»¶â€çš„æ¡ä»¶ç‹¬ç«‹å‡è®¾çš„å¼å­ä¸ä¸Šå¼ç±»ä¼¼ï¼Œæ­¤å¤„çœå»ã€‚æ¥ç€ï¼Œå°†æ¡ä»¶ç‹¬ç«‹å‡è®¾ä»£å…¥ä¸Šé¢ä¸¤ä¸ªç›¸åäº‹ä»¶çš„è´å¶æ–¯å…¬å¼ã€‚</p>
<p>äºæ˜¯æˆ‘ä»¬å°±åªéœ€è¦æ¯”è¾ƒä»¥ä¸‹ä¸¤ä¸ªå¼å­çš„å¤§å°ï¼š</p>
<blockquote>
<p>C=P(â€œæˆ‘â€|S)P(â€œå¸â€|S)P(â€œå¯â€|S)P(â€œåŠç†â€|S)P(â€œæ­£è§„å‘ç¥¨â€|S) Ã—P(â€œä¿çœŸâ€|S)P(â€œå¢å€¼ç¨â€|S)P(â€œå‘ç¥¨â€|S)P(â€œç‚¹æ•°â€|S)P(â€œä¼˜æƒ â€|S)P(â€œåƒåœ¾é‚®ä»¶â€) Câ¯â¯â¯â¯=P(â€œæˆ‘â€|H)P(â€œå¸â€|H)P(â€œå¯â€|H)P(â€œåŠç†â€|H)P(â€œæ­£è§„å‘ç¥¨â€|H) Ã—P(â€œä¿çœŸâ€|H)P(â€œå¢å€¼ç¨â€|H)P(â€œå‘ç¥¨â€|H)P(â€œç‚¹æ•°â€|H)P(â€œä¼˜æƒ â€|H)P(â€œæ­£å¸¸é‚®ä»¶â€)</p>
</blockquote>
<p>å‰(wo)å®³(cao)ï¼é…±ç´«å¤„ç†å<strong>å¼å­ä¸­çš„æ¯ä¸€é¡¹éƒ½ç‰¹åˆ«å¥½æ±‚</strong>ï¼åªéœ€è¦<strong>åˆ†åˆ«ç»Ÿè®¡å„ç±»é‚®ä»¶ä¸­è¯¥å…³é”®è¯å‡ºç°çš„æ¦‚ç‡</strong>å°±å¯ä»¥äº†ï¼ï¼ï¼æ¯”å¦‚ï¼š</p>
<blockquote>
<p>P(â€œå‘ç¥¨â€|Sï¼‰=åƒåœ¾é‚®ä»¶ä¸­æ‰€æœ‰â€œå‘ç¥¨â€çš„æ¬¡æ•°åƒåœ¾é‚®ä»¶ä¸­æ‰€æœ‰è¯è¯­çš„æ¬¡æ•°</p>
</blockquote>
<p>ç»Ÿè®¡æ¬¡æ•°éå¸¸æ–¹ä¾¿ï¼Œè€Œä¸”æ ·æœ¬æ•°é‡è¶³å¤Ÿå¤§ï¼Œç®—å‡ºæ¥çš„æ¦‚ç‡æ¯”è¾ƒæ¥è¿‘çœŸå®ã€‚äºæ˜¯åƒåœ¾é‚®ä»¶è¯†åˆ«çš„é—®é¢˜å°±å¯è§£äº†ã€‚</p>
<h2 id="7-æœ´ç´ è´å¶æ–¯-Naive-Bayes-ï¼Œâ€œNaiveâ€åœ¨ä½•å¤„ï¼Ÿ"><a href="#7-æœ´ç´ è´å¶æ–¯-Naive-Bayes-ï¼Œâ€œNaiveâ€åœ¨ä½•å¤„ï¼Ÿ" class="headerlink" title="7. æœ´ç´ è´å¶æ–¯(Naive Bayes)ï¼Œâ€œNaiveâ€åœ¨ä½•å¤„ï¼Ÿ"></a>7. æœ´ç´ è´å¶æ–¯(Naive Bayes)ï¼Œâ€œNaiveâ€åœ¨ä½•å¤„ï¼Ÿ</h2><p><strong>åŠ ä¸Šæ¡ä»¶ç‹¬ç«‹å‡è®¾çš„è´å¶æ–¯æ–¹æ³•å°±æ˜¯æœ´ç´ è´å¶æ–¯æ–¹æ³•ï¼ˆNaive Bayesï¼‰ã€‚</strong> Naiveçš„å‘éŸ³æ˜¯â€œä¹ƒä¸€æ±¡â€ï¼Œæ„æ€æ˜¯â€œæœ´ç´ çš„â€ã€â€œå¹¼ç¨šçš„â€ã€<strong>â€œè ¢è ¢çš„â€</strong>ã€‚å’³å’³ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œå¤§ç¥ä»¬å–åè¯´è¯¥æ–¹æ³•æ˜¯ä¸€ç§æ¯”è¾ƒèŒè ¢çš„æ–¹æ³•ï¼Œä¸ºå•¥ï¼Ÿ</p>
<p>å°†å¥å­ï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€) ä¸­çš„ ï¼ˆâ€œæˆ‘â€,â€œå¸â€ï¼‰ä¸ï¼ˆâ€œæ­£è§„å‘ç¥¨â€ï¼‰è°ƒæ¢ä¸€ä¸‹é¡ºåºï¼Œå°±å˜æˆäº†ä¸€ä¸ªæ–°çš„å¥å­ï¼ˆâ€œæ­£è§„å‘ç¥¨â€,â€œå¯â€,â€œåŠç†â€, â€œæˆ‘â€, â€œå¸â€)ã€‚æ–°å¥å­ä¸æ—§å¥å­çš„æ„æ€å®Œå…¨ä¸åŒã€‚<strong>ä½†ç”±äºä¹˜æ³•äº¤æ¢å¾‹ï¼Œæœ´ç´ è´å¶æ–¯æ–¹æ³•ä¸­ç®—å‡ºæ¥äºŒè€…çš„æ¡ä»¶æ¦‚ç‡å®Œå…¨ä¸€æ ·ï¼</strong>è®¡ç®—è¿‡ç¨‹å¦‚ä¸‹ï¼š</p>
<blockquote>
<p>P(ï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€)|S) =P(â€œæˆ‘â€|S)P(â€œå¸â€|S)P(â€œå¯â€|S)P(â€œåŠç†â€|S)P(â€œæ­£è§„å‘ç¥¨â€|S) =P(â€œæ­£è§„å‘ç¥¨â€|S)P(â€œå¯â€|S)P(â€œåŠç†â€|S)P(â€œæˆ‘â€|S)P(â€œå¸â€|Sï¼‰ =P(ï¼ˆâ€œæ­£è§„å‘ç¥¨â€,â€œå¯â€,â€œåŠç†â€,â€œæˆ‘â€,â€œå¸â€)|S)</p>
</blockquote>
<p><strong>ä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨æœ´ç´ è´å¶æ–¯çœ¼é‡Œï¼Œâ€œæˆ‘å¸å¯åŠç†æ­£è§„å‘ç¥¨â€ä¸â€œæ­£è§„å‘ç¥¨å¯åŠç†æˆ‘å¸â€å®Œå…¨ç›¸åŒã€‚æœ´ç´ è´å¶æ–¯å¤±å»äº†è¯è¯­ä¹‹é—´çš„é¡ºåºä¿¡æ¯ã€‚</strong>è¿™å°±ç›¸å½“äºæŠŠæ‰€æœ‰çš„è¯æ±‡æ‰”è¿›åˆ°ä¸€ä¸ªè¢‹å­é‡Œéšä¾¿æ…å’Œï¼Œè´å¶æ–¯éƒ½è®¤ä¸ºå®ƒä»¬ä¸€æ ·ã€‚å› æ­¤è¿™ç§æƒ…å†µä¹Ÿç§°ä½œ<strong>è¯è¢‹å­æ¨¡å‹(bag of words)</strong>ã€‚</p>
<p><img src="blob:file:///f3e451e8-1f8f-4c4c-b15f-25793dff88ca" alt="è¯è¢‹å­é…å›¾"></p>
<p>è¯è¢‹å­æ¨¡å‹ä¸äººä»¬çš„æ—¥å¸¸ç»éªŒå®Œå…¨ä¸åŒã€‚æ¯”å¦‚ï¼Œåœ¨æ¡ä»¶ç‹¬ç«‹å‡è®¾çš„æƒ…å†µä¸‹ï¼Œ<strong>â€œæ­¦æ¾æ‰“æ­»äº†è€è™â€ä¸â€œè€è™æ‰“æ­»äº†æ­¦æ¾â€è¢«å®ƒè®¤ä½œä¸€ä¸ªæ„æ€äº†ã€‚</strong>æ©ï¼Œæœ´ç´ è´å¶æ–¯å°±æ˜¯è¿™ä¹ˆå•çº¯å’Œç›´æ¥ï¼Œå¯¹æ¯”äºå…¶ä»–åˆ†ç±»å™¨ï¼Œå¥½åƒæ˜¯æ˜¾å¾—æœ‰é‚£ä¹ˆç‚¹èŒè ¢ã€‚</p>
<h2 id="8-ç®€å•é«˜æ•ˆï¼ŒåŠä¸é€†è¢­"><a href="#8-ç®€å•é«˜æ•ˆï¼ŒåŠä¸é€†è¢­" class="headerlink" title="8. ç®€å•é«˜æ•ˆï¼ŒåŠä¸é€†è¢­"></a>8. ç®€å•é«˜æ•ˆï¼ŒåŠä¸é€†è¢­</h2><p>è™½ç„¶è¯´æœ´ç´ è´å¶æ–¯æ–¹æ³•èŒè ¢èŒè ¢çš„ï¼Œä½†å®è·µè¯æ˜åœ¨åƒåœ¾é‚®ä»¶è¯†åˆ«çš„åº”ç”¨è¿˜<strong>ä»¤äººè¯§å¼‚åœ°å¥½</strong>ã€‚Paul Grahamå…ˆç”Ÿè‡ªå·±ç®€å•åšäº†ä¸€ä¸ªæœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ï¼Œ<strong>â€œ1000å°åƒåœ¾é‚®ä»¶èƒ½å¤Ÿè¢«è¿‡æ»¤æ‰995å°ï¼Œå¹¶ä¸”æ²¡æœ‰ä¸€ä¸ªè¯¯åˆ¤â€ã€‚</strong>ï¼ˆPaul Grahamã€Šé»‘å®¢ä¸ç”»å®¶ã€‹ï¼‰</p>
<p>é‚£ä¸ªâ€¦æ•ˆæœä¸ºå•¥å¥½å‘¢ï¼Ÿ</p>
<p>â€œæœ‰äººå¯¹æ­¤æå‡ºäº†ä¸€ä¸ªç†è®ºè§£é‡Šï¼Œå¹¶ä¸”å»ºç«‹äº†ä»€ä¹ˆæ—¶å€™æœ´ç´ è´å¶æ–¯çš„æ•ˆæœèƒ½å¤Ÿç­‰ä»·äºéæœ´ç´ è´å¶æ–¯çš„å……è¦æ¡ä»¶ï¼Œè¿™ä¸ªè§£é‡Šçš„æ ¸å¿ƒå°±æ˜¯ï¼šæœ‰äº›ç‹¬ç«‹å‡è®¾åœ¨å„ä¸ªåˆ†ç±»ä¹‹é—´çš„åˆ†å¸ƒéƒ½æ˜¯å‡åŒ€çš„æ‰€ä»¥å¯¹äºä¼¼ç„¶çš„ç›¸å¯¹å¤§å°ä¸äº§ç”Ÿå½±å“ï¼›å³ä¾¿ä¸æ˜¯å¦‚æ­¤ï¼Œä¹Ÿæœ‰å¾ˆå¤§çš„å¯èƒ½æ€§<strong>å„ä¸ªç‹¬ç«‹å‡è®¾æ‰€äº§ç”Ÿçš„æ¶ˆæå½±å“æˆ–ç§¯æå½±å“äº’ç›¸æŠµæ¶ˆï¼Œæœ€ç»ˆå¯¼è‡´ç»“æœå—åˆ°çš„å½±å“ä¸å¤§</strong>ã€‚å…·ä½“çš„æ•°å­¦å…¬å¼è¯·å‚è€ƒ<a href="http://www.cs.unb.ca/profs/hzhang/publications/FLAIRS04ZhangH.pdf" target="_blank" rel="noopener">è¿™ç¯‡ paper</a>ã€‚â€ï¼ˆåˆ˜æœªé¹ã€Šï¼šå¹³å‡¡è€Œåˆç¥å¥‡çš„è´å¶æ–¯æ–¹æ³•ã€‹ï¼‰</p>
<p>æ©ï¼Œè¿™ä¸ªåˆ†ç±»å™¨ä¸­æœ€ç®€å•ç›´æ¥çœ‹ä¼¼èŒè ¢çš„å°ç›†å‹ã€æœ´ç´ è´å¶æ–¯ã€ï¼Œå®é™…ä¸Šå´æ˜¯<strong>ç®€å•ã€å®ç”¨ã€ä¸”å¼ºå¤§</strong>çš„ã€‚</p>
<h2 id="9-å¤„ç†é‡å¤è¯è¯­çš„ä¸‰ç§æ–¹å¼"><a href="#9-å¤„ç†é‡å¤è¯è¯­çš„ä¸‰ç§æ–¹å¼" class="headerlink" title="9. å¤„ç†é‡å¤è¯è¯­çš„ä¸‰ç§æ–¹å¼"></a>9. å¤„ç†é‡å¤è¯è¯­çš„ä¸‰ç§æ–¹å¼</h2><p>æˆ‘ä»¬<strong>ä¹‹å‰çš„åƒåœ¾é‚®ä»¶å‘é‡ï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€,â€œä¿çœŸâ€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œç‚¹æ•°â€,â€œä¼˜æƒ â€)ï¼Œå…¶ä¸­æ¯ä¸ªè¯éƒ½ä¸é‡å¤ã€‚</strong>è€Œè¿™åœ¨ç°å®ä¸­å…¶å®å¾ˆå°‘è§ã€‚å› ä¸ºå¦‚æœæ–‡æœ¬é•¿åº¦å¢åŠ ï¼Œæˆ–è€…åˆ†è¯æ–¹æ³•æ”¹å˜ï¼Œ<strong>å¿…ç„¶ä¼šæœ‰è®¸å¤šè¯é‡å¤å‡ºç°</strong>ï¼Œå› æ­¤éœ€è¦å¯¹è¿™ç§æƒ…å†µè¿›è¡Œè¿›ä¸€æ­¥æ¢è®¨ã€‚æ¯”å¦‚ä»¥ä¸‹è¿™æ®µé‚®ä»¶ï¼š</p>
<blockquote>
<p>â€œä»£å¼€å‘ç¥¨ã€‚å¢å€¼ç¨å‘ç¥¨ï¼Œæ­£è§„å‘ç¥¨ã€‚â€ åˆ†è¯åä¸ºå‘é‡ï¼š ï¼ˆâ€œä»£å¼€â€,â€œå‘ç¥¨â€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œæ­£è§„â€,â€œå‘ç¥¨â€ï¼‰</p>
</blockquote>
<p>å…¶ä¸­â€œå‘ç¥¨â€é‡å¤äº†ä¸‰æ¬¡ã€‚</p>
<h3 id="9-1-å¤šé¡¹å¼æ¨¡å‹ï¼š"><a href="#9-1-å¤šé¡¹å¼æ¨¡å‹ï¼š" class="headerlink" title="9.1 å¤šé¡¹å¼æ¨¡å‹ï¼š"></a>9.1 å¤šé¡¹å¼æ¨¡å‹ï¼š</h3><p>å¦‚æœæˆ‘ä»¬è€ƒè™‘é‡å¤è¯è¯­çš„æƒ…å†µï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œ<strong>é‡å¤çš„è¯è¯­æˆ‘ä»¬è§†ä¸ºå…¶å‡ºç°å¤šæ¬¡</strong>ï¼Œç›´æ¥æŒ‰æ¡ä»¶ç‹¬ç«‹å‡è®¾çš„æ–¹å¼æ¨å¯¼ï¼Œåˆ™æœ‰</p>
<blockquote>
<p>P(ï¼ˆâ€œä»£å¼€â€,â€œå‘ç¥¨â€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œæ­£è§„â€,â€œå‘ç¥¨â€)|Sï¼‰ =P(â€œä»£å¼€â€â€|S)P(â€œå‘ç¥¨â€|S)P(â€œå¢å€¼ç¨â€|S)P(â€œå‘ç¥¨â€|S)P(â€œæ­£è§„â€|S)P(â€œå‘ç¥¨â€|Sï¼‰=P(â€œä»£å¼€â€â€|S)P3(â€œå‘ç¥¨â€|S)P(â€œå¢å€¼ç¨â€|S)P(â€œæ­£è§„â€|S) <strong>æ³¨æ„è¿™ä¸€é¡¹</strong>:P3(â€œå‘ç¥¨â€|Sï¼‰ã€‚</p>
</blockquote>
<p>åœ¨ç»Ÿè®¡è®¡ç®—P(â€œå‘ç¥¨â€|Sï¼‰æ—¶ï¼Œæ¯ä¸ªè¢«ç»Ÿè®¡çš„åƒåœ¾é‚®ä»¶æ ·æœ¬ä¸­é‡å¤çš„è¯è¯­ä¹Ÿç»Ÿè®¡å¤šæ¬¡ã€‚</p>
<blockquote>
<p>P(â€œå‘ç¥¨â€|Sï¼‰=æ¯å°åƒåœ¾é‚®ä»¶ä¸­å‡ºç°â€œå‘ç¥¨â€çš„æ¬¡æ•°çš„æ€»å’Œæ¯å°åƒåœ¾é‚®ä»¶ä¸­æ‰€æœ‰è¯å‡ºç°æ¬¡æ•°ï¼ˆè®¡ç®—é‡å¤æ¬¡æ•°ï¼‰çš„æ€»å’Œ</p>
</blockquote>
<p>ä½ çœ‹è¿™ä¸ªå¤šæ¬¡å‡ºç°çš„ç»“æœï¼Œå‡ºç°åœ¨æ¦‚ç‡çš„æŒ‡æ•°/æ¬¡æ–¹ä¸Šï¼Œå› æ­¤è¿™æ ·çš„æ¨¡å‹å«ä½œ<strong>å¤šé¡¹å¼æ¨¡å‹</strong>ã€‚</p>
<h3 id="9-2-ä¼¯åŠªåˆ©æ¨¡å‹"><a href="#9-2-ä¼¯åŠªåˆ©æ¨¡å‹" class="headerlink" title="9.2 ä¼¯åŠªåˆ©æ¨¡å‹"></a>9.2 ä¼¯åŠªåˆ©æ¨¡å‹</h3><p>å¦ä¸€ç§æ›´åŠ ç®€åŒ–çš„æ–¹æ³•æ˜¯<strong>å°†é‡å¤çš„è¯è¯­éƒ½è§†ä¸ºå…¶åªå‡ºç°1æ¬¡</strong>ï¼Œ</p>
<blockquote>
<p>P(ï¼ˆâ€œä»£å¼€â€,â€œå‘ç¥¨â€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œæ­£è§„â€,â€œå‘ç¥¨â€)|Sï¼‰ =P(â€œå‘ç¥¨â€|S)P(â€œä»£å¼€â€â€|S)P(â€œå¢å€¼ç¨â€|S)P(â€œæ­£è§„â€|Sï¼‰</p>
</blockquote>
<p>ç»Ÿè®¡è®¡ç®—P(â€œè¯è¯­â€|Sï¼‰æ—¶ä¹Ÿæ˜¯å¦‚æ­¤ã€‚</p>
<blockquote>
<p>P(â€œå‘ç¥¨â€|Sï¼‰=å‡ºç°â€œå‘ç¥¨â€çš„åƒåœ¾é‚®ä»¶çš„å°æ•°æ¯å°åƒåœ¾é‚®ä»¶ä¸­æ‰€æœ‰è¯å‡ºç°æ¬¡æ•°ï¼ˆå‡ºç°äº†åªè®¡ç®—ä¸€æ¬¡ï¼‰çš„æ€»å’Œ</p>
</blockquote>
<p>è¿™æ ·çš„æ¨¡å‹å«ä½œ<strong>ä¼¯åŠªåˆ©æ¨¡å‹</strong>ï¼ˆåˆç§°ä¸º<strong>äºŒé¡¹ç‹¬ç«‹æ¨¡å‹</strong>ï¼‰ã€‚è¿™ç§æ–¹å¼æ›´åŠ ç®€åŒ–ä¸æ–¹ä¾¿ã€‚å½“ç„¶å®ƒä¸¢å¤±äº†è¯é¢‘çš„ä¿¡æ¯ï¼Œå› æ­¤æ•ˆæœå¯èƒ½ä¼šå·®ä¸€äº›ã€‚</p>
<h3 id="9-3-æ··åˆæ¨¡å‹"><a href="#9-3-æ··åˆæ¨¡å‹" class="headerlink" title="9.3 æ··åˆæ¨¡å‹"></a>9.3 æ··åˆæ¨¡å‹</h3><p>ç¬¬ä¸‰ç§æ–¹å¼æ˜¯åœ¨è®¡ç®—å¥å­æ¦‚ç‡æ—¶ï¼Œä¸è€ƒè™‘é‡å¤è¯è¯­å‡ºç°çš„æ¬¡æ•°ï¼Œä½†æ˜¯åœ¨ç»Ÿè®¡è®¡ç®—è¯è¯­çš„æ¦‚ç‡P(â€œè¯è¯­â€|Sï¼‰æ—¶ï¼Œå´è€ƒè™‘é‡å¤è¯è¯­çš„å‡ºç°æ¬¡æ•°ï¼Œè¿™æ ·çš„æ¨¡å‹å¯ä»¥å«ä½œ<strong>æ··åˆæ¨¡å‹</strong>ã€‚</p>
<p>æˆ‘ä»¬é€šè¿‡ä¸‹å›¾å±•ç¤ºä¸‰ç§æ¨¡å‹çš„å…³ç³»ã€‚</p>
<p><img src="blob:file:///157f8870-f4d9-4b18-9922-0c1e7a18074b" alt="ä¸‰ç§å½¢æ€"></p>
<p>å…·ä½“å®è·µä¸­é‡‡ç”¨é‚£ç§æ¨¡å‹ï¼Œå…³é”®çœ‹å…·ä½“çš„ä¸šåŠ¡åœºæ™¯ï¼Œä¸€ä¸ªç®€å•ç»éªŒæ˜¯ï¼Œ<strong>å¯¹äºåƒåœ¾é‚®ä»¶è¯†åˆ«ï¼Œæ··åˆæ¨¡å‹æ›´å¥½äº›</strong>ã€‚</p>
<h2 id="10-å»é™¤åœç”¨è¯ä¸é€‰æ‹©å…³é”®è¯"><a href="#10-å»é™¤åœç”¨è¯ä¸é€‰æ‹©å…³é”®è¯" class="headerlink" title="10. å»é™¤åœç”¨è¯ä¸é€‰æ‹©å…³é”®è¯"></a>10. å»é™¤åœç”¨è¯ä¸é€‰æ‹©å…³é”®è¯</h2><p>æˆ‘ä»¬ç»§ç»­è§‚å¯Ÿ<strong>ï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€,â€œä¿çœŸâ€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œç‚¹æ•°â€,â€œä¼˜æƒ â€)</strong> è¿™å¥è¯ã€‚å…¶å®ï¼Œåƒ<strong>â€œæˆ‘â€ã€â€œå¯â€</strong>ä¹‹ç±»è¯å…¶å®éå¸¸ä¸­æ€§ï¼Œæ— è®ºå…¶æ˜¯å¦å‡ºç°åœ¨åƒåœ¾é‚®ä»¶ä¸­éƒ½æ— æ³•å¸®åŠ©åˆ¤æ–­çš„æœ‰ç”¨ä¿¡æ¯ã€‚æ‰€ä»¥å¯ä»¥ç›´æ¥ä¸è€ƒè™‘è¿™äº›å…¸å‹çš„è¯ã€‚è¿™äº›æ— åŠ©äºæˆ‘ä»¬åˆ†ç±»çš„è¯è¯­å«ä½œ<strong>â€œåœç”¨è¯â€ï¼ˆStop Wordsï¼‰</strong>ã€‚è¿™æ ·å¯ä»¥<strong>å‡å°‘æˆ‘ä»¬è®­ç»ƒæ¨¡å‹ã€åˆ¤æ–­åˆ†ç±»çš„æ—¶é—´</strong>ã€‚ äºæ˜¯ä¹‹å‰çš„å¥å­å°±å˜æˆäº†<strong>ï¼ˆâ€œå¸â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€,â€œä¿çœŸâ€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œç‚¹æ•°â€,â€œä¼˜æƒ â€)</strong> ã€‚</p>
<p>æˆ‘ä»¬è¿›ä¸€æ­¥åˆ†æã€‚ä»¥äººç±»çš„ç»éªŒï¼Œå…¶å®<strong>â€œæ­£è§„å‘ç¥¨â€ã€â€œå‘ç¥¨â€</strong>è¿™ç±»çš„è¯å¦‚æœå‡ºç°çš„è¯ï¼Œé‚®ä»¶ä½œä¸ºåƒåœ¾é‚®ä»¶çš„æ¦‚ç‡éå¸¸å¤§ï¼Œå¯ä»¥ä½œä¸ºæˆ‘ä»¬åŒºåˆ†åƒåœ¾é‚®ä»¶çš„<strong>â€œå…³é”®è¯â€</strong>ã€‚è€Œåƒ<strong>â€œå¸â€ã€â€œåŠç†â€ã€â€œä¼˜æƒ â€</strong>è¿™ç±»çš„è¯åˆ™æœ‰ç‚¹é¸¡è‚‹ï¼Œå¯èƒ½æœ‰åŠ©äºåˆ†ç±»ï¼Œä½†åˆä¸é‚£ä¹ˆå¼ºçƒˆã€‚å¦‚æœæƒ³çœäº‹åšä¸ªç®€å•çš„åˆ†ç±»å™¨çš„è¯ï¼Œåˆ™å¯ä»¥ç›´æ¥é‡‡ç”¨â€œå…³é”®è¯â€è¿›è¡Œç»Ÿè®¡ä¸åˆ¤æ–­ï¼Œå‰©ä¸‹çš„è¯å°±å¯ä»¥å…ˆä¸ç®¡äº†ã€‚äºæ˜¯ä¹‹å‰çš„åƒåœ¾é‚®ä»¶å¥å­å°±å˜æˆäº†<strong>ï¼ˆâ€œæ­£è§„å‘ç¥¨â€,â€œå‘ç¥¨â€)</strong> ã€‚è¿™æ ·å°±æ›´åŠ å‡å°‘äº†æˆ‘ä»¬è®­ç»ƒæ¨¡å‹ã€åˆ¤æ–­åˆ†ç±»çš„æ—¶é—´ï¼Œé€Ÿåº¦éå¸¸å¿«ã€‚</p>
<p><strong>â€œåœç”¨è¯â€å’Œâ€œå…³é”®è¯â€ä¸€èˆ¬éƒ½å¯ä»¥æå‰é äººå·¥ç»éªŒæŒ‡å®š</strong>ã€‚ä¸åŒçš„â€œåœç”¨è¯â€å’Œâ€œå…³é”®è¯â€è®­ç»ƒå‡ºæ¥çš„åˆ†ç±»å™¨çš„æ•ˆæœä¹Ÿä¼šæœ‰äº›å·®å¼‚ã€‚</p>
<h2 id="11-æµ…è°ˆå¹³æ»‘æŠ€æœ¯"><a href="#11-æµ…è°ˆå¹³æ»‘æŠ€æœ¯" class="headerlink" title="11. æµ…è°ˆå¹³æ»‘æŠ€æœ¯"></a>11. æµ…è°ˆå¹³æ»‘æŠ€æœ¯</h2><p>æˆ‘ä»¬æ¥è¯´ä¸ªé—®é¢˜(ä¸­æ–‡NLPé‡Œé—®é¢˜è¶…çº§å¤šï¼Œå“­çT_T)ï¼Œæ¯”å¦‚åœ¨è®¡ç®—ä»¥ä¸‹ç‹¬ç«‹æ¡ä»¶å‡è®¾çš„æ¦‚ç‡ï¼š</p>
<blockquote>
<p>P(ï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€)|S) =P(â€œæˆ‘â€|S)P(â€œå¸â€|S)P(â€œå¯â€|S)P(â€œåŠç†â€|S)P(â€œæ­£è§„å‘ç¥¨â€|Sï¼‰</p>
</blockquote>
<p>æˆ‘ä»¬æ‰«æä¸€ä¸‹è®­ç»ƒé›†ï¼Œå‘ç°<strong>â€œæ­£è§„å‘ç¥¨â€è¿™ä¸ªè¯ä»å‡ºç°è¿‡ï¼ï¼ï¼*ï¼Œäºæ˜¯P(â€œæ­£è§„å‘ç¥¨â€|Sï¼‰=0â€¦é—®é¢˜ä¸¥é‡äº†ï¼Œæ•´ä¸ªæ¦‚ç‡éƒ½å˜æˆ0äº†ï¼ï¼ï¼æœ´ç´ è´å¶æ–¯æ–¹æ³•é¢å¯¹ä¸€å †0ï¼Œå¾ˆå‡„æƒ¨åœ°å¤±æ•ˆäº†â€¦æ›´æ®‹é…·çš„æ˜¯</strong>è¿™ç§æƒ…å†µå…¶å®å¾ˆå¸¸è§<strong>ï¼Œå› ä¸ºå“ªæ€•è®­ç»ƒé›†å†å¤§ï¼Œä¹Ÿå¯èƒ½æœ‰è¦†ç›–ä¸åˆ°çš„è¯è¯­ã€‚æœ¬è´¨ä¸Šè¿˜æ˜¯</strong>æ ·æœ¬æ•°é‡å¤ªå°‘ï¼Œä¸æ»¡è¶³å¤§æ•°å®šå¾‹ï¼Œè®¡ç®—å‡ºæ¥çš„æ¦‚ç‡å¤±çœŸ**ã€‚ä¸ºäº†è§£å†³è¿™æ ·çš„é—®é¢˜ï¼Œä¸€ç§åˆ†ææ€è·¯å°±æ˜¯ç›´æ¥ä¸è€ƒè™‘è¿™æ ·çš„è¯è¯­ï¼Œä½†è¿™ç§æ–¹æ³•å°±ç›¸å½“äºé»˜è®¤ç»™P(â€œæ­£è§„å‘ç¥¨â€|Sï¼‰èµ‹å€¼ä¸º1ã€‚å…¶å®æ•ˆæœä¸å¤ªå¥½ï¼Œå¤§é‡çš„ç»Ÿè®¡ä¿¡æ¯ç»™æµªè´¹æ‰äº†ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥åˆ†æï¼Œæ—¢ç„¶å¯ä»¥é»˜è®¤èµ‹å€¼ä¸º1ï¼Œä¸ºä»€ä¹ˆä¸èƒ½é»˜è®¤èµ‹å€¼ä¸ºä¸€ä¸ªå¾ˆå°çš„æ•°ï¼Ÿè¿™å°±æ˜¯å¹³æ»‘æŠ€æœ¯çš„åŸºæœ¬æ€è·¯ï¼Œä¾æ—§ä¿æŒç€ä¸€è´¯çš„ä½œé£ï¼Œ<code>æœ´å®/åœŸ</code>ä½†æ˜¯<code>ç›´æ¥è€Œæœ‰æ•ˆ</code>ã€‚</p>
<p>å¯¹äºä¼¯åŠªåˆ©æ¨¡å‹ï¼ŒP(â€œæ­£è§„å‘ç¥¨â€|Sï¼‰çš„ä¸€ç§å¹³æ»‘ç®—æ³•æ˜¯ï¼š</p>
<blockquote>
<p>P(â€œæ­£è§„å‘ç¥¨â€|Sï¼‰=å‡ºç°â€œæ­£è§„å‘ç¥¨â€çš„åƒåœ¾é‚®ä»¶çš„å°æ•°+1æ¯å°åƒåœ¾é‚®ä»¶ä¸­æ‰€æœ‰è¯å‡ºç°æ¬¡æ•°ï¼ˆå‡ºç°äº†åªè®¡ç®—ä¸€æ¬¡ï¼‰çš„æ€»å’Œ+2</p>
</blockquote>
<p>å¯¹äºå¤šé¡¹å¼æ¨¡å‹ï¼ŒP(â€œæ­£è§„å‘ç¥¨â€| Sï¼‰çš„ä¸€ç§å¹³æ»‘ç®—æ³•æ˜¯ï¼š</p>
<blockquote>
<p>P(â€œå‘ç¥¨â€|Sï¼‰=æ¯å°åƒåœ¾é‚®ä»¶ä¸­å‡ºç°â€œå‘ç¥¨â€çš„æ¬¡æ•°çš„æ€»å’Œ+1æ¯å°åƒåœ¾é‚®ä»¶ä¸­æ‰€æœ‰è¯å‡ºç°æ¬¡æ•°ï¼ˆè®¡ç®—é‡å¤æ¬¡æ•°ï¼‰çš„æ€»å’Œ+è¢«ç»Ÿè®¡çš„è¯è¡¨çš„è¯è¯­æ•°é‡</p>
</blockquote>
<p>è¯´èµ·æ¥ï¼Œå¹³æ»‘æŠ€æœ¯çš„ç§ç±»å…¶å®éå¸¸å¤šï¼Œæœ‰å…´è¶£çš„è¯å›å¤´æˆ‘ä»¬ä¸“é—¨æ‹‰ä¸ªä¸“é¢˜è®²è®²å¥½äº†ã€‚è¿™é‡Œåªæä¸€ç‚¹ï¼Œå°±æ˜¯æ‰€æœ‰çš„<strong>å¹³æ»‘æŠ€æœ¯éƒ½æ˜¯ç»™æœªå‡ºç°åœ¨è®­ç»ƒé›†ä¸­çš„è¯è¯­ä¸€ä¸ªä¼°è®¡çš„æ¦‚ç‡ï¼Œè€Œç›¸åº”åœ°è°ƒä½å…¶ä»–å·²ç»å‡ºç°çš„è¯è¯­çš„æ¦‚ç‡</strong>ã€‚</p>
<p>å¹³æ»‘æŠ€æœ¯æ˜¯å› ä¸ºæ•°æ®é›†å¤ªå°è€Œäº§ç”Ÿçš„ç°å®éœ€æ±‚ã€‚<strong>å¦‚æœæ•°æ®é›†è¶³å¤Ÿå¤§ï¼Œå¹³æ»‘æŠ€æœ¯å¯¹ç»“æœçš„å½±å“å°†ä¼šå˜å°ã€‚</strong></p>
<h2 id="12-å†…å®¹å°ç»“"><a href="#12-å†…å®¹å°ç»“" class="headerlink" title="12. å†…å®¹å°ç»“"></a>12. å†…å®¹å°ç»“</h2><p>æˆ‘ä»¬æ‰¾äº†ä¸ªæœ€ç®€å•å¸¸è§çš„ä¾‹å­ï¼šåƒåœ¾é‚®ä»¶è¯†åˆ«ï¼Œè¯´æ˜äº†ä¸€ä¸‹æœ´ç´ è´å¶æ–¯è¿›è¡Œæ–‡æœ¬åˆ†ç±»çš„æ€è·¯è¿‡ç¨‹ã€‚åŸºæœ¬æ€è·¯æ˜¯å…ˆåŒºåˆ†å¥½è®­ç»ƒé›†ä¸æµ‹è¯•é›†ï¼Œå¯¹æ–‡æœ¬é›†åˆè¿›è¡Œåˆ†è¯ã€å»é™¤æ ‡ç‚¹ç¬¦å·ç­‰ç‰¹å¾é¢„å¤„ç†çš„æ“ä½œï¼Œç„¶åä½¿ç”¨æ¡ä»¶ç‹¬ç«‹å‡è®¾ï¼Œå°†åŸæ¦‚ç‡è½¬æ¢æˆè¯æ¦‚ç‡ä¹˜ç§¯ï¼Œå†è¿›è¡Œåç»­çš„å¤„ç†ã€‚</p>
<blockquote>
<p>è´å¶æ–¯å…¬å¼ + æ¡ä»¶ç‹¬ç«‹å‡è®¾ = æœ´ç´ è´å¶æ–¯æ–¹æ³•</p>
</blockquote>
<p>åŸºäºå¯¹é‡å¤è¯è¯­åœ¨è®­ç»ƒé˜¶æ®µä¸åˆ¤æ–­ï¼ˆæµ‹è¯•ï¼‰é˜¶æ®µçš„ä¸‰ç§ä¸åŒå¤„ç†æ–¹å¼ï¼Œæˆ‘ä»¬ç›¸åº”çš„æœ‰ä¼¯åŠªåˆ©æ¨¡å‹ã€å¤šé¡¹å¼æ¨¡å‹å’Œæ··åˆæ¨¡å‹ã€‚åœ¨è®­ç»ƒé˜¶æ®µï¼Œå¦‚æœæ ·æœ¬é›†åˆå¤ªå°å¯¼è‡´æŸäº›è¯è¯­å¹¶æœªå‡ºç°ï¼Œæˆ‘ä»¬å¯ä»¥é‡‡ç”¨å¹³æ»‘æŠ€æœ¯å¯¹å…¶æ¦‚ç‡ç»™ä¸€ä¸ªä¼°è®¡å€¼ã€‚è€Œä¸”å¹¶ä¸æ˜¯æ‰€æœ‰çš„è¯è¯­éƒ½éœ€è¦ç»Ÿè®¡ï¼Œæˆ‘ä»¬å¯ä»¥æŒ‰ç›¸åº”çš„â€œåœç”¨è¯â€å’Œâ€œå…³é”®è¯â€å¯¹æ¨¡å‹è¿›è¡Œè¿›ä¸€æ­¥ç®€åŒ–ï¼Œæé«˜è®­ç»ƒå’Œåˆ¤æ–­é€Ÿåº¦ã€‚</p>
<h2 id="13-ä¸ºä»€ä¹ˆä¸ç›´æ¥åŒ¹é…å…³é”®è¯æ¥è¯†åˆ«åƒåœ¾é‚®ä»¶ï¼Ÿ"><a href="#13-ä¸ºä»€ä¹ˆä¸ç›´æ¥åŒ¹é…å…³é”®è¯æ¥è¯†åˆ«åƒåœ¾é‚®ä»¶ï¼Ÿ" class="headerlink" title="13. ä¸ºä»€ä¹ˆä¸ç›´æ¥åŒ¹é…å…³é”®è¯æ¥è¯†åˆ«åƒåœ¾é‚®ä»¶ï¼Ÿ"></a>13. ä¸ºä»€ä¹ˆä¸ç›´æ¥åŒ¹é…å…³é”®è¯æ¥è¯†åˆ«åƒåœ¾é‚®ä»¶ï¼Ÿ</h2><p>æœ‰åŒå­¦å¯èƒ½ä¼šé—®ï¼šâ€œä½•å¿…è´¹è¿™ä¹ˆå¤§åŠ²ç®—é‚£ä¹ˆå¤šè¯çš„æ¦‚ç‡ï¼Ÿç›´æ¥çœ‹é‚®ä»¶ä¸­æœ‰æ²¡æœ‰â€˜ä»£å¼€å‘ç¥¨â€™ã€â€˜è½¬å”®å‘ç¥¨â€™ä¹‹ç±»çš„å…³é”®è¯ä¸å°±å¾—äº†ï¼Ÿå¦‚æœå…³é”®è¯æ¯”è¾ƒå¤šå°±è®¤ä¸ºæ˜¯åƒåœ¾é‚®ä»¶å‘—ã€‚â€</p>
<p>å…¶å®å…³é”®è¯åŒ¹é…çš„æ–¹æ³•å¦‚æœæœ‰æ•ˆçš„è¯çœŸä¸å¿…ç”¨æœ´ç´ è´å¶æ–¯ã€‚æ¯•ç«Ÿè¿™ç§æ–¹æ³•ç®€å•å˜›ï¼Œ<strong>å°±æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²åŒ¹é…</strong>ã€‚ä»å†å²æ¥çœ‹ï¼Œä¹‹å‰æ²¡æœ‰è´å¶æ–¯æ–¹æ³•çš„æ—¶å€™ä¸»è¦ä¹Ÿæ˜¯ç”¨å…³é”®è¯åŒ¹é…ã€‚<strong>ä½†æ˜¯è¿™ç§æ–¹æ³•å‡†ç¡®ç‡å¤ªä½</strong>ã€‚æˆ‘ä»¬åœ¨å·¥ä½œé¡¹ç›®ä¸­ä¹Ÿå°è¯•è¿‡ç”¨å…³é”®è¯åŒ¹é…çš„æ–¹æ³•å»è¿›è¡Œæ–‡æœ¬åˆ†ç±»ï¼Œå‘ç°å¤§é‡è¯¯æŠ¥ã€‚æ„Ÿè§‰å°±åƒæ‰”åˆ°åƒåœ¾ç®±çš„é‚®ä»¶99%éƒ½æ˜¯æ­£å¸¸çš„ï¼è¿™æ ·çš„æ•ˆæœä¸å¿ç›´è§†ã€‚è€ŒåŠ ä¸€ä¸ªæœ´ç´ è´å¶æ–¯æ–¹æ³•å°±å¯èƒ½æŠŠè¯¯æŠ¥ç‡æ‹‰ä½è¿‘ä¸€ä¸ªæ•°é‡çº§ï¼Œä½“éªŒå¥½å¾—ä¸è¦ä¸è¦çš„ã€‚</p>
<p><strong>å¦ä¸€ä¸ªåŸå› æ˜¯è¯è¯­ä¼šéšç€æ—¶é—´ä¸æ–­å˜åŒ–</strong>ã€‚å‘åƒåœ¾é‚®ä»¶çš„äººä¹Ÿä¸å‚»ï¼Œå½“ä»–ä»¬å‘ç°è‡ªå·±çš„é‚®ä»¶è¢«å¤§é‡å±è”½ä¹‹åï¼Œä¹Ÿä¼šè€ƒè™‘é‡‡ç”¨æ–°çš„æ–¹å¼ï¼Œ<strong>å¦‚å˜æ¢æ–‡å­—ã€è¯è¯­ã€å¥å¼ã€é¢œè‰²ç­‰æ–¹å¼æ¥ç»•è¿‡ååƒåœ¾é‚®ä»¶ç³»ç»Ÿ</strong>ã€‚æ¯”å¦‚å¯¹äºåƒåœ¾é‚®ä»¶â€œæˆ‘å¸å¯åŠç†æ­£è§„å‘ç¥¨ï¼Œ17%å¢å€¼ç¨å‘ç¥¨ç‚¹æ•°ä¼˜æƒ â€,ä»–ä»¬é‡‡ç”¨ç«æ˜Ÿæ–‡ï¼š<strong>â€œæ¶å¸å²¢åŠç†ãŠ£è¦é«®ç¥¨ï¼Œ17%å¢å€¤ç¨…é«®ç¥¨åš¸æ•¸å„ªè•™â€</strong>ï¼Œé‚£ä¹ˆå­—ç¬¦ä¸²åŒ¹é…çš„æ–¹æ³•åˆè¦é‡æ–°æ‰¾å‡ºè¿™äº›ç«æ˜Ÿæ–‡ï¼Œä¸€ä¸ªä¸€ä¸ªæ‰¾å‡ºå…³é”®è¯ï¼Œé‡æ–°å†™ä¸€äº›åŒ¹é…è§„åˆ™ã€‚æ›´å¯æ€•çš„æ˜¯ï¼Œè¿™äº›è§„åˆ™å¯èƒ½ç›¸äº’ä¹‹é—´çš„è€¦åˆå…³ç³»å¼‚å¸¸å¤æ‚ï¼Œè¦æŠŠå®ƒä»¬æ¢³ç†æ¸…æ¥šåˆæ˜¯å¤§ä¸€ä¸ªæ•°é‡çº§çš„å·¥ä½œé‡ã€‚ç­‰è¿™äº›è§„åˆ™å¤±æ•ˆäº†åˆè¦æ‰‹åŠ¨æ›´æ–°æ–°çš„è§„åˆ™â€¦â€¦<strong>æ— ç©·æ— å°½çŒ«é¼ æ¸¸æˆæœ€ç»ˆä¼šæŠŠçŒ«ç»™ç´¯æ­»</strong>ã€‚</p>
<p>è€Œæœ´ç´ è´å¶æ–¯æ–¹æ³•å´æ˜¾ç¤ºå‡ºæ— æ¯”çš„ä¼˜åŠ¿ã€‚å› ä¸ºå®ƒæ˜¯<strong>åŸºäºç»Ÿè®¡æ–¹æ³•</strong>çš„ï¼Œåªè¦è®­ç»ƒæ ·æœ¬ä¸­æœ‰æ›´æ–°çš„åƒåœ¾é‚®ä»¶çš„æ–°è¯è¯­ï¼Œå“ªæ€•å®ƒä»¬æ˜¯ç«æ˜Ÿæ–‡ï¼Œ<strong>éƒ½èƒ½è‡ªåŠ¨åœ°æŠŠå“ªäº›æ›´æ•æ„Ÿçš„è¯è¯­ï¼ˆå¦‚â€œé«®â€ã€â€œãŠ£â€ç­‰ï¼‰ç»™å‡¸æ˜¾å‡ºæ¥ï¼Œå¹¶æ ¹æ®ç»Ÿè®¡æ„ä¹‰ä¸Šçš„æ•æ„Ÿæ€§ç»™ä»–ä»¬åˆ†é…é€‚å½“çš„æƒé‡</strong> ï¼Œè¿™æ ·å°±ä¸éœ€è¦ä»€ä¹ˆäººå·¥äº†ï¼Œéå¸¸çœäº‹ã€‚<strong>ä½ åªéœ€è¦æ—¶ä¸æ—¶åœ°æ‹¿ä¸€äº›æœ€æ–°çš„æ ·æœ¬æ‰”åˆ°è®­ç»ƒé›†ä¸­ï¼Œé‡æ–°è®­ç»ƒä¸€æ¬¡å³å¯</strong>ã€‚</p>
<p>å°è¡¥å……ä¸€ä¸‹ï¼Œå¯¹äºç«æ˜Ÿæ–‡ã€åŒéŸ³å­—ç­‰æ›¿ä»£è¯­è¨€ï¼Œä¸€èˆ¬çš„åˆ†è¯æŠ€æœ¯å¯èƒ½ä¼šåˆ†å¾—ä¸å‡†ï¼Œæœ€ç»ˆå¯èƒ½åªæŠŠä¸€ä¸ªä¸€ä¸ªå­—ç»™åˆ†å‡ºæ¥ï¼Œæˆä¸ºâ€œåˆ†å­—â€ã€‚æ•ˆæœå¯èƒ½ä¸ä¼šå¤ªå¥½ã€‚ä¹Ÿå¯ä»¥ç”¨è¿‡n-gramä¹‹ç±»çš„è¯­è¨€æ¨¡å‹ï¼Œæ‹¿åˆ°æœ€å¸¸è§çŸ­è¯­ã€‚å½“ç„¶ï¼Œå¯¹äºè‹±æ–‡ç­‰å¤©ç”Ÿè‡ªå¸¦ç©ºæ ¼æ¥é—´éš”å•è¯çš„è¯­è¨€ï¼Œåˆ†è¯åˆ™ä¸æ˜¯ä»€ä¹ˆé—®é¢˜ï¼Œä½¿ç”¨æœ´ç´ è´å¶æ–¯æ–¹æ³•å°†ä¼šæ›´åŠ é¡ºç•…ã€‚</p>
<h2 id="14-å®é™…å·¥ç¨‹çš„tricks"><a href="#14-å®é™…å·¥ç¨‹çš„tricks" class="headerlink" title="14.å®é™…å·¥ç¨‹çš„tricks"></a>14.å®é™…å·¥ç¨‹çš„tricks</h2><p>åº”ç”¨æœ´ç´ è´å¶æ–¯æ–¹æ³•çš„è¿‡ç¨‹ä¸­ï¼Œä¸€äº›tricksèƒ½æ˜¾è‘—å¸®åŠ©å·¥ç¨‹è§£å†³é—®é¢˜ã€‚æˆ‘ä»¬æ¯•ç«Ÿç»éªŒæœ‰é™ï¼Œæ— æ³•å°†å®ƒä»¬å…¨éƒ½ç½—åˆ—å‡ºæ¥ï¼Œåªèƒ½å°±æ‰€çŸ¥çš„ä¸€ç‚¹ç‚¹ç»éªŒä¸å¤§å®¶åˆ†äº«ï¼Œæ¬¢è¿æ‰¹è¯„æŒ‡æ­£ã€‚</p>
<h3 id="14-1-trick1ï¼šå–å¯¹æ•°"><a href="#14-1-trick1ï¼šå–å¯¹æ•°" class="headerlink" title="14.1 trick1ï¼šå–å¯¹æ•°"></a>14.1 trick1ï¼šå–å¯¹æ•°</h3><p>æˆ‘ä»¬æåˆ°ç”¨æ¥è¯†åˆ«åƒåœ¾é‚®ä»¶çš„æ–¹æ³•æ˜¯æ¯”è¾ƒä»¥ä¸‹ä¸¤ä¸ªæ¦‚ç‡çš„å¤§å°ï¼ˆå­—æ¯Sè¡¨ç¤ºâ€œåƒåœ¾é‚®ä»¶â€,å­—æ¯Hè¡¨ç¤ºâ€œæ­£å¸¸é‚®ä»¶â€ï¼‰ï¼š</p>
<blockquote>
<p>C=P(â€œæˆ‘â€|S)P(â€œå¸â€|S)P(â€œå¯â€|S)P(â€œåŠç†â€|S)P(â€œæ­£è§„å‘ç¥¨â€|S)</p>
<p>Ã—P(â€œä¿çœŸâ€|S)P(â€œå¢å€¼ç¨â€|S)P(â€œå‘ç¥¨â€|S)P(â€œç‚¹æ•°â€|S)P(â€œä¼˜æƒ â€|S)P(â€œåƒåœ¾é‚®ä»¶â€)</p>
<p>Câ¯â¯â¯â¯=P(â€œæˆ‘â€|H)P(â€œå¸â€|H)P(â€œå¯â€|H)P(â€œåŠç†â€|H)P(â€œæ­£è§„å‘ç¥¨â€|H)</p>
<p>Ã—P(â€œä¿çœŸâ€|H)P(â€œå¢å€¼ç¨â€|H)P(â€œå‘ç¥¨â€|H)P(â€œç‚¹æ•°â€|H)P(â€œä¼˜æƒ â€|H)P(â€œæ­£å¸¸é‚®ä»¶â€)</p>
</blockquote>
<p>ä½†è¿™é‡Œè¿›è¡Œäº†<strong>å¾ˆå¤šä¹˜æ³•è¿ç®—ï¼Œè®¡ç®—çš„æ—¶é—´å¼€é”€æ¯”è¾ƒå¤§</strong>ã€‚å°¤å…¶æ˜¯å¯¹äºç¯‡å¹…æ¯”è¾ƒé•¿çš„é‚®ä»¶ï¼Œå‡ ä¸‡ä¸ªæ•°ç›¸ä¹˜èµ·æ¥è¿˜æ˜¯éå¸¸èŠ±æ—¶é—´çš„ã€‚å¦‚æœèƒ½<strong>æŠŠè¿™äº›ä¹˜æ³•å˜æˆåŠ æ³•åˆ™æ–¹ä¾¿å¾—å¤š</strong>ã€‚åˆšå¥½æ•°å­¦ä¸­çš„å¯¹æ•°å‡½æ•°logå°±å¯ä»¥å®ç°è¿™æ ·çš„åŠŸèƒ½ã€‚ä¸¤è¾¹åŒæ—¶å–å¯¹æ•°ï¼ˆæœ¬æ–‡ç»Ÿä¸€å–åº•æ•°ä¸º2ï¼‰ï¼Œåˆ™ä¸Šé¢çš„å…¬å¼å˜ä¸ºï¼š</p>
<blockquote>
<p>logC=logP(â€œæˆ‘â€|S)+logP(â€œå¸â€|S)+logP(â€œå¯â€|S)+logP(â€œåŠç†â€|S)+logP(â€œæ­£è§„å‘ç¥¨â€|S)</p>
<p>+logP(â€œä¿çœŸâ€|S)+logP(â€œå¢å€¼ç¨â€|S)+logP(â€œå‘ç¥¨â€|S)+logP(â€œç‚¹æ•°â€|S)+logP(â€œä¼˜æƒ â€|S)+logP(â€œåƒåœ¾é‚®ä»¶â€)</p>
<p>logCâ¯â¯â¯â¯=logP(â€œæˆ‘â€|H)+logP(â€œå¸â€|H)+logP(â€œå¯â€|H)+logP(â€œåŠç†â€|H)+logP(â€œæ­£è§„å‘ç¥¨â€|H)</p>
<p>+logP(â€œä¿çœŸâ€|H)+logP(â€œå¢å€¼ç¨â€|H)+logP(â€œå‘ç¥¨â€|H)+logP(â€œç‚¹æ•°â€|H)+logP(â€œä¼˜æƒ â€|H)+logP(â€œæ­£å¸¸é‚®ä»¶â€)</p>
</blockquote>
<p>æœ‰åŒå­¦å¯èƒ½è¦å«äº†ï¼šâ€œåšå¯¹æ•°è¿ç®—å²‚ä¸ä¼šä¹Ÿå¾ˆèŠ±æ—¶é—´ï¼Ÿâ€çš„ç¡®å¦‚æ­¤ï¼Œä½†æ˜¯å¯ä»¥åœ¨è®­ç»ƒé˜¶æ®µç›´æ¥è®¡ç®— logP ï¼Œç„¶åæŠŠä»–ä»¬å­˜åœ¨ä¸€å¼ å¤§çš„hashè¡¨é‡Œã€‚<strong>åœ¨åˆ¤æ–­çš„æ—¶å€™ç›´æ¥æå–hashè¡¨ä¸­å·²ç»è®¡ç®—å¥½çš„å¯¹æ•°æ¦‚ç‡ï¼Œç„¶åç›¸åŠ å³å¯ã€‚è¿™æ ·ä½¿å¾—åˆ¤æ–­æ‰€éœ€è¦çš„è®¡ç®—æ—¶é—´è¢«è½¬ç§»åˆ°äº†è®­ç»ƒé˜¶æ®µ</strong>ï¼Œå®æ—¶è¿è¡Œçš„æ—¶å€™é€Ÿåº¦å°±æ¯”ä¹‹å‰å¿«å¾—å¤šï¼Œè¿™å¯ä¸æ­¢å‡ ä¸ªæ•°é‡çº§çš„æå‡ã€‚</p>
<h3 id="14-2-trick2ï¼šè½¬æ¢ä¸ºæƒé‡"><a href="#14-2-trick2ï¼šè½¬æ¢ä¸ºæƒé‡" class="headerlink" title="14.2 trick2ï¼šè½¬æ¢ä¸ºæƒé‡"></a>14.2 trick2ï¼šè½¬æ¢ä¸ºæƒé‡</h3><p>å¯¹äºäºŒåˆ†ç±»ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥ç»§ç»­æé«˜åˆ¤æ–­çš„é€Ÿåº¦ã€‚æ—¢ç„¶è¦æ¯”è¾ƒlogC å’ŒlogCâ¯â¯â¯â¯ çš„å¤§å°ï¼Œé‚£å°±å¯ä»¥ç›´æ¥å°†ä¸Šä¸‹ä¸¤å¼ç›¸å‡ï¼Œå¹¶ç»§ç»­åŒ–ç®€ï¼š</p>
<blockquote>
<p>logCCâ¯â¯â¯â¯â¯=logP(â€œæˆ‘â€|S)P(â€œæˆ‘â€|H)+logP(â€œå¸â€|S)P(â€œå¸â€|H)+logP(â€œå¯â€|S)P(â€œå¯â€|H)+logP(â€œåŠç†â€|S)P(â€œåŠç†â€|H)+logP(â€œæ­£è§„å‘ç¥¨â€|S)P(â€œæ­£è§„å‘ç¥¨â€|H)</p>
<p>+logP(â€œä¿çœŸâ€|S)P(â€œä¿çœŸâ€|H)+logP(â€œå¢å€¼ç¨â€|S)P(â€œå¢å€¼ç¨â€|H)+logP(â€œå‘ç¥¨â€|S)P(â€œå‘ç¥¨â€|H)+logP(â€œç‚¹æ•°â€|S)P(â€œç‚¹æ•°â€|H)+logP(â€œä¼˜æƒ â€|S)P(â€œä¼˜æƒ â€|H)+logP(â€œæ­£å¸¸é‚®ä»¶â€|S)P(â€œæ­£å¸¸é‚®ä»¶â€)</p>
</blockquote>
<p><strong>logCCâ¯â¯â¯â¯â¯ å¦‚æœå¤§äº0åˆ™å±äºåƒåœ¾é‚®ä»¶ã€‚æˆ‘ä»¬å¯ä»¥æŠŠå…¶ä¸­æ¯ä¸€é¡¹ä½œä¸ºå…¶å¯¹åº”è¯è¯­çš„æƒé‡</strong>ï¼Œæ¯”å¦‚logP(â€œå‘ç¥¨â€|S)P(â€œå‘ç¥¨â€|H) å°±å¯ä»¥ä½œä¸ºè¯è¯­â€œå‘ç¥¨â€çš„æƒé‡ï¼Œæƒé‡è¶Šå¤§å°±è¶Šè¯´æ˜â€œå‘ç¥¨â€æ›´å¯èƒ½æ˜¯ä¸â€œåƒåœ¾é‚®ä»¶â€ç›¸å…³çš„ç‰¹å¾ã€‚<strong>è¿™æ ·å¯ä»¥æ ¹æ®æƒé‡çš„å¤§å°æ¥è¯„ä¼°å’Œç­›é€‰æ˜¾è‘—çš„ç‰¹å¾ï¼Œæ¯”å¦‚å…³é”®è¯ã€‚è€Œè¿™äº›æƒé‡å€¼å¯ä»¥ç›´æ¥æå‰è®¡ç®—å¥½è€Œå­˜åœ¨hashè¡¨ä¸­</strong> ã€‚åˆ¤æ–­çš„æ—¶å€™ç›´æ¥å°†æƒé‡æ±‚å’Œå³å¯ã€‚</p>
<p>å…³é”®è¯hashè¡¨çš„æ ·å­å¦‚ä¸‹ï¼Œå·¦åˆ—æ˜¯æƒé‡ï¼Œå³åˆ—æ˜¯å…¶å¯¹åº”çš„è¯è¯­ï¼Œæƒé‡è¶Šé«˜çš„è¯´æ˜è¶Šâ€œå…³é”®â€ï¼š</p>
<p><img src="blob:file:///6f29d16a-1075-45cb-9c7e-206aefcf4e4a" alt="hash"></p>
<h3 id="14-3-trick3ï¼šé€‰å–topkçš„å…³é”®è¯"><a href="#14-3-trick3ï¼šé€‰å–topkçš„å…³é”®è¯" class="headerlink" title="14.3 trick3ï¼šé€‰å–topkçš„å…³é”®è¯"></a>14.3 trick3ï¼šé€‰å–topkçš„å…³é”®è¯</h3><p>å‰æ–‡è¯´è¿‡å¯ä»¥é€šè¿‡æå‰é€‰å–å…³é”®è¯æ¥æé«˜åˆ¤æ–­çš„é€Ÿåº¦ã€‚æœ‰ä¸€ç§æ–¹æ³•å¯ä»¥çœç•¥æå‰é€‰å–å…³é”®è¯çš„æ­¥éª¤ï¼Œ<strong>å°±æ˜¯ç›´æ¥é€‰å–ä¸€æ®µæ–‡æœ¬ä¸­æƒé‡æœ€é«˜çš„Kä¸ªè¯è¯­ï¼Œå°†å…¶æƒé‡è¿›è¡ŒåŠ å’Œ</strong>ã€‚æ¯”å¦‚Paul Graham åœ¨ã€Šé»‘å®¢ä¸ç”»å®¶ã€‹ä¸­æ˜¯é€‰å–é‚®ä»¶ä¸­æƒé‡æœ€é«˜çš„15ä¸ªè¯è¯­è®¡ç®—çš„ã€‚</p>
<p>é€šè¿‡æƒé‡hashè¡¨å¯çŸ¥ï¼Œå¦‚æœæ˜¯æ‰€æœ‰è¯è¯­çš„æƒé‡ï¼Œåˆ™æƒé‡æœ‰æ­£æœ‰è´Ÿã€‚å¦‚æœåªé€‰æ‹©æƒé‡æœ€é«˜çš„Kä¸ªè¯è¯­ï¼Œåˆ™å®ƒä»¬çš„æƒé‡åŸºæœ¬éƒ½æ˜¯æ­£çš„ã€‚æ‰€ä»¥å°±ä¸èƒ½åƒä¹‹å‰é‚£æ ·åˆ¤æ–­logCCâ¯â¯â¯â¯â¯ æ˜¯å¦å¤§äº0æ¥åŒºåˆ†é‚®ä»¶äº†ã€‚è€Œè¿™<strong>éœ€è¦ä¾é ç»éªŒé€‰å®šä¸€ä¸ªæ­£æ•°çš„é˜ˆå€¼ï¼ˆé—¨æ§›å€¼ï¼‰</strong> ï¼Œä¾æ®logCCâ¯â¯â¯â¯â¯ ä¸è¯¥é—¨æ§›å€¼çš„å¤§å°æ¥è¯†åˆ«åƒåœ¾é‚®ä»¶ã€‚</p>
<p>å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œè“è‰²ç‚¹ä»£è¡¨åƒåœ¾é‚®ä»¶ï¼Œç»¿è‰²ç‚¹ä»£è¡¨æ­£å¸¸é‚®ä»¶ï¼Œæ¨ªåæ ‡ä¸ºè®¡ç®—å‡ºæ¥çš„logCCâ¯â¯â¯â¯â¯ å€¼ï¼Œä¸­é—´çš„çº¢çº¿ä»£è¡¨é˜ˆå€¼ã€‚</p>
<p><img src="blob:file:///fa290902-0e88-4f3b-8a65-79c442c05c05" alt="æƒé‡"></p>
<h3 id="14-4-trick4ï¼šåˆ†å‰²æ ·æœ¬"><a href="#14-4-trick4ï¼šåˆ†å‰²æ ·æœ¬" class="headerlink" title="14.4 trick4ï¼šåˆ†å‰²æ ·æœ¬"></a>14.4 trick4ï¼šåˆ†å‰²æ ·æœ¬</h3><p>é€‰å–topkä¸ªè¯è¯­çš„æ–¹æ³•å¯¹äºç¯‡å¹…å˜åŠ¨ä¸å¤§çš„é‚®ä»¶æ ·æœ¬æ¯”è¾ƒæœ‰æ•ˆã€‚ä½†æ˜¯å¯¹ç¯‡å¹…è¿‡å¤§æˆ–è€…è¿‡å°çš„é‚®ä»¶åˆ™ä¼šæœ‰åˆ¤æ–­è¯¯å·®ã€‚</p>
<p>æ¯”å¦‚è¿™ä¸ªåƒåœ¾é‚®ä»¶çš„ä¾‹å­ï¼šï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€,â€œä¿çœŸâ€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œç‚¹æ•°â€,â€œä¼˜æƒ â€)ã€‚åˆ†è¯å‡ºäº†10ä¸ªè¯è¯­ï¼Œå…¶ä¸­æœ‰â€œæ­£è§„å‘ç¥¨â€ã€â€œå‘ç¥¨â€2ä¸ªå…³é”®è¯ã€‚å…³é”®è¯çš„å¯†åº¦è¿˜æ˜¯è›®å¤§çš„ï¼Œåº”è¯¥ç®—æ˜¯æ•æ„Ÿé‚®ä»¶ã€‚ä½†å› ä¸ºé‡‡ç”¨æœ€é«˜15ä¸ªè¯è¯­çš„æƒé‡æ±‚å’Œï¼Œå¹¶ä¸”ç›¸åº”çš„é˜ˆå€¼æ˜¯åŸºäº15ä¸ªè¯çš„æƒ…å†µæœ‰æ•ˆï¼Œå¯èƒ½ç®—å‡ºæ¥çš„ç»“æœè¿˜å°äºä¹‹å‰çš„é˜ˆå€¼ï¼Œè¿™å°±é€ æˆæ¼åˆ¤äº†ã€‚</p>
<p>ç±»ä¼¼çš„ï¼Œå¦‚æœä¸€å°ç¨åŠ¡ä¸»é¢˜çš„é‚®ä»¶æœ‰1000ä¸ªè¯è¯­ï¼Œå…¶ä¸­åªæœ‰â€œæ­£è§„å‘ç¥¨â€ã€â€œå‘ç¥¨â€ã€â€œé¿ç¨æ–¹æ³•â€3ä¸ªæƒé‡æ¯”è¾ƒå¤§çš„è¯è¯­ï¼Œå®ƒä»¬åªæ˜¯åœ¨æ­£æ–‡è¡¨è¿°ä¸­é¡ºå¸¦æåˆ°çš„å†…å®¹ã€‚å…³é”®è¯çš„å¯†åº¦è¢«è¾ƒé•¿çš„ç¯‡å¹…ç¨€é‡Šäº†ï¼Œåº”è¯¥ç®—æ˜¯æ­£å¸¸é‚®ä»¶ã€‚ä½†æ˜¯å´è¢«é˜ˆå€¼åˆ¤æ–­æˆæ•æ„Ÿé‚®ä»¶ï¼Œé€ æˆè¯¯åˆ¤äº†ã€‚</p>
<p><strong>è¿™ä¸¤ç§æƒ…å†µéƒ½è¯´æ˜topkå…³é”®è¯çš„æ–¹æ³•éœ€è¦è€ƒè™‘ç¯‡å¹…çš„å½±å“</strong>ã€‚è¿™é‡Œæœ‰è®¸å¤šç§å¤„ç†æ–¹å¼ï¼Œ<strong>å®ƒä»¬çš„åŸºæœ¬æ€æƒ³éƒ½æ˜¯é€‰å–è¯è¯­çš„ä¸ªæ•°åŠå¯¹åº”çš„é˜ˆå€¼è¦ä¸ç¯‡å¹…çš„å¤§å°æˆæ­£æ¯”</strong>ï¼Œæœ¬æ–‡åªä»‹ç»å…¶ä¸­ä¸€ç§æ–¹æ–¹æ³•ï¼š</p>
<ul>
<li>å¯¹äºé•¿ç¯‡å¹…é‚®ä»¶ï¼ŒæŒ‰ä¸€å®šçš„å¤§å°ï¼Œæ¯”å¦‚æ¯500å­—ï¼Œå°†å…¶åˆ†å‰²æˆå°çš„æ–‡æœ¬æ®µè½ï¼Œå†å¯¹å°æ–‡æœ¬æ®µè½é‡‡ç”¨topkå…³é”®è¯çš„æ–¹æ³•ã€‚åªè¦å…¶ä¸­æœ‰ä¸€ä¸ªå°æ–‡æœ¬æ®µè½è¶…è¿‡é˜ˆå€¼å°±åˆ¤æ–­æ•´å°é‚®ä»¶æ˜¯åƒåœ¾é‚®ä»¶ã€‚</li>
<li>å¯¹äºè¶…çŸ­ç¯‡å¹…é‚®ä»¶ï¼Œæ¯”å¦‚50å­—ï¼Œå¯ä»¥æŒ‰ç¯‡å¹…ä¸æ ‡å‡†æ¯”è¾ƒç¯‡å¹…çš„æ¯”ä¾‹æ¥é€‰å–topkï¼Œä»¥ç¡®å®šåº”è¯¥åŒ¹é…å…³é”®è¯è¯­çš„ä¸ªæ•°ã€‚æ¯”å¦‚é€‰å– 50500Ã—15â‰ˆ2 ä¸ªè¯è¯­è¿›è¡ŒåŒ¹é…ï¼Œç›¸åº”çš„é˜ˆå€¼å¯ä»¥æ˜¯ä¹‹å‰é˜ˆå€¼çš„ 215 ã€‚ä»¥æ­¤æ¥åˆ¤æ–­åˆ™æ›´åˆç†ã€‚</li>
</ul>
<h3 id="14-5-trick5ï¼šä½ç½®æƒé‡"><a href="#14-5-trick5ï¼šä½ç½®æƒé‡" class="headerlink" title="14.5 trick5ï¼šä½ç½®æƒé‡"></a>14.5 trick5ï¼šä½ç½®æƒé‡</h3><p>åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å¯¹è¯è¯­æƒé‡æ±‚å’Œçš„è¿‡ç¨‹éƒ½æ²¡æœ‰è€ƒè™‘é‚®ä»¶ç¯‡ç« ç»“æ„çš„å› ç´ ã€‚æ¯”å¦‚â€œæ­£è§„å‘ç¥¨â€å¦‚æœå‡ºç°åœ¨æ ‡é¢˜ä¸­åº”è¯¥æ¯”å®ƒå‡ºç°åœ¨æ­£æ–‡ä¸­å¯¹åˆ¤æ–­æ•´ä¸ªé‚®ä»¶çš„å½±å“æ›´å¤§ï¼›è€Œå‡ºç°åœ¨æ®µé¦–å¥ä¸­åˆæ¯”å…¶å‡ºç°åœ¨æ®µè½æ­£æ–‡ä¸­å¯¹åˆ¤æ–­æ•´ä¸ªé‚®ä»¶çš„å½±å“æ›´å¤§ã€‚<strong>æ‰€ä»¥å¯ä»¥æ ¹æ®è¯è¯­å‡ºç°çš„ä½ç½®ï¼Œå¯¹å…¶æƒé‡å†ä¹˜ä»¥ä¸€ä¸ªæ”¾å¤§ç³»æ•°ï¼Œä»¥æ‰©å¤§å…¶å¯¹æ•´å°é‚®ä»¶çš„å½±å“ï¼Œæé«˜è¯†åˆ«å‡†ç¡®åº¦</strong>ã€‚</p>
<p>æ¯”å¦‚ä¸€å°é‚®ä»¶å…¶æ ‡é¢˜æ˜¯â€œæ­£è§„å‘ç¥¨â€ï¼ˆå‡è®¾æ ‡é¢˜çš„æ”¾å¤§ç³»æ•°ä¸º2ï¼‰ï¼Œæ®µé¦–å¥æ˜¯â€œå‘ç¥¨â€,â€œç‚¹æ•°â€,â€œä¼˜æƒ â€ï¼ˆå‡è®¾æ®µé¦–çš„æ”¾å¤§ç³»æ•°ä¸º1.5ï¼‰ï¼Œå‰©ä¸‹çš„å¥å­æ˜¯ï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œä¿çœŸâ€ï¼‰ã€‚åˆ™è®¡ç®—logCCâ¯â¯â¯â¯â¯ æ—¶çš„å…¬å¼å°±å¯ä»¥è°ƒæ•´ä¸ºï¼š</p>
<blockquote>
<p>logCCâ¯â¯â¯â¯â¯=2Ã—logP(â€œæ­£è§„å‘ç¥¨â€|S)P(â€œæ­£è§„å‘ç¥¨â€|H)+1.5Ã—logP(â€œå‘ç¥¨â€|S)P(â€œå‘ç¥¨â€|H)+1.5Ã—logP(â€œç‚¹æ•°â€|S)P(â€œç‚¹æ•°â€|H)+1.5Ã—logP(â€œä¼˜æƒ â€|S)P(â€œä¼˜æƒ â€|H)</p>
<p>+logP(â€œæˆ‘â€|S)P(â€œæˆ‘â€|H)+logP(â€œå¸â€|S)P(â€œå¸â€|H)+logP(â€œå¯â€|S)P(â€œå¯â€|H)+logP(â€œåŠç†â€|S)P(â€œåŠç†â€|H)+logP(â€œä¿çœŸâ€|S)P(â€œä¿çœŸâ€|H)+logP(â€œæ­£å¸¸é‚®ä»¶â€|S)P(â€œæ­£å¸¸é‚®ä»¶â€)</p>
</blockquote>
<h3 id="14-6-trick6ï¼šèœœç½"><a href="#14-6-trick6ï¼šèœœç½" class="headerlink" title="14.6 trick6ï¼šèœœç½"></a>14.6 trick6ï¼šèœœç½</h3><p>æˆ‘ä»¬é€šè¿‡è¾›è¾›è‹¦è‹¦çš„ç»Ÿè®¡ä¸è®¡ç®—ï¼Œå¥½ä¸å®¹æ˜“å¾—åˆ°äº†ä¸åŒè¯è¯­çš„æƒé‡ã€‚ç„¶è€Œè¿™å¹¶ä¸æ˜¯ä¸€åŠ³æ°¸é€¸çš„ã€‚æˆ‘ä»¬æˆ‘ä»¬ä¹‹å‰äº¤ä»£è¿‡ï¼Œ<strong>è¯è¯­åŠå…¶æƒé‡ä¼šéšç€æ—¶é—´ä¸æ–­å˜åŒ–ï¼Œéœ€è¦æ—¶ä¸æ—¶åœ°ç”¨æœ€æ–°çš„æ ·æœ¬æ¥è®­ç»ƒä»¥æ›´æ–°è¯è¯­åŠå…¶æƒé‡</strong>ã€‚</p>
<p>è€Œæœé›†æœ€æ–°åƒåœ¾é‚®ä»¶æœ‰ä¸€ä¸ªæŠ€å·§ï¼Œå°±æ˜¯éšä¾¿æ³¨å†Œä¸€äº›é‚®ç®±ï¼Œç„¶åå°†å®ƒä»¬å…¬å¸ƒåœ¨å„å¤§è®ºå›ä¸Šã€‚æ¥ä¸‹æ¥å°±åç­‰ä¸€ä¸ªæœˆï¼Œåˆ°æ—¶å€™æ”¶åˆ°çš„é‚®ä»¶å°±ç»å¤§éƒ¨åˆ†éƒ½æ˜¯åƒåœ¾é‚®ä»¶äº†ï¼ˆå¥½å¥¸è¯ˆï¼‰ã€‚å†æ‰¾ä¸€äº›æ­£å¸¸çš„é‚®ä»¶ï¼ŒåŸºæœ¬å°±èƒ½å¤Ÿè®­ç»ƒäº†ã€‚è¿™äº›ç”¨äºè‡ªåŠ¨æœé›†åƒåœ¾é‚®ä»¶çš„é‚®ç®±å«åšâ€œèœœç½â€ã€‚<strong>â€œèœœç½â€æ˜¯ç½‘ç»œå®‰å…¨é¢†åŸŸå¸¸ç”¨çš„æ‰‹æ®µï¼Œå› å…¶åŸç†ç±»ä¼¼è¯±æ•æ˜†è™«çš„è£…æœ‰èœœçš„ç½å­è€Œå¾—å</strong>ã€‚æ¯”å¦‚æ€æ¯’è½¯ä»¶å…¬å¸ä¼šåˆ©ç”¨èœœç½æ¥ç›‘è§†æˆ–è·å¾—è®¡ç®—æœºç½‘ç»œä¸­çš„ç—…æ¯’æ ·æœ¬ã€æ”»å‡»è¡Œä¸ºç­‰ã€‚</p>
<h2 id="15-è´å¶æ–¯æ–¹æ³•çš„æ€ç»´æ–¹å¼"><a href="#15-è´å¶æ–¯æ–¹æ³•çš„æ€ç»´æ–¹å¼" class="headerlink" title="15. è´å¶æ–¯æ–¹æ³•çš„æ€ç»´æ–¹å¼"></a>15. è´å¶æ–¯æ–¹æ³•çš„æ€ç»´æ–¹å¼</h2><p>è®²äº†è¿™ä¹ˆå¤štricksï¼Œä½†è¿™äº›æ‰‹æ®µéƒ½æ˜¯å»ºç«‹åœ¨è´å¶æ–¯æ–¹æ³•åŸºç¡€ä¹‹ä¸Šçš„ã€‚å› æ­¤æœ‰å¿…è¦æ¢è®¨ä¸€ä¸‹è´å¶æ–¯æ–¹æ³•çš„æ€ç»´æ–¹å¼ï¼Œä»¥ä¾¿æ›´å¥½åœ°åº”ç”¨è¿™ç§æ–¹æ³•è§£å†³å®é™…é—®é¢˜ã€‚</p>
<h3 id="15-1-é€†æ¦‚é—®é¢˜"><a href="#15-1-é€†æ¦‚é—®é¢˜" class="headerlink" title="15.1 é€†æ¦‚é—®é¢˜"></a>15.1 é€†æ¦‚é—®é¢˜</h3><p>æˆ‘ä»¬é‡æ–°çœ‹ä¸€çœ¼è´å¶æ–¯å…¬å¼ï¼š</p>
<blockquote>
<p>P(Y|X)=P(X|Y)P(Y)P(X)</p>
</blockquote>
<p>å…ˆä¸è€ƒè™‘å…ˆéªŒæ¦‚ç‡P(Y)ä¸P(X)ï¼Œè§‚å¯Ÿä¸¤ä¸ªåéªŒæ¦‚ç‡P(Y|X)ä¸P(X|Y)ï¼Œå¯è§è´å¶æ–¯å…¬å¼èƒ½å¤Ÿæ­ç¤º<strong>ä¸¤ä¸ªç›¸åæ–¹å‘çš„æ¡ä»¶æ¦‚ç‡ä¹‹é—´çš„è½¬æ¢å…³ç³»</strong>ã€‚</p>
<p>ä»è´å¶æ–¯å…¬å¼çš„å‘ç°å†å²æ¥çœ‹ï¼Œå…¶å°±æ˜¯ä¸ºäº†å¤„ç†æ‰€è°“â€œé€†æ¦‚â€é—®é¢˜è€Œè¯ç”Ÿçš„ã€‚æ¯”å¦‚P(Y|X) ä¸èƒ½é€šè¿‡ç›´æ¥è§‚æµ‹æ¥å¾—åˆ°ç»“æœï¼Œè€ŒP(X|Y) å´å®¹æ˜“é€šè¿‡ç›´æ¥è§‚æµ‹å¾—åˆ°ç»“æœï¼Œå°±å¯ä»¥é€šè¿‡è´å¶æ–¯å…¬å¼<strong>ä»é—´æ¥åœ°è§‚æµ‹å¯¹è±¡å»æ¨æ–­ä¸å¯ç›´æ¥è§‚æµ‹çš„å¯¹è±¡çš„æƒ…å†µ</strong>ã€‚</p>
<p>å¥½å§ï¼Œæˆ‘ä»¬è¯´äººè¯ã€‚åŸºäºé‚®ä»¶çš„æ–‡æœ¬å†…å®¹åˆ¤æ–­å…¶å±äºåƒåœ¾é‚®ä»¶çš„æ¦‚ç‡ä¸å¥½æ±‚ï¼ˆä¸å¯é€šè¿‡ç›´æ¥è§‚æµ‹ã€ç»Ÿè®¡å¾—åˆ°ï¼‰ï¼Œä½†æ˜¯åŸºäºå·²ç»æœé›†å¥½çš„åƒåœ¾é‚®ä»¶æ ·æœ¬ï¼Œå»ç»Ÿè®¡ï¼ˆç›´æ¥è§‚æµ‹ï¼‰å…¶æ–‡æœ¬å†…éƒ¨å„ä¸ªè¯è¯­çš„æ¦‚ç‡å´éå¸¸æ–¹ä¾¿ã€‚è¿™å°±å¯ä»¥ç”¨è´å¶æ–¯æ–¹æ³•ã€‚</p>
<p>å¼•ç”³ä¸€æ­¥ï¼ŒåŸºäºæ ·æœ¬ç‰¹å¾å»åˆ¤æ–­å…¶æ‰€å±æ ‡ç­¾çš„æ¦‚ç‡ä¸å¥½æ±‚ï¼Œä½†æ˜¯åŸºäºå·²ç»æœé›†å¥½çš„æ‰“ä¸Šæ ‡ç­¾çš„æ ·æœ¬ï¼ˆæœ‰ç›‘ç£ï¼‰ï¼Œå´å¯ä»¥ç›´æ¥ç»Ÿè®¡å±äºåŒä¸€æ ‡ç­¾çš„æ ·æœ¬å†…éƒ¨å„ä¸ªç‰¹å¾çš„æ¦‚ç‡åˆ†å¸ƒã€‚å› æ­¤è´å¶æ–¯æ–¹æ³•çš„ç†è®ºè§†è§’é€‚ç”¨äºä¸€åˆ‡åˆ†ç±»é—®é¢˜çš„æ±‚è§£ã€‚</p>
<h3 id="15-2-å¤„ç†å¤šåˆ†ç±»é—®é¢˜"><a href="#15-2-å¤„ç†å¤šåˆ†ç±»é—®é¢˜" class="headerlink" title="15.2 å¤„ç†å¤šåˆ†ç±»é—®é¢˜"></a>15.2 å¤„ç†å¤šåˆ†ç±»é—®é¢˜</h3><p>å‰é¢æˆ‘ä»¬ä¸€ç›´åœ¨æ¢è®¨äºŒåˆ†ç±»ï¼ˆåˆ¤æ–­é¢˜ï¼‰é—®é¢˜ï¼Œç°åœ¨å¯ä»¥å¼•ç”³åˆ°å¤šåˆ†ç±»ï¼ˆå•é€‰é¢˜ï¼‰é—®é¢˜äº†ã€‚</p>
<p>è¿˜æ˜¯ç”¨é‚®ä»¶åˆ†ç±»çš„ä¾‹å­ï¼Œè¿™æ˜¯ç°åœ¨ä¸åªè¦åˆ¤æ–­åƒåœ¾é‚®ä»¶ï¼Œè¿˜è¦å°†æ­£å¸¸é‚®ä»¶ç»†åˆ†ä¸ºç§äººé‚®ä»¶ã€å·¥ä½œé‚®ä»¶ã€‚ç°åœ¨æœ‰è¿™3ç±»é‚®ä»¶å„1ä¸‡å°ä½œä¸ºæ ·æœ¬ã€‚éœ€è¦è®­ç»ƒå‡ºä¸€ä¸ªè´å¶æ–¯åˆ†ç±»å™¨ã€‚è¿™é‡Œä¾æ¬¡ç”¨Y1,Y2,Y3è¡¨ç¤ºè¿™ä¸‰ç±»é‚®ä»¶ï¼Œç”¨Xè¡¨ç¤ºè¢«åˆ¤æ–­çš„é‚®ä»¶ã€‚å¥—ç”¨è´å¶æ–¯å…¬å¼æœ‰ï¼š</p>
<blockquote>
<p>P(Y1|X)=P(X|Y1)P(Y1)P(X)</p>
<p>P(Y2|X)=P(X|Y2)P(Y2)P(X)</p>
<p>P(Y3|X)=P(X|Y3)P(Y3)P(X)</p>
</blockquote>
<p>é€šè¿‡æ¯”è¾ƒ3ä¸ªæ¦‚ç‡å€¼çš„å¤§å°å³å¯å¾—åˆ°Xæ‰€å±çš„åˆ†ç±»ã€‚å‘ç°ä¸‰ä¸ªå¼å­çš„åˆ†æ¯P(X) ä¸€æ ·ï¼Œæ¯”è¾ƒå¤§å°æ—¶å¯ä»¥å¿½ç•¥ä¸è®¡ï¼Œäºæ˜¯å°±å¯ä»¥ç”¨ä¸‹é¢è¿™ä¸€ä¸ªå¼å­è¡¨è¾¾ä¸Šé¢3å¼ï¼š</p>
<blockquote>
<p>P(Yi|X)âˆP(X|Yi)P(Yi)ï¼›i=1,2,3</p>
</blockquote>
<p>å…¶ä¸­ âˆ è¡¨ç¤ºâ€œæ­£æ¯”äºâ€ã€‚è€ŒP(X|Yi) åˆ™æœ‰ä¸ªç‰¹åˆ«é«˜é€¼æ ¼çš„åå­—å«åšâ€œ<strong>ä¼¼ç„¶å‡½æ•°</strong>â€ã€‚æˆ‘ä»¬ä¸Šå¤§å­¦çš„æ—¶å€™ä¹Ÿè¢«è¿™ä¸ªåå­—æå¾—æ™•æ™•ä¹ä¹çš„ï¼Œå…¶å®å®ƒä¹Ÿæ˜¯ä¸ªæ¦‚ç‡ï¼Œç›´æ¥ç†è§£æˆ<strong>â€œP(Yi|X) çš„é€†åæ¡ä»¶æ¦‚ç‡â€</strong> å°±æ–¹ä¾¿äº†ã€‚</p>
<p>è¿™é‡Œåªæ˜¯ä»¥åƒåœ¾é‚®ä»¶3åˆ†ç±»é—®é¢˜ä¸¾äº†ä¸ªä¾‹å­ï¼Œ<strong>å¯¹äºä»»æ„å¤šåˆ†ç±»çš„é—®é¢˜éƒ½å¯ä»¥ç”¨è¿™æ ·çš„æ€è·¯å»ç†è§£ã€‚æ¯”å¦‚æ–°é—»åˆ†ç±»ã€æƒ…æ„Ÿå–œæ€’å“€ä¹åˆ†ç±»ç­‰ç­‰</strong>ã€‚</p>
<h3 id="15-3-å…ˆéªŒæ¦‚ç‡çš„é—®é¢˜"><a href="#15-3-å…ˆéªŒæ¦‚ç‡çš„é—®é¢˜" class="headerlink" title="15.3 å…ˆéªŒæ¦‚ç‡çš„é—®é¢˜"></a>15.3 å…ˆéªŒæ¦‚ç‡çš„é—®é¢˜</h3><p>åœ¨åƒåœ¾é‚®ä»¶çš„ä¾‹å­ä¸­ï¼Œå…ˆéªŒæ¦‚ç‡éƒ½ç›¸ç­‰ï¼ŒP(Y1)=P(Y2)=P(Y3)=10000/30000=1/3ï¼Œæ‰€ä»¥ä¸Šé¢æ˜¯å¼å­åˆå¯ä»¥è¿›ä¸€æ­¥åŒ–ç®€ï¼š</p>
<blockquote>
<p>P(Yi|X)âˆP(X|Yi)ï¼›i=1,2,3</p>
</blockquote>
<p>åªéœ€æ¯”è¾ƒå³è¾¹å¼å­ï¼ˆä¹Ÿå°±æ˜¯â€œä¼¼ç„¶å‡½æ•°â€ï¼‰çš„å¤§å°å°±å¯ä»¥äº†ã€‚è¿™ç§æ–¹æ³•å°±æ˜¯ä¼ è¯´ä¸­çš„<strong>æœ€å¤§ä¼¼ç„¶æ³•</strong>:ä¸è€ƒè™‘å…ˆéªŒæ¦‚ç‡è€Œç›´æ¥æ¯”è¾ƒä¼¼ç„¶å‡½æ•°ã€‚</p>
<p>å…³äºé€‰å‡ºæœ€ä½³åˆ†ç±»Yiæ˜¯å¦è¦è€ƒè™‘å…ˆéªŒæ¦‚ç‡P(Yi)çš„é—®é¢˜ï¼Œæ›¾ç»åœ¨é¢‘ç‡å­¦æ´¾å’Œè´å¶æ–¯å­¦æ´¾ä¹‹é—´äº§ç”Ÿäº†æ¿€çƒˆçš„æ•™æ´¾å†²çªã€‚ç»Ÿè®¡å­¦å®¶ï¼ˆé¢‘ç‡å­¦æ´¾ï¼‰è¯´ï¼šæˆ‘ä»¬è®©æ•°æ®è‡ªå·±è¯´è¯ã€‚è¨€ä¸‹ä¹‹æ„å°±æ˜¯è¦æ‘’å¼ƒå…ˆéªŒæ¦‚ç‡ã€‚è€Œè´å¶æ–¯å­¦æ´¾æ”¯æŒè€…åˆ™è¯´ï¼šæ•°æ®ä¼šæœ‰å„ç§å„æ ·çš„åå·®ï¼Œè€Œä¸€ä¸ª<strong>é è°±çš„å…ˆéªŒæ¦‚ç‡</strong>åˆ™å¯ä»¥å¯¹è¿™äº›éšæœºå™ªéŸ³åšåˆ°å¥å£®ã€‚å¯¹æ­¤æœ‰å…´è¶£çš„åŒå­¦å¯ä»¥æ‰¾æ›´å¤šèµ„æ–™è¿›è¡Œäº†è§£ï¼Œæœ¬æ–‡åœ¨æ­¤ä¸åšæ›´å¤šçš„å¼•ç”³ï¼ŒåªåŸºäºåƒåœ¾é‚®ä»¶è¯†åˆ«çš„ä¾‹å­è¿›è¡Œæ¢è®¨ã€‚</p>
<p>æ¯”å¦‚æˆ‘ä»¬åœ¨é‡‡é›†åƒåœ¾é‚®ä»¶æ ·æœ¬çš„æ—¶å€™ï¼Œä¸å°å¿ƒdeleteæ‰äº†ä¸€åŠçš„æ•°æ®ï¼Œå°±å‰©ä¸‹5000å°é‚®ä»¶ã€‚åˆ™è®¡ç®—å‡ºæ¥çš„å…ˆéªŒæ¦‚ç‡ä¸º:</p>
<blockquote>
<p>P(Y1)=5000/25000=1/5ï¼Œ</p>
<p>P(Y2)=P(Y3)=10000/25000=2/5</p>
</blockquote>
<p>å¦‚æœè¿˜ç”¨è´å¶æ–¯æ–¹æ³•,å°±è¦åœ¨ä¼¼ç„¶å‡½æ•°åé¢ä¹˜ä¸Šå…ˆéªŒæ¦‚ç‡ã€‚æ¯”å¦‚ä¹‹å‰ç”¨æœ€å¤§ä¼¼ç„¶æ³•ç®—å‡ºY1 åƒåœ¾é‚®ä»¶çš„æ¦‚ç‡å¤§ï¼Œä½†æ˜¯å› ä¸ºP(Y1)ç‰¹åˆ«å°ï¼Œç”¨è´å¶æ–¯æ–¹æ³•å¾—å‡ºçš„ç»“æœæ˜¯Y2 ç§äººé‚®ä»¶çš„æ¦‚ç‡å¤§ã€‚é‚£ç›¸ä¿¡å“ªä¸ªå‘¢ï¼Ÿå…¶å®ï¼Œæˆ‘ä»¬åˆ æ‰äº†éƒ¨åˆ†å¸¦æ ‡ç­¾çš„æ ·æœ¬ï¼Œä»è®¡ç®—ç»“æœçœ‹P(Y1)ï¼ŒP(Y2)ï¼ŒP(Y3)çš„æ¦‚ç‡åˆ†å¸ƒå˜åŒ–äº†ï¼Œä½†å®é™…ä¸Š<strong>è¿™ä¸‰ä¸ªç±»åˆ«çš„çœŸå®åˆ†å¸ƒåº”è¯¥æ˜¯ä¸€ä¸ªå®¢è§‚çš„çŠ¶æ€ï¼Œä¸åº”è¯¥å› ä¸ºæˆ‘ä»¬çš„è®¡ç®—æ–¹æ³•è€Œå‘ç”Ÿå˜åŒ–</strong>ã€‚æ‰€ä»¥æ˜¯æˆ‘ä»¬è®¡ç®—å‡ºæ¥çš„å…ˆéªŒæ¦‚ç‡å¤±çœŸï¼Œåº”è¯¥æ”¾å¼ƒè¿™æ ·è®¡ç®—å‡ºæ¥çš„å…ˆéªŒæ¦‚ç‡ï¼Œè€Œç”¨æœ€å¤§ä¼¼ç„¶æ³•ã€‚ä½†å³ä¾¿æˆ‘ä»¬ä¸åˆ æ‰ä¸€åŠåƒåœ¾é‚®ä»¶ï¼Œè¿™ä¸‰ç±»é‚®ä»¶çš„åˆ†å¸ƒå°±çœŸçš„æ˜¯1:1:1é‚£æ ·å¹³å‡å—ï¼Ÿé‚£ä¹Ÿæœªå¿…ã€‚<strong>æˆ‘ä»¬åªæ˜¯æŒ‰1:1:1è¿™æ ·çš„æ–¹å¼è¿›è¡Œäº†æŠ½æ ·è€Œå·²ï¼ŒçœŸæ­£åœ¨é‚®ç®±é‡Œæ”¶åˆ°çš„è¿™ä¸‰ç±»é‚®ä»¶çš„åˆ†å¸ƒå¯èƒ½å¹¶ä¸æ˜¯è¿™æ ·</strong>ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œ<strong>åœ¨æˆ‘ä»¬å¯¹äºå…ˆéªŒæ¦‚ç‡ä¸€æ— æ‰€çŸ¥æ—¶ï¼Œåªèƒ½å‡è®¾æ¯ç§çŒœæµ‹çš„å…ˆéªŒæ¦‚ç‡æ˜¯å‡ç­‰çš„ï¼ˆå…¶å®è¿™ä¹Ÿæ˜¯äººç±»ç»éªŒçš„ç»“æœï¼‰ï¼Œè¿™ä¸ªæ—¶å€™å°±åªæœ‰ç”¨æœ€å¤§ä¼¼ç„¶äº†</strong>ã€‚åœ¨ç°å®è¿ç”¨è¿‡ç¨‹ä¸­å¦‚æœå‘ç°æœ€å¤§ä¼¼ç„¶æ³•æœ‰åå·®ï¼Œå¯ä»¥è€ƒè™‘å¯¹ä¸åŒçš„ä¼¼ç„¶å‡½æ•°è®¾å®šä¸€äº›ç³»æ•°æˆ–è€…é˜ˆå€¼ï¼Œä½¿å…¶æ¥è¿‘çœŸå®æƒ…å†µã€‚</p>
<p>ä½†æ˜¯ï¼Œ<strong>å¦‚æœæˆ‘ä»¬æœ‰è¶³å¤Ÿçš„è‡ªä¿¡ï¼Œè®­ç»ƒé›†ä¸­è¿™ä¸‰ç±»çš„æ ·æœ¬åˆ†å¸ƒçš„ç¡®å¾ˆæ¥è¿‘çœŸå®çš„æƒ…å†µï¼Œè¿™æ—¶å°±åº”è¯¥ç”¨è´å¶æ–¯æ–¹æ³•</strong>ã€‚éš¾æ€ªå‰é¢çš„è´å¶æ–¯å­¦æ´¾å¼ºè°ƒçš„æ˜¯â€œé è°±çš„å…ˆéªŒæ¦‚ç‡â€ã€‚æ‰€ä»¥è¯´<strong>è´å¶æ–¯å­¦æ´¾çš„é€‚ç”¨èŒƒå›´æ›´å¹¿ï¼Œå…³é”®è¦å…ˆéªŒæ¦‚ç‡é è°±ï¼Œè€Œé¢‘ç‡å­¦æ´¾æœ‰æ•ˆçš„å‰æä¹Ÿæ˜¯ä»–ä»¬çš„å…ˆéªŒæ¦‚ç‡åŒæ ·æ˜¯ç»éªŒç»Ÿè®¡çš„ç»“æœ</strong>ã€‚</p>
<h2 id="16-æœ´ç´ -è´å¶æ–¯æ–¹æ³•çš„å¸¸è§åº”ç”¨"><a href="#16-æœ´ç´ -è´å¶æ–¯æ–¹æ³•çš„å¸¸è§åº”ç”¨" class="headerlink" title="16. (æœ´ç´ )è´å¶æ–¯æ–¹æ³•çš„å¸¸è§åº”ç”¨"></a>16. (æœ´ç´ )è´å¶æ–¯æ–¹æ³•çš„å¸¸è§åº”ç”¨</h2><p>è¯´äº†è¿™ä¹ˆå¤šç†è®ºçš„é—®é¢˜ï¼Œå’±ä»¬å°±å¯ä»¥æ¢è®¨ä¸€ä¸‹(æœ´ç´ )è´å¶æ–¯æ–¹æ³•åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„ä¸€äº›å¸¸è§åº”ç”¨äº†ã€‚ä»¥ä¸‹åªæ˜¯ä»åŸç†ä¸Šè¿›è¡Œæ¢è®¨ï¼Œå¯¹äºå…·ä½“çš„æŠ€æœ¯ç»†èŠ‚é¡¾åŠä¸å¤šã€‚</p>
<h3 id="16-1-è¤’è´¬åˆ†æ"><a href="#16-1-è¤’è´¬åˆ†æ" class="headerlink" title="16.1 è¤’è´¬åˆ†æ"></a>16.1 è¤’è´¬åˆ†æ</h3><p>ä¸€ä¸ªæ¯”è¾ƒå¸¸è§çš„åº”ç”¨åœºæ™¯æ˜¯æƒ…æ„Ÿè¤’è´¬åˆ†æã€‚æ¯”å¦‚ä½ è¦ç»Ÿè®¡å¾®åšä¸Šäººä»¬å¯¹ä¸€ä¸ªæ–°ä¸Šæ˜ ç”µå½±çš„è¤’è´¬ç¨‹åº¦è¯„ä»·ï¼šå¥½ç‰‡è¿˜æ˜¯çƒ‚ç‰‡ã€‚ä½†æ˜¯ä¸€æ¡ä¸€æ¡åœ°çœ‹å¾®åšæ˜¯æ ¹æœ¬çœ‹ä¸è¿‡æ¥ï¼Œåªèƒ½ç”¨è‡ªåŠ¨åŒ–çš„æ–¹æ³•ã€‚æˆ‘ä»¬å¯ä»¥æœ‰ä¸€ä¸ªå¾ˆç²—ç•¥çš„æ€è·¯ï¼š</p>
<ul>
<li>é¦–å…ˆæ˜¯ç”¨çˆ¬è™«å°†å¾®åšä¸Šæåˆ°è¿™ä¸ªç”µå½±åå­—çš„å¾®åšå…¨éƒ½æŠ“å–ä¸‹æ¥ï¼Œæ¯”å¦‚æœ‰10ä¸‡æ¡ã€‚</li>
<li>ç„¶åç”¨è®­ç»ƒå¥½çš„æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨åˆ†åˆ«åˆ¤æ–­è¿™äº›å¾®åšå¯¹ç”µå½±æ˜¯å¥½è¯„è¿˜æ˜¯å·®è¯„ã€‚</li>
<li>æœ€åç»Ÿè®¡å‡ºè¿™äº›å¥½è¯„çš„å½±è¯„å æ‰€æœ‰æ ·æœ¬ä¸­çš„æ¯”ä¾‹ï¼Œå°±èƒ½å½¢æˆå¾®åšç½‘å‹å¯¹è¿™ä¸ªç”µå½±ç»¼åˆè¯„ä»·çš„å¤§è‡´ä¼°è®¡ã€‚</li>
</ul>
<p>æ¥ä¸‹æ¥çš„æ ¸å¿ƒé—®é¢˜å°±æ˜¯è®­ç»ƒå‡ºä¸€ä¸ªé è°±çš„åˆ†ç±»å™¨ã€‚é¦–å…ˆéœ€è¦æœ‰æ‰“å¥½æ ‡ç­¾çš„æ–‡æœ¬ã€‚è¿™ä¸ªå¥½æ‰¾ï¼Œè±†ç“£å½±è¯„ä¸Šå°±æœ‰å¤§é‡ç½‘å‹å¯¹ä¹‹å‰ç”µå½±çš„è¯„ä»·ï¼Œå¹¶ä¸”å¯¹ç”µå½±è¿›è¡Œ1æ˜Ÿåˆ°5æ˜Ÿçš„è¯„ä»·ã€‚æˆ‘ä»¬å¯ä»¥è®¤ä¸º3æ˜Ÿä»¥ä¸Šçš„è¯„è®ºéƒ½æ˜¯å¥½è¯„ï¼Œ3æ˜Ÿä»¥ä¸‹çš„è¯„è®ºéƒ½æ˜¯å·®è¯„ã€‚è¿™æ ·å°±åˆ†åˆ«å¾—åˆ°äº†å¥½è¯„å·®è¯„ä¸¤ç±»çš„è¯­æ–™æ ·æœ¬ã€‚å‰©ä¸‹å°±å¯ä»¥ç”¨æœ´ç´ è´å¶æ–¯æ–¹æ³•è¿›è¡Œè®­ç»ƒäº†ã€‚åŸºæœ¬æ€è·¯å¦‚ä¸‹ï¼š</p>
<ul>
<li>è®­ç»ƒä¸æµ‹è¯•æ ·æœ¬ï¼šè±†ç“£å½±è¯„çš„ç½‘å‹è¯„è®ºï¼Œç”¨çˆ¬è™«æŠ“å–ä¸‹100ä¸‡æ¡ã€‚</li>
<li>æ ‡ç­¾ï¼š3æ˜Ÿä»¥ä¸Šçš„æ˜¯å¥½è¯„ï¼Œ3æ˜Ÿä»¥ä¸‹çš„æ˜¯å·®è¯„ã€‚</li>
<li>ç‰¹å¾ï¼šè±†ç“£è¯„è®ºåˆ†è¯åçš„è¯è¯­ã€‚ä¸€ä¸ªç®€å•çš„æ–¹æ³•æ˜¯åªé€‰æ‹©å…¶ä¸­çš„å½¢å®¹è¯ï¼Œç½‘ä¸Šæœ‰å¤§é‡çš„æƒ…ç»ªè¯åº“å¯ä»¥ä¸ºæˆ‘ä»¬æ‰€ç”¨ã€‚</li>
<li>ç„¶åå†ç”¨å¸¸è§„çš„æœ´ç´ è´å¶æ–¯æ–¹æ³•è¿›è¡Œè®­ç»ƒã€‚</li>
</ul>
<p>ä½†æ˜¯ç”±äºè‡ªç„¶è¯­è¨€çš„ç‰¹ç‚¹ï¼Œåœ¨æå–ç‰¹å¾çš„è¿‡ç¨‹å½“ä¸­ï¼Œæœ‰ä¸€äº›trickséœ€è¦æ³¨æ„ï¼š</p>
<ul>
<li><strong>å¯¹å¦å®šå¥è¿›è¡Œç‰¹åˆ«çš„å¤„ç†</strong>ã€‚æ¯”å¦‚è¿™å¥è¯â€œæˆ‘ä¸æ˜¯å¾ˆå–œæ¬¢éƒ¨ç”µå½±ï¼Œå› ä¸ºå®ƒè®©æˆ‘å¼€å¿ƒä¸èµ·æ¥ã€‚â€å…¶ä¸­ä¸¤ä¸ªå½¢å®¹è¯â€œå–œæ¬¢â€ã€â€œå¼€å¿ƒâ€éƒ½æ˜¯è¤’ä¹‰è¯ï¼Œä½†æ˜¯å› ä¸ºå¥å­çš„å¦å®šå¥ï¼Œæ‰€ä»¥æ•´ä½“æ˜¯è´¬ä¹‰çš„ã€‚æœ‰ä¸€ç§æ¯”è¾ƒç®€å•ç²—æš´çš„å¤„ç†æ–¹å¼ï¼Œå°±æ˜¯<strong>â€œå¯¹å¦å®šè¯ï¼ˆâ€œä¸â€ã€â€œéâ€ã€â€œæ²¡â€ç­‰ï¼‰ä¸å¥å°¾æ ‡ç‚¹ä¹‹é—´çš„æ‰€æœ‰å½¢å®¹è¯éƒ½é‡‡ç”¨å…¶å¦å®šå½¢å¼â€</strong> ã€‚åˆ™è¿™å¥è¯ä¸­æå–å‡ºæ¥çš„å½¢å®¹è¯å°±åº”è¯¥æ˜¯â€œä¸å–œæ¬¢â€å’Œâ€œä¸å¼€å¿ƒâ€ã€‚</li>
<li>ä¸€èˆ¬è¯´æ¥ï¼Œæœ€ç›¸å…³çš„æƒ…æ„Ÿè¯åœ¨ä¸€äº›æ–‡æœ¬ç‰‡æ®µä¸­ä»…ä»…å‡ºç°ä¸€æ¬¡ï¼Œè¯é¢‘æ¨¡å‹èµ·å¾—ä½œç”¨æœ‰é™ï¼Œç”šè‡³æ˜¯è´Ÿä½œç”¨ï¼Œ<strong>åˆ™ä½¿ç”¨ä¼¯åŠªåˆ©æ¨¡å‹ä»£æ›¿å¤šé¡¹å¼æ¨¡å‹</strong>ã€‚è¿™ç§æƒ…å†µåœ¨å¾®åšè¿™æ ·çš„å°ç¯‡å¹…æ–‡æœ¬ä¸­ä¼¼ä¹ä¸å¤ªæ˜æ˜¾ï¼Œä½†æ˜¯åœ¨åšå®¢ã€ç©ºé—´ã€è®ºå›ä¹‹ç±»å…è®¸é•¿ç¯‡å¹…æ–‡æœ¬å‡ºç°çš„å¹³å°ä¸­éœ€è¦æ³¨æ„ã€‚</li>
<li>å…¶å®ï¼Œå‰¯è¯å¯¹æƒ…æ„Ÿçš„è¯„ä»·æœ‰ä¸€å®šå½±å“ã€‚â€œä¸å¾ˆå–œæ¬¢â€ä¸â€œå¾ˆä¸å–œæ¬¢â€çš„ç¨‹åº¦å°±æœ‰å¾ˆå¤§å·®å¼‚ã€‚ä½†å¦‚æœæ˜¯æœ´ç´ è´å¶æ–¯æ–¹æ³•çš„è¯æ¯”è¾ƒéš¾å¤„ç†è¿™æ ·çš„æƒ…å†µã€‚æˆ‘ä»¬å¯ä»¥è€ƒè™‘ç”¨è¯­è¨€æ¨¡å‹æˆ–è€…åŠ å…¥è¯æ€§æ ‡æ³¨çš„ä¿¡æ¯è¿›è¡Œç»¼åˆåˆ¤æ–­ã€‚è¿™äº›å†…å®¹æˆ‘ä»¬å°†åœ¨ä¹‹åçš„æ–‡ç« è¿›è¡Œæ¢è®¨ã€‚</li>
</ul>
<p>å½“ç„¶ç»è¿‡ä»¥ä¸Šçš„å¤„ç†ï¼Œæƒ…æ„Ÿåˆ†æè¿˜æ˜¯ä¼šæœ‰ä¸€éƒ¨åˆ†è¯¯åˆ¤ã€‚è¿™é‡Œæ¶‰åŠåˆ°è®¸å¤šé—®é¢˜ï¼Œéƒ½æ˜¯æƒ…æ„Ÿåˆ†æçš„éš¾ç‚¹ï¼š</p>
<ul>
<li><strong>æƒ…ç»ªè¡¨è¾¾çš„å«è“„å¾®å¦™</strong>ï¼šâ€œå¯¼æ¼”ä½ å‡ºæ¥ï¼Œæˆ‘ä¿è¯ä¸æ‰“æ­»ä½ ã€‚â€ä½ è®©æœºå™¨æ€ä¹ˆåˆ¤æ–­æ˜¯è¤’è¿˜æ˜¯è´¬ï¼Ÿ</li>
<li><strong>è½¬æŠ˜æ€§è¡¨è¾¾</strong>ï¼šâ€œæˆ‘éå¸¸å–œæ¬¢è¿™äº›å¤§ç‰Œæ¼”å‘˜ï¼Œéå¸¸å´‡æ‹œè¿™ä¸ªå¯¼æ¼”ï¼Œéå¸¸èµèµè¿™ä¸ªå‰§æœ¬ï¼Œéå¸¸æ¬£èµä»–ä»¬çš„é¢„å‘Šç‰‡ï¼Œæˆ‘ç”šè‡³ä¸ºäº†è¿™éƒ¨å½±ç‰‡æ•´æ•´æœŸå¾…äº†ä¸€å¹´ï¼Œæœ€åè¿›äº†ç”µå½±é™¢å‘ç°è¿™æ˜¯ä¸ªå™©æ¢¦ã€‚â€ äº”ä¸ªè¤’ä¹‰çš„å½¢å®¹è¯ã€å‰¯è¯å¯¹ä¸€ä¸ªä¸é‚£ä¹ˆè´¬ä¹‰çš„è¯ã€‚æœºå™¨è‡ªç„¶åˆ¤æ–­æˆè¤’ä¹‰ï¼Œä½†è¿™å¥è¯æ˜¯å¦¥å¦¥çš„è´¬ä¹‰ã€‚</li>
</ul>
<h3 id="16-2-æ‹¼å†™çº é”™"><a href="#16-2-æ‹¼å†™çº é”™" class="headerlink" title="16.2 æ‹¼å†™çº é”™"></a>16.2 æ‹¼å†™çº é”™</h3><p>æ‹¼å†™çº é”™æœ¬è´¨ä¸Šä¹Ÿæ˜¯ä¸€ä¸ªåˆ†ç±»é—®é¢˜ã€‚ä½†æŒ‰ç…§é”™è¯¯ç±»å‹ä¸åŒï¼Œåˆåˆ†ä¸ºä¸¤ç§æƒ…å†µï¼š</p>
<ul>
<li>éè¯é”™è¯¯ï¼ˆNon-word Errorsï¼‰ï¼šæŒ‡é‚£äº›æ‹¼å†™é”™è¯¯åçš„è¯æœ¬èº«å°±ä¸åˆæ³•ï¼Œå¦‚å°†â€œwifiâ€å†™æˆâ€œwifyâ€ï¼›</li>
<li>çœŸè¯é”™è¯¯ï¼ˆReal-word Errorsï¼‰ï¼šæŒ‡é‚£äº›æ‹¼å†™é”™è¯¯åçš„è¯ä»ç„¶æ˜¯åˆæ³•çš„æƒ…å†µï¼Œå¦‚å°†â€œwifiâ€å†™æˆâ€œwifeâ€ã€‚</li>
</ul>
<p>çœŸè¯é”™è¯¯å¤æ‚ä¸€äº›ï¼Œæˆ‘ä»¬å°†åœ¨æ¥ä¸‹æ¥çš„æ–‡ç« ä¸­è¿›è¡Œæ¢è®¨ã€‚è€Œå¯¹äºéè¯é”™è¯¯ï¼Œå°±å¯ä»¥ç›´æ¥é‡‡ç”¨è´å¶æ–¯æ–¹æ³•ï¼Œå…¶åŸºæœ¬æ€è·¯å¦‚ä¸‹ï¼š</p>
<ul>
<li>æ ‡ç­¾ï¼šé€šè¿‡è®¡ç®—é”™è¯¯è¯è¯­çš„æœ€å°ç¼–è¾‘è·ç¦»ï¼ˆä¹‹å‰å’±ä»¬æåˆ°è¿‡çš„ï¼‰ï¼Œè·å–æœ€ç›¸ä¼¼çš„å€™é€‰è¯ï¼Œæ¯ä¸ªå€™é€‰è¯ä½œä¸ºä¸€ä¸ªåˆ†ç±»ã€‚</li>
<li>ç‰¹å¾ï¼šæ‹¼å†™é”™è¯¯çš„è¯æœ¬èº«ã€‚å› ä¸ºå®ƒå°±ä¸€ä¸ªç‰¹å¾ï¼Œæ‰€ä»¥æ²¡æœ‰ä»€ä¹ˆæ¡ä»¶ç‹¬ç«‹æ€§å‡è®¾ã€æœ´ç´ è´å¶æ–¯å•¥çš„ã€‚å®ƒå°±æ˜¯çº¯è€Œåˆçº¯çš„è´å¶æ–¯æ–¹æ³•ã€‚</li>
<li>åˆ¤åˆ«å…¬å¼:</li>
</ul>
<blockquote>
<p>P(å€™é€‰è¯i|é”™è¯¯è¯)âˆP(é”™è¯¯è¯|å€™é€‰è¯i)P(å€™é€‰è¯i)ï¼›i=1,2,3,â€¦</p>
</blockquote>
<ul>
<li>è®­ç»ƒæ ·æœ¬1ï¼šè¯¥åœºæ™¯ä¸‹çš„æ­£å¸¸ç”¨è¯è¯­æ–™åº“ï¼Œç”¨äºè®¡ç®—P(å€™é€‰è¯i)ã€‚</li>
</ul>
<blockquote>
<p>P(å€™é€‰è¯i)=å€™é€‰è¯å‡ºç°çš„æ¬¡æ•°æ‰€æœ‰è¯å‡ºç°çš„æ¬¡æ•°</p>
</blockquote>
<ul>
<li>è®­ç»ƒæ ·æœ¬2ï¼šè¯¥åœºæ™¯ä¸‹é”™è¯¯è¯ä¸æ­£ç¡®è¯å¯¹åº”å…³ç³»çš„è¯­æ–™åº“ï¼Œç”¨äºè®¡ç®—P(é”™è¯¯è¯|å€™é€‰è¯i)</li>
</ul>
<blockquote>
<p>P(é”™è¯¯è¯|å€™é€‰è¯i)=å€™é€‰è¯è¢«æ‹¼å†™æˆè¯¥â€œé”™è¯¯è¯â€çš„æ¬¡æ•°å€™é€‰è¯å‡ºç°çš„æ¬¡æ•°</p>
</blockquote>
<p>ç”±äºè‡ªç„¶è¯­è¨€çš„ç‰¹ç‚¹ï¼Œæœ‰ä¸€äº›trickséœ€è¦æ³¨æ„ï¼š</p>
<ul>
<li>æ®ç»Ÿè®¡ï¼Œ80%çš„æ‹¼å†™é”™è¯¯ç¼–è¾‘è·ç¦»ä¸º1ï¼Œå‡ ä¹æ‰€æœ‰çš„æ‹¼å†™é”™è¯¯ç¼–è¾‘è·ç¦»å°äºç­‰äº2ã€‚æˆ‘ä»¬<strong>åªé€‰æ‹©ç¼–è¾‘è·ç¦»ä¸º1æˆ–2çš„è¯ä½œä¸ºå€™é€‰è¯ï¼Œè¿™æ ·å°±å¯ä»¥å‡å°‘å¤§é‡ä¸å¿…è¦çš„è®¡ç®—</strong>ã€‚</li>
<li>ç”±äºæˆ‘ä»¬åªé€‰æ‹©ç¼–è¾‘è·ç¦»ä¸º1æˆ–2çš„è¯ï¼Œå…¶å·®åˆ«åªæ˜¯ä¸€ä¸¤ä¸ªå­—æ¯çº§åˆ«å·®åˆ«ã€‚å› æ­¤è®¡ç®—ä¼¼ç„¶å‡½æ•°çš„æ—¶å€™ï¼Œ<strong>å¯ä»¥åªç»Ÿè®¡å­—æ¯å±‚é¢çš„ç¼–è¾‘é”™è¯¯ï¼Œè¿™æ ·æœé›†çš„æ ·æœ¬æ›´å¤šï¼Œæ›´æ»¡è¶³å¤§æ•°å®šå¾‹ï¼Œä¹Ÿæ›´ç®€å•</strong>ã€‚å¯¹äºç¼–è¾‘è·ç¦»ä¸º1çš„ä¼¼ç„¶å‡½æ•°è®¡ç®—å…¬å¼å¯ä»¥è¿›åŒ–ä¸ºï¼š</li>
</ul>
<blockquote>
<p>P(é”™è¯¯è¯|å€™é€‰è¯i)=â§â©â¨âªâªâªâªâªâªå­—æ¯â€œxyâ€è¢«æ‹¼å†™æˆâ€œyâ€çš„æ¬¡æ•°å­—æ¯â€œxyâ€å‡ºç°çš„æ¬¡æ•°,å­—æ¯â€œxâ€è¢«æ‹¼å†™æˆâ€œxyâ€çš„æ¬¡æ•°å­—æ¯â€œxâ€å‡ºç°çš„æ¬¡æ•°,å­—æ¯â€œxâ€è¢«æ‹¼å†™æˆâ€œyâ€çš„æ¬¡æ•°å­—æ¯â€œxâ€å‡ºç°çš„æ¬¡æ•°,å­—æ¯â€œxyâ€è¢«æ‹¼å†™æˆâ€œyxçš„æ¬¡æ•°å­—æ¯â€œxyâ€å‡ºç°çš„æ¬¡æ•°,</p>
</blockquote>
<ul>
<li><strong>é”®ç›˜ä¸Šä¸´è¿‘çš„æŒ‰é”®æ›´å®¹æ˜“æ‹¼å†™é”™è¯¯ï¼Œæ®æ­¤å¯ä»¥å¯¹ä¸Šé¢è¿™ä¸ªæ¡ä»¶æ¦‚ç‡è¿›è¡ŒåŠ æƒ</strong>ã€‚</li>
</ul>
<p><img src="blob:file:///3ecb40bd-0f8b-4742-ac50-e0912d5c6cc0" alt="\[é”®ç›˜\]"></p>
<h2 id="17-å†…å®¹å°ç»“"><a href="#17-å†…å®¹å°ç»“" class="headerlink" title="17. å†…å®¹å°ç»“"></a>17. å†…å®¹å°ç»“</h2><p>ä»å‰é¢å¤§å®¶åŸºæœ¬å¯ä»¥çœ‹å‡ºï¼Œå·¥ç¨‹åº”ç”¨ä¸åŒäºå­¦æœ¯ç†è®ºï¼Œæœ‰è®¸å¤štrickséœ€è¦è€ƒè™‘ï¼Œè€Œç†è®ºæœ¬è´¨å°±æ˜¯ç¿»æ¥å€’å»æŠ˜è…¾è´å¶æ–¯å…¬å¼ï¼Œéƒ½å¿«ç©å‡ºèŠ±æ¥äº†ã€‚</p>
<p>In [ ]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/æœºå™¨å­¦ä¹ /">æœºå™¨å­¦ä¹ </a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/æœ´ç´ è´å¶æ–¯/">æœ´ç´ è´å¶æ–¯</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
  
</article>










  
    <article id="post-GPTæ¨¡å‹" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/05/30/GPTæ¨¡å‹/" class="article-date">
      <time datetime="2020-05-30T00:30:42.000Z" itemprop="datePublished">2020-05-30</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/05/30/GPTæ¨¡å‹/">GPTæ¨¡å‹</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>æ–‡æœ¬åˆ†ç±»ï¼š</p>
<p>æ•°æ®é›†</p>
<p>THUCNews æ•°æ®é›†å­é›†,é“¾æ¥: <a href="https://pan.baidu.com/s/1hugrfRu" target="_blank" rel="noopener">https://pan.baidu.com/s/1hugrfRu</a> å¯†ç : qfud</p>
<p>Language Understanding</p>
<ul>
<li><p>intent classification</p>
</li>
<li><p>dialogue state tracking</p>
</li>
<li><p>sentiment classification</p>
</li>
</ul>
<p>Language Generation</p>
<ul>
<li>information, structured, sentiment â€“&gt; language</li>
</ul>
<h1 id="å¿…è¯»è®ºæ–‡"><a href="#å¿…è¯»è®ºæ–‡" class="headerlink" title="å¿…è¯»è®ºæ–‡"></a>å¿…è¯»è®ºæ–‡</h1><h1 id="GPT"><a href="#GPT" class="headerlink" title="GPT"></a>GPT</h1><p>Radford et. al., Improving Language Understanding by Generative Pre-Training</p>
<p><a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf" target="_blank" rel="noopener">https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf</a></p>
<p>è¿™ç¯‡æ–‡ç« æ¨å‡ºäº†generative pre-training + discriminative fine-tuningçš„æ–¹æ³•ï¼Œåæ¥ä¹Ÿè¢«BERTæ²¿ç”¨ã€‚task-aware input transformationä¹Ÿæ˜¯BERTå€Ÿç”¨çš„ä¸€ä¸ªç‚¹ã€‚å½“å¹´è¿™ç¯‡æ–‡ç« åˆšå‡ºæ¥çš„æ—¶å€™åˆ·æ¦œä¸€æ³¢ï¼Œä¸è¿‡ç¦»BERTå¤ªè¿‘ï¼Œå¯¼è‡´åæ¥å¤§å®¶éƒ½ä¸æ€ä¹ˆå…³å¿ƒè¿™ç¯‡æ–‡ç« äº†ã€‚</p>
<p><s>  a b c d e f </s></p>
<p>|        |  |  |  |  |  |</p>
<p>a       b c d e f  </p>
<p>1 0 0 0 0 0 0</p>
<p>1 1 0 0 0 0 0</p>
<p>1 1 1 0 0 0 0</p>
<p>1 1 1 1 0 0 0</p>
<p>1 1 1 1 1 0 0</p>
<p>1 1 1 1 1 1 0</p>
<h2 id="é¢„è®­ç»ƒ"><a href="#é¢„è®­ç»ƒ" class="headerlink" title="é¢„è®­ç»ƒ"></a>é¢„è®­ç»ƒ</h2><p>è¯­è¨€æ¨¡å‹objective</p>
<p><img src="https://uploader.shimo.im/f/jUXNKYwxjuUim5hM.png!thumbnail" alt="img"></p>
<p>Transformer Decoder</p>
<p><img src="https://uploader.shimo.im/f/2VVdkCN84SM8h2NA.png!thumbnail" alt="img"></p>
<p>è®­ç»ƒä½¿ç”¨BooksCorpusæ•°æ®é›†ï¼Œ7000æœ¬ä¹¦ã€‚</p>
<p>æ¨¡å‹å‚æ•°ï¼š</p>
<ul>
<li><p>12å±‚transformer decoder</p>
</li>
<li><p>768 hidden states, 12 attention heads</p>
</li>
<li><p>FFNå±‚æœ‰3072ç»´åº¦inner states</p>
</li>
</ul>
<h2 id="Fine-tuning"><a href="#Fine-tuning" class="headerlink" title="Fine tuning"></a>Fine tuning</h2><p>ä½¿ç”¨æœ€åä¸€å±‚æœ€åä¸€ä¸ªtokençš„representationæ¥åštask specificçš„æ¨¡å‹fine tuning</p>
<p><img src="https://uploader.shimo.im/f/sMzH5VF5BcQsk8pY.png!thumbnail" alt="img"></p>
<p>ä¾ç„¶ä½¿ç”¨Log loss</p>
<p><img src="https://uploader.shimo.im/f/odJ6a19y3swDAYcI.png!thumbnail" alt="img"></p>
<p>ä½œè€…å‘ç°åœ¨fine tuningçš„æ—¶å€™ç»§ç»­ä½¿ç”¨è¯­è¨€æ¨¡å‹çš„lossä¹Ÿæœ‰å¥½å¤„</p>
<p><img src="https://uploader.shimo.im/f/z2GX6ss3yL8CrvaN.png!thumbnail" alt="img"></p>
<h2 id="Task-specific-Input-Transformations"><a href="#Task-specific-Input-Transformations" class="headerlink" title="Task-specific Input Transformations"></a>Task-specific Input Transformations</h2><p>å››ç§é—®é¢˜æœ‰å››ç§ä¸åŒçš„æ–‡æœ¬è¡¨ç¤ºæ–¹æ³•</p>
<p><img src="https://uploader.shimo.im/f/e3Ep9QOmlzI2YmM8.png!thumbnail" alt="img"></p>
<p>Natural Language Inference</p>
<ul>
<li><p>åˆ¤æ–­ä¸¤å¥è¯çš„å…³ç³»ï¼Œentailment æ‰¿æ¥å…³ç³»ï¼Œcontradiction çŸ›ç›¾å…³ç³»ï¼Œneutral ä¸­ç«‹å…³ç³»</p>
</li>
<li><p>åœ¨å‡ ä¸ªNLIä»»åŠ¡ä¸Šéƒ½æœ‰ä¸å°çš„æå‡</p>
</li>
</ul>
<p>Question Answering and Common Sense Reasoning</p>
<p>Semantic Similarity è¯­ä¹‰ç›¸ä¼¼åº¦</p>
<ul>
<li><p>Microsoft Paraphrase Corpus</p>
</li>
<li><p>Quora Question Pairs</p>
</li>
</ul>
<p>åˆ†ç±»é—®é¢˜ </p>
<ul>
<li><p>Corpus of Lingustic Acceptabilityï¼Œåˆ¤æ–­ä¸€å¥è¯çš„è¯­æ³•æ˜¯ä¸æ˜¯æ­£ç¡®ã€‚</p>
</li>
<li><p>Stanford Sentiment Treebank æƒ…æ„Ÿåˆ†ç±»</p>
</li>
</ul>
<h1 id="GPT2"><a href="#GPT2" class="headerlink" title="GPT2"></a>GPT2</h1><p>Radford et. al., <a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" target="_blank" rel="noopener">Language Models are Unsupervised Multitask Learners</a></p>
<p><a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" target="_blank" rel="noopener">https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf</a></p>
<p>æ¯”GPTæ›´å¤§çš„è®­ç»ƒæ•°æ®é›†</p>
<ul>
<li>Common Crawlæ¥è‡ªç½‘é¡µçˆ¬å–ï¼Œåˆ é™¤äº†Wikipediaï¼Œæ€»å…±40GBæ•°æ®ã€‚</li>
</ul>
<p>evaluationä»»åŠ¡</p>
<ul>
<li><p>The Winograd Schema Challenge</p>
</li>
<li><p>LAMBADA dataset <a href="https://arxiv.org/pdf/1606.06031.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1606.06031.pdf</a></p>
</li>
</ul>
<p>å…³äºæ–‡æœ¬ç”Ÿæˆ</p>
<p><a href="https://arxiv.org/pdf/1904.09751.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1904.09751.pdf</a></p>
<h2 id="ä»£ç è§£è¯»"><a href="#ä»£ç è§£è¯»" class="headerlink" title="ä»£ç è§£è¯»"></a>ä»£ç è§£è¯»</h2><p>æˆ‘å¯¹ä»£ç æ·»åŠ äº†ä¸€äº›æ³¨é‡Š</p>
<p><a href="https://github.com/ZeweiChu/gpt-2/blob/master/src/model.py" target="_blank" rel="noopener">https://github.com/ZeweiChu/gpt-2/blob/master/src/model.py</a></p>
<p>huggingfaceä»£ç </p>
<p><a href="https://github.com/huggingface/transformers/blob/master/src/transformers/modeling_gpt2.py" target="_blank" rel="noopener">https://github.com/huggingface/transformers/blob/master/src/transformers/modeling_gpt2.py</a></p>
<p>è‡ªåŠ¨æ£€æµ‹</p>
<p>def attention_mask(nd, ns, *, dtype):</p>
<p>â€‹    â€œâ€â€1â€™s in the lower triangle, counting from the lower right corner.</p>
<p>â€‹    å·¦ä¸‹è§’çš„ä¸‰è§’å½¢éƒ½æ˜¯1ï¼Œå…¶ä½™æ˜¯0ï¼Œç”¨äºç”Ÿæˆmaskã€‚</p>
<p>â€‹    Same as tf.matrix_band_part(tf.ones([nd, ns]), -1, ns-nd), but doesnâ€™t produce garbage on TPUs.</p>
<p>â€‹    â€œâ€â€</p>
<p>â€‹    i = tf.range(nd)[:,None]</p>
<p>â€‹    j = tf.range(ns)</p>
<p>â€‹    m = i &gt;= j - ns + nd</p>
<p>â€‹    return tf.cast(m, dtype)</p>
<p>0 0 0 0 0</p>
<p>1 1 1 1 1</p>
<p>2 2 2 2 2</p>
<p>3 3 3 3 3</p>
<p>4 4 4 4 4</p>
<p>0 1 2 3 4 </p>
<p>1 0 0 0 0</p>
<p>1 1 0 0 0</p>
<p>1 1 1 0 0</p>
<p>1 1 1 1 0</p>
<p>1 1 1 1 1</p>
<p>w00 w01-inf w02-inf w03-inf w04-inf</p>
<p>w10 w11 w12-inf w13-inf w14-inf</p>
<p>w20 w21 w22 w23-inf w24-inf</p>
<p>w30 w31 w32 w33 w34-inf</p>
<p>w40 w41 w42 w43 w44</p>
<p>é˜…è¯»GPT2ä»£ç ï¼š<a href="https://github.com/ZeweiChu/gpt-2/blob/master/src/model.py" target="_blank" rel="noopener">https://github.com/ZeweiChu/gpt-2/blob/master/src/model.py</a></p>
<h1 id="Google-T5-Transformeré¢„è®­ç»ƒæ¨¡å‹å¤§æ€»ç»“"><a href="#Google-T5-Transformeré¢„è®­ç»ƒæ¨¡å‹å¤§æ€»ç»“" class="headerlink" title="Google T5: Transformeré¢„è®­ç»ƒæ¨¡å‹å¤§æ€»ç»“"></a>Google T5: Transformeré¢„è®­ç»ƒæ¨¡å‹å¤§æ€»ç»“</h1><p>è®ºæ–‡åœ°å€ï¼š<a href="https://arxiv.org/pdf/1910.10683.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1910.10683.pdf</a></p>
<p>ä»£ç +é¢„è®­ç»ƒæ¨¡å‹ï¼š<a href="https://github.com/google-research/text-to-text-transfer-transformer" target="_blank" rel="noopener">https://github.com/google-research/text-to-text-transfer-transformer</a></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/NLP/">NLP</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GPT/">GPT</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
  
</article>










  
    <article id="post-BERTç³»åˆ—é¢„è®­ç»ƒæ¨¡å‹" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/05/30/BERTç³»åˆ—é¢„è®­ç»ƒæ¨¡å‹/" class="article-date">
      <time datetime="2020-05-30T00:29:27.000Z" itemprop="datePublished">2020-05-30</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/05/30/BERTç³»åˆ—é¢„è®­ç»ƒæ¨¡å‹/">BERTç³»åˆ—é¢„è®­ç»ƒæ¨¡å‹</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>BERTï¼šMasked Language Modelingé¢„è®­ç»ƒæ¨¡å‹</p>
<p>è®ºæ–‡åœ°å€ï¼š<a href="https://arxiv.org/pdf/1810.04805.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1810.04805.pdf</a></p>
<p>ä¸­æ–‡ç¿»è¯‘ï¼š<a href="https://zhuanlan.zhihu.com/p/59775981" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/59775981</a></p>
<p> Language modelingé¢„è®­ç»ƒä»»åŠ¡</p>
<h2 id="Masked-Language-Model"><a href="#Masked-Language-Model" class="headerlink" title="Masked Language Model"></a>Masked Language Model</h2><p>å®Œå½¢å¡«ç©º</p>
<p>I study at Julyedu . </p>
<p>80% I study at [MASK] . </p>
<p>10% I study at Apple . </p>
<p>10% I study at Julyedu . </p>
<p>[CLS] I study at [MASK] .  [SEP] I love [MASK] language processing . [SEP]</p>
<p>â€“&gt; transformer encoder</p>
<p>o1, o2, o3, o4, o5, â€¦., o_n</p>
<p>o5 â€“&gt; Julyedu  cross entropy</p>
<p>o10 â€“&gt; natural cross entropy</p>
<p>o1 â€“&gt; True cross entropy</p>
<p>BERTè¯´ï¼šâ€œæˆ‘è¦ç”¨ transformer çš„ encodersâ€</p>
<p>Ernieä¸å±‘é“ï¼šâ€œå‘µå‘µï¼Œä½ ä¸èƒ½åƒBi-Lstmä¸€æ ·è€ƒè™‘æ–‡ç« â€</p>
<p>BERTè‡ªä¿¡å›ç­”é“ï¼šâ€œæˆ‘ä»¬ä¼šç”¨masksâ€</p>
<blockquote>
<p>è§£é‡Šä¸€ä¸‹Maskï¼š</p>
</blockquote>
<blockquote>
</blockquote>
<blockquote>
<p>è¯­è¨€æ¨¡å‹ä¼šæ ¹æ®å‰é¢å•è¯æ¥é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ï¼Œä½†æ˜¯self-attentionçš„æ³¨æ„åŠ›åªä¼šæ”¾åœ¨è‡ªå·±èº«ä¸Šï¼Œé‚£ä¹ˆè¿™æ ·100%é¢„æµ‹åˆ°è‡ªå·±ï¼Œæ¯«æ— æ„ä¹‰ï¼Œæ‰€ä»¥ç”¨Maskï¼ŒæŠŠéœ€è¦é¢„æµ‹çš„è¯ç»™æŒ¡ä½ã€‚</p>
</blockquote>
<p>å¦‚ä¸‹å›¾ï¼š</p>
<p><img src="https://uploader.shimo.im/f/jvcJ8SPeBEwszR8M.png!thumbnail" alt="img"></p>
<h2 id="Two-sentence-Tasks"><a href="#Two-sentence-Tasks" class="headerlink" title="Two-sentence Tasks"></a>Two-sentence Tasks</h2><p>æˆ‘ä»¬å›é¡¾ä¸€ä¸‹OpenAI transformerå¤„ç†ä¸åŒä»»åŠ¡çš„è¾“å…¥è½¬æ¢ï¼Œä½ ä¼šå‘ç°åœ¨æŸäº›ä»»åŠ¡ä¸Šæˆ‘ä»¬éœ€è¦2ä¸ªå¥å­ä½œä¸ºè¾“å…¥ï¼Œå¹¶åšä¸€äº›æ›´ä¸ºæ™ºèƒ½çš„åˆ¤æ–­ï¼Œæ¯”å¦‚æ˜¯å¦ç›¸ä¼¼ï¼Œæ¯”å¦‚ ç»™å‡ºä¸€ä¸ªç»´åŸºç™¾ç§‘çš„å†…å®¹ä½œä¸ºè¾“å…¥ï¼ŒåŒæ—¶åœ¨æ”¾å…¥ä¸€æ¡é’ˆå¯¹è¯¥æ¡ç›®çš„é—®é¢˜ï¼Œé‚£ä¹ˆæˆ‘ä»¬çš„ç®—æ³•æ¨¡å‹èƒ½å¤Ÿå¤„ç†è¿™ä¸ªé—®é¢˜å—ï¼Ÿ</p>
<p>ä¸ºäº†ä½¿BERTæ›´å¥½çš„å¤„ç†2ä¸ªå¥å­ä¹‹é—´çš„å…³ç³»ï¼Œé¢„è®­ç»ƒçš„è¿‡ç¨‹è¿˜æœ‰ä¸€ä¸ªé¢å¤–çš„ä»»åŠ¡ï¼šç»™å®š2ä¸ªå¥å­ï¼ˆAå’ŒBï¼‰,Aä¸Bæ˜¯å¦ç›¸ä¼¼ï¼Ÿï¼ˆ0æˆ–è€…1ï¼‰</p>
<h2 id="ç‰¹æ®ŠNLPä»»åŠ¡"><a href="#ç‰¹æ®ŠNLPä»»åŠ¡" class="headerlink" title="ç‰¹æ®ŠNLPä»»åŠ¡"></a>ç‰¹æ®ŠNLPä»»åŠ¡</h2><p>BERTçš„è®ºæ–‡ä¸ºæˆ‘ä»¬ä»‹ç»äº†å‡ ç§BERTå¯ä»¥å¤„ç†çš„NLPä»»åŠ¡ï¼š</p>
<ol>
<li><p>çŸ­æ–‡æœ¬ç›¸ä¼¼ </p>
</li>
<li><p>æ–‡æœ¬åˆ†ç±»</p>
</li>
<li><p>QAæœºå™¨äºº</p>
</li>
<li><p>è¯­ä¹‰æ ‡æ³¨</p>
</li>
</ol>
<p><img src="https://uploader.shimo.im/f/yKFxOevBvMQXvjnv.png!thumbnail" alt="img"></p>
<h2 id="BERTç”¨åšç‰¹å¾æå–"><a href="#BERTç”¨åšç‰¹å¾æå–" class="headerlink" title="BERTç”¨åšç‰¹å¾æå–"></a>BERTç”¨åšç‰¹å¾æå–</h2><p>å¾®è°ƒæ–¹æ³•å¹¶ä¸æ˜¯ä½¿ç”¨BERTçš„å”¯ä¸€æ–¹æ³•ï¼Œå°±åƒELMoä¸€æ ·ï¼Œä½ å¯ä»¥ä½¿ç”¨é¢„é€‰è®­ç»ƒå¥½çš„BERTæ¥åˆ›å»ºè¯­å¢ƒåŒ–è¯åµŒå…¥ã€‚ç„¶åä½ å¯ä»¥å°†è¿™äº›åµŒå…¥æä¾›ç»™ç°æœ‰çš„æ¨¡å‹ã€‚</p>
<p><img src="https://uploader.shimo.im/f/uKUkG73gELQGry4L.png!thumbnail" alt="img"></p>
<p>å“ªä¸ªå‘é‡æœ€é€‚åˆä½œä¸ºä¸Šä¸‹æ–‡åµŒå…¥ï¼Ÿ æˆ‘è®¤ä¸ºè¿™å–å†³äºä»»åŠ¡ã€‚ æœ¬æ–‡è€ƒå¯Ÿäº†å…­ç§é€‰æ‹©ï¼ˆä¸å¾®è°ƒæ¨¡å‹ç›¸æ¯”ï¼Œå¾—åˆ†ä¸º96.4ï¼‰ï¼š</p>
<p><img src="https://uploader.shimo.im/f/bfpUyWE9YCEP9IU2.png!thumbnail" alt="img"></p>
<ul>
<li><p>Feature Extractionï¼šç‰¹å¾æå–</p>
</li>
<li><p>Finetuneï¼šå¾®è°ƒ</p>
</li>
</ul>
<h1 id="å¦‚ä½•ä½¿ç”¨BERT"><a href="#å¦‚ä½•ä½¿ç”¨BERT" class="headerlink" title="å¦‚ä½•ä½¿ç”¨BERT"></a>å¦‚ä½•ä½¿ç”¨BERT</h1><h2 id="BERTæºç "><a href="#BERTæºç " class="headerlink" title="BERTæºç "></a>BERTæºç </h2><p>æŸ¥çœ‹<a href="https://github.com/google-research/bert" target="_blank" rel="noopener">BERTä»“åº“</a>ä¸­çš„ä»£ç ï¼š</p>
<ol>
<li><p>è¯¥æ¨¡å‹åœ¨modeling.pyï¼ˆBertModelç±»ï¼‰ä¸­æ„å»ºï¼Œä¸vanilla Transformerç¼–ç å™¨å®Œå…¨ç›¸åŒã€‚</p>
</li>
<li><p>run_classifier.pyæ˜¯å¾®è°ƒè¿‡ç¨‹çš„ä¸€ä¸ªç¤ºä¾‹ã€‚å®ƒè¿˜æ„å»ºäº†ç›‘ç£æ¨¡å‹çš„åˆ†ç±»å±‚ã€‚å¦‚æœè¦æ„å»ºè‡ªå·±çš„åˆ†ç±»å™¨ï¼Œè¯·æŸ¥çœ‹è¯¥æ–‡ä»¶ä¸­çš„create_model()æ–¹æ³•ã€‚</p>
</li>
<li><p>å¯ä»¥ä¸‹è½½å‡ ç§é¢„å…ˆè®­ç»ƒçš„æ¨¡å‹ã€‚æ¶µç›–102ç§è¯­è¨€çš„å¤šè¯­è¨€æ¨¡å‹ï¼Œè¿™äº›è¯­è¨€éƒ½æ˜¯åœ¨ç»´åŸºç™¾ç§‘çš„æ•°æ®åŸºç¡€ä¸Šè®­ç»ƒè€Œæˆçš„ã€‚</p>
</li>
<li><p>BERTä¸ä¼šå°†å•è¯è§†ä¸ºtokensã€‚ç›¸åï¼Œå®ƒæ³¨é‡WordPiecesã€‚ tokenization.pyæ˜¯å°†ä½ çš„å•è¯è½¬æ¢ä¸ºé€‚åˆBERTçš„wordPiecesçš„tokensizerã€‚</p>
</li>
</ol>
<p>å¯ä»¥æŸ¥çœ‹BERTçš„PyTorchå®ç° (<a href="https://github.com/huggingface/transformers)ã€‚" target="_blank" rel="noopener">https://github.com/huggingface/transformers)ã€‚</a> </p>
<ul>
<li><p>modeling: <a href="https://github.com/huggingface/transformers/blob/master/src/transformers/modeling_bert.py" target="_blank" rel="noopener">https://github.com/huggingface/transformers/blob/master/src/transformers/modeling_bert.py</a></p>
</li>
<li><p>BertEmbedding: wordpiece embedding + position embedding + token type embedding</p>
</li>
<li><p>BertSelfAttnetion: query, key, valueçš„å˜æ¢</p>
</li>
<li><p>BertSelfOutput: </p>
</li>
<li><p>BertIntermediate</p>
</li>
<li><p>BertOutput</p>
</li>
<li><p>BertForSequenceClassification</p>
</li>
<li><p>configuration: <a href="https://github.com/huggingface/transformers/blob/master/transformers/configuration_bert.py" target="_blank" rel="noopener">https://github.com/huggingface/transformers/blob/master/transformers/configuration_bert.py</a></p>
</li>
<li><p>tokenization: <a href="https://github.com/huggingface/transformers/blob/master/transformers/tokenization_bert.py" target="_blank" rel="noopener">https://github.com/huggingface/transformers/blob/master/transformers/tokenization_bert.py</a></p>
</li>
<li><p>DataProcessor: <a href="https://github.com/huggingface/transformers/blob/master/transformers/data/processors/glue.py#L194" target="_blank" rel="noopener">https://github.com/huggingface/transformers/blob/master/transformers/data/processors/glue.py#L194</a></p>
</li>
</ul>
<h2 id="BERTæ¨¡å‹çš„ä½¿ç”¨"><a href="#BERTæ¨¡å‹çš„ä½¿ç”¨" class="headerlink" title="BERTæ¨¡å‹çš„ä½¿ç”¨"></a>BERTæ¨¡å‹çš„ä½¿ç”¨</h2><ul>
<li>æ–‡æœ¬åˆ†ç±»ï¼š<a href="https://github.com/huggingface/transformers/blob/master/examples/run_glue.py" target="_blank" rel="noopener">https://github.com/huggingface/transformers/blob/master/examples/run_glue.py</a></li>
</ul>
<h1 id="BERTå‡çº§ç‰ˆ"><a href="#BERTå‡çº§ç‰ˆ" class="headerlink" title="BERTå‡çº§ç‰ˆ"></a>BERTå‡çº§ç‰ˆ</h1><h2 id="RoBERTaï¼šæ›´å¼ºå¤§çš„BERT"><a href="#RoBERTaï¼šæ›´å¼ºå¤§çš„BERT" class="headerlink" title="RoBERTaï¼šæ›´å¼ºå¤§çš„BERT"></a>RoBERTaï¼šæ›´å¼ºå¤§çš„BERT</h2><p>è®ºæ–‡åœ°å€ï¼š<a href="https://arxiv.org/pdf/1907.11692.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1907.11692.pdf</a></p>
<ul>
<li><p>åŠ å¤§è®­ç»ƒæ•°æ® 16GB -&gt; 160GBï¼Œæ›´å¤§çš„batch sizeï¼Œè®­ç»ƒæ—¶é—´åŠ é•¿</p>
</li>
<li><p>ä¸éœ€è¦NSP Loss: natural inference </p>
</li>
<li><p>ä½¿ç”¨æ›´é•¿çš„è®­ç»ƒ Sequence</p>
</li>
<li><p>Static vs. Dynamic Masking </p>
</li>
<li><p>æ¨¡å‹è®­ç»ƒæˆæœ¬åœ¨6ä¸‡ç¾é‡‘ä»¥ä¸Šï¼ˆä¼°ç®—ï¼‰</p>
</li>
</ul>
<h2 id="ALBERTï¼šå‚æ•°æ›´å°‘çš„BERT"><a href="#ALBERTï¼šå‚æ•°æ›´å°‘çš„BERT" class="headerlink" title="ALBERTï¼šå‚æ•°æ›´å°‘çš„BERT"></a>ALBERTï¼šå‚æ•°æ›´å°‘çš„BERT</h2><p>è®ºæ–‡åœ°å€ï¼š<a href="https://arxiv.org/pdf/1909.11942.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1909.11942.pdf</a></p>
<ul>
<li><p>ä¸€ä¸ªè½»é‡çº§çš„BERTæ¨¡å‹</p>
</li>
<li><p>æ ¸å¿ƒæ€æƒ³ï¼š</p>
</li>
<li><p>å…±äº«å±‚ä¸å±‚ä¹‹é—´çš„å‚æ•° ï¼ˆå‡å°‘æ¨¡å‹å‚æ•°ï¼‰</p>
</li>
<li><p>å¢åŠ å•å±‚å‘é‡ç»´åº¦</p>
</li>
</ul>
<h2 id="DistilBERTï¼šè½»é‡ç‰ˆBERT"><a href="#DistilBERTï¼šè½»é‡ç‰ˆBERT" class="headerlink" title="DistilBERTï¼šè½»é‡ç‰ˆBERT"></a>DistilBERTï¼šè½»é‡ç‰ˆBERT</h2><p>MNIST</p>
<p>0, 1, 2, 3, â€¦, 9</p>
<p>logits: [0.1, 0.6, â€¦, 0.01] q</p>
<p><strong>label: 2 [0, 0, 1, â€¦, 0] p</strong></p>
<p>loss: cross entropy loss -\sum_{i=1}^10 p_i*log q_i</p>
<p>loss: -log q_{label}</p>
<p>è®­ç»ƒä¸€ä¸ªStudent networkï¼Œmimic the behavior of the teacher network</p>
<p>teacher network: [0.1, 0.6, â€¦, 0.01] t</p>
<p><strong>student network</strong>: [s_1, s_2, .., s_10]</p>
<p>cross entropy loss: -sum_{i=1}^10 t_i * log s_i</p>
<p>4, 7</p>
<p><a href="https://arxiv.org/pdf/1910.01108.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1910.01108.pdf</a></p>
<ul>
<li><p>MLM, NSP</p>
</li>
<li><p>MLM: cross entropy loss: -\sum_{i=1}^k p_i log (q_i) = - log (q_{label})</p>
</li>
<li><p>teacher (MLM) = distribution</p>
</li>
<li><p>student: å­¦ä¹ distribution: -\sum_{i=1}^k p_teacher_i log (q_student_i)</p>
</li>
</ul>
<p>Patient Distillation</p>
<p><a href="https://arxiv.org/abs/1908.09355" target="_blank" rel="noopener">https://arxiv.org/abs/1908.09355</a></p>
<p><img src="https://uploader.shimo.im/f/FtKDArmN5UoEwpsF.png!thumbnail" alt="img"></p>
<h1 id="å‚è€ƒé˜…è¯»èµ„æ–™"><a href="#å‚è€ƒé˜…è¯»èµ„æ–™" class="headerlink" title="å‚è€ƒé˜…è¯»èµ„æ–™"></a>å‚è€ƒé˜…è¯»èµ„æ–™</h1><h3 id="BERT-Distillation"><a href="#BERT-Distillation" class="headerlink" title="BERT Distillation"></a>BERT Distillation</h3><p>å¯¹äºBERTæ¨¡å‹å‹ç¼©æ„Ÿå…´è¶£çš„åŒå­¦å¯ä»¥å‚è€ƒä»¥ä¸‹èµ„æ–™</p>
<ul>
<li>Patient Knowledge Distillation for BERT Model Compression  <a href="https://www.aclweb.org/anthology/D19-1441.pdf" target="_blank" rel="noopener">https://www.aclweb.org/anthology/D19-1441.pdf</a></li>
</ul>
<p>å…³äºBERTæ¨¡å‹å‹ç¼©çš„ä¸€å¥—æ–¹æ³•</p>
<h3 id="ELECTRA"><a href="#ELECTRA" class="headerlink" title="ELECTRA"></a>ELECTRA</h3><p><a href="https://openreview.net/pdf?id=r1xMH1BtvB" target="_blank" rel="noopener">https://openreview.net/pdf?id=r1xMH1BtvB</a></p>
<p>ä½¿ç”¨GANè®­ç»ƒBERTæ¨¡å‹</p>
<p><img src="https://uploader.shimo.im/f/PJ9RGb3HpgIA4WYN.png!thumbnail" alt="img"></p>
<ul>
<li><p>Generatoré’ˆå¯¹[MASK]ä½ç½®ç”Ÿæˆå•è¯ï¼ŒDiscriminatoråˆ¤æ–­è¿™äº›å•è¯æ˜¯ç”±Generator (ä»[MASK]) ç”Ÿæˆçš„è¿˜æ˜¯åŸæœ¬å°±å­˜åœ¨çš„ã€‚</p>
</li>
<li><p>Discriminatorè¢«ç”¨äºdownstream task finetuningã€‚</p>
</li>
</ul>
<h3 id="XLNet"><a href="#XLNet" class="headerlink" title="XLNet"></a>XLNet</h3><p>æˆ‘åœ¨ä¸Šä¸€æœŸNLPå°±ä¸šç­ä¸­ä»‹ç»äº†XLNetï¼Œä¸è¿‡ç”±äºè¿‘äº›æ—¥å­BERTçš„å„ç§åŠ å¼ºç‰ˆå±‚å‡ºä¸ç©·ï¼ŒXLNetæ˜¾å¾—å¹¶ä¸ç‰¹åˆ«çªå‡ºã€‚æ„Ÿå…´è¶£çš„åŒå­¦å¯ä»¥å‚è€ƒä¸Šä¸€æœŸçš„è¯¾ä»¶ï¼š<a href="https://shimo.im/docs/PHqcpWtYjJjW3yH3" target="_blank" rel="noopener">https://shimo.im/docs/PHqcpWtYjJjW3yH3</a></p>
<p>XLNetçš„ä»£ç å’Œé¢„è®­ç»ƒæ¨¡å‹ä¹Ÿå¯ä»¥åœ¨Huggingfaceçš„ç‰ˆæœ¬ä¸­æ‰¾åˆ°ã€‚</p>
<h3 id="NLPé¢„è®­ç»ƒæ¨¡å‹ä¸²è®²"><a href="#NLPé¢„è®­ç»ƒæ¨¡å‹ä¸²è®²" class="headerlink" title="NLPé¢„è®­ç»ƒæ¨¡å‹ä¸²è®²"></a>NLPé¢„è®­ç»ƒæ¨¡å‹ä¸²è®²</h3><p>æˆ‘ä¹‹å‰åœ¨ä¸ƒæœˆåœ¨çº¿çš„å…¬å¼€è¯¾ä¸­ä½¿ç”¨çš„PPT</p>
<p>NLPé¢„è®­ç»ƒæ¨¡å‹.pdf1.9MB</p>
<h3 id="å‚è€ƒé˜…è¯»ï¼šThe-Illustrated-BERT-ELMo-and-co"><a href="#å‚è€ƒé˜…è¯»ï¼šThe-Illustrated-BERT-ELMo-and-co" class="headerlink" title="å‚è€ƒé˜…è¯»ï¼šThe Illustrated BERT, ELMo, and co."></a>å‚è€ƒé˜…è¯»ï¼šThe Illustrated BERT, ELMo, and co.</h3><p><a href="https://shimo.im/docs/Y6q3gX8yGGjpWqXx" target="_blank" rel="noopener">https://shimo.im/docs/Y6q3gX8yGGjpWqXx</a></p>
<ul>
<li><p>é˜…è¯»BertSelfAttentionä»£ç  <a href="https://github.com/huggingface/transformers/blob/master/transformers/modeling_bert.py#L190" target="_blank" rel="noopener">https://github.com/huggingface/transformers/blob/master/transformers/modeling_bert.py#L190</a></p>
</li>
<li><p>é˜…è¯»run_glue.py <a href="https://github.com/huggingface/transformers/blob/master/examples/run_glue.py#L152" target="_blank" rel="noopener">https://github.com/huggingface/transformers/blob/master/examples/run_glue.py#L152</a></p>
</li>
<li><p>é˜…è¯»BertForSequenceClassification <a href="https://github.com/huggingface/transformers/blob/master/transformers/modeling_bert.py#L970" target="_blank" rel="noopener">https://github.com/huggingface/transformers/blob/master/transformers/modeling_bert.py#L970</a></p>
</li>
<li><p>é˜…è¯»glue.py <a href="https://github.com/huggingface/transformers/blob/master/transformers/data/processors/glue.py" target="_blank" rel="noopener">https://github.com/huggingface/transformers/blob/master/transformers/data/processors/glue.py</a> ç”¨æ¥åšæ–‡æœ¬é¢„å¤„ç†</p>
</li>
</ul>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/NLP/">NLP</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/BERT/">BERT</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
  
</article>










  
    <article id="post-é˜…è¯»ç†è§£" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/05/19/é˜…è¯»ç†è§£/" class="article-date">
      <time datetime="2020-05-19T00:45:58.000Z" itemprop="datePublished">2020-05-19</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/05/19/é˜…è¯»ç†è§£/">é˜…è¯»ç†è§£</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>NLPå½“ä¸­çš„é˜…è¯»ç†è§£(Reading Comprehension, Question Answering)ä»»åŠ¡ä¸»è¦æ˜¯ä»¥ä¸‹å½¢å¼ï¼šç»™å®šä¸€äº›èƒŒæ™¯çŸ¥è¯†ï¼Œä¸»è¦æ˜¯ä¸€ç¯‡æ–‡ç« ï¼Œæœ‰æ—¶å€™ä¹Ÿå¯èƒ½æ˜¯ä¸€äº›ç»“æ„åŒ–çš„çŸ¥è¯†å›¾è°±ï¼Œç„¶åå›ç­”ä¸è¯¥èƒŒæ™¯çŸ¥è¯†çš„ç›¸å…³é—®é¢˜ã€‚</p>
<p>å¸¸è§çš„é—®é¢˜å’Œç­”æ¡ˆå½¢å¼æœ‰ï¼š</p>
<ul>
<li><p>å®Œå½¢å¡«ç©ºï¼šåœ¨æ–‡ç« ä¸­ç»™å®šä¸€ä¸ªç©ºä½å’Œä¸€äº›å€™é€‰ç­”æ¡ˆï¼Œæˆ‘ä»¬éœ€è¦æŠŠä¸€ä¸ªå€™é€‰ç­”æ¡ˆå¡«å……è¿›å»ã€‚</p>
</li>
<li><p>ç®€ç­”é¢˜ï¼šç»™å®šä¸€ç¯‡æ–‡ç« å’Œä¸€ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦ä»æ–‡ç« ä¸­å»æ‰¾ç­”æ¡ˆï¼Œä¸”è¿™ä¸ªç­”æ¡ˆä¸€å®šåœ¨æ–‡ç« ä¸­å‡ºç°è¿‡ã€‚SQuAD</p>
</li>
<li><p>é€‰æ‹©é¢˜ï¼šç»™å®šä¸€ç¯‡æ–‡ç« ï¼Œä¸€ä¸ªé—®é¢˜å’Œä¸€äº›å€™é€‰ç­”æ¡ˆï¼Œé€‰æ‹©ä¸€ä¸ªæ­£ç¡®ç­”æ¡ˆã€‚</p>
</li>
</ul>
<p>è¿˜æœ‰ä¸€äº›åœ¨ä¸Šè¿°é—®ç­”ä»»åŠ¡åŸºç¡€ä¸Šçš„æ‹“å±•æƒ…å†µï¼Œä¾‹å¦‚æœ‰çš„ä»»åŠ¡éœ€è¦åœ¨å¤šç¯‡æ–‡ç« çš„åŸºç¡€ä¸Šä½œç­”ï¼Œæœ‰çš„QAä»»åŠ¡éœ€è¦æˆ‘ä»¬è‡ªå·±æ¥æ¨ç†å’Œæ’°å†™ç­”æ¡ˆ (open domain)ï¼Œæ— æ³•ç›´æ¥ä»æ–‡ä¸­æ‰¾åˆ°ç­”æ¡ˆã€‚</p>
<p>æ•´ä¸ªQAé¢†åŸŸçš„å‘å±•ä¸»è¦éƒ½æ˜¯ä¾é ä¸€äº›æ•°æ®é›†çš„æå‡ºå’Œè§£å†³æ¥æ¨åŠ¨çš„ã€‚å¾€å¾€æ˜¯æœ‰äººåˆ¶ä½œäº†ä¸€ä¸ªæ•°æ®é›†å’Œä¸€ä¸ªQAä»»åŠ¡ï¼Œç„¶åå¤§å®¶å¼€å§‹æ¯”èµ›è°èƒ½æ›´å¥½åœ°è§£å†³å®ƒã€‚</p>
<p>æˆ‘è®¤ä¸ºæœ€å¥½çš„å­¦ä¹ æ–¹æ³•æ˜¯å»äº†è§£è¿™äº›QAæ•°æ®é›†ï¼ˆ<a href="http://nlpprogress.com/english/question_answering.htmlï¼‰ï¼Œé’ˆå¯¹è‡ªå·±æ„Ÿå…´è¶£çš„æ•°æ®é›†å»å¯»æ‰¾ç›¸åº”çš„è§£å†³æ–¹æ¡ˆï¼Œåœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­äº†è§£QAçš„è§£å†³æ–¹æ³•ã€‚å°†æ¥å¦‚æœåœ¨å®é™…çš„åº”ç”¨åœºæ™¯ä¸­é‡åˆ°ç±»ä¼¼çš„QAä»»åŠ¡ï¼ˆä¾‹å¦‚ä¸€äº›å®¢æœæœºå™¨äººç­‰ï¼‰ï¼Œæˆ‘ä»¬å°±å¯ä»¥å¯»æ‰¾åˆ°æ¯”è¾ƒç›¸å…³çš„QAæ•°æ®é›†ï¼Œä½¿ç”¨åœ¨è¿™äº›æ•°æ®é›†ä¸Šæœ€å¥½çš„è§£å†³æ–¹æ¡ˆæ¥è§£å†³è‡ªå·±çš„ä»»åŠ¡ã€‚" target="_blank" rel="noopener">http://nlpprogress.com/english/question_answering.htmlï¼‰ï¼Œé’ˆå¯¹è‡ªå·±æ„Ÿå…´è¶£çš„æ•°æ®é›†å»å¯»æ‰¾ç›¸åº”çš„è§£å†³æ–¹æ¡ˆï¼Œåœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­äº†è§£QAçš„è§£å†³æ–¹æ³•ã€‚å°†æ¥å¦‚æœåœ¨å®é™…çš„åº”ç”¨åœºæ™¯ä¸­é‡åˆ°ç±»ä¼¼çš„QAä»»åŠ¡ï¼ˆä¾‹å¦‚ä¸€äº›å®¢æœæœºå™¨äººç­‰ï¼‰ï¼Œæˆ‘ä»¬å°±å¯ä»¥å¯»æ‰¾åˆ°æ¯”è¾ƒç›¸å…³çš„QAæ•°æ®é›†ï¼Œä½¿ç”¨åœ¨è¿™äº›æ•°æ®é›†ä¸Šæœ€å¥½çš„è§£å†³æ–¹æ¡ˆæ¥è§£å†³è‡ªå·±çš„ä»»åŠ¡ã€‚</a></p>
<h2 id><a href="#" class="headerlink" title=" "></a> </h2><h1 id="ä¸€äº›æœ‰åçš„é˜…è¯»ç†è§£æ•°æ®é›†å’Œæ¨¡å‹"><a href="#ä¸€äº›æœ‰åçš„é˜…è¯»ç†è§£æ•°æ®é›†å’Œæ¨¡å‹" class="headerlink" title="ä¸€äº›æœ‰åçš„é˜…è¯»ç†è§£æ•°æ®é›†å’Œæ¨¡å‹"></a>ä¸€äº›æœ‰åçš„é˜…è¯»ç†è§£æ•°æ®é›†å’Œæ¨¡å‹</h1><h2 id="SQuAD-1-0-2-0"><a href="#SQuAD-1-0-2-0" class="headerlink" title="SQuAD 1.0/2.0"></a>SQuAD 1.0/2.0</h2><p>ä»æ–‡ç« ä¸­æ‰¾ç­”æ¡ˆ</p>
<p><a href="https://aclweb.org/anthology/D16-1264" target="_blank" rel="noopener">https://aclweb.org/anthology/D16-1264</a></p>
<p><img src="https://uploader.shimo.im/f/yqtsScSwls8OkJWs.png!thumbnail" alt="img"></p>
<h3 id="BiDAFæ¨¡å‹"><a href="#BiDAFæ¨¡å‹" class="headerlink" title="BiDAFæ¨¡å‹"></a>BiDAFæ¨¡å‹</h3><p>Bi-Directional Attention Fflow for Machine Comprehension</p>
<p><a href="https://arxiv.org/pdf/1611.01603.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1611.01603.pdf</a></p>
<p>2017å¹´çš„æ¨¡å‹ï¼Œç”¨äºè§£å†³SQuADä¹‹ç±»çš„é—®é¢˜ã€‚åæ¥çš„å¾ˆå¤šæ¨¡å‹éƒ½å‚è€ƒäº†è¯¥æ¨¡å‹çš„è®¾è®¡æ€æƒ³</p>
<p><img src="https://uploader.shimo.im/f/hL8lQitMAxMtYJ5w.png!thumbnail" alt="img"></p>
<p>é¢„æµ‹ï¼š start_pos, end_pos</p>
<p>å…¶ä»–ç›¸å…³æ¨¡å‹</p>
<p>Document Reader (single model)</p>
<p>r-net (single model)</p>
<p>QANet (single)</p>
<p><a href="https://github.com/allenai/bi-att-flow" target="_blank" rel="noopener">https://github.com/allenai/bi-att-flow</a></p>
<p>MCTest</p>
<p><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/11/MCTest_EMNLP2013.pdf" target="_blank" rel="noopener">https://www.microsoft.com/en-us/research/wp-content/uploads/2016/11/MCTest_EMNLP2013.pdf</a></p>
<h3 id="BERTæ¨¡å‹"><a href="#BERTæ¨¡å‹" class="headerlink" title="BERTæ¨¡å‹"></a>BERTæ¨¡å‹</h3><p>æ¨¡å‹ <a href="https://arxiv.org/pdf/1810.04805.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1810.04805.pdf</a></p>
<p>ä»£ç  <a href="https://github.com/huggingface/transformers/blob/master/src/transformers/modeling_bert.py#L1402" target="_blank" rel="noopener">https://github.com/huggingface/transformers/blob/master/src/transformers/modeling_bert.py#L1402</a></p>
<p><a href="https://github.com/huggingface/transformers/blob/master/examples/run_squad.py" target="_blank" rel="noopener">https://github.com/huggingface/transformers/blob/master/examples/run_squad.py</a></p>
<h2 id="CNN-Daily-Mail"><a href="#CNN-Daily-Mail" class="headerlink" title="CNN/Daily Mail"></a>CNN/Daily Mail</h2><p>å®Œå½¢å¡«ç©ºç±»é—®é¢˜</p>
<p>Teaching Machines to Read and Comprehend</p>
<p><a href="https://arxiv.org/pdf/1506.03340.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1506.03340.pdf</a></p>
<p><img src="https://uploader.shimo.im/f/ppAcqx7DjtM3486H.png!thumbnail" alt="img"></p>
<h3 id="Attention-Sumæ¨¡å‹"><a href="#Attention-Sumæ¨¡å‹" class="headerlink" title="Attention Sumæ¨¡å‹"></a>Attention Sumæ¨¡å‹</h3><p><a href="https://arxiv.org/pdf/1603.01547.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1603.01547.pdf</a></p>
<p>Gated Attention Sumæ¨¡å‹æ˜¯è¯¥æ¨¡å‹çš„ä¸€ä¸ªæ‹“å±•å½¢å¼</p>
<p><a href="https://arxiv.org/abs/1606.01549" target="_blank" rel="noopener">https://arxiv.org/abs/1606.01549</a></p>
<h3 id="é™ˆä¸¹ç¦åœ¨CNN-Daily-Mailä¸Šçš„å·¥ä½œ"><a href="#é™ˆä¸¹ç¦åœ¨CNN-Daily-Mailä¸Šçš„å·¥ä½œ" class="headerlink" title="é™ˆä¸¹ç¦åœ¨CNN/Daily Mailä¸Šçš„å·¥ä½œ"></a>é™ˆä¸¹ç¦åœ¨CNN/Daily Mailä¸Šçš„å·¥ä½œ</h3><p>A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task</p>
<p><a href="https://www.aclweb.org/anthology/P16-1223" target="_blank" rel="noopener">https://www.aclweb.org/anthology/P16-1223</a></p>
<p><img src="https://uploader.shimo.im/f/BKipbLYDzic4bWbc.png!thumbnail" alt="img"></p>
<p>é¡ºä¾¿ä»‹ç»ä¸€ä¸‹ï¼Œ<a href="https://www.cs.princeton.edu/~danqic/" target="_blank" rel="noopener">é™ˆä¸¹ç¦</a>åœ¨QAé¢†åŸŸåšäº†å¾ˆå¤šå·¥ä½œï¼Œå¯¹QAæ„Ÿå…´è¶£çš„åŒå­¦å¯ä»¥å‚è€ƒå¥¹çš„åšå£«è®ºæ–‡ã€‚</p>
<p><a href="https://www.cs.princeton.edu/~danqic/" target="_blank" rel="noopener">https://www.cs.princeton.edu/~danqic/</a></p>
<p><a href="https://www.cs.princeton.edu/~danqic/papers/thesis.pdf" target="_blank" rel="noopener">https://www.cs.princeton.edu/~danqic/papers/thesis.pdf</a></p>
<p><a href="https://arxiv.org/pdf/1506.03340.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1506.03340.pdf</a></p>
<p><a href="https://arxiv.org/pdf/1603.01547.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1603.01547.pdf</a></p>
<p><a href="http://www.cs.cmu.edu/~bdhingra/papers/ga_reader.pdf" target="_blank" rel="noopener">http://www.cs.cmu.edu/~bdhingra/papers/ga_reader.pdf</a></p>
<p><a href="https://arxiv.org/pdf/1611.07954.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1611.07954.pdf</a></p>
<h2 id="RACEæ•°æ®é›†"><a href="#RACEæ•°æ®é›†" class="headerlink" title="RACEæ•°æ®é›†"></a>RACEæ•°æ®é›†</h2><p>RACE: Large-scale ReAding Comprehension Dataset From Examinations</p>
<p><a href="https://arxiv.org/pdf/1704.04683.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1704.04683.pdf</a></p>
<p>RACEæ•°æ®é›†æ¥è‡ªä¸­å›½çš„ä¸­é«˜è€ƒè‹±è¯­é˜…è¯»ç†è§£é¢˜ã€‚</p>
<p>ä»£ç ï¼š</p>
<p><a href="https://github.com/huggingface/transformers/blob/master/src/transformers/modeling_bert.py#L1204" target="_blank" rel="noopener">https://github.com/huggingface/transformers/blob/master/src/transformers/modeling_bert.py#L1204</a></p>
<p><a href="https://github.com/huggingface/transformers/blob/master/examples/utils_multiple_choice.py#L36" target="_blank" rel="noopener">https://github.com/huggingface/transformers/blob/master/examples/utils_multiple_choice.py#L36</a></p>
<p><a href="https://github.com/huggingface/transformers/blob/master/examples/run_multiple_choice.py" target="_blank" rel="noopener">https://github.com/huggingface/transformers/blob/master/examples/run_multiple_choice.py</a></p>
<p>SWAG</p>
<p>åæ¥å‡ºç°äº†å¾ˆå¤šçš„ä¸åŒæ–¹å‘çš„QAé—®é¢˜</p>
<ul>
<li><p>åŸºäºå¤šæ–‡æœ¬çš„ã€é•¿æ–‡ç« çš„é—®ç­”</p>
</li>
<li><p>narrative qa <a href="https://arxiv.org/pdf/1712.07040.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1712.07040.pdf</a></p>
</li>
<li><p>åŸºäºç»´åŸºç™¾ç§‘ï¼Œç»“åˆæ–‡æœ¬æœç´¢ç³»ç»Ÿçš„é—®ç­”</p>
</li>
<li><p>Dr QA <a href="https://arxiv.org/pdf/1704.00051.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1704.00051.pdf</a></p>
</li>
<li><p>åŸºäºèŠå¤©è®°å½•çš„é—®ç­” </p>
</li>
<li><p>QuAC : Question Answering in Context <a href="https://arxiv.org/pdf/1808.07036.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1808.07036.pdf</a></p>
</li>
</ul>
<p>å‚è€ƒä»¥ä¸‹é“¾æ¥</p>
<ul>
<li><p><a href="https://github.com/karthikncode/nlp-datasets#question-answering" target="_blank" rel="noopener">https://github.com/karthikncode/nlp-datasets#question-answering</a></p>
</li>
<li><p><a href="http://nlpprogress.com/english/question_answering.html" target="_blank" rel="noopener">http://nlpprogress.com/english/question_answering.html</a></p>
</li>
</ul>
<h2 id="åŸºäºå¤šæ–‡æœ¬çš„QAä»»åŠ¡"><a href="#åŸºäºå¤šæ–‡æœ¬çš„QAä»»åŠ¡" class="headerlink" title="åŸºäºå¤šæ–‡æœ¬çš„QAä»»åŠ¡"></a>åŸºäºå¤šæ–‡æœ¬çš„QAä»»åŠ¡</h2><p>HOTPOTQA: A Dataset for Diverse, Explainable Multi-hop Question Answering</p>
<p><a href="https://www.aclweb.org/anthology/D18-1259" target="_blank" rel="noopener">https://www.aclweb.org/anthology/D18-1259</a></p>
<p>HotpotQAçš„ä¸»è¦ç‰¹ç‚¹æ˜¯ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºå¤šæ–‡æœ¬çš„QAä»»åŠ¡ã€‚ç»™å®šä¸€ç³»åˆ—çš„æ–‡ç« å’Œä¸€ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦ç»™å‡ºè¯¥é—®é¢˜çš„ç­”æ¡ˆï¼Œå¹¶ä¸”å›ç­”æˆ‘ä»¬æ˜¯ä»å“ªäº›ç›¸å…³çš„å¥å­ä¸­å¾—åˆ°é—®é¢˜çš„ç­”æ¡ˆçš„ã€‚</p>
<p>å·²ç»å…¬å¼€çš„å¯å‚è€ƒè®ºæ–‡</p>
<p>Hierarchical Graph Network for Multi-hop Question Answering <a href="https://arxiv.org/pdf/1911.00484.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1911.00484.pdf</a></p>
<p>Select, Answer and Explain: Interpretable Multi-hop Reading Comprehension over Multiple Documents <a href="https://arxiv.org/pdf/1911.03631.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1911.03631.pdf</a></p>
<h2 id="CoQA-åŸºäºå¯¹è¯çš„é—®ç­”æ•°æ®é›†"><a href="#CoQA-åŸºäºå¯¹è¯çš„é—®ç­”æ•°æ®é›†" class="headerlink" title="CoQA åŸºäºå¯¹è¯çš„é—®ç­”æ•°æ®é›†"></a>CoQA åŸºäºå¯¹è¯çš„é—®ç­”æ•°æ®é›†</h2><p>leaderboard <a href="https://stanfordnlp.github.io/coqa/" target="_blank" rel="noopener">https://stanfordnlp.github.io/coqa/</a></p>
<p>è®ºæ–‡ <a href="https://arxiv.org/abs/1808.07042" target="_blank" rel="noopener">https://arxiv.org/abs/1808.07042</a></p>
<p>æœç‹—æœ‰ä¸€ä¸ªBERTæ¨¡å‹çš„å®ç°</p>
<p><a href="https://github.com/sogou/SMRCToolkit" target="_blank" rel="noopener">https://github.com/sogou/SMRCToolkit</a></p>
<p>è¿™ä½åŒå­¦ä¹Ÿå®ç°äº†ä¸€äº›æ¨¡å‹</p>
<p><a href="https://github.com/jayelm/dialog-qa" target="_blank" rel="noopener">https://github.com/jayelm/dialog-qa</a></p>
<h2 id="ä¸­æ–‡æ•°æ®é›†"><a href="#ä¸­æ–‡æ•°æ®é›†" class="headerlink" title="ä¸­æ–‡æ•°æ®é›†"></a>ä¸­æ–‡æ•°æ®é›†</h2><h3 id="æ³•ç ”æ¯-é˜…è¯»ç†è§£æ•°æ®é›†"><a href="#æ³•ç ”æ¯-é˜…è¯»ç†è§£æ•°æ®é›†" class="headerlink" title="æ³•ç ”æ¯ é˜…è¯»ç†è§£æ•°æ®é›†"></a>æ³•ç ”æ¯ é˜…è¯»ç†è§£æ•°æ®é›†</h3><p><a href="http://cail.cipsc.org.cn/" target="_blank" rel="noopener">http://cail.cipsc.org.cn/</a></p>
<h3 id="è®¯é£æ¯-ä¸­æ–‡é˜…è¯»ç†è§£è¯„æµ‹"><a href="#è®¯é£æ¯-ä¸­æ–‡é˜…è¯»ç†è§£è¯„æµ‹" class="headerlink" title="è®¯é£æ¯ ä¸­æ–‡é˜…è¯»ç†è§£è¯„æµ‹"></a>è®¯é£æ¯ ä¸­æ–‡é˜…è¯»ç†è§£è¯„æµ‹</h3><p><a href="https://hfl-rc.github.io/cmrc2017/" target="_blank" rel="noopener">https://hfl-rc.github.io/cmrc2017/</a></p>
<p><a href="https://hfl-rc.github.io/cmrc2018/" target="_blank" rel="noopener">https://hfl-rc.github.io/cmrc2018/</a></p>
<p><a href="https://hfl-rc.github.io/cmrc2019/" target="_blank" rel="noopener">https://hfl-rc.github.io/cmrc2019/</a></p>
<p>åŒå­¦ä»¬å¯ä»¥æ‰¾åˆ°è¿™ä¸‰æ¬¡æ¯”èµ›çš„æ•°æ®é›†å’Œç›¸åº”çš„è¡¨ç°æœ€å¥½çš„æ¨¡å‹ä»£ç è¿›è¡Œå­¦ä¹ ã€‚</p>
<p>KBQA</p>
<p><a href="http://tcci.ccf.org.cn/conference/2018/papers/EV51.pdf" target="_blank" rel="noopener">http://tcci.ccf.org.cn/conference/2018/papers/EV51.pdf</a></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/NLP/">NLP</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/QA/">QA</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
  
</article>










  
    <article id="post-Transformeræ¨¡å‹è§£è¯»" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/05/18/Transformeræ¨¡å‹è§£è¯»/" class="article-date">
      <time datetime="2020-05-18T00:28:15.000Z" itemprop="datePublished">2020-05-18</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/05/18/Transformeræ¨¡å‹è§£è¯»/">Transformeræ¨¡å‹è§£è¯»</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>contextualized word vectors</p>
<p>RNN, LSTM</p>
<p>RNN(I study at Julyedu.) â€“&gt; RNN(I)-&gt;h1, RNN(study, h1)-&gt;h2, RNN(at, h2)-&gt;h3. </p>
<p>Encoder. æˆ‘å¯ä»¥åŒæ—¶è§‚çœ‹å…¨å±€ä¿¡æ¯ã€‚</p>
<p>query, keys, values</p>
<p>q1, q2, .., q5</p>
<p>k1, k2, k3, k4, k5</p>
<p>score(q, k1), score(q, k2), â€¦, score(q, k5)</p>
<p>v1, v2, v3, v4, v5</p>
<p>\sum_{i=1}^5 func(score_i) v_i</p>
<p>dot(a, b)</p>
<p>mean</p>
<p>var(dot(a, b))</p>
<p>dot(a, b) = a1<em>b1 + a2</em>b2. â€¦. </p>
<p>E(dot(a, b)) = n * E(ai*bi)</p>
<p>var(dot(a, b)) = E(dot(a, b)^2) - E(dot(a, b))^2</p>
<p>affine transformation</p>
<p>WX+b</p>
<p>Attention(Q, K, V ) = softmax(QKT âˆš dk )V</p>
<p>Q : seq_len, hid_size</p>
<p>K^T:  hid_size, seq_len</p>
<p>V: seq_len, hid_size</p>
<p>QK^T : seq_len, seq_len</p>
<p>QK^T V: seq_len, hid_size</p>
<p>[emb_w(x), emb_p(i)]W â€“&gt; </p>
<p>è¿‘ä¸¤å¹´æ¥ï¼ŒNLPé¢†åŸŸçš„æ¨¡å‹ç ”ç©¶å·²ç»è¢«transformeræ¨¡å‹ä»¥åŠå®ƒçš„å„ç§å˜ç§ç»™å é¢†äº†ã€‚Transformeræ¨¡å‹çš„ç«çˆ†æœ‰å¾ˆå¤šåŸå› ï¼Œä¾‹å¦‚ï¼š</p>
<ul>
<li><p>æ¨¡å‹ç®€å•æ˜“æ‡‚ï¼Œencoderå’Œdecoderæ¨¡å—é«˜åº¦ç›¸ä¼¼ä¸”é€šç”¨</p>
</li>
<li><p>ï¼ˆencoderï¼‰å®¹æ˜“å¹¶è¡Œï¼Œæ¨¡å‹è®­ç»ƒé€Ÿåº¦å¿«</p>
</li>
<li><p>æ•ˆæœæ‹”ç¾¤ï¼Œåœ¨NMTç­‰é¢†åŸŸéƒ½å–å¾—äº†state-of-the-artçš„æ•ˆæœ</p>
</li>
</ul>
<p>è®ºæ–‡åœ°å€</p>
<ul>
<li><a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">Attention Is All You Need</a> </li>
</ul>
<p>ä¸‹é¢çš„æ–‡ç« ç¿»è¯‘è‡ª</p>
<ul>
<li><p><a href="https://jalammar.github.io/illustrated-transformer/" target="_blank" rel="noopener">The Illustrated Transformer</a></p>
</li>
<li><p><a href="https://blog.csdn.net/yujianmin1990/article/details/85221271" target="_blank" rel="noopener">ä¸­æ–‡ç¿»è¯‘</a></p>
</li>
</ul>
<p>é«˜å±‹å»ºç“´åœ°è¯´ï¼ŒTransformeræ¨¡å‹æ‹¿åˆ°ä¸€ä¸ªåºåˆ—ï¼Œç”¨æ¥ç”Ÿæˆå¦ä¸€ä¸ªåºåˆ—ã€‚</p>
<p><img src="https://uploader.shimo.im/f/vkvOEopS6TMPw0SL.png!thumbnail" alt="img"></p>
<p>æ‰“å¼€è¿™ä¸ªé»‘ç®±ï¼Œæˆ‘ä»¬ä¼šçœ‹åˆ°å…¶ä¸­åŒ…å«äº†ä¸¤ä¸ªéƒ¨åˆ†ï¼Œencoderså’Œdecodersã€‚</p>
<p><img src="https://uploader.shimo.im/f/hraPVC4iek06oDwt.png!thumbnail" alt="img"></p>
<p>å…¶ä¸­encoderså’Œdecoderséƒ½æ˜¯ä¸¤ä¸ªå †å æ¶æ„ã€‚ä¸€å±‚ä¸€å±‚åŒè´¨çš„ç»“æ„å †å åˆ°ä¸€èµ·ï¼Œç»„æˆäº†ç¼–ç å™¨å’Œè§£ç å™¨ã€‚</p>
<p><img src="https://uploader.shimo.im/f/WFbnFyb8peoeJuXW.png!thumbnail" alt="img"></p>
<p>é¦–å…ˆæˆ‘ä»¬æ‰“å¼€æ¯ä¸ªencoderæ¥å‚è§‚ä¸€ä¸‹å…¶ä¸­åŒ…å«çš„å†…å®¹ï¼š</p>
<p><img src="https://uploader.shimo.im/f/c7oNzYNSIoceXYFZ.png!thumbnail" alt="img"></p>
<p>æ¯ä¸€ä¸ªencoderéƒ½åŒ…å«äº†ä¸€ä¸ªè‡ªæ³¨æ„åŠ›ï¼ˆself-attentionï¼‰å±‚å’Œä¸€ä¸ªFeed Forward Neural Networkã€‚</p>
<p>encoderçš„è¾“å…¥é¦–å…ˆä¼šç»è¿‡ä¸€ä¸ªself-attentionå±‚ã€‚self-attentionçš„ä½œç”¨æ˜¯è®©æ¯ä¸ªå•è¯å¯ä»¥çœ‹åˆ°è‡ªå·±å’Œå…¶ä»–å•è¯çš„å…³ç³»ï¼Œå¹¶ä¸”å°†è‡ªå·±è½¬æ¢æˆä¸€ä¸ªä¸æ‰€æœ‰å•è¯ç›¸å…³çš„ï¼Œ<strong>focusåœ¨è‡ªå·±èº«ä¸Šçš„è¯å‘é‡(?)</strong>ã€‚</p>
<p>self-attentionä¹‹åçš„è¾“å‡ºä¼šå†ç»è¿‡ä¸€å±‚feed-forwardç¥ç»ç½‘ç»œã€‚æ¯ä¸ªä½ç½®çš„è¾“å‡ºè¢«åŒæ ·çš„feed-forward networkå¤„ç†ã€‚</p>
<p>decoderä¹Ÿæœ‰åŒæ ·çš„self-attentionå’Œfeed-forwardç»“æ„ï¼Œä½†æ˜¯åœ¨è¿™ä¸¤å±‚ä¹‹é—´è¿˜æœ‰ä¸€å±‚encoder-decoder attentionå±‚ï¼Œå¸®åŠ©decoderå…³æ³¨åˆ°æŸä¸€äº›ç‰¹åˆ«éœ€è¦å…³æ³¨çš„encoderä½ç½®ã€‚</p>
<h2 id="Tensorçš„å˜åŒ–"><a href="#Tensorçš„å˜åŒ–" class="headerlink" title="Tensorçš„å˜åŒ–"></a>Tensorçš„å˜åŒ–</h2><p><img src="https://uploader.shimo.im/f/Hmbb5V4mEJkBYpFS.png!thumbnail" alt="img"></p>
<h2 id="ç¼–ç å™¨"><a href="#ç¼–ç å™¨" class="headerlink" title="ç¼–ç å™¨"></a>ç¼–ç å™¨</h2><p>ä¸‹é¢æˆ‘ä»¬æ¥è¯¦ç»†è§£è¯»ä¸€ä¸‹ç¼–ç å™¨çš„å·¥ä½œã€‚</p>
<p><img src="https://uploader.shimo.im/f/MzJmdqVJiSUz4DT9.png!thumbnail" alt="img"></p>
<h3 id="Self-Attentionæœºåˆ¶"><a href="#Self-Attentionæœºåˆ¶" class="headerlink" title="Self-Attentionæœºåˆ¶"></a>Self-Attentionæœºåˆ¶</h3><p>æˆ‘ä»¬è€ƒè™‘ç”¨Transformeræ¨¡å‹ç¿»è¯‘ä¸‹é¢è¿™ä¸€å¥è¯ï¼š</p>
<p>â€œThe animal didnâ€™t cross the street because it was too tiredâ€ã€‚</p>
<p>å½“æˆ‘ä»¬ç¿»è¯‘åˆ° it çš„æ—¶å€™ï¼Œæˆ‘ä»¬çŸ¥é“ it æŒ‡ä»£çš„æ˜¯ animal è€Œä¸æ˜¯ streetã€‚æ‰€ä»¥ï¼Œå¦‚æœæœ‰åŠæ³•å¯ä»¥è®© it å¯¹åº”ä½ç½®çš„ embedding é€‚å½“åŒ…å« animal çš„ä¿¡æ¯ï¼Œå°±ä¼šéå¸¸æœ‰ç”¨ã€‚self-attentionçš„å‡ºç°å°±æ˜¯ä¸ºäº†å®Œæˆè¿™ä¸€ä»»åŠ¡ã€‚</p>
<p>å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œself attnetionä¼šè®©å•è¯ it å’Œ æŸäº›å•è¯å‘ç”Ÿæ¯”è¾ƒå¼ºçš„è”ç³»ï¼Œå¾—åˆ°æ¯”è¾ƒæçš„attentionåˆ†æ•°ã€‚</p>
<p><img src="https://uploader.shimo.im/f/UsNXjO1OpN0usuAg.png!thumbnail" alt="img"></p>
<p>weight(The) = softmax(v(it) * v(The) / \sqrt(d))</p>
<p>weight(The) = softmx(Query(It) * Key(The) / \sqrt(d))</p>
<p>\sum_{word} weight(word) * Value(word)</p>
<h3 id="Self-attentionçš„ç»†èŠ‚"><a href="#Self-attentionçš„ç»†èŠ‚" class="headerlink" title="Self-attentionçš„ç»†èŠ‚"></a>Self-attentionçš„ç»†èŠ‚</h3><p>ä¸ºäº†å®ç° self-attentionï¼Œæ¯ä¸ªè¾“å…¥çš„ä½ç½®éœ€è¦äº§ç”Ÿä¸‰ä¸ªå‘é‡ï¼Œåˆ†åˆ«æ˜¯ <strong>Query å‘é‡ï¼ŒKey å‘é‡å’Œ Value å‘é‡</strong>ã€‚è¿™äº›å‘é‡éƒ½æ˜¯ç”±è¾“å…¥ embedding é€šè¿‡ä¸‰ä¸ª matrices ï¼ˆä¹Ÿå°±æ˜¯çº¿æ€§å˜åŒ–ï¼‰äº§ç”Ÿçš„ã€‚</p>
<p>æ³¨æ„åˆ°åœ¨Transformeræ¶æ„ä¸­ï¼Œè¿™äº›æ–°çš„å‘é‡æ¯”åŸæ¥çš„è¾“å…¥å‘é‡è¦å°ï¼ŒåŸæ¥çš„å‘é‡æ˜¯512ç»´ï¼Œè½¬å˜åçš„ä¸‰ä¸ªå‘é‡éƒ½æ˜¯64ç»´ã€‚</p>
<p><img src="https://uploader.shimo.im/f/MAqlj67rbPYBI7Ad.png!thumbnail" alt="img"></p>
<p>ç¬¬äºŒæ­¥æ˜¯<strong>è®¡ç®—åˆ†æ•°</strong>ã€‚å½“æˆ‘ä»¬åœ¨ç”¨self-attention encodeæŸä¸ªä½ç½®ä¸Šçš„æŸä¸ªå•è¯çš„æ—¶å€™ï¼Œæˆ‘ä»¬å¸Œæœ›çŸ¥é“è¿™ä¸ªå•è¯å¯¹åº”çš„å¥å­ä¸Šå…¶ä»–å•è¯çš„åˆ†æ•°ã€‚å…¶ä»–å•è¯æ‰€å¾—åˆ°çš„åˆ†æ•°è¡¨ç¤ºäº†å½“æˆ‘ä»¬encodeå½“å‰å•è¯çš„æ—¶å€™ï¼Œåº”è¯¥æ”¾å¤šå°‘çš„å…³æ³¨åº¦åœ¨å…¶ä½™çš„æ¯ä¸ªå•è¯ä¸Šã€‚åˆæˆ–è€…è¯´ï¼Œå…¶ä»–å•è¯å’Œæˆ‘å½“å‰çš„å•è¯æœ‰å¤šå¤§çš„ç›¸å…³æ€§æˆ–è€…ç›¸ä¼¼æ€§ã€‚</p>
<p>åœ¨transformeræ¨¡å‹ä¸­ï¼Œè¿™ä¸ªåˆ†æ•°æ˜¯ç”±query vectorå’Œkey vectoråšç‚¹ç§¯ï¼ˆdot productï¼‰æ‰€å¾—çš„ç»“æœã€‚æ‰€ä»¥è¯´ï¼Œå½“æˆ‘ä»¬åœ¨å¯¹ç¬¬ä¸€ä¸ªå•è¯åšself-attentionå¤„ç†çš„æ—¶å€™ï¼Œç¬¬ä¸€ä¸ªå•è¯çš„åˆ†æ•°æ˜¯q_1å’Œk_1çš„ç‚¹ç§¯ï¼Œç¬¬äºŒä¸ªåˆ†æ•°æ˜¯q_1å’Œk_2çš„åˆ†æ•°ã€‚</p>
<p><img src="https://uploader.shimo.im/f/kW9cJM4TjTc9xtMV.png!thumbnail" alt="img"></p>
<p>ç¬¬ä¸‰æ­¥å’Œç¬¬å››æ­¥æ˜¯å°†è¿™äº›åˆ†æ•°é™¤ä»¥8ã€‚8è¿™ä¸ªæ•°å­—æ˜¯64çš„å¼€æ–¹ï¼Œä¹Ÿå°±æ˜¯key vectorçš„ç»´åº¦çš„å¼€æ–¹ã€‚æ®è¯´è¿™ä¹ˆåšå¯ä»¥ç¨³å®šæ¨¡å‹çš„gradientã€‚ç„¶åæˆ‘ä»¬å°†è¿™äº›åˆ†æ•°ä¼ å…¥softmaxå±‚äº§ç”Ÿä¸€äº›ç¬¦åˆæ¦‚ç‡åˆ†å¸ƒçš„probability scoresã€‚</p>
<p><img src="https://uploader.shimo.im/f/6kTtVymp0XgZCDh0.png!thumbnail" alt="img"></p>
<p>softmax = exp(x_i) / sum exp(x_i)</p>
<p>è¿™äº›åˆ†æ•°å°±è¡¨ç¤ºäº†åœ¨å¤„ç†å½“å‰å•è¯çš„æ—¶å€™æˆ‘ä»¬åº”è¯¥åˆ†é…å¤šå°‘çš„å…³æ³¨åº¦ç»™å…¶ä»–å•è¯ã€‚</p>
<p>ç¬¬äº”æ­¥æ˜¯å°†æ¯ä¸ªvalue vectorä¹˜ä»¥å®ƒä»¬å„è‡ªçš„attention scoreã€‚ç¬¬å…­æ­¥æ˜¯æŠŠè¿™äº›weighted value vectorsç›¸åŠ ï¼Œæˆä¸ºå½“å‰å•è¯çš„vectorè¡¨ç¤ºã€‚</p>
<p><img src="https://uploader.shimo.im/f/FrqMNrQrlo0tLBgV.png!thumbnail" alt="img"></p>
<p>å¾—åˆ°äº†self-attentionç”Ÿæˆçš„è¯å‘é‡ä¹‹åï¼Œæˆ‘ä»¬å°±å¯ä»¥å°†å®ƒä»¬ä¼ å…¥feed-forward networkäº†ã€‚</p>
<h3 id="Self-Attentionä¸­çš„çŸ©é˜µè¿ç®—"><a href="#Self-Attentionä¸­çš„çŸ©é˜µè¿ç®—" class="headerlink" title="Self-Attentionä¸­çš„çŸ©é˜µè¿ç®—"></a>Self-Attentionä¸­çš„çŸ©é˜µè¿ç®—</h3><p>é¦–å…ˆï¼Œæˆ‘ä»¬è¦å¯¹æ¯ä¸€ä¸ªè¯å‘é‡è®¡ç®—Query, Keyå’ŒValueçŸ©é˜µã€‚æˆ‘ä»¬æŠŠå¥å­ä¸­çš„æ¯ä¸ªè¯å‘é‡æ‹¼æ¥åˆ°ä¸€èµ·å˜æˆä¸€ä¸ªçŸ©é˜µXï¼Œç„¶åä¹˜ä»¥ä¸åŒçš„çŸ©é˜µåšçº¿æ€§å˜æ¢ï¼ˆWQ, WK, WVï¼‰ã€‚</p>
<p><img src="https://uploader.shimo.im/f/xRsGTXMRHTQsNPiL.png!thumbnail" alt="img"></p>
<p>ç„¶åæˆ‘ä»¬å°±ç”¨çŸ©é˜µä¹˜æ³•å®ç°ä¸Šé¢ä»‹ç»è¿‡çš„Self-Attentionæœºåˆ¶äº†ã€‚</p>
<p><img src="https://uploader.shimo.im/f/S1IEPFyGeMUTWMBk.png!thumbnail" alt="img"></p>
<h3 id="Multi-headed-attention"><a href="#Multi-headed-attention" class="headerlink" title="Multi-headed attention"></a>Multi-headed attention</h3><p>åœ¨è®ºæ–‡å½“ä¸­ï¼Œæ¯ä¸ªembedding vectorå¹¶ä¸æ­¢äº§ç”Ÿä¸€ä¸ªkey, value, query vectorsï¼Œè€Œæ˜¯äº§ç”Ÿè‹¥å¹²ç»„è¿™æ ·çš„vectorsï¼Œç§°ä¹‹ä¸ºâ€multi-headedâ€ attentionã€‚è¿™ä¹ˆåšæœ‰å‡ ä¸ªå¥½å¤„ï¼š</p>
<ul>
<li><p>k: key, q: query, v: value</p>
</li>
<li><p>æ¨¡å‹æœ‰æ›´å¼ºçš„èƒ½åŠ›äº§ç”Ÿä¸åŒçš„attentionæœºåˆ¶ï¼Œfocusåœ¨ä¸åŒçš„å•è¯ä¸Šã€‚</p>
</li>
<li><p>attention layeræœ‰å¤šä¸ªä¸åŒçš„â€representation spaceâ€ã€‚</p>
</li>
</ul>
<p><img src="https://uploader.shimo.im/f/vQX0sIYIoqUNYO4J.png!thumbnail" alt="img"></p>
<p>æ¯ä¸ªattention headæœ€ç»ˆéƒ½äº§ç”Ÿäº†ä¸€ä¸ªmatrixè¡¨ç¤ºè¿™ä¸ªå¥å­ä¸­çš„æ‰€æœ‰è¯å‘é‡ã€‚åœ¨transformeræ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬äº§ç”Ÿäº†å…«ä¸ªmatricesã€‚æˆ‘ä»¬çŸ¥é“self attentionä¹‹åå°±æ˜¯ä¸€ä¸ªfeed-forward networkã€‚é‚£ä¹ˆæˆ‘ä»¬æ˜¯å¦éœ€è¦åš8æ¬¡feed-forward networkè¿ç®—å‘¢ï¼Ÿäº‹å®ä¸Šæ˜¯ä¸ç”¨çš„ã€‚æˆ‘ä»¬åªéœ€è¦å°†è¿™8ä¸ªmatricesæ‹¼æ¥åˆ°ä¸€èµ·ï¼Œç„¶ååšä¸€æ¬¡å‰å‘ç¥ç»ç½‘ç»œçš„è¿ç®—å°±å¯ä»¥äº†ã€‚</p>
<p><img src="https://uploader.shimo.im/f/E4AxOnUs2JgGJ0bW.png!thumbnail" alt="img"></p>
<p>ç»¼åˆèµ·æ¥ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ä¸‹é¢ä¸€å¼ å›¾è¡¨ç¤ºSelf-Attentionæ¨¡å—æ‰€åšçš„äº‹æƒ…ã€‚</p>
<p><img src="https://uploader.shimo.im/f/YmfWxTGsc48tTbfi.png!thumbnail" alt="img"></p>
<h3 id="Positional-Encoding"><a href="#Positional-Encoding" class="headerlink" title="Positional Encoding"></a>Positional Encoding</h3><p>thinking machine</p>
<p>w_1, w_2</p>
<p>p_1, p_2</p>
<p>positional_embedding = nn.Embedding(512, 300)</p>
<p>w_1 + p_1, w_2 + p_2, w_3 + p_3, â€¦, w_n + p_n</p>
<p>åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å®Œå…¨æ²¡æœ‰è€ƒè™‘å•è¯çš„é¡ºåºã€‚å³ä½¿æˆ‘ä»¬å°†å¥å­ä¸­å•è¯çš„é¡ºåºå®Œå…¨æ‰“ä¹±ï¼Œå¯¹äºtransformerè¿™ä¸ªæ¨¡å‹æ¥è¯´ï¼Œå¹¶æ²¡æœ‰ä»€ä¹ˆåŒºåˆ«ã€‚ä¸ºäº†åŠ å…¥å¥å­ä¸­å•è¯çš„é¡ºåºä¿¡æ¯ï¼Œæˆ‘ä»¬å¼•å…¥ä¸€ä¸ªæ¦‚å¿µå«åšpositional encodingã€‚</p>
<p><img src="https://uploader.shimo.im/f/1F6bv1ngvE4hEp99.png!thumbnail" alt="img"></p>
<p>å¦‚æœæˆ‘ä»¬å‡è®¾è¾“å…¥çš„embeddingæ˜¯4ä¸ªç»´åº¦çš„ï¼Œé‚£ä¹ˆä»–ä»¬çš„position encodingså¤§æ¦‚é•¿ä¸‹é¢è¿™æ ·ã€‚</p>
<p><img src="https://uploader.shimo.im/f/1p4K2IclsvwWGw0Z.png!thumbnail" alt="img"></p>
<p>ä¸‹é¢è¿™å¼ å›¾çš„æ¯ä¸€è¡Œè¡¨ç¤ºä¸€ä¸ªpositional encoding vectorã€‚ç¬¬ä¸€è¡Œè¡¨ç¤ºç¬¬ä¸€ä¸ªå•è¯çš„positional encodingï¼Œä»¥æ­¤ç±»æ¨ã€‚æ¯ä¸€è¡Œéƒ½æœ‰512ä¸ª-1åˆ°1ä¹‹é—´çš„æ•°å­—ã€‚æˆ‘ä»¬ç”¨é¢œè‰²æ ‡è®°äº†è¿™äº›vectorsã€‚</p>
<p><img src="https://uploader.shimo.im/f/HMQy3lipFooyu8rO.png!thumbnail" alt="img"></p>
<h3 id="Residuals"><a href="#Residuals" class="headerlink" title="Residuals"></a>Residuals</h3><p>å¦å¤–ä¸€ä¸ªç»†èŠ‚æ˜¯ï¼Œencoderä¸­çš„æ¯ä¸€å±‚éƒ½åŒ…å«äº†ä¸€ä¸ªresidual connectionå’Œlayer-normalizationã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚</p>
<p><img src="https://uploader.shimo.im/f/1qIGhKLQLYkHahSn.png!thumbnail" alt="img"></p>
<p>ä¸‹é¢è¿™å¼ å›¾æ˜¯æ›´è¯¦ç»†çš„vectorè¡¨ç¤ºã€‚</p>
<p><img src="https://uploader.shimo.im/f/ivgMtxCc8CsI7lAF.png!thumbnail" alt="img"></p>
<p>decoderä¹Ÿæ˜¯åŒæ ·çš„æ¶æ„ã€‚å¦‚æœæˆ‘ä»¬æŠŠencoderå’Œdecoderæ”¾åˆ°ä¸€èµ·ï¼Œä»–ä»¬å°±é•¿è¿™æ ·ã€‚</p>
<p><img src="https://uploader.shimo.im/f/TumXWzLQ6XMjJneZ.png!thumbnail" alt="img"></p>
<h2 id="è§£ç å™¨"><a href="#è§£ç å™¨" class="headerlink" title="è§£ç å™¨"></a>è§£ç å™¨</h2><p>encoderæœ€åä¸€å±‚ä¼šè¾“å‡ºattention vectors Kå’ŒVã€‚Kå’ŒVä¼šè¢«decoderç”¨ä½œè§£ç çš„åŸææ–™ã€‚</p>
<p><img src="https://uploader.shimo.im/f/3AgIt6lqzgADLwuf.png!thumbnail" alt="img"></p>
<p>åœ¨è§£ç çš„è¿‡ç¨‹ä¸­ï¼Œè§£ç å™¨æ¯ä¸€æ­¥ä¼šè¾“å‡ºä¸€ä¸ªtokenã€‚ä¸€ç›´å¾ªç¯å¾€å¤ï¼Œç›´åˆ°å®ƒè¾“å‡ºäº†ä¸€ä¸ªç‰¹æ®Šçš„end of sequence tokenï¼Œè¡¨ç¤ºè§£ç ç»“æŸäº†ã€‚</p>
<p><img src="https://uploader.shimo.im/f/ai444UV6eQ4E0f6O.png!thumbnail" alt="img"></p>
<p>decoderçš„self attentionæœºåˆ¶ä¸encoderç¨æœ‰ä¸åŒã€‚åœ¨decoderå½“ä¸­ï¼Œself attentionå±‚åªèƒ½çœ‹åˆ°ä¹‹å‰å·²ç»è§£ç çš„æ–‡å­—ã€‚æˆ‘ä»¬åªéœ€è¦æŠŠå½“å‰è¾“å‡ºä½ç½®ä¹‹åçš„å•è¯å…¨éƒ½maskæ‰ï¼ˆsoftmaxå±‚ä¹‹å‰å…¨éƒ½è®¾ç½®æˆ-infï¼‰å³å¯ã€‚</p>
<p>softmax(Q matmul K^T / sqrt(d)) matmul V</p>
<p>weights = Q matmul K^T: [seq_len, seq_len]</p>
<p>Masked Self Attention</p>
<p>q, k (<strong>100, 24</strong>, 35 - inf, 88 - inf, -55 - inf) â€“&gt; softmax â€“&gt; (0.9, 0.1, 0, 0, 0)</p>
<p>attention_mask</p>
<p>0, -inf, -inf, -inf</p>
<p>0, 0, -inf, -inf</p>
<p>0, 0, 0, -inf </p>
<p>0, 0, 0, 0</p>
<p>softmax(weights - attention_mask, -1)</p>
<p>è®­ç»ƒ</p>
<p>QKV, å¹¶è¡Œè®­ç»ƒ</p>
<p>é¢„æµ‹</p>
<p>ä¸€ä¸ªå•è¯ä¸€ä¸ªå•è¯è§£ç </p>
<p>Encoder-Decoder Attentionå±‚å’Œæ™®é€šçš„multiheaded self-attentionä¸€æ ·ï¼Œé™¤äº†å®ƒçš„Querieså®Œå…¨æ¥è‡ªä¸‹é¢çš„decoderå±‚ï¼Œç„¶åKeyå’ŒValueæ¥è‡ªencoderçš„è¾“å‡ºå‘é‡ã€‚</p>
<p>batch_size * seq_length * hidden_size </p>
<p>padding_mask</p>
<p>tgt_mask</p>
<h3 id="æœ€åçš„çº¿æ€§å±‚å’Œsoftmaxå±‚"><a href="#æœ€åçš„çº¿æ€§å±‚å’Œsoftmaxå±‚" class="headerlink" title="æœ€åçš„çº¿æ€§å±‚å’Œsoftmaxå±‚"></a>æœ€åçš„çº¿æ€§å±‚å’Œsoftmaxå±‚</h3><p>è§£ç å™¨æœ€åè¾“å‡ºæµ®ç‚¹å‘é‡ï¼Œå¦‚ä½•å°†å®ƒè½¬æˆè¯ï¼Ÿè¿™æ˜¯æœ€åçš„çº¿æ€§å±‚å’Œsoftmaxå±‚çš„ä¸»è¦å·¥ä½œã€‚</p>
<p>çº¿æ€§å±‚æ˜¯ä¸ªç®€å•çš„å…¨è¿æ¥å±‚ï¼Œå°†è§£ç å™¨çš„æœ€åè¾“å‡ºæ˜ å°„åˆ°ä¸€ä¸ªéå¸¸å¤§çš„logitså‘é‡ä¸Šã€‚å‡è®¾æ¨¡å‹å·²çŸ¥æœ‰1ä¸‡ä¸ªå•è¯ï¼ˆè¾“å‡ºçš„è¯è¡¨ï¼‰ä»è®­ç»ƒé›†ä¸­å­¦ä¹ å¾—åˆ°ã€‚é‚£ä¹ˆï¼Œlogitså‘é‡å°±æœ‰1ä¸‡ç»´ï¼Œæ¯ä¸ªå€¼è¡¨ç¤ºæ˜¯æŸä¸ªè¯çš„å¯èƒ½å€¾å‘å€¼ã€‚</p>
<p>softmaxå±‚å°†è¿™äº›åˆ†æ•°è½¬æ¢æˆæ¦‚ç‡å€¼ï¼ˆéƒ½æ˜¯æ­£å€¼ï¼Œä¸”åŠ å’Œä¸º1ï¼‰ï¼Œæœ€é«˜å€¼å¯¹åº”çš„ç»´ä¸Šçš„è¯å°±æ˜¯è¿™ä¸€æ­¥çš„è¾“å‡ºå•è¯ã€‚</p>
<p><img src="https://uploader.shimo.im/f/7ffWFIfMqOgtsK22.png!thumbnail" alt="img"></p>
<h2 id="æ¨¡å‹çš„è®­ç»ƒ"><a href="#æ¨¡å‹çš„è®­ç»ƒ" class="headerlink" title="æ¨¡å‹çš„è®­ç»ƒ"></a>æ¨¡å‹çš„è®­ç»ƒ</h2><p>ç°åœ¨æˆ‘ä»¬å·²ç»äº†è§£äº†ä¸€ä¸ªè®­ç»ƒå®Œæ¯•çš„Transformerçš„å‰å‘è¿‡ç¨‹ï¼Œé¡ºé“çœ‹ä¸‹è®­ç»ƒçš„æ¦‚å¿µä¹Ÿæ˜¯éå¸¸æœ‰ç”¨çš„ã€‚åœ¨è®­ç»ƒæ—¶ï¼Œæ¨¡å‹å°†ç»å†ä¸Šè¿°çš„å‰å‘è¿‡ç¨‹ï¼Œå½“æˆ‘ä»¬åœ¨æ ‡è®°è®­ç»ƒé›†ä¸Šè®­ç»ƒæ—¶ï¼Œå¯ä»¥å¯¹æ¯”é¢„æµ‹è¾“å‡ºä¸å®é™…è¾“å‡ºã€‚ä¸ºäº†å¯è§†åŒ–ï¼Œå‡è®¾è¾“å‡ºä¸€å…±åªæœ‰6ä¸ªå•è¯ï¼ˆâ€œaâ€, â€œamâ€, â€œiâ€, â€œthanksâ€, â€œstudentâ€, â€œâ€ï¼‰</p>
<p><img src="https://uploader.shimo.im/f/FNgjBBm5gbUGYgbs.png!thumbnail" alt="img"></p>
<p>æ¨¡å‹çš„è¯è¡¨æ˜¯åœ¨è®­ç»ƒä¹‹å‰çš„é¢„å¤„ç†ä¸­ç”Ÿæˆçš„</p>
<p>ä¸€æ—¦å®šä¹‰äº†è¯è¡¨ï¼Œæˆ‘ä»¬å°±èƒ½å¤Ÿæ„é€ ä¸€ä¸ªåŒç»´åº¦çš„å‘é‡æ¥è¡¨ç¤ºæ¯ä¸ªå•è¯ï¼Œæ¯”å¦‚one-hotç¼–ç ï¼Œä¸‹é¢ä¸¾ä¾‹ç¼–ç â€œamâ€ã€‚</p>
<p><img src="https://uploader.shimo.im/f/feV2TQAHPF0z3Rr2.png!thumbnail" alt="img"></p>
<p>ä¸¾ä¾‹é‡‡ç”¨one-hotç¼–ç è¾“å‡ºè¯è¡¨</p>
<p>ä¸‹é¢è®©æˆ‘ä»¬è®¨è®ºä¸‹æ¨¡å‹çš„lossæŸå¤±ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç”¨æ¥ä¼˜åŒ–çš„æŒ‡æ ‡ï¼ŒæŒ‡å¯¼å­¦ä¹ å¾—åˆ°ä¸€ä¸ªéå¸¸å‡†ç¡®çš„æ¨¡å‹ã€‚</p>
<h3 id="æŸå¤±å‡½æ•°"><a href="#æŸå¤±å‡½æ•°" class="headerlink" title="æŸå¤±å‡½æ•°"></a>æŸå¤±å‡½æ•°</h3><p>æˆ‘ä»¬ç”¨ä¸€ä¸ªç®€å•çš„ä¾‹å­æ¥ç¤ºèŒƒè®­ç»ƒï¼Œæ¯”å¦‚ç¿»è¯‘â€œmerciâ€ä¸ºâ€œthanksâ€ã€‚é‚£æ„å‘³ç€è¾“å‡ºçš„æ¦‚ç‡åˆ†å¸ƒæŒ‡å‘å•è¯â€œthanksâ€ï¼Œä½†æ˜¯ç”±äºæ¨¡å‹æœªè®­ç»ƒæ˜¯éšæœºåˆå§‹åŒ–çš„ï¼Œä¸å¤ªå¯èƒ½å°±æ˜¯æœŸæœ›çš„è¾“å‡ºã€‚</p>
<p><img src="https://uploader.shimo.im/f/aWNgQPklQh8odGQP.png!thumbnail" alt="img"></p>
<p>ç”±äºæ¨¡å‹å‚æ•°æ˜¯éšæœºåˆå§‹åŒ–çš„ï¼Œæœªè®­ç»ƒçš„æ¨¡å‹è¾“å‡ºéšæœºå€¼ã€‚æˆ‘ä»¬å¯ä»¥å¯¹æ¯”çœŸå®è¾“å‡ºï¼Œç„¶ååˆ©ç”¨è¯¯å·®åä¼ è°ƒæ•´æ¨¡å‹æƒé‡ï¼Œä½¿å¾—è¾“å‡ºæ›´æ¥è¿‘ä¸çœŸå®è¾“å‡ºã€‚å¦‚ä½•å¯¹æ¯”ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒå‘¢ï¼Ÿç®€å•é‡‡ç”¨ <a href="https://colah.github.io/posts/2015-09-Visual-Information/" target="_blank" rel="noopener">cross-entropy</a>æˆ–è€…<a href="https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained" target="_blank" rel="noopener">Kullback-Leibler divergence</a>ä¸­çš„ä¸€ç§ã€‚é‰´äºè¿™æ˜¯ä¸ªæå…¶ç®€å•çš„ä¾‹å­ï¼Œæ›´çœŸå®çš„æƒ…å†µæ˜¯ï¼Œä½¿ç”¨ä¸€ä¸ªå¥å­ä½œä¸ºè¾“å…¥ã€‚æ¯”å¦‚ï¼Œè¾“å…¥æ˜¯â€œje suis Ã©tudiantâ€ï¼ŒæœŸæœ›è¾“å‡ºæ˜¯â€œi am a studentâ€ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸‹ï¼Œæˆ‘ä»¬æœŸæœ›æ¨¡å‹è¾“å‡ºè¿ç»­çš„æ¦‚ç‡åˆ†å¸ƒæ»¡è¶³å¦‚ä¸‹æ¡ä»¶ï¼š</p>
<ol>
<li><p>æ¯ä¸ªæ¦‚ç‡åˆ†å¸ƒéƒ½ä¸è¯è¡¨åŒç»´åº¦</p>
</li>
<li><p>ç¬¬ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒå¯¹â€œiâ€å…·æœ‰æœ€é«˜çš„é¢„æµ‹æ¦‚ç‡å€¼ã€‚</p>
</li>
<li><p>ç¬¬äºŒä¸ªæ¦‚ç‡åˆ†å¸ƒå¯¹â€œamâ€å…·æœ‰æœ€é«˜çš„é¢„æµ‹æ¦‚ç‡å€¼ã€‚</p>
</li>
<li><p>ä¸€ç›´åˆ°ç¬¬äº”ä¸ªè¾“å‡ºæŒ‡å‘â€â€æ ‡è®°ã€‚</p>
</li>
</ol>
<p><img src="https://uploader.shimo.im/f/rAnz8qY0eHgt2OAe.png!thumbnail" alt="img"></p>
<p>å¯¹ä¸€ä¸ªå¥å­è€Œè¨€ï¼Œè®­ç»ƒæ¨¡å‹çš„ç›®æ ‡æ¦‚ç‡åˆ†å¸ƒ</p>
<p>åœ¨è¶³å¤Ÿå¤§çš„è®­ç»ƒé›†ä¸Šè®­ç»ƒè¶³å¤Ÿæ—¶é—´ä¹‹åï¼Œæˆ‘ä»¬æœŸæœ›äº§ç”Ÿçš„æ¦‚ç‡åˆ†å¸ƒå¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<p><img src="https://uploader.shimo.im/f/IyKk2fNcC3k4tgBt.png!thumbnail" alt="img"></p>
<p>è®­ç»ƒå¥½ä¹‹åï¼Œæ¨¡å‹çš„è¾“å‡ºæ˜¯æˆ‘ä»¬æœŸæœ›çš„ç¿»è¯‘ã€‚å½“ç„¶ï¼Œè¿™å¹¶ä¸æ„å‘³ç€è¿™ä¸€è¿‡ç¨‹æ˜¯æ¥è‡ªè®­ç»ƒé›†ã€‚æ³¨æ„ï¼Œæ¯ä¸ªä½ç½®éƒ½èƒ½æœ‰å€¼ï¼Œå³ä¾¿ä¸è¾“å‡ºè¿‘ä¹æ— å…³ï¼Œè¿™ä¹Ÿæ˜¯softmaxå¯¹è®­ç»ƒæœ‰å¸®åŠ©çš„åœ°æ–¹ã€‚ç°åœ¨ï¼Œå› ä¸ºæ¨¡å‹æ¯æ­¥åªäº§ç”Ÿä¸€ç»„è¾“å‡ºï¼Œå‡è®¾æ¨¡å‹é€‰æ‹©æœ€é«˜æ¦‚ç‡ï¼Œæ‰”æ‰å…¶ä»–çš„éƒ¨åˆ†ï¼Œè¿™æ˜¯ç§äº§ç”Ÿé¢„æµ‹ç»“æœçš„æ–¹æ³•ï¼Œå«åšgreedy è§£ç ã€‚å¦å¤–ä¸€ç§æ–¹æ³•æ˜¯beam searchï¼Œæ¯ä¸€æ­¥ä»…ä¿ç•™æœ€å¤´éƒ¨é«˜æ¦‚ç‡çš„ä¸¤ä¸ªè¾“å‡ºï¼Œæ ¹æ®è¿™ä¿©è¾“å‡ºå†é¢„æµ‹ä¸‹ä¸€æ­¥ï¼Œå†ä¿ç•™å¤´éƒ¨é«˜æ¦‚ç‡çš„ä¸¤ä¸ªè¾“å‡ºï¼Œé‡å¤ç›´åˆ°é¢„æµ‹ç»“æŸ</p>
<h2 id="æ›´å¤šèµ„æ–™"><a href="#æ›´å¤šèµ„æ–™" class="headerlink" title="æ›´å¤šèµ„æ–™"></a>æ›´å¤šèµ„æ–™</h2><ul>
<li><p><a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">Attention Is All You Need</a> </p>
</li>
<li><p>Transformeråšå®¢æ–‡ç«  <a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html" target="_blank" rel="noopener">Transformer: A Novel Neural Network Architecture for Language Understanding</a></p>
</li>
<li><p><a href="https://ai.googleblog.com/2017/06/accelerating-deep-learning-research.html" target="_blank" rel="noopener">Tensor2Tensor announcement</a>.</p>
</li>
<li><p><a href="https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb" target="_blank" rel="noopener">Jupyter Notebook provided as part of the Tensor2Tensor repo</a></p>
</li>
<li><p><a href="https://github.com/tensorflow/tensor2tensor" target="_blank" rel="noopener">Tensor2Tensor repo</a>.</p>
</li>
</ul>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/NLP/">NLP</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Transformer/">Transformer</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
  
</article>










  
    <article id="post-Transformer-XL" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/05/16/Transformer-XL/" class="article-date">
      <time datetime="2020-05-16T00:34:49.000Z" itemprop="datePublished">2020-05-16</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/05/16/Transformer-XL/">Transformer-XL</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h2 id="Transformer-XL-Attentive-Language-Models-Beyond-a-Fixed-Length-Context"><a href="#Transformer-XL-Attentive-Language-Models-Beyond-a-Fixed-Length-Context" class="headerlink" title="Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context"></a>Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context</h2><p><a href="https://arxiv.org/pdf/1901.02860.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1901.02860.pdf</a></p>
<p>ç›¸è¾ƒäºä¼ ç»Ÿtransformer decoderï¼Œå¼•å…¥ä¸¤ä¸ªæ–°æ¨¡å—</p>
<ul>
<li>segment-level recurrence mechanism</li>
</ul>
<p><img src="https://uploader.shimo.im/f/DpNe30kuahkbOeW5.png!thumbnail" alt="img"></p>
<ul>
<li><p>a novel positional encoding scheme</p>
</li>
<li><p>è€ƒè™‘æˆ‘ä»¬åœ¨attentionæœºåˆ¶ä¸­å¦‚ä½•ä½¿ç”¨positional encoding</p>
</li>
</ul>
<p>(E_{x_i}^T+U_i^T)W_q^TW_kE_{x_j}U_j</p>
<p><img src="https://uploader.shimo.im/f/5zNU9yZQtQMClNiY.png!thumbnail" alt="img"></p>
<ul>
<li><p>Rä»–ä»¬é‡‡ç”¨çš„æ˜¯transformerå½“ä¸­çš„positional encoding</p>
</li>
<li><p>uå’Œvæ˜¯éœ€è¦è®­ç»ƒçš„æ¨¡å‹å‚æ•°</p>
</li>
</ul>
<p>æœ€ç»ˆTransformer XLæ¨¡å‹</p>
<p><img src="https://uploader.shimo.im/f/Nm1uk49MIjUys1aK.png!thumbnail" alt="img"></p>
<p>ä»£ç </p>
<p><a href="https://github.com/kimiyoung/transformer-xl" target="_blank" rel="noopener">https://github.com/kimiyoung/transformer-xl</a></p>
<h2 id="XLNet-Generalized-Autoregressive-Pretraining-for-Language-Understanding"><a href="#XLNet-Generalized-Autoregressive-Pretraining-for-Language-Understanding" class="headerlink" title="XLNet: Generalized Autoregressive Pretraining for Language Understanding"></a>XLNet: Generalized Autoregressive Pretraining for Language Understanding</h2><p><a href="https://arxiv.org/pdf/1906.08237.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1906.08237.pdf</a></p>
<p>èƒŒæ™¯çŸ¥è¯†</p>
<ul>
<li><p>è‡ªå›å½’è¯­è¨€æ¨¡å‹ï¼ˆAutoregressive Language Modelï¼‰ï¼šé‡‡ç”¨ä»å·¦å¾€å³æˆ–ä»å³å¾€å·¦çš„è¯­è¨€æ¨¡å‹ï¼Œæ ¹æ®ä¸Šæ–‡é¢„æµ‹ä¸‹æ–‡ã€‚</p>
</li>
<li><p>ç¼ºç‚¹ï¼šåªåˆ©ç”¨äº†é¢„æµ‹å•è¯å·¦è¾¹æˆ–å³è¾¹çš„ä¿¡æ¯ï¼Œæ— æ³•åŒæ—¶åˆ©ç”¨ä¸¤è¾¹çš„ä¿¡æ¯ã€‚ELMoåœ¨ä¸€å®šç¨‹åº¦ä¸Šè§£å†³äº†è¿™ä¸ªé—®é¢˜ã€‚</p>
</li>
<li><p><img src="https://uploader.shimo.im/f/cpfGbeRfzf8c1ga8.png!thumbnail" alt="img"></p>
</li>
<li><p>è‡ªç¼–ç æ¨¡å‹ï¼ˆDenoising Auto Encoder, DAEï¼‰ï¼šåœ¨è¾“å…¥ä¸­éšæœºmaskä¸€äº›å•è¯ï¼Œåˆ©ç”¨ä¸Šä¸‹æ–‡æ¥é¢„æµ‹è¢«maskæ‰çš„å•è¯ã€‚BERTé‡‡ç”¨äº†è¿™ä¸€æ€è·¯ã€‚</p>
</li>
<li><p><img src="https://uploader.shimo.im/f/za1FnG3zHdsbm5gD.png!thumbnail" alt="img"></p>
</li>
</ul>
<p>ä¸¤ä¸ªæ¨¡å‹çš„é—®é¢˜</p>
<p><img src="https://uploader.shimo.im/f/A1rO6rAR1nAQqqvu.png!thumbnail" alt="img"></p>
<p>XLNetçš„ç›®æ ‡æ˜¯èåˆä»¥ä¸Šä¸¤ç§æ¨¡å‹çš„ä¼˜ç‚¹ï¼Œè§£å†³å®ƒä»¬å„è‡ªå­˜åœ¨çš„é—®é¢˜ã€‚</p>
<p>XLNetæ¨¡å‹ï¼šPermutation Language Modeling</p>
<p><img src="https://uploader.shimo.im/f/LdaKeEgG8XwH3iNj.png!thumbnail" alt="img"></p>
<p>Two-Stream Self-Attention</p>
<p><img src="https://uploader.shimo.im/f/TdQVsxOeYMoakBW0.png!thumbnail" alt="img"></p>
<p><img src="https://uploader.shimo.im/f/iLMqF1WinQI6wOsW.png!thumbnail" alt="img"></p>
<p>å‚è€ƒèµ„æ–™</p>
<p><a href="https://zhuanlan.zhihu.com/p/70257427" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/70257427</a></p>
<p>ä»£ç </p>
<p><a href="https://github.com/zihangdai/xlnet" target="_blank" rel="noopener">https://github.com/zihangdai/xlnet</a></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/NLP/">NLP</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Transformer-XL/">Transformer-XL</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/XLNet/">XLNet</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
  
</article>










  
    <article id="post-è‹±æ–‡ä¹¦ç±wordçº§åˆ«çš„æ–‡æœ¬ç”Ÿæˆä»£ç æ³¨é‡Š" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/05/12/è‹±æ–‡ä¹¦ç±wordçº§åˆ«çš„æ–‡æœ¬ç”Ÿæˆä»£ç æ³¨é‡Š/" class="article-date">
      <time datetime="2020-05-12T10:52:06.000Z" itemprop="datePublished">2020-05-12</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/05/12/è‹±æ–‡ä¹¦ç±wordçº§åˆ«çš„æ–‡æœ¬ç”Ÿæˆä»£ç æ³¨é‡Š/">è‹±æ–‡ä¹¦ç±wordçº§åˆ«çš„æ–‡æœ¬ç”Ÿæˆä»£ç æ³¨é‡Š</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p><strong>å…ˆçœ‹ä¸˜å‰å°”çš„äººç‰©ä¼ è®°charçº§åˆ«çš„æ–‡æœ¬ç”Ÿæˆ</strong></p>
<p>ä¸¾ä¸ªå°å°çš„ä¾‹å­ï¼Œæ¥çœ‹çœ‹LSTMæ˜¯æ€ä¹ˆç©çš„</p>
<p>æˆ‘ä»¬è¿™é‡Œä¸å†ç”¨charçº§åˆ«ï¼Œæˆ‘ä»¬ç”¨wordçº§åˆ«æ¥åšã€‚æˆ‘ä»¬è¿™é‡Œçš„æ–‡æœ¬é¢„æµ‹å°±æ˜¯ï¼Œç»™äº†å‰é¢çš„å•è¯ä»¥åï¼Œä¸‹ä¸€ä¸ªå•è¯æ˜¯è°ï¼Ÿ</p>
<p>æ¯”å¦‚ï¼Œhello from the other, ç»™å‡º side</p>
<p>ç¬¬ä¸€æ­¥ï¼Œä¸€æ ·ï¼Œå…ˆå¯¼å…¥å„ç§åº“</p>
<h3 id="å¯¼å…¥æ•°æ®å¹¶åˆ†è¯"><a href="#å¯¼å…¥æ•°æ®å¹¶åˆ†è¯" class="headerlink" title="å¯¼å…¥æ•°æ®å¹¶åˆ†è¯"></a>å¯¼å…¥æ•°æ®å¹¶åˆ†è¯</h3><p>In [1]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dropout</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> LSTM</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ModelCheckpoint</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> gensim.models.word2vec <span class="keyword">import</span> Word2Vec</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Using TensorFlow backend.</span><br></pre></td></tr></table></figure>

<p>In [8]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># è¿è¡Œèµ„æºå……è¶³çš„å¯ä»¥è¯•è¯•ä¸‹é¢çš„ä»£ç </span></span><br><span class="line"><span class="comment"># raw_text = ''</span></span><br><span class="line"><span class="comment"># for file in os.listdir("./input/"):</span></span><br><span class="line"><span class="comment">#     # os.listdiråˆ—å‡ºè·¯å¾„ä¸‹çš„æ‰€æœ‰æ–‡ä»¶çš„åå­—</span></span><br><span class="line"><span class="comment">#     if file.endswith(".txt"): # å–å‡ºåç¼€.txtçš„æ–‡ä»¶</span></span><br><span class="line"><span class="comment">#         raw_text += open("./input/"+file, errors='ignore').read() + '\n\n'</span></span><br><span class="line">raw_text = open(<span class="string">'./input/Winston_Churchil.txt'</span>).read()</span><br><span class="line"><span class="comment"># æˆ‘ä»¬ä»ç”¨ä¸˜å‰å°”çš„è¯­æ–™ç”Ÿæˆæ–‡æœ¬</span></span><br><span class="line">raw_text = raw_text.lower()</span><br><span class="line">sentensor = nltk.data.load(<span class="string">'tokenizers/punkt/english.pickle'</span>)   </span><br><span class="line"><span class="comment"># åŠ è½½è‹±æ–‡çš„åˆ’åˆ†å¥å­çš„æ¨¡å‹</span></span><br><span class="line">sents = sentensor.tokenize(raw_text)</span><br><span class="line"><span class="comment"># .tokenizeå¯¹ä¸€æ®µæ–‡æœ¬è¿›è¡Œåˆ†å¥ï¼Œåˆ†æˆå„ä¸ªå¥å­ç»„æˆçš„åˆ—è¡¨ã€‚è¯¦è§£çœ‹ä¸‹è¿™ä¸ªåšå®¢ï¼Œè›®æœ‰æ„æ€çš„</span></span><br><span class="line"><span class="comment"># https://blog.csdn.net/ustbbsy/article/details/80053307</span></span><br><span class="line">print(sents[:<span class="number">2</span>])</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&apos;\ufeffproject gutenbergâ€™s real soldiers of fortune, by richard harding davis\n\nthis ebook is for the use of anyone anywhere at no cost and with\nalmost no restrictions whatsoever.&apos;, &apos;you may copy it, give it away or\nre-use it under the terms of the project gutenberg license included\nwith this ebook or online at www.gutenberg.org\n\n\ntitle: real soldiers of fortune\n\nauthor: richard harding davis\n\nposting date: february 22, 2009 [ebook #3029]\nlast updated: september 26, 2016\n\nlanguage: english\n\ncharacter set encoding: utf-8\n\n*** start of this project gutenberg ebook real soldiers of fortune ***\n\n\n\n\nproduced by david reed, and ronald j. wilson\n\n\n\n\n\nreal soldiers of fortune\n\n\nby richard harding davis\n\n\n\n\n\nmajor-general henry ronald douglas maciver\n\nany sunny afternoon, on fifth avenue, or at night in the _table dâ€™hote_\nrestaurants of university place, you may meet the soldier of fortune who\nof all his brothers in arms now living is the most remarkable.&apos;]</span><br></pre></td></tr></table></figure>

<p>In [9]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">corpus = []</span><br><span class="line"><span class="keyword">for</span> sen <span class="keyword">in</span> sents: <span class="comment"># é’ˆå¯¹æ¯ä¸ªå¥å­ï¼Œå†æ¬¡è¿›è¡Œåˆ†è¯ã€‚</span></span><br><span class="line">    corpus.append(nltk.word_tokenize(sen))</span><br><span class="line"></span><br><span class="line">print(len(corpus))</span><br><span class="line">print(corpus[:<span class="number">2</span>])</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1792</span><br><span class="line">[[&apos;\ufeffproject&apos;, &apos;gutenberg&apos;, &apos;â€™&apos;, &apos;s&apos;, &apos;real&apos;, &apos;soldiers&apos;, &apos;of&apos;, &apos;fortune&apos;, &apos;,&apos;, &apos;by&apos;, &apos;richard&apos;, &apos;harding&apos;, &apos;davis&apos;, &apos;this&apos;, &apos;ebook&apos;, &apos;is&apos;, &apos;for&apos;, &apos;the&apos;, &apos;use&apos;, &apos;of&apos;, &apos;anyone&apos;, &apos;anywhere&apos;, &apos;at&apos;, &apos;no&apos;, &apos;cost&apos;, &apos;and&apos;, &apos;with&apos;, &apos;almost&apos;, &apos;no&apos;, &apos;restrictions&apos;, &apos;whatsoever&apos;, &apos;.&apos;], [&apos;you&apos;, &apos;may&apos;, &apos;copy&apos;, &apos;it&apos;, &apos;,&apos;, &apos;give&apos;, &apos;it&apos;, &apos;away&apos;, &apos;or&apos;, &apos;re-use&apos;, &apos;it&apos;, &apos;under&apos;, &apos;the&apos;, &apos;terms&apos;, &apos;of&apos;, &apos;the&apos;, &apos;project&apos;, &apos;gutenberg&apos;, &apos;license&apos;, &apos;included&apos;, &apos;with&apos;, &apos;this&apos;, &apos;ebook&apos;, &apos;or&apos;, &apos;online&apos;, &apos;at&apos;, &apos;www.gutenberg.org&apos;, &apos;title&apos;, &apos;:&apos;, &apos;real&apos;, &apos;soldiers&apos;, &apos;of&apos;, &apos;fortune&apos;, &apos;author&apos;, &apos;:&apos;, &apos;richard&apos;, &apos;harding&apos;, &apos;davis&apos;, &apos;posting&apos;, &apos;date&apos;, &apos;:&apos;, &apos;february&apos;, &apos;22&apos;, &apos;,&apos;, &apos;2009&apos;, &apos;[&apos;, &apos;ebook&apos;, &apos;#&apos;, &apos;3029&apos;, &apos;]&apos;, &apos;last&apos;, &apos;updated&apos;, &apos;:&apos;, &apos;september&apos;, &apos;26&apos;, &apos;,&apos;, &apos;2016&apos;, &apos;language&apos;, &apos;:&apos;, &apos;english&apos;, &apos;character&apos;, &apos;set&apos;, &apos;encoding&apos;, &apos;:&apos;, &apos;utf-8&apos;, &apos;***&apos;, &apos;start&apos;, &apos;of&apos;, &apos;this&apos;, &apos;project&apos;, &apos;gutenberg&apos;, &apos;ebook&apos;, &apos;real&apos;, &apos;soldiers&apos;, &apos;of&apos;, &apos;fortune&apos;, &apos;***&apos;, &apos;produced&apos;, &apos;by&apos;, &apos;david&apos;, &apos;reed&apos;, &apos;,&apos;, &apos;and&apos;, &apos;ronald&apos;, &apos;j.&apos;, &apos;wilson&apos;, &apos;real&apos;, &apos;soldiers&apos;, &apos;of&apos;, &apos;fortune&apos;, &apos;by&apos;, &apos;richard&apos;, &apos;harding&apos;, &apos;davis&apos;, &apos;major-general&apos;, &apos;henry&apos;, &apos;ronald&apos;, &apos;douglas&apos;, &apos;maciver&apos;, &apos;any&apos;, &apos;sunny&apos;, &apos;afternoon&apos;, &apos;,&apos;, &apos;on&apos;, &apos;fifth&apos;, &apos;avenue&apos;, &apos;,&apos;, &apos;or&apos;, &apos;at&apos;, &apos;night&apos;, &apos;in&apos;, &apos;the&apos;, &apos;_table&apos;, &apos;d&apos;, &apos;â€™&apos;, &apos;hote_&apos;, &apos;restaurants&apos;, &apos;of&apos;, &apos;university&apos;, &apos;place&apos;, &apos;,&apos;, &apos;you&apos;, &apos;may&apos;, &apos;meet&apos;, &apos;the&apos;, &apos;soldier&apos;, &apos;of&apos;, &apos;fortune&apos;, &apos;who&apos;, &apos;of&apos;, &apos;all&apos;, &apos;his&apos;, &apos;brothers&apos;, &apos;in&apos;, &apos;arms&apos;, &apos;now&apos;, &apos;living&apos;, &apos;is&apos;, &apos;the&apos;, &apos;most&apos;, &apos;remarkable&apos;, &apos;.&apos;]]</span><br></pre></td></tr></table></figure>

<h1 id="word2vecç”Ÿæˆè¯å‘é‡"><a href="#word2vecç”Ÿæˆè¯å‘é‡" class="headerlink" title="word2vecç”Ÿæˆè¯å‘é‡"></a>word2vecç”Ÿæˆè¯å‘é‡</h1><p>In [45]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">w2v_model = Word2Vec(corpus, size=<span class="number">128</span>, window=<span class="number">5</span>, min_count=<span class="number">2</span>, workers=<span class="number">4</span>)</span><br><span class="line"><span class="comment"># Word2Vec()å‚æ•°çœ‹è¿™ä¸ªåšå®¢ï¼šhttps://www.cnblogs.com/pinard/p/7278324.html</span></span><br><span class="line"><span class="comment"># sizeï¼šè¯å‘é‡çš„ç»´åº¦</span></span><br><span class="line"><span class="comment"># windowï¼šå³è¯å‘é‡ä¸Šä¸‹æ–‡æœ€å¤§è·ç¦»ï¼Œwindowè¶Šå¤§ï¼Œåˆ™å’ŒæŸä¸€è¯è¾ƒè¿œçš„è¯ä¹Ÿä¼šäº§ç”Ÿä¸Šä¸‹æ–‡å…³ç³»ã€‚é»˜è®¤å€¼ä¸º5ã€‚</span></span><br><span class="line"><span class="comment"># min_countï¼šéœ€è¦è®¡ç®—è¯å‘é‡çš„æœ€å°è¯é¢‘ã€‚è¿™ä¸ªå€¼å¯ä»¥å»æ‰ä¸€äº›å¾ˆç”Ÿåƒ»çš„ä½é¢‘è¯ï¼Œé»˜è®¤æ˜¯5ã€‚å¦‚æœæ˜¯å°è¯­æ–™ï¼Œå¯ä»¥è°ƒä½è¿™ä¸ªå€¼ã€‚</span></span><br><span class="line"><span class="comment"># workersï¼šç”¨äºæ§åˆ¶è®­ç»ƒçš„å¹¶è¡Œæ•°ã€‚</span></span><br><span class="line"></span><br><span class="line">print(w2v_model[<span class="string">'office'</span>][:<span class="number">20</span>])</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[-0.03379476 -0.22743131 -0.17660786 -0.00957653 -0.10752155 -0.14298159</span><br><span class="line">  0.02914934 -0.08970737 -0.15872304 -0.05246524 -0.00084796 -0.05634443</span><br><span class="line"> -0.1461402   0.03880814 -0.12331649 -0.06511988 -0.08555544 -0.2300725</span><br><span class="line"> -0.0083805   0.02204316]</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/Users/yyg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).</span><br></pre></td></tr></table></figure>

<h3 id="æ„é€ è®­ç»ƒé›†"><a href="#æ„é€ è®­ç»ƒé›†" class="headerlink" title="æ„é€ è®­ç»ƒé›†"></a>æ„é€ è®­ç»ƒé›†</h3><p>In [46]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">raw_input = [item <span class="keyword">for</span> sublist <span class="keyword">in</span> corpus <span class="keyword">for</span> item <span class="keyword">in</span> sublist]</span><br><span class="line">print(len(raw_input)) <span class="comment"># åŸå§‹è¯­æ–™åº“é‡Œçš„è¯è¯­æ€»æ•°</span></span><br><span class="line">text_stream = []</span><br><span class="line">vocab = w2v_model.wv.vocab <span class="comment"># æŸ¥çœ‹w2v_modelç”Ÿæˆçš„è¯å‘é‡</span></span><br><span class="line"><span class="keyword">for</span> word <span class="keyword">in</span> raw_input:</span><br><span class="line">    <span class="keyword">if</span> word <span class="keyword">in</span> vocab:</span><br><span class="line">        text_stream.append(word)</span><br><span class="line">print(len(text_stream))  </span><br><span class="line"><span class="comment"># æŸ¥çœ‹å»æ‰ä½é¢‘è¯åçš„æ€»çš„è¯æ•°ï¼Œå› ä¸ºmin_countæŠŠä½é¢‘è¯å»æ‰äº†</span></span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">55562</span><br><span class="line">51876</span><br></pre></td></tr></table></figure>

<p>In [47]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å¤„ç†æ–¹å¼åŒcharçº§åˆ«çš„æ–‡æœ¬ç”Ÿæˆ</span></span><br><span class="line">seq_length = <span class="number">10</span> </span><br><span class="line">x = []</span><br><span class="line">y = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, len(text_stream) - seq_length):</span><br><span class="line">    given = text_stream[i:i + seq_length]</span><br><span class="line">    predict = text_stream[i + seq_length]</span><br><span class="line">    x.append([w2v_model[word] <span class="keyword">for</span> word <span class="keyword">in</span> given])</span><br><span class="line">    y.append(w2v_model[predict])</span><br><span class="line"></span><br><span class="line">x = np.reshape(x, (<span class="number">-1</span>, seq_length, <span class="number">128</span>))</span><br><span class="line">y = np.reshape(y, (<span class="number">-1</span>,<span class="number">128</span>))</span><br><span class="line">print(x.shape)</span><br><span class="line">print(y.shape)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/Users/yyg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).</span><br><span class="line">  </span><br><span class="line">/Users/yyg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).</span><br><span class="line">  if __name__ == &apos;__main__&apos;:</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(51866, 10, 128)</span><br><span class="line">(51866, 128)</span><br></pre></td></tr></table></figure>

<h3 id="æ„å»ºå’Œè®­ç»ƒæ¨¡å‹"><a href="#æ„å»ºå’Œè®­ç»ƒæ¨¡å‹" class="headerlink" title="æ„å»ºå’Œè®­ç»ƒæ¨¡å‹"></a>æ„å»ºå’Œè®­ç»ƒæ¨¡å‹</h3><p>In [53]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line">model.add(LSTM(<span class="number">256</span>, input_shape=(seq_length, <span class="number">128</span>),dropout=<span class="number">0.2</span>, recurrent_dropout=<span class="number">0.2</span>))</span><br><span class="line"><span class="comment"># ç¬¬ä¸€ä¸ªdropoutæ˜¯xå’Œhiddenä¹‹é—´çš„dropout</span></span><br><span class="line"><span class="comment"># ç¬¬äºŒä¸ªrecurrent_dropoutï¼Œè¿™é‡Œæˆ‘ç†è§£ä¸ºæ˜¯æ¨ªå‘ä¸åŒæ—¶åˆ»éšè—å±‚ä¹‹é—´çš„dropout</span></span><br><span class="line">model.add(Dropout(<span class="number">0.2</span>)) <span class="comment"># ç¬¬ä¸‰ä¸ªï¼Œè¿™é‡Œæˆ‘ç†è§£ä¸ºçºµå‘å±‚ä¸å±‚ä¹‹é—´çš„dropout</span></span><br><span class="line">model.add(Dense(<span class="number">128</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line">model.compile(loss=<span class="string">'mse'</span>, optimizer=<span class="string">'adam'</span>)</span><br><span class="line"><span class="comment"># æŸå¤±ç”¨çš„å‡æ–¹å·®æŸå¤±ï¼Œä¼˜åŒ–å™¨adam</span></span><br></pre></td></tr></table></figure>

<p>In [54]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.fit(x, y, nb_epoch=<span class="number">10</span>, batch_size=<span class="number">4096</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/Users/yyg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.</span><br><span class="line">  &quot;&quot;&quot;Entry point for launching an IPython kernel.</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Epoch 1/10</span><br><span class="line">51866/51866 [==============================] - 28s 539us/step - loss: 0.3177</span><br><span class="line">Epoch 2/10</span><br><span class="line">51866/51866 [==============================] - 28s 542us/step - loss: 0.1405</span><br><span class="line">Epoch 3/10</span><br><span class="line">51866/51866 [==============================] - 29s 560us/step - loss: 0.1329</span><br><span class="line">Epoch 4/10</span><br><span class="line">51866/51866 [==============================] - 30s 584us/step - loss: 0.1318</span><br><span class="line">Epoch 5/10</span><br><span class="line">51866/51866 [==============================] - 28s 548us/step - loss: 0.1313</span><br><span class="line">Epoch 6/10</span><br><span class="line">51866/51866 [==============================] - 30s 574us/step - loss: 0.1309</span><br><span class="line">Epoch 7/10</span><br><span class="line">51866/51866 [==============================] - 30s 570us/step - loss: 0.1306</span><br><span class="line">Epoch 8/10</span><br><span class="line">51866/51866 [==============================] - 29s 551us/step - loss: 0.1303</span><br><span class="line">Epoch 9/10</span><br><span class="line">51866/51866 [==============================] - 27s 524us/step - loss: 0.1299</span><br><span class="line">Epoch 10/10</span><br><span class="line">51866/51866 [==============================] - 27s 512us/step - loss: 0.1296</span><br></pre></td></tr></table></figure>

<p>Out[54]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;keras.callbacks.History at 0x1a32c9a2b0&gt;</span><br></pre></td></tr></table></figure>

<h3 id="é¢„æµ‹æ¨¡å‹"><a href="#é¢„æµ‹æ¨¡å‹" class="headerlink" title="é¢„æµ‹æ¨¡å‹"></a>é¢„æµ‹æ¨¡å‹</h3><p>In [55]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ä»£ç æ³¨é‡ŠåŒä¸˜å‰å°”çš„äººç‰©ä¼ è®°charçº§åˆ«çš„æ–‡æœ¬ç”Ÿæˆ</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_next</span><span class="params">(input_array)</span>:</span></span><br><span class="line">    x = np.reshape(input_array, (<span class="number">-1</span>,seq_length,<span class="number">128</span>))</span><br><span class="line">    y = model.predict(x)</span><br><span class="line">    <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">string_to_index</span><span class="params">(raw_input)</span>:</span></span><br><span class="line">    raw_input = raw_input.lower()</span><br><span class="line">    input_stream = nltk.word_tokenize(raw_input)</span><br><span class="line">    res = []</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> input_stream[(len(input_stream)-seq_length):]:</span><br><span class="line">        res.append(w2v_model[word])</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">y_to_word</span><span class="params">(y)</span>:</span></span><br><span class="line">    word = w2v_model.most_similar(positive=y, topn=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> word</span><br></pre></td></tr></table></figure>

<p>In [56]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_article</span><span class="params">(init, rounds=<span class="number">30</span>)</span>:</span></span><br><span class="line">    in_string = init.lower()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(rounds):</span><br><span class="line">        n = y_to_word(predict_next(string_to_index(in_string)))</span><br><span class="line">        in_string += <span class="string">' '</span> + n[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> in_string</span><br></pre></td></tr></table></figure>

<p>In [58]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">init = <span class="string">'His object in coming to New York was to engage officers for that service. He came at an  moment'</span></span><br><span class="line">article = generate_article(init)</span><br><span class="line">print(article) <span class="comment"># è¯­æ–™åº“è¾ƒå°ï¼Œå¯ä»¥çœ‹åˆ°é‡å¤äº†</span></span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/Users/yyg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).</span><br><span class="line">  if sys.path[0] == &apos;&apos;:</span><br><span class="line">/Users/yyg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).</span><br><span class="line">  app.launch_new_instance()</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">his object in coming to new york was to engage officers for that service. he came at an  moment battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery</span><br></pre></td></tr></table></figure>

<p>In [ ]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/NLP/">NLP</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LSTM/">LSTM</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
  
</article>










  
  
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
    </nav>
  
</div>
      <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
<footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                <i class="fa fa-copyright"></i> 
                2019-2020 MingmingYe
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank" title="å¿«é€Ÿã€ç®€æ´ä¸”é«˜æ•ˆçš„åšå®¢æ¡†æ¶">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="ç®€è€Œä¸å‡ Hexo åŒæ åšå®¢ä¸»é¢˜  v3.5">Yelee</a> by MOxFIVE <i class="fa fa-heart animated infinite pulse"></i>
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" title="æœ¬ç«™åˆ°è®¿æ•°"><i class="fa fa-user" aria-hidden="true"></i><span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>| </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit"  title="æœ¬é¡µé˜…è¯»é‡"><i class="fa fa-eye animated infinite pulse" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>

    </div>
    
<script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.2.0/require.min.js"></script>

    <script>
        $(document).ready(function() {
            var iPad = window.navigator.userAgent.indexOf('iPad');
            if (iPad > -1 || $(".left-col").css("display") === "none") {
                var bgColorList = ["#9db3f4", "#414141", "#e5a859", "#f5dfc6", "#c084a0", "#847e72", "#cd8390", "#996731"];
                var bgColor = Math.ceil(Math.random() * (bgColorList.length - 1));
                $("body").css({"background-color": bgColorList[bgColor], "background-size": "cover"});
            }
            else {
                var backgroundnum = 5;
                var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
                $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
            }
        })
    </script>





    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<div class="scroll" id="scroll">
    <a href="#" title="è¿”å›é¡¶éƒ¨"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" onclick="load$hide();" title="æŸ¥çœ‹è¯„è®º"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="è½¬åˆ°åº•éƒ¨"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    // Open in New Window
    
        var oOpenInNew = {
            
            
            
            
            
            
             archives: ".archive-article-title", 
             miniArchives: "a.post-list-link", 
            
             friends: "#js-friends a", 
             socail: ".social a" 
        }
        for (var x in oOpenInNew) {
            $(oOpenInNew[x]).attr("target", "_blank");
        }
    
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>
</body>
</html>