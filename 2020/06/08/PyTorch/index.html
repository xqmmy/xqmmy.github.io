<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">

    <!--[if lt IE 9]>
        <style>body {display: none; background: none !important} </style>
        <meta http-equiv="Refresh" Content="0; url=//outdatedbrowser.com/" />
    <![endif]-->

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="format-detection" content="telephone=no">
<meta name="author" content="MingmingYe">



<meta name="description" content="ä»€ä¹ˆæ˜¯PyTorch?PyTorchæ˜¯ä¸€ä¸ªåŸºäºPythonçš„ç§‘å­¦è®¡ç®—åº“ï¼Œå®ƒæœ‰ä»¥ä¸‹ç‰¹ç‚¹:  ç±»ä¼¼äºNumPyï¼Œä½†æ˜¯å®ƒå¯ä»¥ä½¿ç”¨GPU å¯ä»¥ç”¨å®ƒå®šä¹‰æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå¯ä»¥çµæ´»åœ°è¿›è¡Œæ·±åº¦å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒå’Œä½¿ç”¨  TensorsTensorç±»ä¼¼ä¸NumPyçš„ndarrayï¼Œå”¯ä¸€çš„åŒºåˆ«æ˜¯Tensorå¯ä»¥åœ¨GPUä¸ŠåŠ é€Ÿè¿ç®—ã€‚ In [2]: 1import torch  æ„é€ ä¸€ä¸ªæœªåˆå§‹åŒ–çš„5x3çŸ©é˜µ: In [4]:">
<meta name="keywords" content="PyTorch">
<meta property="og:type" content="article">
<meta property="og:title" content="PyTorch">
<meta property="og:url" content="http://mmyblog.cn/2020/06/08/PyTorch/index.html">
<meta property="og:site_name" content="Stay hungry, Stay foolish.">
<meta property="og:description" content="ä»€ä¹ˆæ˜¯PyTorch?PyTorchæ˜¯ä¸€ä¸ªåŸºäºPythonçš„ç§‘å­¦è®¡ç®—åº“ï¼Œå®ƒæœ‰ä»¥ä¸‹ç‰¹ç‚¹:  ç±»ä¼¼äºNumPyï¼Œä½†æ˜¯å®ƒå¯ä»¥ä½¿ç”¨GPU å¯ä»¥ç”¨å®ƒå®šä¹‰æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå¯ä»¥çµæ´»åœ°è¿›è¡Œæ·±åº¦å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒå’Œä½¿ç”¨  TensorsTensorç±»ä¼¼ä¸NumPyçš„ndarrayï¼Œå”¯ä¸€çš„åŒºåˆ«æ˜¯Tensorå¯ä»¥åœ¨GPUä¸ŠåŠ é€Ÿè¿ç®—ã€‚ In [2]: 1import torch  æ„é€ ä¸€ä¸ªæœªåˆå§‹åŒ–çš„5x3çŸ©é˜µ: In [4]:">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2020-06-09T01:28:17.998Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="PyTorch">
<meta name="twitter:description" content="ä»€ä¹ˆæ˜¯PyTorch?PyTorchæ˜¯ä¸€ä¸ªåŸºäºPythonçš„ç§‘å­¦è®¡ç®—åº“ï¼Œå®ƒæœ‰ä»¥ä¸‹ç‰¹ç‚¹:  ç±»ä¼¼äºNumPyï¼Œä½†æ˜¯å®ƒå¯ä»¥ä½¿ç”¨GPU å¯ä»¥ç”¨å®ƒå®šä¹‰æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå¯ä»¥çµæ´»åœ°è¿›è¡Œæ·±åº¦å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒå’Œä½¿ç”¨  TensorsTensorç±»ä¼¼ä¸NumPyçš„ndarrayï¼Œå”¯ä¸€çš„åŒºåˆ«æ˜¯Tensorå¯ä»¥åœ¨GPUä¸ŠåŠ é€Ÿè¿ç®—ã€‚ In [2]: 1import torch  æ„é€ ä¸€ä¸ªæœªåˆå§‹åŒ–çš„5x3çŸ©é˜µ: In [4]:">

<link rel="apple-touch-icon" href="/apple-touch-icon.png">


    <link rel="alternate" href="/atom.xml" title="Stay hungry, Stay foolish." type="application/atom+xml">



    <link rel="shortcut icon" href="/favicon.png">



    <link href="//cdn.bootcss.com/animate.css/3.5.1/animate.min.css" rel="stylesheet">



    <link href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet">



    <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
    <link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-minimal.css" rel="stylesheet">


<link rel="stylesheet" href="/css/style.css">



<link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">


<title>PyTorch | Stay hungry, Stay foolish.</title>

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

<script>
    var yiliaConfig = {
        fancybox: true,
        animate: true,
        isHome: false,
        isPost: true,
        isArchive: false,
        isTag: false,
        isCategory: false,
        fancybox_js: "//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js",
        scrollreveal: "//cdn.bootcss.com/scrollReveal.js/3.1.4/scrollreveal.min.js",
        search: true
    }
</script>


    <script>
        yiliaConfig.jquery_ui = [true, "//cdn.bootcss.com/jqueryui/1.10.4/jquery-ui.min.js", "//cdn.bootcss.com/jqueryui/1.10.4/css/jquery-ui.min.css"];
    </script>



    <script> yiliaConfig.rootUrl = "\/";</script>






</head></html>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            <img src="/img/deep.png" class="animated zoomIn">
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">MingmingYe</a></h1>
        </hgroup>

        
        <p class="header-subtitle">å½“ä½ çš„æ‰åæ’‘ä¸èµ·ä½ çš„é‡å¿ƒæ—¶ï¼Œåªæœ‰é™ä¸‹å¿ƒæ¥å¥½å¥½å­¦ä¹ ï¼çºµä½¿å‘½è¿æ³¨å®šæ˜¯ä¸ªæ‰“é…±æ²¹çš„ï¼Œä¹Ÿè¦æ‰“ä¸€ç“¶ä¸åˆ«äººä¸ä¸€æ ·çš„é…±æ²¹ï¼</p>
        

        
            <form id="search-form">
            <input type="text" id="local-search-input" name="q" placeholder="search..." class="search form-control" autocomplete="off" autocorrect="off" searchonload="false" />
            <i class="fa fa-times" onclick="resetSearch()"></i>
            </form>
            <div id="local-search-result"></div>
            <p class='no-result'>No results found <i class='fa fa-spinner fa-pulse'></i></p>
        


        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>èœå•</li>
                        <li>æ ‡ç­¾</li>
                        
                        <li>å‹æƒ…é“¾æ¥</li>
                        
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/">ä¸»é¡µ</a></li>
                        
                            <li><a href="/archives/">æ‰€æœ‰æ–‡ç« </a></li>
                        
                            <li><a href="/tags/">æ ‡ç­¾äº‘</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" href="mailto:878759487@qq.com" title="Email"></a>
                            
                                <a class="fa GitHub" href="#" title="GitHub"></a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/AUC/">AUC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Attention/">Attention</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BERT/">BERT</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BLUE/">BLUE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Beam-search/">Beam search</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN/">CNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CRF/">CRF</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ConvNet/">ConvNet</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ELMo/">ELMo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GPT/">GPT</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GRU/">GRU</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Gradient-Clipping/">Gradient Clipping</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LR/">LR</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LSTM/">LSTM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linear/">Linear</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Parsing/">Parsing</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PyTorch/">PyTorch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/QA/">QA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RNN/">RNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RNN-LSTM/">RNN/LSTM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ROC/">ROC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Recursive-Neural-Networks/">Recursive Neural Networks</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SQuAD-BiDAF/">SQuAD-BiDAF</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SVM/">SVM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Seq2Seq/">Seq2Seq</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TorchText/">TorchText</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Transformer/">Transformer</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Transformer-XL/">Transformer-XL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/XLNet/">XLNet</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/boosting/">boosting</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cbow/">cbow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hierarchical-softmax/">hierarchical softmax</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/inference/">inference</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/jiaba/">jiaba</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/jieba/">jieba</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mumpy/">mumpy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/negative-sampling/">negative sampling</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pandas/">pandas</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pyspark/">pyspark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/seaborn/">seaborn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/skip-gram/">skip-gram</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/softmax/">softmax</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/word-embedding/">word-embedding</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/wxBot/">wxBot</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ä¸­æ–‡åˆ†è¯/">ä¸­æ–‡åˆ†è¯</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ä¼˜åŒ–æ–¹æ³•/">ä¼˜åŒ–æ–¹æ³•</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/å†³ç­–æ ‘/">å†³ç­–æ ‘</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/å›¾ç¥ç»ç½‘ç»œ/">å›¾ç¥ç»ç½‘ç»œ</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/å¾®ç§¯åˆ†/">å¾®ç§¯åˆ†</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/æœ´ç´ è´å¶æ–¯/">æœ´ç´ è´å¶æ–¯</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/æœºå™¨å­¦ä¹ /">æœºå™¨å­¦ä¹ </a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/æ¦‚ç‡/">æ¦‚ç‡</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/æ¨¡å‹è°ƒä¼˜/">æ¨¡å‹è°ƒä¼˜</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/æ­£åˆ™è¡¨è¾¾å¼/">æ­£åˆ™è¡¨è¾¾å¼</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/æ·±åº¦å­¦ä¹ é€ŸæŸ¥è¡¨/">æ·±åº¦å­¦ä¹ é€ŸæŸ¥è¡¨</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ç‰¹å¾å·¥ç¨‹/">ç‰¹å¾å·¥ç¨‹</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ç®—æ³•/">ç®—æ³•</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/çº¿æ€§ä»£æ•°/">çº¿æ€§ä»£æ•°</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ç»Ÿè®¡/">ç»Ÿè®¡</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/èŠå¤©æœºå™¨äºº/">èŠå¤©æœºå™¨äºº</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/èšç±»/">èšç±»</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/è¯­è¨€æ¨¡å‹/">è¯­è¨€æ¨¡å‹</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/è´å¶æ–¯åˆ†ç±»å™¨/">è´å¶æ–¯åˆ†ç±»å™¨</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/é™ç»´/">é™ç»´</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/é›†æˆå­¦ä¹ /">é›†æˆå­¦ä¹ </a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/é¢è¯•/">é¢è¯•</a></li></ul>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a class="main-nav-link switch-friends-link" href="https://hexo.io">Hexo</a>
                    
                      <a class="main-nav-link switch-friends-link" href="https://pages.github.com/">GitHub</a>
                    
                      <a class="main-nav-link switch-friends-link" href="http://mmyblog.cn/">mmy</a>
                    
                    </div>
                </section>
                

                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="å›åˆ°ä¸»é¡µ">MingmingYe</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                <img src="/img/deep.png" class="animated zoomIn">
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="å›åˆ°ä¸»é¡µ">MingmingYe</a></h1>
            </hgroup>
            
            <p class="header-subtitle">å½“ä½ çš„æ‰åæ’‘ä¸èµ·ä½ çš„é‡å¿ƒæ—¶ï¼Œåªæœ‰é™ä¸‹å¿ƒæ¥å¥½å¥½å­¦ä¹ ï¼çºµä½¿å‘½è¿æ³¨å®šæ˜¯ä¸ªæ‰“é…±æ²¹çš„ï¼Œä¹Ÿè¦æ‰“ä¸€ç“¶ä¸åˆ«äººä¸ä¸€æ ·çš„é…±æ²¹ï¼</p>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/">ä¸»é¡µ</a></li>
                
                    <li><a href="/archives/">æ‰€æœ‰æ–‡ç« </a></li>
                
                    <li><a href="/tags/">æ ‡ç­¾äº‘</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" target="_blank" href="mailto:878759487@qq.com" title="Email"></a>
                            
                                <a class="fa GitHub" target="_blank" href="#" title="GitHub"></a>
                            
                        </ul>
            </nav>
        </header>                
    </div>
    <link class="menu-list" tags="æ ‡ç­¾" friends="å‹æƒ…é“¾æ¥" about="å…³äºæˆ‘"/>
</nav>
      <div class="body-wrap"><article id="post-PyTorch" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/06/08/PyTorch/" class="article-date">
      <time datetime="2020-06-08T11:12:06.000Z" itemprop="datePublished">2020-06-08</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      PyTorch
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/æœºå™¨å­¦ä¹ /">æœºå™¨å­¦ä¹ </a>
    </div>


        
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/PyTorch/">PyTorch</a></li></ul>
    </div>

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="ä»€ä¹ˆæ˜¯PyTorch"><a href="#ä»€ä¹ˆæ˜¯PyTorch" class="headerlink" title="ä»€ä¹ˆæ˜¯PyTorch?"></a>ä»€ä¹ˆæ˜¯PyTorch?</h1><p>PyTorchæ˜¯ä¸€ä¸ªåŸºäºPythonçš„ç§‘å­¦è®¡ç®—åº“ï¼Œå®ƒæœ‰ä»¥ä¸‹ç‰¹ç‚¹:</p>
<ul>
<li>ç±»ä¼¼äºNumPyï¼Œä½†æ˜¯å®ƒå¯ä»¥ä½¿ç”¨GPU</li>
<li>å¯ä»¥ç”¨å®ƒå®šä¹‰æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå¯ä»¥çµæ´»åœ°è¿›è¡Œæ·±åº¦å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒå’Œä½¿ç”¨</li>
</ul>
<h2 id="Tensors"><a href="#Tensors" class="headerlink" title="Tensors"></a>Tensors</h2><p>Tensorç±»ä¼¼ä¸NumPyçš„ndarrayï¼Œå”¯ä¸€çš„åŒºåˆ«æ˜¯Tensorå¯ä»¥åœ¨GPUä¸ŠåŠ é€Ÿè¿ç®—ã€‚</p>
<p>In [2]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br></pre></td></tr></table></figure>

<p>æ„é€ ä¸€ä¸ªæœªåˆå§‹åŒ–çš„5x3çŸ©é˜µ:</p>
<p>In [4]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.empty(5,3)</span><br><span class="line">x</span><br></pre></td></tr></table></figure>

<p>Out[4]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 0.0000e+00, -8.5899e+09,  0.0000e+00],</span><br><span class="line">        [-8.5899e+09,         nan,  0.0000e+00],</span><br><span class="line">        [ 2.7002e-06,  1.8119e+02,  1.2141e+01],</span><br><span class="line">        [ 7.8503e+02,  6.7504e-07,  6.5200e-10],</span><br><span class="line">        [ 2.9537e-06,  1.7186e-04,         nan]])</span><br></pre></td></tr></table></figure>

<p>æ„å»ºä¸€ä¸ªéšæœºåˆå§‹åŒ–çš„çŸ©é˜µ:</p>
<p>In [5]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.rand(5,3)</span><br><span class="line">x</span><br></pre></td></tr></table></figure>

<p>Out[5]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0.4628, 0.7432, 0.9785],</span><br><span class="line">        [0.2068, 0.4441, 0.9176],</span><br><span class="line">        [0.1027, 0.5275, 0.3884],</span><br><span class="line">        [0.9380, 0.2113, 0.2839],</span><br><span class="line">        [0.0094, 0.4001, 0.6483]])</span><br></pre></td></tr></table></figure>

<p>æ„å»ºä¸€ä¸ªå…¨éƒ¨ä¸º0ï¼Œç±»å‹ä¸ºlongçš„çŸ©é˜µ:</p>
<p>In [8]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.zeros(5,3,dtype=torch.long)</span><br><span class="line">x</span><br></pre></td></tr></table></figure>

<p>Out[8]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0, 0, 0],</span><br><span class="line">        [0, 0, 0],</span><br><span class="line">        [0, 0, 0],</span><br><span class="line">        [0, 0, 0],</span><br><span class="line">        [0, 0, 0]])</span><br></pre></td></tr></table></figure>

<p>In [11]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.zeros(5,3).long()</span><br><span class="line">x.dtype</span><br></pre></td></tr></table></figure>

<p>Out[11]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.int64</span><br></pre></td></tr></table></figure>

<p>ä»æ•°æ®ç›´æ¥ç›´æ¥æ„å»ºtensor:</p>
<p>In [12]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([5.5,3])</span><br><span class="line">x</span><br></pre></td></tr></table></figure>

<p>Out[12]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([5.5000, 3.0000])</span><br></pre></td></tr></table></figure>

<p>ä¹Ÿå¯ä»¥ä»ä¸€ä¸ªå·²æœ‰çš„tensoræ„å»ºä¸€ä¸ªtensorã€‚è¿™äº›æ–¹æ³•ä¼šé‡ç”¨åŸæ¥tensorçš„ç‰¹å¾ï¼Œä¾‹å¦‚ï¼Œæ•°æ®ç±»å‹ï¼Œé™¤éæä¾›æ–°çš„æ•°æ®ã€‚</p>
<p>In [16]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = x.new_ones(5,3, dtype=torch.double)</span><br><span class="line">x</span><br></pre></td></tr></table></figure>

<p>Out[16]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[1., 1., 1.],</span><br><span class="line">        [1., 1., 1.],</span><br><span class="line">        [1., 1., 1.],</span><br><span class="line">        [1., 1., 1.],</span><br><span class="line">        [1., 1., 1.]], dtype=torch.float64)</span><br></pre></td></tr></table></figure>

<p>In [17]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn_like(x, dtype=torch.float)</span><br><span class="line">x</span><br></pre></td></tr></table></figure>

<p>Out[17]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 0.2411, -0.3961, -0.9206],</span><br><span class="line">        [-0.0508,  0.2653,  0.4685],</span><br><span class="line">        [ 0.5368, -0.3606, -0.0073],</span><br><span class="line">        [ 0.3383,  0.6826,  1.7368],</span><br><span class="line">        [-0.0811, -0.6957, -0.4566]])</span><br></pre></td></tr></table></figure>

<p>å¾—åˆ°tensorçš„å½¢çŠ¶:</p>
<p>In [20]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x.shape</span><br></pre></td></tr></table></figure>

<p>Out[20]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([5, 3])</span><br></pre></td></tr></table></figure>

<h4 id="æ³¨æ„"><a href="#æ³¨æ„" class="headerlink" title="æ³¨æ„"></a>æ³¨æ„</h4><p><code>torch.Size</code> è¿”å›çš„æ˜¯ä¸€ä¸ªtuple</p>
<p>Operations</p>
<p>æœ‰å¾ˆå¤šç§tensorè¿ç®—ã€‚æˆ‘ä»¬å…ˆä»‹ç»åŠ æ³•è¿ç®—ã€‚</p>
<p>In [21]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y = torch.rand(5,3)</span><br><span class="line">y</span><br></pre></td></tr></table></figure>

<p>Out[21]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0.9456, 0.3996, 0.1981],</span><br><span class="line">        [0.8728, 0.7097, 0.3721],</span><br><span class="line">        [0.7489, 0.9502, 0.6241],</span><br><span class="line">        [0.5176, 0.0200, 0.5130],</span><br><span class="line">        [0.3552, 0.2710, 0.7392]])</span><br></pre></td></tr></table></figure>

<p>In [23]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x + y</span><br></pre></td></tr></table></figure>

<p>Out[23]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 1.1866,  0.0035, -0.7225],</span><br><span class="line">        [ 0.8220,  0.9750,  0.8406],</span><br><span class="line">        [ 1.2857,  0.5896,  0.6168],</span><br><span class="line">        [ 0.8559,  0.7026,  2.2498],</span><br><span class="line">        [ 0.2741, -0.4248,  0.2826]])</span><br></pre></td></tr></table></figure>

<p>å¦ä¸€ç§ç€åŠ æ³•çš„å†™æ³•</p>
<p>In [24]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.add(x, y)</span><br></pre></td></tr></table></figure>

<p>Out[24]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 1.1866,  0.0035, -0.7225],</span><br><span class="line">        [ 0.8220,  0.9750,  0.8406],</span><br><span class="line">        [ 1.2857,  0.5896,  0.6168],</span><br><span class="line">        [ 0.8559,  0.7026,  2.2498],</span><br><span class="line">        [ 0.2741, -0.4248,  0.2826]])</span><br></pre></td></tr></table></figure>

<p>åŠ æ³•ï¼šæŠŠè¾“å‡ºä½œä¸ºä¸€ä¸ªå˜é‡</p>
<p>In [26]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">result = torch.empty(5,3)</span><br><span class="line">torch.add(x, y, out=result)</span><br><span class="line"># result = x + y</span><br><span class="line">result</span><br></pre></td></tr></table></figure>

<p>Out[26]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 1.1866,  0.0035, -0.7225],</span><br><span class="line">        [ 0.8220,  0.9750,  0.8406],</span><br><span class="line">        [ 1.2857,  0.5896,  0.6168],</span><br><span class="line">        [ 0.8559,  0.7026,  2.2498],</span><br><span class="line">        [ 0.2741, -0.4248,  0.2826]])</span><br></pre></td></tr></table></figure>

<p>in-placeåŠ æ³•</p>
<p>In [28]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y.add_(x)</span><br><span class="line">y</span><br></pre></td></tr></table></figure>

<p>Out[28]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 1.1866,  0.0035, -0.7225],</span><br><span class="line">        [ 0.8220,  0.9750,  0.8406],</span><br><span class="line">        [ 1.2857,  0.5896,  0.6168],</span><br><span class="line">        [ 0.8559,  0.7026,  2.2498],</span><br><span class="line">        [ 0.2741, -0.4248,  0.2826]])</span><br></pre></td></tr></table></figure>

<h4 id="æ³¨æ„-1"><a href="#æ³¨æ„-1" class="headerlink" title="æ³¨æ„"></a>æ³¨æ„</h4><p>ä»»ä½•in-placeçš„è¿ç®—éƒ½ä¼šä»¥<code>_</code>ç»“å°¾ã€‚ ä¸¾ä¾‹æ¥è¯´ï¼š<code>x.copy_(y)</code>, <code>x.t_()</code>, ä¼šæ”¹å˜ <code>x</code>ã€‚</p>
<p>å„ç§ç±»ä¼¼NumPyçš„indexingéƒ½å¯ä»¥åœ¨PyTorch tensorä¸Šé¢ä½¿ç”¨ã€‚</p>
<p>In [31]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x[1:, 1:]</span><br></pre></td></tr></table></figure>

<p>Out[31]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 0.2653,  0.4685],</span><br><span class="line">        [-0.3606, -0.0073],</span><br><span class="line">        [ 0.6826,  1.7368],</span><br><span class="line">        [-0.6957, -0.4566]])</span><br></pre></td></tr></table></figure>

<p>Resizing: å¦‚æœä½ å¸Œæœ›resize/reshapeä¸€ä¸ªtensorï¼Œå¯ä»¥ä½¿ç”¨<code>torch.view</code>ï¼š</p>
<p>In [39]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(4,4)</span><br><span class="line">y = x.view(16)</span><br><span class="line">z = x.view(-1,8)</span><br><span class="line">z</span><br></pre></td></tr></table></figure>

<p>Out[39]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([[-0.5683,  1.3885, -2.0829, -0.7613, -1.9115,  0.3732, -0.2055, -1.2300],</span><br><span class="line">        [-0.2612, -0.4682, -1.0596,  0.7447,  0.7603, -0.4281,  0.5495,  0.1025]])</span><br></pre></td></tr></table></figure>

<p>å¦‚æœä½ æœ‰ä¸€ä¸ªåªæœ‰ä¸€ä¸ªå…ƒç´ çš„tensorï¼Œä½¿ç”¨<code>.item()</code>æ–¹æ³•å¯ä»¥æŠŠé‡Œé¢çš„valueå˜æˆPythonæ•°å€¼ã€‚</p>
<p>In [40]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(1)</span><br><span class="line">x</span><br></pre></td></tr></table></figure>

<p>Out[40]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([-1.1493])</span><br></pre></td></tr></table></figure>

<p>In [44]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x.item()</span><br></pre></td></tr></table></figure>

<p>Out[44]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-1.1493233442306519</span><br></pre></td></tr></table></figure>

<p>In [48]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">z.transpose(1,0)</span><br></pre></td></tr></table></figure>

<p>Out[48]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tensor([[-0.5683, -0.2612],</span><br><span class="line">        [ 1.3885, -0.4682],</span><br><span class="line">        [-2.0829, -1.0596],</span><br><span class="line">        [-0.7613,  0.7447],</span><br><span class="line">        [-1.9115,  0.7603],</span><br><span class="line">        [ 0.3732, -0.4281],</span><br><span class="line">        [-0.2055,  0.5495],</span><br><span class="line">        [-1.2300,  0.1025]])</span><br></pre></td></tr></table></figure>

<p><strong>æ›´å¤šé˜…è¯»</strong></p>
<p>å„ç§Tensor operations, åŒ…æ‹¬transposing, indexing, slicing, mathematical operations, linear algebra, random numbersåœ¨<code>&lt;https://pytorch.org/docs/torch&gt;</code>.</p>
<h2 id="Numpyå’ŒTensorä¹‹é—´çš„è½¬åŒ–"><a href="#Numpyå’ŒTensorä¹‹é—´çš„è½¬åŒ–" class="headerlink" title="Numpyå’ŒTensorä¹‹é—´çš„è½¬åŒ–"></a>Numpyå’ŒTensorä¹‹é—´çš„è½¬åŒ–</h2><p>åœ¨Torch Tensorå’ŒNumPy arrayä¹‹é—´ç›¸äº’è½¬åŒ–éå¸¸å®¹æ˜“ã€‚</p>
<p>Torch Tensorå’ŒNumPy arrayä¼šå…±äº«å†…å­˜ï¼Œæ‰€ä»¥æ”¹å˜å…¶ä¸­ä¸€é¡¹ä¹Ÿä¼šæ”¹å˜å¦ä¸€é¡¹ã€‚</p>
<p>æŠŠTorch Tensorè½¬å˜æˆNumPy Array</p>
<p>In [49]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = torch.ones(5)</span><br><span class="line">a</span><br></pre></td></tr></table></figure>

<p>Out[49]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([1., 1., 1., 1., 1.])</span><br></pre></td></tr></table></figure>

<p>In [50]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">b = a.numpy()</span><br><span class="line">b</span><br></pre></td></tr></table></figure>

<p>Out[50]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([1., 1., 1., 1., 1.], dtype=float32)</span><br></pre></td></tr></table></figure>

<p>æ”¹å˜numpy arrayé‡Œé¢çš„å€¼ã€‚</p>
<p>In [51]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">b[1] = 2</span><br><span class="line">b</span><br></pre></td></tr></table></figure>

<p>Out[51]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([1., 2., 1., 1., 1.], dtype=float32)</span><br></pre></td></tr></table></figure>

<p>In [52]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a</span><br></pre></td></tr></table></figure>

<p>Out[52]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([1., 2., 1., 1., 1.])</span><br></pre></td></tr></table></figure>

<p>æŠŠNumPy ndarrayè½¬æˆTorch Tensor</p>
<p>In [54]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br></pre></td></tr></table></figure>

<p>In [55]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = np.ones(5)</span><br><span class="line">b = torch.from_numpy(a)</span><br><span class="line">np.add(a, 1, out=a)</span><br><span class="line">print(a)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[2. 2. 2. 2. 2.]</span><br></pre></td></tr></table></figure>

<p>In [56]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">b</span><br></pre></td></tr></table></figure>

<p>Out[56]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([2., 2., 2., 2., 2.], dtype=torch.float64)</span><br></pre></td></tr></table></figure>

<p>æ‰€æœ‰CPUä¸Šçš„Tensoréƒ½æ”¯æŒè½¬æˆnumpyæˆ–è€…ä»numpyè½¬æˆTensorã€‚</p>
<h2 id="CUDA-Tensors"><a href="#CUDA-Tensors" class="headerlink" title="CUDA Tensors"></a>CUDA Tensors</h2><p>ä½¿ç”¨<code>.to</code>æ–¹æ³•ï¼ŒTensorå¯ä»¥è¢«ç§»åŠ¨åˆ°åˆ«çš„deviceä¸Šã€‚</p>
<p>In [60]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    device = torch.device(<span class="string">"cuda"</span>)</span><br><span class="line">    y = torch.ones_like(x, device=device)</span><br><span class="line">    x = x.to(device)</span><br><span class="line">    z = x + y</span><br><span class="line">    print(z)</span><br><span class="line">    print(z.to(<span class="string">"cpu"</span>, torch.double))</span><br></pre></td></tr></table></figure>

<p>Out[60]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">False</span><br></pre></td></tr></table></figure>

<p>In [ ]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y.to(<span class="string">"cpu"</span>).data.numpy()</span><br><span class="line">y.cpu().data.numpy()</span><br></pre></td></tr></table></figure>

<p>In [ ]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = model.cuda()</span><br></pre></td></tr></table></figure>

<h2 id="çƒ­èº«-ç”¨numpyå®ç°ä¸¤å±‚ç¥ç»ç½‘ç»œ"><a href="#çƒ­èº«-ç”¨numpyå®ç°ä¸¤å±‚ç¥ç»ç½‘ç»œ" class="headerlink" title="çƒ­èº«: ç”¨numpyå®ç°ä¸¤å±‚ç¥ç»ç½‘ç»œ"></a>çƒ­èº«: ç”¨numpyå®ç°ä¸¤å±‚ç¥ç»ç½‘ç»œ</h2><p>ä¸€ä¸ªå…¨è¿æ¥ReLUç¥ç»ç½‘ç»œï¼Œä¸€ä¸ªéšè—å±‚ï¼Œæ²¡æœ‰biasã€‚ç”¨æ¥ä»xé¢„æµ‹yï¼Œä½¿ç”¨L2 Lossã€‚</p>
<ul>
<li>â„=ğ‘Š1ğ‘‹h=W1X</li>
<li>ğ‘=ğ‘šğ‘ğ‘¥(0,â„)a=max(0,h)</li>
<li>ğ‘¦â„ğ‘ğ‘¡=ğ‘Š2ğ‘yhat=W2a</li>
</ul>
<p>è¿™ä¸€å®ç°å®Œå…¨ä½¿ç”¨numpyæ¥è®¡ç®—å‰å‘ç¥ç»ç½‘ç»œï¼Œlossï¼Œå’Œåå‘ä¼ æ’­ã€‚</p>
<ul>
<li>forward pass</li>
<li>loss</li>
<li>backward pass</li>
</ul>
<p>numpy ndarrayæ˜¯ä¸€ä¸ªæ™®é€šçš„nç»´arrayã€‚å®ƒä¸çŸ¥é“ä»»ä½•å…³äºæ·±åº¦å­¦ä¹ æˆ–è€…æ¢¯åº¦(gradient)çš„çŸ¥è¯†ï¼Œä¹Ÿä¸çŸ¥é“è®¡ç®—å›¾(computation graph)ï¼Œåªæ˜¯ä¸€ç§ç”¨æ¥è®¡ç®—æ•°å­¦è¿ç®—çš„æ•°æ®ç»“æ„ã€‚</p>
<p>In [ ]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># éšæœºåˆ›å»ºä¸€äº›è®­ç»ƒæ•°æ®</span></span><br><span class="line">x = np.random.randn(N, D_in)</span><br><span class="line">y = np.random.randn(N, D_out)</span><br><span class="line"></span><br><span class="line">w1 = np.random.randn(D_in, H)</span><br><span class="line">w2 = np.random.randn(H, D_out)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass</span></span><br><span class="line">    h = x.dot(w1) <span class="comment"># N * H</span></span><br><span class="line">    h_relu = np.maximum(h, <span class="number">0</span>) <span class="comment"># N * H</span></span><br><span class="line">    y_pred = h_relu.dot(w2) <span class="comment"># N * D_out</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute loss</span></span><br><span class="line">    loss = np.square(y_pred - y).sum()</span><br><span class="line">    print(it, loss)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Backward pass</span></span><br><span class="line">    <span class="comment"># compute the gradient</span></span><br><span class="line">    grad_y_pred = <span class="number">2.0</span> * (y_pred - y)</span><br><span class="line">    grad_w2 = h_relu.T.dot(grad_y_pred)</span><br><span class="line">    grad_h_relu = grad_y_pred.dot(w2.T)</span><br><span class="line">    grad_h = grad_h_relu.copy()</span><br><span class="line">    grad_h[h&lt;<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    grad_w1 = x.T.dot(grad_h)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># update weights of w1 and w2</span></span><br><span class="line">    w1 -= learning_rate * grad_w1</span><br><span class="line">    w2 -= learning_rate * grad_w2</span><br></pre></td></tr></table></figure>

<h2 id="PyTorch-Tensors"><a href="#PyTorch-Tensors" class="headerlink" title="PyTorch: Tensors"></a>PyTorch: Tensors</h2><p>è¿™æ¬¡æˆ‘ä»¬ä½¿ç”¨PyTorch tensorsæ¥åˆ›å»ºå‰å‘ç¥ç»ç½‘ç»œï¼Œè®¡ç®—æŸå¤±ï¼Œä»¥åŠåå‘ä¼ æ’­ã€‚</p>
<p>ä¸€ä¸ªPyTorch Tensorå¾ˆåƒä¸€ä¸ªnumpyçš„ndarrayã€‚ä½†æ˜¯å®ƒå’Œnumpy ndarrayæœ€å¤§çš„åŒºåˆ«æ˜¯ï¼ŒPyTorch Tensorå¯ä»¥åœ¨CPUæˆ–è€…GPUä¸Šè¿ç®—ã€‚å¦‚æœæƒ³è¦åœ¨GPUä¸Šè¿ç®—ï¼Œå°±éœ€è¦æŠŠTensoræ¢æˆcudaç±»å‹ã€‚</p>
<p>In [ ]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># éšæœºåˆ›å»ºä¸€äº›è®­ç»ƒæ•°æ®</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line">w1 = torch.randn(D_in, H)</span><br><span class="line">w2 = torch.randn(H, D_out)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass</span></span><br><span class="line">    h = x.mm(w1) <span class="comment"># N * H</span></span><br><span class="line">    h_relu = h.clamp(min=<span class="number">0</span>) <span class="comment"># N * H</span></span><br><span class="line">    y_pred = h_relu.mm(w2) <span class="comment"># N * D_out</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute loss</span></span><br><span class="line">    loss = (y_pred - y).pow(<span class="number">2</span>).sum().item()</span><br><span class="line">    print(it, loss)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Backward pass</span></span><br><span class="line">    <span class="comment"># compute the gradient</span></span><br><span class="line">    grad_y_pred = <span class="number">2.0</span> * (y_pred - y)</span><br><span class="line">    grad_w2 = h_relu.t().mm(grad_y_pred)</span><br><span class="line">    grad_h_relu = grad_y_pred.mm(w2.t())</span><br><span class="line">    grad_h = grad_h_relu.clone()</span><br><span class="line">    grad_h[h&lt;<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    grad_w1 = x.t().mm(grad_h)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># update weights of w1 and w2</span></span><br><span class="line">    w1 -= learning_rate * grad_w1</span><br><span class="line">    w2 -= learning_rate * grad_w2</span><br></pre></td></tr></table></figure>

<p>ç®€å•çš„autograd</p>
<p>In [72]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor(<span class="number">1.</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">w = torch.tensor(<span class="number">2.</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">b = torch.tensor(<span class="number">3.</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">y = w*x + b <span class="comment"># y = 2*1+3</span></span><br><span class="line"></span><br><span class="line">y.backward()</span><br><span class="line"></span><br><span class="line"><span class="comment"># dy / dw = x</span></span><br><span class="line">print(w.grad)</span><br><span class="line">print(x.grad)</span><br><span class="line">print(b.grad)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor(1.)</span><br><span class="line">tensor(2.)</span><br><span class="line">tensor(1.)</span><br></pre></td></tr></table></figure>

<h2 id="PyTorch-Tensorå’Œautograd"><a href="#PyTorch-Tensorå’Œautograd" class="headerlink" title="PyTorch: Tensorå’Œautograd"></a>PyTorch: Tensorå’Œautograd</h2><p>PyTorchçš„ä¸€ä¸ªé‡è¦åŠŸèƒ½å°±æ˜¯autogradï¼Œä¹Ÿå°±æ˜¯è¯´åªè¦å®šä¹‰äº†forward pass(å‰å‘ç¥ç»ç½‘ç»œ)ï¼Œè®¡ç®—äº†lossä¹‹åï¼ŒPyTorchå¯ä»¥è‡ªåŠ¨æ±‚å¯¼è®¡ç®—æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¢¯åº¦ã€‚</p>
<p>ä¸€ä¸ªPyTorchçš„Tensorè¡¨ç¤ºè®¡ç®—å›¾ä¸­çš„ä¸€ä¸ªèŠ‚ç‚¹ã€‚å¦‚æœ<code>x</code>æ˜¯ä¸€ä¸ªTensorå¹¶ä¸”<code>x.requires_grad=True</code>é‚£ä¹ˆ<code>x.grad</code>æ˜¯å¦ä¸€ä¸ªå‚¨å­˜ç€<code>x</code>å½“å‰æ¢¯åº¦(ç›¸å¯¹äºä¸€ä¸ªscalarï¼Œå¸¸å¸¸æ˜¯loss)çš„å‘é‡ã€‚</p>
<p>In [ ]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># éšæœºåˆ›å»ºä¸€äº›è®­ç»ƒæ•°æ®</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line">w1 = torch.randn(D_in, H, requires_grad=<span class="literal">True</span>)</span><br><span class="line">w2 = torch.randn(H, D_out, requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass</span></span><br><span class="line">    y_pred = x.mm(w1).clamp(min=<span class="number">0</span>).mm(w2)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute loss</span></span><br><span class="line">    loss = (y_pred - y).pow(<span class="number">2</span>).sum() <span class="comment"># computation graph</span></span><br><span class="line">    print(it, loss.item())</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Backward pass</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># update weights of w1 and w2</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        w1 -= learning_rate * w1.grad</span><br><span class="line">        w2 -= learning_rate * w2.grad</span><br><span class="line">        w1.grad.zero_()</span><br><span class="line">        w2.grad.zero_()</span><br></pre></td></tr></table></figure>

<h2 id="PyTorch-nn"><a href="#PyTorch-nn" class="headerlink" title="PyTorch: nn"></a>PyTorch: nn</h2><p>è¿™æ¬¡æˆ‘ä»¬ä½¿ç”¨PyTorchä¸­nnè¿™ä¸ªåº“æ¥æ„å»ºç½‘ç»œã€‚ ç”¨PyTorch autogradæ¥æ„å»ºè®¡ç®—å›¾å’Œè®¡ç®—gradientsï¼Œ ç„¶åPyTorchä¼šå¸®æˆ‘ä»¬è‡ªåŠ¨è®¡ç®—gradientã€‚</p>
<p>In [ ]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># éšæœºåˆ›å»ºä¸€äº›è®­ç»ƒæ•°æ®</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line">model = torch.nn.Sequential(</span><br><span class="line">    torch.nn.Linear(D_in, H, bias=<span class="literal">False</span>), <span class="comment"># w_1 * x + b_1</span></span><br><span class="line">    torch.nn.ReLU(),</span><br><span class="line">    torch.nn.Linear(H, D_out, bias=<span class="literal">False</span>),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">torch.nn.init.normal_(model[<span class="number">0</span>].weight)</span><br><span class="line">torch.nn.init.normal_(model[<span class="number">2</span>].weight)</span><br><span class="line"></span><br><span class="line"><span class="comment"># model = model.cuda()</span></span><br><span class="line"></span><br><span class="line">loss_fn = nn.MSELoss(reduction=<span class="string">'sum'</span>)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass</span></span><br><span class="line">    y_pred = model(x) <span class="comment"># model.forward() </span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute loss</span></span><br><span class="line">    loss = loss_fn(y_pred, y) <span class="comment"># computation graph</span></span><br><span class="line">    print(it, loss.item())</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Backward pass</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># update weights of w1 and w2</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> model.parameters(): <span class="comment"># param (tensor, grad)</span></span><br><span class="line">            param -= learning_rate * param.grad</span><br><span class="line">            </span><br><span class="line">    model.zero_grad()</span><br></pre></td></tr></table></figure>

<p>In [113]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model[0].weight</span><br></pre></td></tr></table></figure>

<p>Out[113]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Parameter containing:</span><br><span class="line">tensor([[-0.0218,  0.0212,  0.0243,  ...,  0.0230,  0.0247,  0.0168],</span><br><span class="line">        [-0.0144,  0.0177, -0.0221,  ...,  0.0161,  0.0098, -0.0172],</span><br><span class="line">        [ 0.0086, -0.0122, -0.0298,  ..., -0.0236, -0.0187,  0.0295],</span><br><span class="line">        ...,</span><br><span class="line">        [ 0.0266, -0.0008, -0.0141,  ...,  0.0018,  0.0319, -0.0129],</span><br><span class="line">        [ 0.0296, -0.0005,  0.0115,  ...,  0.0141, -0.0088, -0.0106],</span><br><span class="line">        [ 0.0289, -0.0077,  0.0239,  ..., -0.0166, -0.0156, -0.0235]],</span><br><span class="line">       requires_grad=True)</span><br></pre></td></tr></table></figure>

<h2 id="PyTorch-optim"><a href="#PyTorch-optim" class="headerlink" title="PyTorch: optim"></a>PyTorch: optim</h2><p>è¿™ä¸€æ¬¡æˆ‘ä»¬ä¸å†æ‰‹åŠ¨æ›´æ–°æ¨¡å‹çš„weights,è€Œæ˜¯ä½¿ç”¨optimè¿™ä¸ªåŒ…æ¥å¸®åŠ©æˆ‘ä»¬æ›´æ–°å‚æ•°ã€‚ optimè¿™ä¸ªpackageæä¾›äº†å„ç§ä¸åŒçš„æ¨¡å‹ä¼˜åŒ–æ–¹æ³•ï¼ŒåŒ…æ‹¬SGD+momentum, RMSProp, Adamç­‰ç­‰ã€‚</p>
<p>In [ ]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># éšæœºåˆ›å»ºä¸€äº›è®­ç»ƒæ•°æ®</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line">model = torch.nn.Sequential(</span><br><span class="line">    torch.nn.Linear(D_in, H, bias=<span class="literal">False</span>), <span class="comment"># w_1 * x + b_1</span></span><br><span class="line">    torch.nn.ReLU(),</span><br><span class="line">    torch.nn.Linear(H, D_out, bias=<span class="literal">False</span>),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">torch.nn.init.normal_(model[<span class="number">0</span>].weight)</span><br><span class="line">torch.nn.init.normal_(model[<span class="number">2</span>].weight)</span><br><span class="line"></span><br><span class="line"><span class="comment"># model = model.cuda()</span></span><br><span class="line"></span><br><span class="line">loss_fn = nn.MSELoss(reduction=<span class="string">'sum'</span>)</span><br><span class="line"><span class="comment"># learning_rate = 1e-4</span></span><br><span class="line"><span class="comment"># optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)</span></span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass</span></span><br><span class="line">    y_pred = model(x) <span class="comment"># model.forward() </span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute loss</span></span><br><span class="line">    loss = loss_fn(y_pred, y) <span class="comment"># computation graph</span></span><br><span class="line">    print(it, loss.item())</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    <span class="comment"># Backward pass</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># update model parameters</span></span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure>

<h2 id="PyTorch-è‡ªå®šä¹‰-nn-Modules"><a href="#PyTorch-è‡ªå®šä¹‰-nn-Modules" class="headerlink" title="PyTorch: è‡ªå®šä¹‰ nn Modules"></a>PyTorch: è‡ªå®šä¹‰ nn Modules</h2><p>æˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸€ä¸ªæ¨¡å‹ï¼Œè¿™ä¸ªæ¨¡å‹ç»§æ‰¿è‡ªnn.Moduleç±»ã€‚å¦‚æœéœ€è¦å®šä¹‰ä¸€ä¸ªæ¯”Sequentialæ¨¡å‹æ›´åŠ å¤æ‚çš„æ¨¡å‹ï¼Œå°±éœ€è¦å®šä¹‰nn.Moduleæ¨¡å‹ã€‚</p>
<p>In [ ]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># éšæœºåˆ›å»ºä¸€äº›è®­ç»ƒæ•°æ®</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TwoLayerNet</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, D_in, H, D_out)</span>:</span></span><br><span class="line">        super(TwoLayerNet, self).__init__()</span><br><span class="line">        <span class="comment"># define the model architecture</span></span><br><span class="line">        self.linear1 = torch.nn.Linear(D_in, H, bias=<span class="literal">False</span>)</span><br><span class="line">        self.linear2 = torch.nn.Linear(H, D_out, bias=<span class="literal">False</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        y_pred = self.linear2(self.linear1(x).clamp(min=<span class="number">0</span>))</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br><span class="line">model = TwoLayerNet(D_in, H, D_out)</span><br><span class="line">loss_fn = nn.MSELoss(reduction=<span class="string">'sum'</span>)</span><br><span class="line">learning_rate = <span class="number">1e-4</span></span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass</span></span><br><span class="line">    y_pred = model(x) <span class="comment"># model.forward() </span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute loss</span></span><br><span class="line">    loss = loss_fn(y_pred, y) <span class="comment"># computation graph</span></span><br><span class="line">    print(it, loss.item())</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    <span class="comment"># Backward pass</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># update model parameters</span></span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure>

<p>In [ ]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>
      
    </div>
    
  </div>
  
    
    <div class="copyright">
        <p><span>æœ¬æ–‡æ ‡é¢˜:</span><a href="/2020/06/08/PyTorch/">PyTorch</a></p>
        <p><span>æ–‡ç« ä½œè€…:</span><a href="/" title="å›åˆ°ä¸»é¡µ">MingmingYe</a></p>
        <p><span>å‘å¸ƒæ—¶é—´:</span>2020-06-08, 19:12:06</p>
        <p><span>æœ€åæ›´æ–°:</span>2020-06-09, 09:28:17</p>
        <p>
            <span>åŸå§‹é“¾æ¥:</span><a class="post-url" href="/2020/06/08/PyTorch/" title="PyTorch">http://mmyblog.cn/2020/06/08/PyTorch/</a>
            <span class="copy-path" data-clipboard-text="åŸæ–‡: http://mmyblog.cn/2020/06/08/PyTorch/ã€€ã€€ä½œè€…: MingmingYe" title="ç‚¹å‡»å¤åˆ¶æ–‡ç« é“¾æ¥"><i class="fa fa-clipboard"></i></span>
            <script> var clipboard = new Clipboard('.copy-path'); </script>
        </p>
        <p>
            <span>è®¸å¯åè®®:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" title="CC BY-NC-SA 4.0 International" target = "_blank">"ç½²å-éå•†ç”¨-ç›¸åŒæ–¹å¼å…±äº« 4.0"</a> è½¬è½½è¯·ä¿ç•™åŸæ–‡é“¾æ¥åŠä½œè€…ã€‚
        </p>
    </div>



    <nav id="article-nav">
        
            <div id="article-nav-newer" class="article-nav-title">
                <a href="/2020/06/09/XLNet/">
                    XLNet
                </a>
            </div>
        
        
            <div id="article-nav-older" class="article-nav-title">
                <a href="/2020/06/08/æœ´ç´ è´å¶æ–¯/">
                    æœ´ç´ è´å¶æ–¯
                </a>
            </div>
        
    </nav>

  
  
    <! -- æ·»åŠ æèµ å›¾æ ‡ -->
<div class ="post-donate">
    <div id="donate_board" class="donate_bar center">
        <a id="btn_donate" class="btn_donate" href="javascript:;" title="æ‰“èµ"></a>
        <span class="donate_txt">
           â†‘<br>
           æ¬£èµæ­¤æ–‡ï¼Ÿæ±‚é¼“åŠ±ï¼Œæ±‚æ”¯æŒï¼
        </span>
        <br>
      </div>  
    <div id="donate_guide" class="donate_bar center hidden" >
        
            <!-- <img src="/img/Alipay.jpg" alt="æ”¯ä»˜å®æ‰“èµ">
            <img src="/img/WeChatpay.jpg" alt="å¾®ä¿¡æ‰“èµ"> -->
       
        <!-- æ–¹å¼äºŒï¼›
            step1ï¼šåœ¨_config.ymlä¸­æ·»åŠ é…ç½®
                Alipay: /img/Alipay.jpg
                WeChatpay: /img/WeChatpay.jpg
            step2ï¼šæ­¤å¤„ä¸¤å¼ å›¾ç‰‡çš„è·¯å¾„åˆ†åˆ«è®¾ç½®ä¸ºå¦‚ä¸‹
                <img src=""
                <img src=""
        -->
        <!-- æ”¯ä»˜å®æ‰“èµå›¾æ¡ˆ -->
        <img src="/img/Alipay.jpg" alt="æ”¯ä»˜å®æ‰“èµ">
        <!-- å¾®ä¿¡æ‰“èµå›¾æ¡ˆ -->
        <img src="/img//WeChatpay.jpg" alt="å¾®ä¿¡æ‰“èµ">
    </div>
    <script type="text/javascript">
        document.getElementById('btn_donate').onclick = function(){
            $('#donate_board').addClass('hidden');
            $('#donate_guide').removeClass('hidden');
        }
    </script>
</div>
<! -- æ·»åŠ æèµ å›¾æ ‡ -->
  
</article>

    <div id="toc" class="toc-article">
        <strong class="toc-title">æ–‡ç« ç›®å½•</strong>
        
            <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#ä»€ä¹ˆæ˜¯PyTorch"><span class="toc-number">1.</span> <span class="toc-text">ä»€ä¹ˆæ˜¯PyTorch?</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Tensors"><span class="toc-number">1.1.</span> <span class="toc-text">Tensors</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#æ³¨æ„"><span class="toc-number">1.1.0.1.</span> <span class="toc-text">æ³¨æ„</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#æ³¨æ„-1"><span class="toc-number">1.1.0.2.</span> <span class="toc-text">æ³¨æ„</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Numpyå’ŒTensorä¹‹é—´çš„è½¬åŒ–"><span class="toc-number">1.2.</span> <span class="toc-text">Numpyå’ŒTensorä¹‹é—´çš„è½¬åŒ–</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CUDA-Tensors"><span class="toc-number">1.3.</span> <span class="toc-text">CUDA Tensors</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#çƒ­èº«-ç”¨numpyå®ç°ä¸¤å±‚ç¥ç»ç½‘ç»œ"><span class="toc-number">1.4.</span> <span class="toc-text">çƒ­èº«: ç”¨numpyå®ç°ä¸¤å±‚ç¥ç»ç½‘ç»œ</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PyTorch-Tensors"><span class="toc-number">1.5.</span> <span class="toc-text">PyTorch: Tensors</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PyTorch-Tensorå’Œautograd"><span class="toc-number">1.6.</span> <span class="toc-text">PyTorch: Tensorå’Œautograd</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PyTorch-nn"><span class="toc-number">1.7.</span> <span class="toc-text">PyTorch: nn</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PyTorch-optim"><span class="toc-number">1.8.</span> <span class="toc-text">PyTorch: optim</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PyTorch-è‡ªå®šä¹‰-nn-Modules"><span class="toc-number">1.9.</span> <span class="toc-text">PyTorch: è‡ªå®šä¹‰ nn Modules</span></a></li></ol></li></ol>
        
    </div>
    <style>
        .left-col .switch-btn,
        .left-col .switch-area {
            display: none;
        }
        .toc-level-5 i,
        .toc-level-5 ol {
            display: none !important;
        }
    </style>

    <input type="button" id="tocButton" value="éšè—ç›®å½•"  title="ç‚¹å‡»æŒ‰é’®éšè—æˆ–è€…æ˜¾ç¤ºæ–‡ç« ç›®å½•">

    <script>
        yiliaConfig.toc = ["éšè—ç›®å½•", "æ˜¾ç¤ºç›®å½•", !!"false"];
    </script>



    
<div class="share">
    
        <div class="bdsharebuttonbox">
            <a href="#" class="fa fa-twitter bds_twi" data-cmd="twi" title="åˆ†äº«åˆ°æ¨ç‰¹"></a>
            <a href="#" class="fa fa-weibo bds_tsina" data-cmd="tsina" title="åˆ†äº«åˆ°æ–°æµªå¾®åš"></a>
            <a href="#" class="fa fa-qq bds_sqq" data-cmd="sqq" title="åˆ†äº«ç»™ QQ å¥½å‹"></a>
            <a href="#" class="fa fa-files-o bds_copy" data-cmd="copy" title="å¤åˆ¶ç½‘å€"></a>
            <a href="#" class="fa fa fa-envelope-o bds_mail" data-cmd="mail" title="é€šè¿‡é‚®ä»¶åˆ†äº«"></a>
            <a href="#" class="fa fa-weixin bds_weixin" data-cmd="weixin" title="ç”Ÿæˆæ–‡ç« äºŒç»´ç "></a>
            <a href="#" class="fa fa-share-alt bds_more" data-cmd="more"></i></a>
        </div>
        <script>
            window._bd_share_config={
                "common":{"bdSnsKey":{},"bdText":"PyTorchã€€| Stay hungry, Stay foolish.ã€€","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
        </script>
    

    
</div>







    




    <div class="scroll" id="post-nav-button">
        
            <a href="/2020/06/09/XLNet/" title="ä¸Šä¸€ç¯‡: XLNet">
                <i class="fa fa-angle-left"></i>
            </a>
        

        <a title="æ–‡ç« åˆ—è¡¨"><i class="fa fa-bars"></i><i class="fa fa-times"></i></a>

        
            <a href="/2020/06/08/æœ´ç´ è´å¶æ–¯/" title="ä¸‹ä¸€ç¯‡: æœ´ç´ è´å¶æ–¯">
                <i class="fa fa-angle-right"></i>
            </a>
        
    </div>

    <ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2020/06/09/æ‰©å±•å†…å®¹/">æ‰©å±•å†…å®¹</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/09/XLNet/">XLNet</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/08/PyTorch/">PyTorch</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/08/æœ´ç´ è´å¶æ–¯/">æœ´ç´ è´å¶æ–¯</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/30/GPTæ¨¡å‹/">GPTæ¨¡å‹</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/30/BERTç³»åˆ—é¢„è®­ç»ƒæ¨¡å‹/">BERTç³»åˆ—é¢„è®­ç»ƒæ¨¡å‹</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/19/é˜…è¯»ç†è§£/">é˜…è¯»ç†è§£</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/18/Transformeræ¨¡å‹è§£è¯»/">Transformeræ¨¡å‹è§£è¯»</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/16/Transformer-XL/">Transformer-XL</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/12/è‹±æ–‡ä¹¦ç±wordçº§åˆ«çš„æ–‡æœ¬ç”Ÿæˆä»£ç æ³¨é‡Š/">è‹±æ–‡ä¹¦ç±wordçº§åˆ«çš„æ–‡æœ¬ç”Ÿæˆä»£ç æ³¨é‡Š</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/10/æ–‡æœ¬ç”Ÿæˆä»»åŠ¡/">æ–‡æœ¬ç”Ÿæˆä»»åŠ¡</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/09/å¸¸è§é¢„è®­ç»ƒæ¨¡å‹/">BERT&ELMo&co</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/01/å¤§è§„æ¨¡æ— ç›‘ç£é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ä¸åº”ç”¨ä¸Š/">å¤§è§„æ¨¡æ— ç›‘ç£é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ä¸åº”ç”¨ä¸Š</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/24/word2vec/">word2vec</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/20/ç‰¹å¾å·¥ç¨‹ä¸æ¨¡å‹è°ƒä¼˜/">ç‰¹å¾å·¥ç¨‹ä¸æ¨¡å‹è°ƒä¼˜</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/18/è¯­è¨€æ¨¡å‹/">è¯­è¨€æ¨¡å‹</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/17/SQuAD-BiDAF/">SQuAD-BiDAF</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/15/NLPä¸­çš„ConvNet/">NLPä¸­çš„ConvNet</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/13/seq2seq/">seq2seq</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/09/æœºå™¨ç¿»è¯‘ä¸æ–‡æœ¬æ‘˜è¦/">æœºå™¨ç¿»è¯‘ä¸æ–‡æœ¬æ‘˜è¦</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/28/sentimentæƒ…æ„Ÿåˆ†æä»£ç æ³¨é‡Š/">sentimentæƒ…æ„Ÿåˆ†æä»£ç æ³¨é‡Š</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/11/èŠå¤©æœºå™¨äººäºŒ/">èŠå¤©æœºå™¨äººäºŒ</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/10/èŠå¤©æœºå™¨äººä¸€/">èŠå¤©æœºå™¨äººä¸€</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/09/ç»“æ„åŒ–é¢„æµ‹/">ç»“æ„åŒ–é¢„æµ‹</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/20/SVM/">SVM</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/11/word-embedding/">word-embedding</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/08/é…’åº—è¯„ä»·æƒ…æ„Ÿåˆ†ç±»ä¸CNNæ¨¡å‹/">é…’åº—è¯„ä»·æƒ…æ„Ÿåˆ†ç±»ä¸CNNæ¨¡å‹</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/28/NLPæŠ€æœ¯åŸºç¡€æ•´ç†/">NLPæŠ€æœ¯åŸºç¡€æ•´ç†</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/18/CNN-Image-Classification/">CNN-Image-Classification</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/08/ä¸˜å‰å°”çš„äººç‰©ä¼ è®°charçº§åˆ«çš„æ–‡æœ¬ç”Ÿæˆä»£ç æ³¨é‡Š/">ä¸˜å‰å°”çš„äººç‰©ä¼ è®°charçº§åˆ«çš„æ–‡æœ¬ç”Ÿæˆä»£ç æ³¨é‡Š</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/08/ç”¨æœ´ç´ è´å¶æ–¯å®Œæˆè¯­ç§æ£€æµ‹/">ç”¨æœ´ç´ è´å¶æ–¯å®Œæˆè¯­ç§æ£€æµ‹</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/09/01/æ·±åº¦å­¦ä¹ é€ŸæŸ¥è¡¨/">æ·±åº¦å­¦ä¹ é€ŸæŸ¥è¡¨</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/09/01/æ¨¡å‹è°ƒä¼˜/">æ¨¡å‹è°ƒä¼˜</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/09/01/é›†æˆå­¦ä¹ ä¸boostingæ¨¡å‹/">é›†æˆå­¦ä¹ ä¸boostingæ¨¡å‹</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/09/01/èšç±»ä¸é™ç»´/">èšç±»ä¸é™ç»´</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/09/01/è´å¶æ–¯åˆ†ç±»å™¨/">è´å¶æ–¯åˆ†ç±»å™¨</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/09/01/å†³ç­–æ ‘ä¸éšæœºæ£®æ—/">å†³ç­–æ ‘ä¸éšæœºæ£®æ—</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/29/æœºå™¨å­¦ä¹ é€»è¾‘å›å½’ä¸softmax/">æœºå™¨å­¦ä¹ é€»è¾‘å›å½’ä¸softmax</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/24/æ–‡æœ¬åˆ†ç±»é—®é¢˜/">æ–‡æœ¬åˆ†ç±»é—®é¢˜</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/23/æœºå™¨å­¦ä¹ åŸºæœ¬æ¦‚å¿µ/">æœºå™¨å­¦ä¹ åŸºæœ¬æ¦‚å¿µ</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/23/ç®€æ´ç‰ˆæœºå™¨å­¦ä¹ é€ŸæŸ¥è¡¨/">ç®€æ´ç‰ˆæœºå™¨å­¦ä¹ é€ŸæŸ¥è¡¨</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/23/CS229ç‰ˆæœºå™¨å­¦ä¹ é€ŸæŸ¥è¡¨/">CS229ç‰ˆæœºå™¨å­¦ä¹ é€ŸæŸ¥è¡¨</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/08/è‘«èŠ¦ä¹¦å­¦ä¹ ç¬”è®°/">è‘«èŠ¦ä¹¦å­¦ä¹ ç¬”è®°</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/06/æ•°å­¦åŸºç¡€çŸ¥è¯†æ•´ç†/">æ•°å­¦åŸºç¡€çŸ¥è¯†æ•´ç†</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/07/24/å¤§æ•°æ®åŸºç¡€/">å¤§æ•°æ®åŸºç¡€</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/07/22/æ•°æ®åˆ†æå¸¸ç”¨å·¥å…·æ€»ç»“/">æ•°æ®åˆ†æå¸¸ç”¨å·¥å…·æ€»ç»“</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/07/20/pythonåŸºç¡€çŸ¥è¯†æ•´ç†/">pythonåŸºç¡€çŸ¥è¯†æ•´ç†</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/07/08/pythonæ­£åˆ™è¡¨è¾¾å¼/">pythonæ­£åˆ™è¡¨è¾¾å¼</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/06/08/jiebaä¸­æ–‡å¤„ç†/">jiebaä¸­æ–‡å¤„ç†</a></li></ul>




    <script>
        
    </script>

</div>
      <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
<footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                <i class="fa fa-copyright"></i> 
                2019-2020 MingmingYe
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank" title="å¿«é€Ÿã€ç®€æ´ä¸”é«˜æ•ˆçš„åšå®¢æ¡†æ¶">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="ç®€è€Œä¸å‡ Hexo åŒæ åšå®¢ä¸»é¢˜  v3.5">Yelee</a> by MOxFIVE <i class="fa fa-heart animated infinite pulse"></i>
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" title="æœ¬ç«™åˆ°è®¿æ•°"><i class="fa fa-user" aria-hidden="true"></i><span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>| </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit"  title="æœ¬é¡µé˜…è¯»é‡"><i class="fa fa-eye animated infinite pulse" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>

    </div>
    
<script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.2.0/require.min.js"></script>

    <script>
        $(document).ready(function() {
            var iPad = window.navigator.userAgent.indexOf('iPad');
            if (iPad > -1 || $(".left-col").css("display") === "none") {
                var bgColorList = ["#9db3f4", "#414141", "#e5a859", "#f5dfc6", "#c084a0", "#847e72", "#cd8390", "#996731"];
                var bgColor = Math.ceil(Math.random() * (bgColorList.length - 1));
                $("body").css({"background-color": bgColorList[bgColor], "background-size": "cover"});
            }
            else {
                var backgroundnum = 5;
                var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
                $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
            }
        })
    </script>





    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<div class="scroll" id="scroll">
    <a href="#" title="è¿”å›é¡¶éƒ¨"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" onclick="load$hide();" title="æŸ¥çœ‹è¯„è®º"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="è½¬åˆ°åº•éƒ¨"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    // Open in New Window
    
        var oOpenInNew = {
            
            
            
            
            
            
             archives: ".archive-article-title", 
             miniArchives: "a.post-list-link", 
            
             friends: "#js-friends a", 
             socail: ".social a" 
        }
        for (var x in oOpenInNew) {
            $(oOpenInNew[x]).attr("target", "_blank");
        }
    
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>
</body>
</html>