<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>æ‰©å±•å†…å®¹</title>
      <link href="/2020/06/09/%E6%89%A9%E5%B1%95%E5%86%85%E5%AE%B9/"/>
      <url>/2020/06/09/%E6%89%A9%E5%B1%95%E5%86%85%E5%AE%B9/</url>
      
        <content type="html"><![CDATA[<h3 id="ç»“æ„åŒ–é¢„æµ‹"><a href="#ç»“æ„åŒ–é¢„æµ‹" class="headerlink" title="ç»“æ„åŒ–é¢„æµ‹"></a><a href="https://shimo.im/docs/t9hjVGDx33vyTDjD" target="_blank" rel="noopener">ç»“æ„åŒ–é¢„æµ‹</a></h3><ul><li>éšé©¬å°”ç§‘å¤«æ¨¡å‹ <a href="http://www.cs.columbia.edu/~mcollins/hmms-spring2013.pdf" target="_blank" rel="noopener">http://www.cs.columbia.edu/~mcollins/hmms-spring2013.pdf</a></li><li>æœ€å¤§ç†µä¸è¯æ€§æ ‡æ³¨</li><li>æ¡ä»¶éšæœºåœº</li></ul><h3 id="ä¸­æ–‡åˆ†è¯-Chinese-Word-Segmentation"><a href="#ä¸­æ–‡åˆ†è¯-Chinese-Word-Segmentation" class="headerlink" title="ä¸­æ–‡åˆ†è¯ Chinese Word Segmentation"></a>ä¸­æ–‡åˆ†è¯ Chinese Word Segmentation</h3><ul><li><a href="https://www.aclweb.org/anthology/D18-1529.pdf" target="_blank" rel="noopener">https://www.aclweb.org/anthology/D18-1529.pdf</a></li></ul><h3 id="Parsingä¸Recursive-Neural-Networks"><a href="#Parsingä¸Recursive-Neural-Networks" class="headerlink" title="Parsingä¸Recursive Neural Networks"></a>Parsingä¸Recursive Neural Networks</h3><ul><li><a href="http://web.stanford.edu/class/cs224n/slides/cs224n-2020-lecture18-TreeRNNs.pdf" target="_blank" rel="noopener">http://web.stanford.edu/class/cs224n/slides/cs224n-2020-lecture18-TreeRNNs.pdf</a></li><li><a href="http://web.stanford.edu/class/cs224n/slides/cs224n-2020-lecture05-dep-parsing.pdf" target="_blank" rel="noopener">http://web.stanford.edu/class/cs224n/slides/cs224n-2020-lecture05-dep-parsing.pdf</a></li></ul><h3 id="å›¾ç¥ç»ç½‘ç»œ"><a href="#å›¾ç¥ç»ç½‘ç»œ" class="headerlink" title="å›¾ç¥ç»ç½‘ç»œ"></a>å›¾ç¥ç»ç½‘ç»œ</h3><ul><li>GCN: <a href="https://arxiv.org/pdf/1609.02907.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1609.02907.pdf</a></li><li>GCN for relational graph: <a href="https://arxiv.org/pdf/1703.06103.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1703.06103.pdf</a></li></ul><h3 id="Data-to-Text-æ–‡æœ¬ç”Ÿæˆ"><a href="#Data-to-Text-æ–‡æœ¬ç”Ÿæˆ" class="headerlink" title="Data to Text æ–‡æœ¬ç”Ÿæˆ"></a>Data to Text æ–‡æœ¬ç”Ÿæˆ</h3><ul><li>GCNç”Ÿæˆæ–‡æœ¬ <a href="https://arxiv.org/pdf/1810.09995v1.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1810.09995v1.pdf</a></li></ul><h3 id="çŸ¥è¯†å›¾è°±ç›¸å…³é—®é¢˜"><a href="#çŸ¥è¯†å›¾è°±ç›¸å…³é—®é¢˜" class="headerlink" title="çŸ¥è¯†å›¾è°±ç›¸å…³é—®é¢˜"></a><a href="https://shimo.im/docs/9pwCHPwXxcGHRrxh" target="_blank" rel="noopener">çŸ¥è¯†å›¾è°±ç›¸å…³é—®é¢˜</a></h3>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ä¸­æ–‡åˆ†è¯ </tag>
            
            <tag> å›¾ç¥ç»ç½‘ç»œ </tag>
            
            <tag> Recursive Neural Networks </tag>
            
            <tag> Parsing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>XLNet</title>
      <link href="/2020/06/09/XLNet/"/>
      <url>/2020/06/09/XLNet/</url>
      
        <content type="html"><![CDATA[<h2 id="Transformer-XL-Attentive-Language-Models-Beyond-a-Fixed-Length-Context"><a href="#Transformer-XL-Attentive-Language-Models-Beyond-a-Fixed-Length-Context" class="headerlink" title="Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context"></a>Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context</h2><p><a href="https://arxiv.org/pdf/1901.02860.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1901.02860.pdf</a></p><p>ç›¸è¾ƒäºä¼ ç»Ÿtransformer decoderï¼Œå¼•å…¥ä¸¤ä¸ªæ–°æ¨¡å—</p><ul><li>segment-level recurrence mechanism</li></ul><p><img src="https://uploader.shimo.im/f/DpNe30kuahkbOeW5.png!thumbnail" alt="img"></p><ul><li><p>a novel positional encoding scheme</p></li><li><p>è€ƒè™‘æˆ‘ä»¬åœ¨attentionæœºåˆ¶ä¸­å¦‚ä½•ä½¿ç”¨positional encoding</p></li></ul><p>(E_{x_i}^T+U_i^T)W_q^TW_kE_{x_j}U_j</p><p><img src="https://uploader.shimo.im/f/5zNU9yZQtQMClNiY.png!thumbnail" alt="img"></p><ul><li><p>Rä»–ä»¬é‡‡ç”¨çš„æ˜¯transformerå½“ä¸­çš„positional encoding</p></li><li><p>uå’Œvæ˜¯éœ€è¦è®­ç»ƒçš„æ¨¡å‹å‚æ•°</p></li></ul><p>æœ€ç»ˆTransformer XLæ¨¡å‹</p><p><img src="https://uploader.shimo.im/f/Nm1uk49MIjUys1aK.png!thumbnail" alt="img"></p><p>ä»£ç </p><p><a href="https://github.com/kimiyoung/transformer-xl" target="_blank" rel="noopener">https://github.com/kimiyoung/transformer-xl</a></p><h2 id="XLNet-Generalized-Autoregressive-Pretraining-for-Language-Understanding"><a href="#XLNet-Generalized-Autoregressive-Pretraining-for-Language-Understanding" class="headerlink" title="XLNet: Generalized Autoregressive Pretraining for Language Understanding"></a>XLNet: Generalized Autoregressive Pretraining for Language Understanding</h2><p><a href="https://arxiv.org/pdf/1906.08237.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1906.08237.pdf</a></p><p>èƒŒæ™¯çŸ¥è¯†</p><ul><li><p>è‡ªå›å½’è¯­è¨€æ¨¡å‹ï¼ˆAutoregressive Language Modelï¼‰ï¼šé‡‡ç”¨ä»å·¦å¾€å³æˆ–ä»å³å¾€å·¦çš„è¯­è¨€æ¨¡å‹ï¼Œæ ¹æ®ä¸Šæ–‡é¢„æµ‹ä¸‹æ–‡ã€‚</p></li><li><p>ç¼ºç‚¹ï¼šåªåˆ©ç”¨äº†é¢„æµ‹å•è¯å·¦è¾¹æˆ–å³è¾¹çš„ä¿¡æ¯ï¼Œæ— æ³•åŒæ—¶åˆ©ç”¨ä¸¤è¾¹çš„ä¿¡æ¯ã€‚ELMoåœ¨ä¸€å®šç¨‹åº¦ä¸Šè§£å†³äº†è¿™ä¸ªé—®é¢˜ã€‚</p></li><li><p><img src="https://uploader.shimo.im/f/cpfGbeRfzf8c1ga8.png!thumbnail" alt="img"></p></li><li><p>è‡ªç¼–ç æ¨¡å‹ï¼ˆDenoising Auto Encoder, DAEï¼‰ï¼šåœ¨è¾“å…¥ä¸­éšæœºmaskä¸€äº›å•è¯ï¼Œåˆ©ç”¨ä¸Šä¸‹æ–‡æ¥é¢„æµ‹è¢«maskæ‰çš„å•è¯ã€‚BERTé‡‡ç”¨äº†è¿™ä¸€æ€è·¯ã€‚</p></li><li><p><img src="https://uploader.shimo.im/f/za1FnG3zHdsbm5gD.png!thumbnail" alt="img"></p></li></ul><p>ä¸¤ä¸ªæ¨¡å‹çš„é—®é¢˜</p><p><img src="https://uploader.shimo.im/f/A1rO6rAR1nAQqqvu.png!thumbnail" alt="img"></p><p>XLNetçš„ç›®æ ‡æ˜¯èåˆä»¥ä¸Šä¸¤ç§æ¨¡å‹çš„ä¼˜ç‚¹ï¼Œè§£å†³å®ƒä»¬å„è‡ªå­˜åœ¨çš„é—®é¢˜ã€‚</p><p>XLNetæ¨¡å‹ï¼šPermutation Language Modeling</p><p><img src="https://uploader.shimo.im/f/LdaKeEgG8XwH3iNj.png!thumbnail" alt="img"></p><p>Two-Stream Self-Attention</p><p><img src="https://uploader.shimo.im/f/TdQVsxOeYMoakBW0.png!thumbnail" alt="img"></p><p><img src="https://uploader.shimo.im/f/iLMqF1WinQI6wOsW.png!thumbnail" alt="img"></p><p>å‚è€ƒèµ„æ–™</p><p><a href="https://zhuanlan.zhihu.com/p/70257427" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/70257427</a></p><p>ä»£ç </p><p><a href="https://github.com/zihangdai/xlnet" target="_blank" rel="noopener">https://github.com/zihangdai/xlnet</a></p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> word-embedding </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch</title>
      <link href="/2020/06/08/PyTorch/"/>
      <url>/2020/06/08/PyTorch/</url>
      
        <content type="html"><![CDATA[<h1 id="ä»€ä¹ˆæ˜¯PyTorch"><a href="#ä»€ä¹ˆæ˜¯PyTorch" class="headerlink" title="ä»€ä¹ˆæ˜¯PyTorch?"></a>ä»€ä¹ˆæ˜¯PyTorch?</h1><p>PyTorchæ˜¯ä¸€ä¸ªåŸºäºPythonçš„ç§‘å­¦è®¡ç®—åº“ï¼Œå®ƒæœ‰ä»¥ä¸‹ç‰¹ç‚¹:</p><ul><li>ç±»ä¼¼äºNumPyï¼Œä½†æ˜¯å®ƒå¯ä»¥ä½¿ç”¨GPU</li><li>å¯ä»¥ç”¨å®ƒå®šä¹‰æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå¯ä»¥çµæ´»åœ°è¿›è¡Œæ·±åº¦å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒå’Œä½¿ç”¨</li></ul><h2 id="Tensors"><a href="#Tensors" class="headerlink" title="Tensors"></a>Tensors</h2><p>Tensorç±»ä¼¼ä¸NumPyçš„ndarrayï¼Œå”¯ä¸€çš„åŒºåˆ«æ˜¯Tensorå¯ä»¥åœ¨GPUä¸ŠåŠ é€Ÿè¿ç®—ã€‚</p><p>In [2]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br></pre></td></tr></table></figure><p>æ„é€ ä¸€ä¸ªæœªåˆå§‹åŒ–çš„5x3çŸ©é˜µ:</p><p>In [4]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.empty(5,3)</span><br><span class="line">x</span><br></pre></td></tr></table></figure><p>Out[4]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 0.0000e+00, -8.5899e+09,  0.0000e+00],</span><br><span class="line">        [-8.5899e+09,         nan,  0.0000e+00],</span><br><span class="line">        [ 2.7002e-06,  1.8119e+02,  1.2141e+01],</span><br><span class="line">        [ 7.8503e+02,  6.7504e-07,  6.5200e-10],</span><br><span class="line">        [ 2.9537e-06,  1.7186e-04,         nan]])</span><br></pre></td></tr></table></figure><p>æ„å»ºä¸€ä¸ªéšæœºåˆå§‹åŒ–çš„çŸ©é˜µ:</p><p>In [5]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.rand(5,3)</span><br><span class="line">x</span><br></pre></td></tr></table></figure><p>Out[5]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0.4628, 0.7432, 0.9785],</span><br><span class="line">        [0.2068, 0.4441, 0.9176],</span><br><span class="line">        [0.1027, 0.5275, 0.3884],</span><br><span class="line">        [0.9380, 0.2113, 0.2839],</span><br><span class="line">        [0.0094, 0.4001, 0.6483]])</span><br></pre></td></tr></table></figure><p>æ„å»ºä¸€ä¸ªå…¨éƒ¨ä¸º0ï¼Œç±»å‹ä¸ºlongçš„çŸ©é˜µ:</p><p>In [8]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.zeros(5,3,dtype=torch.long)</span><br><span class="line">x</span><br></pre></td></tr></table></figure><p>Out[8]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0, 0, 0],</span><br><span class="line">        [0, 0, 0],</span><br><span class="line">        [0, 0, 0],</span><br><span class="line">        [0, 0, 0],</span><br><span class="line">        [0, 0, 0]])</span><br></pre></td></tr></table></figure><p>In [11]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.zeros(5,3).long()</span><br><span class="line">x.dtype</span><br></pre></td></tr></table></figure><p>Out[11]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.int64</span><br></pre></td></tr></table></figure><p>ä»æ•°æ®ç›´æ¥ç›´æ¥æ„å»ºtensor:</p><p>In [12]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([5.5,3])</span><br><span class="line">x</span><br></pre></td></tr></table></figure><p>Out[12]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([5.5000, 3.0000])</span><br></pre></td></tr></table></figure><p>ä¹Ÿå¯ä»¥ä»ä¸€ä¸ªå·²æœ‰çš„tensoræ„å»ºä¸€ä¸ªtensorã€‚è¿™äº›æ–¹æ³•ä¼šé‡ç”¨åŸæ¥tensorçš„ç‰¹å¾ï¼Œä¾‹å¦‚ï¼Œæ•°æ®ç±»å‹ï¼Œé™¤éæä¾›æ–°çš„æ•°æ®ã€‚</p><p>In [16]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = x.new_ones(5,3, dtype=torch.double)</span><br><span class="line">x</span><br></pre></td></tr></table></figure><p>Out[16]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[1., 1., 1.],</span><br><span class="line">        [1., 1., 1.],</span><br><span class="line">        [1., 1., 1.],</span><br><span class="line">        [1., 1., 1.],</span><br><span class="line">        [1., 1., 1.]], dtype=torch.float64)</span><br></pre></td></tr></table></figure><p>In [17]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn_like(x, dtype=torch.float)</span><br><span class="line">x</span><br></pre></td></tr></table></figure><p>Out[17]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 0.2411, -0.3961, -0.9206],</span><br><span class="line">        [-0.0508,  0.2653,  0.4685],</span><br><span class="line">        [ 0.5368, -0.3606, -0.0073],</span><br><span class="line">        [ 0.3383,  0.6826,  1.7368],</span><br><span class="line">        [-0.0811, -0.6957, -0.4566]])</span><br></pre></td></tr></table></figure><p>å¾—åˆ°tensorçš„å½¢çŠ¶:</p><p>In [20]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x.shape</span><br></pre></td></tr></table></figure><p>Out[20]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([5, 3])</span><br></pre></td></tr></table></figure><h4 id="æ³¨æ„"><a href="#æ³¨æ„" class="headerlink" title="æ³¨æ„"></a>æ³¨æ„</h4><p><code>torch.Size</code> è¿”å›çš„æ˜¯ä¸€ä¸ªtuple</p><p>Operations</p><p>æœ‰å¾ˆå¤šç§tensorè¿ç®—ã€‚æˆ‘ä»¬å…ˆä»‹ç»åŠ æ³•è¿ç®—ã€‚</p><p>In [21]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y = torch.rand(5,3)</span><br><span class="line">y</span><br></pre></td></tr></table></figure><p>Out[21]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0.9456, 0.3996, 0.1981],</span><br><span class="line">        [0.8728, 0.7097, 0.3721],</span><br><span class="line">        [0.7489, 0.9502, 0.6241],</span><br><span class="line">        [0.5176, 0.0200, 0.5130],</span><br><span class="line">        [0.3552, 0.2710, 0.7392]])</span><br></pre></td></tr></table></figure><p>In [23]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x + y</span><br></pre></td></tr></table></figure><p>Out[23]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 1.1866,  0.0035, -0.7225],</span><br><span class="line">        [ 0.8220,  0.9750,  0.8406],</span><br><span class="line">        [ 1.2857,  0.5896,  0.6168],</span><br><span class="line">        [ 0.8559,  0.7026,  2.2498],</span><br><span class="line">        [ 0.2741, -0.4248,  0.2826]])</span><br></pre></td></tr></table></figure><p>å¦ä¸€ç§ç€åŠ æ³•çš„å†™æ³•</p><p>In [24]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.add(x, y)</span><br></pre></td></tr></table></figure><p>Out[24]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 1.1866,  0.0035, -0.7225],</span><br><span class="line">        [ 0.8220,  0.9750,  0.8406],</span><br><span class="line">        [ 1.2857,  0.5896,  0.6168],</span><br><span class="line">        [ 0.8559,  0.7026,  2.2498],</span><br><span class="line">        [ 0.2741, -0.4248,  0.2826]])</span><br></pre></td></tr></table></figure><p>åŠ æ³•ï¼šæŠŠè¾“å‡ºä½œä¸ºä¸€ä¸ªå˜é‡</p><p>In [26]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">result = torch.empty(5,3)</span><br><span class="line">torch.add(x, y, out=result)</span><br><span class="line"># result = x + y</span><br><span class="line">result</span><br></pre></td></tr></table></figure><p>Out[26]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 1.1866,  0.0035, -0.7225],</span><br><span class="line">        [ 0.8220,  0.9750,  0.8406],</span><br><span class="line">        [ 1.2857,  0.5896,  0.6168],</span><br><span class="line">        [ 0.8559,  0.7026,  2.2498],</span><br><span class="line">        [ 0.2741, -0.4248,  0.2826]])</span><br></pre></td></tr></table></figure><p>in-placeåŠ æ³•</p><p>In [28]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y.add_(x)</span><br><span class="line">y</span><br></pre></td></tr></table></figure><p>Out[28]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 1.1866,  0.0035, -0.7225],</span><br><span class="line">        [ 0.8220,  0.9750,  0.8406],</span><br><span class="line">        [ 1.2857,  0.5896,  0.6168],</span><br><span class="line">        [ 0.8559,  0.7026,  2.2498],</span><br><span class="line">        [ 0.2741, -0.4248,  0.2826]])</span><br></pre></td></tr></table></figure><h4 id="æ³¨æ„-1"><a href="#æ³¨æ„-1" class="headerlink" title="æ³¨æ„"></a>æ³¨æ„</h4><p>ä»»ä½•in-placeçš„è¿ç®—éƒ½ä¼šä»¥<code>_</code>ç»“å°¾ã€‚ ä¸¾ä¾‹æ¥è¯´ï¼š<code>x.copy_(y)</code>, <code>x.t_()</code>, ä¼šæ”¹å˜ <code>x</code>ã€‚</p><p>å„ç§ç±»ä¼¼NumPyçš„indexingéƒ½å¯ä»¥åœ¨PyTorch tensorä¸Šé¢ä½¿ç”¨ã€‚</p><p>In [31]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x[1:, 1:]</span><br></pre></td></tr></table></figure><p>Out[31]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 0.2653,  0.4685],</span><br><span class="line">        [-0.3606, -0.0073],</span><br><span class="line">        [ 0.6826,  1.7368],</span><br><span class="line">        [-0.6957, -0.4566]])</span><br></pre></td></tr></table></figure><p>Resizing: å¦‚æœä½ å¸Œæœ›resize/reshapeä¸€ä¸ªtensorï¼Œå¯ä»¥ä½¿ç”¨<code>torch.view</code>ï¼š</p><p>In [39]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(4,4)</span><br><span class="line">y = x.view(16)</span><br><span class="line">z = x.view(-1,8)</span><br><span class="line">z</span><br></pre></td></tr></table></figure><p>Out[39]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([[-0.5683,  1.3885, -2.0829, -0.7613, -1.9115,  0.3732, -0.2055, -1.2300],</span><br><span class="line">        [-0.2612, -0.4682, -1.0596,  0.7447,  0.7603, -0.4281,  0.5495,  0.1025]])</span><br></pre></td></tr></table></figure><p>å¦‚æœä½ æœ‰ä¸€ä¸ªåªæœ‰ä¸€ä¸ªå…ƒç´ çš„tensorï¼Œä½¿ç”¨<code>.item()</code>æ–¹æ³•å¯ä»¥æŠŠé‡Œé¢çš„valueå˜æˆPythonæ•°å€¼ã€‚</p><p>In [40]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(1)</span><br><span class="line">x</span><br></pre></td></tr></table></figure><p>Out[40]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([-1.1493])</span><br></pre></td></tr></table></figure><p>In [44]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x.item()</span><br></pre></td></tr></table></figure><p>Out[44]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-1.1493233442306519</span><br></pre></td></tr></table></figure><p>In [48]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">z.transpose(1,0)</span><br></pre></td></tr></table></figure><p>Out[48]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tensor([[-0.5683, -0.2612],</span><br><span class="line">        [ 1.3885, -0.4682],</span><br><span class="line">        [-2.0829, -1.0596],</span><br><span class="line">        [-0.7613,  0.7447],</span><br><span class="line">        [-1.9115,  0.7603],</span><br><span class="line">        [ 0.3732, -0.4281],</span><br><span class="line">        [-0.2055,  0.5495],</span><br><span class="line">        [-1.2300,  0.1025]])</span><br></pre></td></tr></table></figure><p><strong>æ›´å¤šé˜…è¯»</strong></p><p>å„ç§Tensor operations, åŒ…æ‹¬transposing, indexing, slicing, mathematical operations, linear algebra, random numbersåœ¨<code>&lt;https://pytorch.org/docs/torch&gt;</code>.</p><h2 id="Numpyå’ŒTensorä¹‹é—´çš„è½¬åŒ–"><a href="#Numpyå’ŒTensorä¹‹é—´çš„è½¬åŒ–" class="headerlink" title="Numpyå’ŒTensorä¹‹é—´çš„è½¬åŒ–"></a>Numpyå’ŒTensorä¹‹é—´çš„è½¬åŒ–</h2><p>åœ¨Torch Tensorå’ŒNumPy arrayä¹‹é—´ç›¸äº’è½¬åŒ–éå¸¸å®¹æ˜“ã€‚</p><p>Torch Tensorå’ŒNumPy arrayä¼šå…±äº«å†…å­˜ï¼Œæ‰€ä»¥æ”¹å˜å…¶ä¸­ä¸€é¡¹ä¹Ÿä¼šæ”¹å˜å¦ä¸€é¡¹ã€‚</p><p>æŠŠTorch Tensorè½¬å˜æˆNumPy Array</p><p>In [49]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = torch.ones(5)</span><br><span class="line">a</span><br></pre></td></tr></table></figure><p>Out[49]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([1., 1., 1., 1., 1.])</span><br></pre></td></tr></table></figure><p>In [50]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">b = a.numpy()</span><br><span class="line">b</span><br></pre></td></tr></table></figure><p>Out[50]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([1., 1., 1., 1., 1.], dtype=float32)</span><br></pre></td></tr></table></figure><p>æ”¹å˜numpy arrayé‡Œé¢çš„å€¼ã€‚</p><p>In [51]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">b[1] = 2</span><br><span class="line">b</span><br></pre></td></tr></table></figure><p>Out[51]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([1., 2., 1., 1., 1.], dtype=float32)</span><br></pre></td></tr></table></figure><p>In [52]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a</span><br></pre></td></tr></table></figure><p>Out[52]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([1., 2., 1., 1., 1.])</span><br></pre></td></tr></table></figure><p>æŠŠNumPy ndarrayè½¬æˆTorch Tensor</p><p>In [54]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br></pre></td></tr></table></figure><p>In [55]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = np.ones(5)</span><br><span class="line">b = torch.from_numpy(a)</span><br><span class="line">np.add(a, 1, out=a)</span><br><span class="line">print(a)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[2. 2. 2. 2. 2.]</span><br></pre></td></tr></table></figure><p>In [56]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">b</span><br></pre></td></tr></table></figure><p>Out[56]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([2., 2., 2., 2., 2.], dtype=torch.float64)</span><br></pre></td></tr></table></figure><p>æ‰€æœ‰CPUä¸Šçš„Tensoréƒ½æ”¯æŒè½¬æˆnumpyæˆ–è€…ä»numpyè½¬æˆTensorã€‚</p><h2 id="CUDA-Tensors"><a href="#CUDA-Tensors" class="headerlink" title="CUDA Tensors"></a>CUDA Tensors</h2><p>ä½¿ç”¨<code>.to</code>æ–¹æ³•ï¼ŒTensorå¯ä»¥è¢«ç§»åŠ¨åˆ°åˆ«çš„deviceä¸Šã€‚</p><p>In [60]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    device = torch.device(<span class="string">"cuda"</span>)</span><br><span class="line">    y = torch.ones_like(x, device=device)</span><br><span class="line">    x = x.to(device)</span><br><span class="line">    z = x + y</span><br><span class="line">    print(z)</span><br><span class="line">    print(z.to(<span class="string">"cpu"</span>, torch.double))</span><br></pre></td></tr></table></figure><p>Out[60]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">False</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y.to(<span class="string">"cpu"</span>).data.numpy()</span><br><span class="line">y.cpu().data.numpy()</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = model.cuda()</span><br></pre></td></tr></table></figure><h2 id="çƒ­èº«-ç”¨numpyå®ç°ä¸¤å±‚ç¥ç»ç½‘ç»œ"><a href="#çƒ­èº«-ç”¨numpyå®ç°ä¸¤å±‚ç¥ç»ç½‘ç»œ" class="headerlink" title="çƒ­èº«: ç”¨numpyå®ç°ä¸¤å±‚ç¥ç»ç½‘ç»œ"></a>çƒ­èº«: ç”¨numpyå®ç°ä¸¤å±‚ç¥ç»ç½‘ç»œ</h2><p>ä¸€ä¸ªå…¨è¿æ¥ReLUç¥ç»ç½‘ç»œï¼Œä¸€ä¸ªéšè—å±‚ï¼Œæ²¡æœ‰biasã€‚ç”¨æ¥ä»xé¢„æµ‹yï¼Œä½¿ç”¨L2 Lossã€‚</p><ul><li>â„=ğ‘Š1ğ‘‹h=W1X</li><li>ğ‘=ğ‘šğ‘ğ‘¥(0,â„)a=max(0,h)</li><li>ğ‘¦â„ğ‘ğ‘¡=ğ‘Š2ğ‘yhat=W2a</li></ul><p>è¿™ä¸€å®ç°å®Œå…¨ä½¿ç”¨numpyæ¥è®¡ç®—å‰å‘ç¥ç»ç½‘ç»œï¼Œlossï¼Œå’Œåå‘ä¼ æ’­ã€‚</p><ul><li>forward pass</li><li>loss</li><li>backward pass</li></ul><p>numpy ndarrayæ˜¯ä¸€ä¸ªæ™®é€šçš„nç»´arrayã€‚å®ƒä¸çŸ¥é“ä»»ä½•å…³äºæ·±åº¦å­¦ä¹ æˆ–è€…æ¢¯åº¦(gradient)çš„çŸ¥è¯†ï¼Œä¹Ÿä¸çŸ¥é“è®¡ç®—å›¾(computation graph)ï¼Œåªæ˜¯ä¸€ç§ç”¨æ¥è®¡ç®—æ•°å­¦è¿ç®—çš„æ•°æ®ç»“æ„ã€‚</p><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># éšæœºåˆ›å»ºä¸€äº›è®­ç»ƒæ•°æ®</span></span><br><span class="line">x = np.random.randn(N, D_in)</span><br><span class="line">y = np.random.randn(N, D_out)</span><br><span class="line"></span><br><span class="line">w1 = np.random.randn(D_in, H)</span><br><span class="line">w2 = np.random.randn(H, D_out)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass</span></span><br><span class="line">    h = x.dot(w1) <span class="comment"># N * H</span></span><br><span class="line">    h_relu = np.maximum(h, <span class="number">0</span>) <span class="comment"># N * H</span></span><br><span class="line">    y_pred = h_relu.dot(w2) <span class="comment"># N * D_out</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute loss</span></span><br><span class="line">    loss = np.square(y_pred - y).sum()</span><br><span class="line">    print(it, loss)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Backward pass</span></span><br><span class="line">    <span class="comment"># compute the gradient</span></span><br><span class="line">    grad_y_pred = <span class="number">2.0</span> * (y_pred - y)</span><br><span class="line">    grad_w2 = h_relu.T.dot(grad_y_pred)</span><br><span class="line">    grad_h_relu = grad_y_pred.dot(w2.T)</span><br><span class="line">    grad_h = grad_h_relu.copy()</span><br><span class="line">    grad_h[h&lt;<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    grad_w1 = x.T.dot(grad_h)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># update weights of w1 and w2</span></span><br><span class="line">    w1 -= learning_rate * grad_w1</span><br><span class="line">    w2 -= learning_rate * grad_w2</span><br></pre></td></tr></table></figure><h2 id="PyTorch-Tensors"><a href="#PyTorch-Tensors" class="headerlink" title="PyTorch: Tensors"></a>PyTorch: Tensors</h2><p>è¿™æ¬¡æˆ‘ä»¬ä½¿ç”¨PyTorch tensorsæ¥åˆ›å»ºå‰å‘ç¥ç»ç½‘ç»œï¼Œè®¡ç®—æŸå¤±ï¼Œä»¥åŠåå‘ä¼ æ’­ã€‚</p><p>ä¸€ä¸ªPyTorch Tensorå¾ˆåƒä¸€ä¸ªnumpyçš„ndarrayã€‚ä½†æ˜¯å®ƒå’Œnumpy ndarrayæœ€å¤§çš„åŒºåˆ«æ˜¯ï¼ŒPyTorch Tensorå¯ä»¥åœ¨CPUæˆ–è€…GPUä¸Šè¿ç®—ã€‚å¦‚æœæƒ³è¦åœ¨GPUä¸Šè¿ç®—ï¼Œå°±éœ€è¦æŠŠTensoræ¢æˆcudaç±»å‹ã€‚</p><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># éšæœºåˆ›å»ºä¸€äº›è®­ç»ƒæ•°æ®</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line">w1 = torch.randn(D_in, H)</span><br><span class="line">w2 = torch.randn(H, D_out)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass</span></span><br><span class="line">    h = x.mm(w1) <span class="comment"># N * H</span></span><br><span class="line">    h_relu = h.clamp(min=<span class="number">0</span>) <span class="comment"># N * H</span></span><br><span class="line">    y_pred = h_relu.mm(w2) <span class="comment"># N * D_out</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute loss</span></span><br><span class="line">    loss = (y_pred - y).pow(<span class="number">2</span>).sum().item()</span><br><span class="line">    print(it, loss)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Backward pass</span></span><br><span class="line">    <span class="comment"># compute the gradient</span></span><br><span class="line">    grad_y_pred = <span class="number">2.0</span> * (y_pred - y)</span><br><span class="line">    grad_w2 = h_relu.t().mm(grad_y_pred)</span><br><span class="line">    grad_h_relu = grad_y_pred.mm(w2.t())</span><br><span class="line">    grad_h = grad_h_relu.clone()</span><br><span class="line">    grad_h[h&lt;<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    grad_w1 = x.t().mm(grad_h)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># update weights of w1 and w2</span></span><br><span class="line">    w1 -= learning_rate * grad_w1</span><br><span class="line">    w2 -= learning_rate * grad_w2</span><br></pre></td></tr></table></figure><p>ç®€å•çš„autograd</p><p>In [72]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor(<span class="number">1.</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">w = torch.tensor(<span class="number">2.</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">b = torch.tensor(<span class="number">3.</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">y = w*x + b <span class="comment"># y = 2*1+3</span></span><br><span class="line"></span><br><span class="line">y.backward()</span><br><span class="line"></span><br><span class="line"><span class="comment"># dy / dw = x</span></span><br><span class="line">print(w.grad)</span><br><span class="line">print(x.grad)</span><br><span class="line">print(b.grad)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor(1.)</span><br><span class="line">tensor(2.)</span><br><span class="line">tensor(1.)</span><br></pre></td></tr></table></figure><h2 id="PyTorch-Tensorå’Œautograd"><a href="#PyTorch-Tensorå’Œautograd" class="headerlink" title="PyTorch: Tensorå’Œautograd"></a>PyTorch: Tensorå’Œautograd</h2><p>PyTorchçš„ä¸€ä¸ªé‡è¦åŠŸèƒ½å°±æ˜¯autogradï¼Œä¹Ÿå°±æ˜¯è¯´åªè¦å®šä¹‰äº†forward pass(å‰å‘ç¥ç»ç½‘ç»œ)ï¼Œè®¡ç®—äº†lossä¹‹åï¼ŒPyTorchå¯ä»¥è‡ªåŠ¨æ±‚å¯¼è®¡ç®—æ¨¡å‹æ‰€æœ‰å‚æ•°çš„æ¢¯åº¦ã€‚</p><p>ä¸€ä¸ªPyTorchçš„Tensorè¡¨ç¤ºè®¡ç®—å›¾ä¸­çš„ä¸€ä¸ªèŠ‚ç‚¹ã€‚å¦‚æœ<code>x</code>æ˜¯ä¸€ä¸ªTensorå¹¶ä¸”<code>x.requires_grad=True</code>é‚£ä¹ˆ<code>x.grad</code>æ˜¯å¦ä¸€ä¸ªå‚¨å­˜ç€<code>x</code>å½“å‰æ¢¯åº¦(ç›¸å¯¹äºä¸€ä¸ªscalarï¼Œå¸¸å¸¸æ˜¯loss)çš„å‘é‡ã€‚</p><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># éšæœºåˆ›å»ºä¸€äº›è®­ç»ƒæ•°æ®</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line">w1 = torch.randn(D_in, H, requires_grad=<span class="literal">True</span>)</span><br><span class="line">w2 = torch.randn(H, D_out, requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass</span></span><br><span class="line">    y_pred = x.mm(w1).clamp(min=<span class="number">0</span>).mm(w2)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute loss</span></span><br><span class="line">    loss = (y_pred - y).pow(<span class="number">2</span>).sum() <span class="comment"># computation graph</span></span><br><span class="line">    print(it, loss.item())</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Backward pass</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># update weights of w1 and w2</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        w1 -= learning_rate * w1.grad</span><br><span class="line">        w2 -= learning_rate * w2.grad</span><br><span class="line">        w1.grad.zero_()</span><br><span class="line">        w2.grad.zero_()</span><br></pre></td></tr></table></figure><h2 id="PyTorch-nn"><a href="#PyTorch-nn" class="headerlink" title="PyTorch: nn"></a>PyTorch: nn</h2><p>è¿™æ¬¡æˆ‘ä»¬ä½¿ç”¨PyTorchä¸­nnè¿™ä¸ªåº“æ¥æ„å»ºç½‘ç»œã€‚ ç”¨PyTorch autogradæ¥æ„å»ºè®¡ç®—å›¾å’Œè®¡ç®—gradientsï¼Œ ç„¶åPyTorchä¼šå¸®æˆ‘ä»¬è‡ªåŠ¨è®¡ç®—gradientã€‚</p><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># éšæœºåˆ›å»ºä¸€äº›è®­ç»ƒæ•°æ®</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line">model = torch.nn.Sequential(</span><br><span class="line">    torch.nn.Linear(D_in, H, bias=<span class="literal">False</span>), <span class="comment"># w_1 * x + b_1</span></span><br><span class="line">    torch.nn.ReLU(),</span><br><span class="line">    torch.nn.Linear(H, D_out, bias=<span class="literal">False</span>),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">torch.nn.init.normal_(model[<span class="number">0</span>].weight)</span><br><span class="line">torch.nn.init.normal_(model[<span class="number">2</span>].weight)</span><br><span class="line"></span><br><span class="line"><span class="comment"># model = model.cuda()</span></span><br><span class="line"></span><br><span class="line">loss_fn = nn.MSELoss(reduction=<span class="string">'sum'</span>)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass</span></span><br><span class="line">    y_pred = model(x) <span class="comment"># model.forward() </span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute loss</span></span><br><span class="line">    loss = loss_fn(y_pred, y) <span class="comment"># computation graph</span></span><br><span class="line">    print(it, loss.item())</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Backward pass</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># update weights of w1 and w2</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> model.parameters(): <span class="comment"># param (tensor, grad)</span></span><br><span class="line">            param -= learning_rate * param.grad</span><br><span class="line">            </span><br><span class="line">    model.zero_grad()</span><br></pre></td></tr></table></figure><p>In [113]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model[0].weight</span><br></pre></td></tr></table></figure><p>Out[113]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Parameter containing:</span><br><span class="line">tensor([[-0.0218,  0.0212,  0.0243,  ...,  0.0230,  0.0247,  0.0168],</span><br><span class="line">        [-0.0144,  0.0177, -0.0221,  ...,  0.0161,  0.0098, -0.0172],</span><br><span class="line">        [ 0.0086, -0.0122, -0.0298,  ..., -0.0236, -0.0187,  0.0295],</span><br><span class="line">        ...,</span><br><span class="line">        [ 0.0266, -0.0008, -0.0141,  ...,  0.0018,  0.0319, -0.0129],</span><br><span class="line">        [ 0.0296, -0.0005,  0.0115,  ...,  0.0141, -0.0088, -0.0106],</span><br><span class="line">        [ 0.0289, -0.0077,  0.0239,  ..., -0.0166, -0.0156, -0.0235]],</span><br><span class="line">       requires_grad=True)</span><br></pre></td></tr></table></figure><h2 id="PyTorch-optim"><a href="#PyTorch-optim" class="headerlink" title="PyTorch: optim"></a>PyTorch: optim</h2><p>è¿™ä¸€æ¬¡æˆ‘ä»¬ä¸å†æ‰‹åŠ¨æ›´æ–°æ¨¡å‹çš„weights,è€Œæ˜¯ä½¿ç”¨optimè¿™ä¸ªåŒ…æ¥å¸®åŠ©æˆ‘ä»¬æ›´æ–°å‚æ•°ã€‚ optimè¿™ä¸ªpackageæä¾›äº†å„ç§ä¸åŒçš„æ¨¡å‹ä¼˜åŒ–æ–¹æ³•ï¼ŒåŒ…æ‹¬SGD+momentum, RMSProp, Adamç­‰ç­‰ã€‚</p><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># éšæœºåˆ›å»ºä¸€äº›è®­ç»ƒæ•°æ®</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line">model = torch.nn.Sequential(</span><br><span class="line">    torch.nn.Linear(D_in, H, bias=<span class="literal">False</span>), <span class="comment"># w_1 * x + b_1</span></span><br><span class="line">    torch.nn.ReLU(),</span><br><span class="line">    torch.nn.Linear(H, D_out, bias=<span class="literal">False</span>),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">torch.nn.init.normal_(model[<span class="number">0</span>].weight)</span><br><span class="line">torch.nn.init.normal_(model[<span class="number">2</span>].weight)</span><br><span class="line"></span><br><span class="line"><span class="comment"># model = model.cuda()</span></span><br><span class="line"></span><br><span class="line">loss_fn = nn.MSELoss(reduction=<span class="string">'sum'</span>)</span><br><span class="line"><span class="comment"># learning_rate = 1e-4</span></span><br><span class="line"><span class="comment"># optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)</span></span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass</span></span><br><span class="line">    y_pred = model(x) <span class="comment"># model.forward() </span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute loss</span></span><br><span class="line">    loss = loss_fn(y_pred, y) <span class="comment"># computation graph</span></span><br><span class="line">    print(it, loss.item())</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    <span class="comment"># Backward pass</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># update model parameters</span></span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure><h2 id="PyTorch-è‡ªå®šä¹‰-nn-Modules"><a href="#PyTorch-è‡ªå®šä¹‰-nn-Modules" class="headerlink" title="PyTorch: è‡ªå®šä¹‰ nn Modules"></a>PyTorch: è‡ªå®šä¹‰ nn Modules</h2><p>æˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸€ä¸ªæ¨¡å‹ï¼Œè¿™ä¸ªæ¨¡å‹ç»§æ‰¿è‡ªnn.Moduleç±»ã€‚å¦‚æœéœ€è¦å®šä¹‰ä¸€ä¸ªæ¯”Sequentialæ¨¡å‹æ›´åŠ å¤æ‚çš„æ¨¡å‹ï¼Œå°±éœ€è¦å®šä¹‰nn.Moduleæ¨¡å‹ã€‚</p><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># éšæœºåˆ›å»ºä¸€äº›è®­ç»ƒæ•°æ®</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TwoLayerNet</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, D_in, H, D_out)</span>:</span></span><br><span class="line">        super(TwoLayerNet, self).__init__()</span><br><span class="line">        <span class="comment"># define the model architecture</span></span><br><span class="line">        self.linear1 = torch.nn.Linear(D_in, H, bias=<span class="literal">False</span>)</span><br><span class="line">        self.linear2 = torch.nn.Linear(H, D_out, bias=<span class="literal">False</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        y_pred = self.linear2(self.linear1(x).clamp(min=<span class="number">0</span>))</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br><span class="line">model = TwoLayerNet(D_in, H, D_out)</span><br><span class="line">loss_fn = nn.MSELoss(reduction=<span class="string">'sum'</span>)</span><br><span class="line">learning_rate = <span class="number">1e-4</span></span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass</span></span><br><span class="line">    y_pred = model(x) <span class="comment"># model.forward() </span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute loss</span></span><br><span class="line">    loss = loss_fn(y_pred, y) <span class="comment"># computation graph</span></span><br><span class="line">    print(it, loss.item())</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    <span class="comment"># Backward pass</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># update model parameters</span></span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>æœ´ç´ è´å¶æ–¯</title>
      <link href="/2020/06/08/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/"/>
      <url>/2020/06/08/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/</url>
      
        <content type="html"><![CDATA[<h1 id="æœ´ç´ è´å¶æ–¯"><a href="#æœ´ç´ è´å¶æ–¯" class="headerlink" title="æœ´ç´ è´å¶æ–¯"></a>æœ´ç´ è´å¶æ–¯</h1><h2 id="1-å¼•è¨€"><a href="#1-å¼•è¨€" class="headerlink" title="1. å¼•è¨€"></a>1. å¼•è¨€</h2><p>è´å¶æ–¯æ–¹æ³•æ˜¯ä¸€ä¸ªå†å²æ‚ ä¹…ï¼Œæœ‰ç€åšå®çš„ç†è®ºåŸºç¡€çš„æ–¹æ³•ï¼ŒåŒæ—¶å¤„ç†å¾ˆå¤šé—®é¢˜æ—¶ç›´æ¥è€Œåˆé«˜æ•ˆï¼Œå¾ˆå¤šé«˜çº§è‡ªç„¶è¯­è¨€å¤„ç†æ¨¡å‹ä¹Ÿå¯ä»¥ä»å®ƒæ¼”åŒ–è€Œæ¥ã€‚å› æ­¤ï¼Œå­¦ä¹ è´å¶æ–¯æ–¹æ³•ï¼Œæ˜¯ç ”ç©¶è‡ªç„¶è¯­è¨€å¤„ç†é—®é¢˜çš„ä¸€ä¸ªéå¸¸å¥½çš„åˆ‡å…¥å£ã€‚</p><h2 id="2-è´å¶æ–¯å…¬å¼"><a href="#2-è´å¶æ–¯å…¬å¼" class="headerlink" title="2. è´å¶æ–¯å…¬å¼"></a>2. è´å¶æ–¯å…¬å¼</h2><p>è´å¶æ–¯å…¬å¼å°±ä¸€è¡Œï¼š</p><blockquote><p>$$<br>P(Y|X)=P(X|Y)P(Y)/P(X)<br>$$</p></blockquote><p>è€Œå®ƒå…¶å®æ˜¯ç”±ä»¥ä¸‹çš„è”åˆæ¦‚ç‡å…¬å¼æ¨å¯¼å‡ºæ¥ï¼š<br>$$<br>P(Y,X)=P(Y|X)P(X)=P(X|Y)P(Y)<br>$$<br>å…¶ä¸­P(Y)å«åšå…ˆéªŒæ¦‚ç‡ï¼ŒP(Y|X)å«åšåéªŒæ¦‚ç‡ï¼ŒP(Y,X)å«åšè”åˆæ¦‚ç‡ã€‚</p><p>æ²¡äº†ï¼Œè´å¶æ–¯æœ€æ ¸å¿ƒçš„å…¬å¼å°±è¿™ä¹ˆäº›ã€‚</p><h2 id="3-ç”¨æœºå™¨å­¦ä¹ çš„è§†è§’ç†è§£è´å¶æ–¯å…¬å¼"><a href="#3-ç”¨æœºå™¨å­¦ä¹ çš„è§†è§’ç†è§£è´å¶æ–¯å…¬å¼" class="headerlink" title="3. ç”¨æœºå™¨å­¦ä¹ çš„è§†è§’ç†è§£è´å¶æ–¯å…¬å¼"></a>3. ç”¨æœºå™¨å­¦ä¹ çš„è§†è§’ç†è§£è´å¶æ–¯å…¬å¼</h2><p>åœ¨æœºå™¨å­¦ä¹ çš„è§†è§’ä¸‹ï¼Œæˆ‘ä»¬æŠŠXç†è§£æˆ<strong>â€œå…·æœ‰æŸç‰¹å¾â€</strong>ï¼ŒæŠŠYç†è§£æˆ<strong>â€œç±»åˆ«æ ‡ç­¾â€</strong>(ä¸€èˆ¬æœºå™¨å­¦ä¹ ä¸ºé¢˜ä¸­éƒ½æ˜¯<code>X=&gt;ç‰¹å¾</code>, <code>Y=&gt;ç»“æœ</code>å¯¹å§)ã€‚åœ¨æœ€ç®€å•çš„äºŒåˆ†ç±»é—®é¢˜(<code>æ˜¯</code>ä¸<code>å¦</code>åˆ¤å®š)ä¸‹ï¼Œæˆ‘ä»¬å°†Yç†è§£æˆ<strong>â€œå±äºæŸç±»</strong>â€çš„æ ‡ç­¾ã€‚äºæ˜¯è´å¶æ–¯å…¬å¼å°±å˜å½¢æˆäº†ä¸‹é¢çš„æ ·å­:</p><blockquote><p>P(â€œå±äºæŸç±»â€|â€œå…·æœ‰æŸç‰¹å¾â€)=P(â€œå…·æœ‰æŸç‰¹å¾â€|â€œå±äºæŸç±»â€)P(â€œå±äºæŸç±»â€)P(â€œå…·æœ‰æŸç‰¹å¾â€)</p></blockquote><p>æˆ‘ä»¬ç®€åŒ–è§£é‡Šä¸€ä¸‹ä¸Šè¿°å…¬å¼ï¼š</p><blockquote><p>P(â€œå±äºæŸç±»â€|â€œå…·æœ‰æŸç‰¹å¾â€)=åœ¨å·²çŸ¥æŸæ ·æœ¬â€œå…·æœ‰æŸç‰¹å¾â€çš„æ¡ä»¶ä¸‹ï¼Œè¯¥æ ·æœ¬â€œå±äºæŸç±»â€çš„æ¦‚ç‡ã€‚æ‰€ä»¥å«åš<strong>ã€åéªŒæ¦‚ç‡ã€</strong>ã€‚<br>P(â€œå…·æœ‰æŸç‰¹å¾â€|â€œå±äºæŸç±»â€)=åœ¨å·²çŸ¥æŸæ ·æœ¬â€œå±äºæŸç±»â€çš„æ¡ä»¶ä¸‹ï¼Œè¯¥æ ·æœ¬â€œå…·æœ‰æŸç‰¹å¾â€çš„æ¦‚ç‡ã€‚<br>P(â€œå±äºæŸç±»â€)=ï¼ˆåœ¨æœªçŸ¥æŸæ ·æœ¬å…·æœ‰è¯¥â€œå…·æœ‰æŸç‰¹å¾â€çš„æ¡ä»¶ä¸‹ï¼Œï¼‰è¯¥æ ·æœ¬â€œå±äºæŸç±»â€çš„æ¦‚ç‡ã€‚æ‰€ä»¥å«åš<strong>ã€å…ˆéªŒæ¦‚ç‡ã€</strong>ã€‚<br>P(â€œå…·æœ‰æŸç‰¹å¾â€)=(åœ¨æœªçŸ¥æŸæ ·æœ¬â€œå±äºæŸç±»â€çš„æ¡ä»¶ä¸‹ï¼Œ)è¯¥æ ·æœ¬â€œå…·æœ‰æŸç‰¹å¾â€çš„æ¦‚ç‡ã€‚</p></blockquote><p>è€Œæˆ‘ä»¬äºŒåˆ†ç±»é—®é¢˜çš„æœ€ç»ˆç›®çš„å°±æ˜¯è¦<strong>åˆ¤æ–­P(â€œå±äºæŸç±»â€|â€œå…·æœ‰æŸç‰¹å¾â€)æ˜¯å¦å¤§äº1/2</strong>å°±å¤Ÿäº†ã€‚è´å¶æ–¯æ–¹æ³•æŠŠè®¡ç®—<strong>â€œå…·æœ‰æŸç‰¹å¾çš„æ¡ä»¶ä¸‹å±äºæŸç±»â€</strong>çš„æ¦‚ç‡è½¬æ¢æˆéœ€è¦è®¡ç®—<strong>â€œå±äºæŸç±»çš„æ¡ä»¶ä¸‹å…·æœ‰æŸç‰¹å¾â€</strong>çš„æ¦‚ç‡ï¼Œè€Œåè€…è·å–æ–¹æ³•å°±ç®€å•å¤šäº†ï¼Œæˆ‘ä»¬åªéœ€è¦æ‰¾åˆ°ä¸€äº›åŒ…å«å·²çŸ¥ç‰¹å¾æ ‡ç­¾çš„æ ·æœ¬ï¼Œå³å¯è¿›è¡Œè®­ç»ƒã€‚è€Œæ ·æœ¬çš„ç±»åˆ«æ ‡ç­¾éƒ½æ˜¯æ˜ç¡®çš„ï¼Œæ‰€ä»¥è´å¶æ–¯æ–¹æ³•åœ¨æœºå™¨å­¦ä¹ é‡Œå±äºæœ‰ç›‘ç£å­¦ä¹ æ–¹æ³•ã€‚</p><p>è¿™é‡Œå†è¡¥å……ä¸€ä¸‹ï¼Œä¸€èˆ¬<strong>ã€å…ˆéªŒæ¦‚ç‡ã€ã€ã€åéªŒæ¦‚ç‡ã€æ˜¯ç›¸å¯¹</strong>å‡ºç°çš„ï¼Œæ¯”å¦‚P(Y)ä¸P(Y|X)æ˜¯å…³äºYçš„å…ˆéªŒæ¦‚ç‡ä¸åéªŒæ¦‚ç‡ï¼ŒP(X)ä¸P(X|Y)æ˜¯å…³äºXçš„å…ˆéªŒæ¦‚ç‡ä¸åéªŒæ¦‚ç‡ã€‚</p><h2 id="4-åƒåœ¾é‚®ä»¶è¯†åˆ«"><a href="#4-åƒåœ¾é‚®ä»¶è¯†åˆ«" class="headerlink" title="4. åƒåœ¾é‚®ä»¶è¯†åˆ«"></a>4. åƒåœ¾é‚®ä»¶è¯†åˆ«</h2><p>ä¸¾ä¸ªä¾‹å­å¥½å•¦ï¼Œæˆ‘ä»¬ç°åœ¨è¦å¯¹é‚®ä»¶è¿›è¡Œåˆ†ç±»ï¼Œè¯†åˆ«åƒåœ¾é‚®ä»¶å’Œæ™®é€šé‚®ä»¶ï¼Œå¦‚æœæˆ‘ä»¬é€‰æ‹©ä½¿ç”¨æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ï¼Œé‚£ç›®æ ‡å°±æ˜¯<strong>åˆ¤æ–­P(â€œåƒåœ¾é‚®ä»¶â€|â€œå…·æœ‰æŸç‰¹å¾â€)æ˜¯å¦å¤§äº1/2</strong>ã€‚ç°åœ¨å‡è®¾æˆ‘ä»¬æœ‰åƒåœ¾é‚®ä»¶å’Œæ­£å¸¸é‚®ä»¶å„1ä¸‡å°ä½œä¸ºè®­ç»ƒé›†ã€‚éœ€è¦åˆ¤æ–­ä»¥ä¸‹è¿™ä¸ªé‚®ä»¶æ˜¯å¦å±äºåƒåœ¾é‚®ä»¶ï¼š</p><blockquote><p>â€œæˆ‘å¸å¯åŠç†æ­£è§„å‘ç¥¨ï¼ˆä¿çœŸï¼‰17%å¢å€¼ç¨å‘ç¥¨ç‚¹æ•°ä¼˜æƒ ï¼â€</p></blockquote><p>ä¹Ÿå°±æ˜¯<strong>åˆ¤æ–­æ¦‚ç‡P(â€œåƒåœ¾é‚®ä»¶â€|â€œæˆ‘å¸å¯åŠç†æ­£è§„å‘ç¥¨ï¼ˆä¿çœŸï¼‰17%å¢å€¼ç¨å‘ç¥¨ç‚¹æ•°ä¼˜æƒ ï¼â€)æ˜¯å¦å¤§äº1/2</strong>ã€‚</p><p>å’³å’³ï¼Œæœ‰æœ¨æœ‰å‘ç°ï¼Œè½¬æ¢æˆçš„è¿™ä¸ªæ¦‚ç‡ï¼Œè®¡ç®—çš„æ–¹æ³•ï¼šå°±æ˜¯å†™ä¸ªè®¡æ•°å™¨ï¼Œç„¶å+1 +1 +1ç»Ÿè®¡å‡ºæ‰€æœ‰åƒåœ¾é‚®ä»¶å’Œæ­£å¸¸é‚®ä»¶ä¸­å‡ºç°è¿™å¥è¯çš„æ¬¡æ•°å•Šï¼ï¼ï¼å¥½ï¼Œå…·ä½“ç‚¹è¯´ï¼š</p><blockquote><p>P(â€œåƒåœ¾é‚®ä»¶â€|â€œæˆ‘å¸å¯åŠç†æ­£è§„å‘ç¥¨ï¼ˆä¿çœŸï¼‰17%å¢å€¼ç¨å‘ç¥¨ç‚¹æ•°ä¼˜æƒ ï¼â€) =åƒåœ¾é‚®ä»¶ä¸­å‡ºç°è¿™å¥è¯çš„æ¬¡æ•°åƒåœ¾é‚®ä»¶ä¸­å‡ºç°è¿™å¥è¯çš„æ¬¡æ•°+æ­£å¸¸é‚®ä»¶ä¸­å‡ºç°è¿™å¥è¯çš„æ¬¡æ•°</p></blockquote><h2 id="5-åˆ†è¯"><a href="#5-åˆ†è¯" class="headerlink" title="5. åˆ†è¯"></a>5. åˆ†è¯</h2><p>ä¸€ä¸ªå¾ˆæ‚²å“€ä½†æ˜¯å¾ˆç°å®çš„ç»“è®ºï¼š <strong>è®­ç»ƒé›†æ˜¯æœ‰é™çš„ï¼Œè€Œå¥å­çš„å¯èƒ½æ€§åˆ™æ˜¯æ— é™çš„ã€‚æ‰€ä»¥è¦†ç›–æ‰€æœ‰å¥å­å¯èƒ½æ€§çš„è®­ç»ƒé›†æ˜¯ä¸å­˜åœ¨çš„ã€‚</strong></p><p>æ‰€ä»¥è§£å†³æ–¹æ³•æ˜¯ï¼Ÿ <strong>å¥å­çš„å¯èƒ½æ€§æ— é™ï¼Œä½†æ˜¯è¯è¯­å°±é‚£ä¹ˆäº›ï¼ï¼</strong>æ±‰è¯­å¸¸ç”¨å­—2500ä¸ªï¼Œå¸¸ç”¨è¯è¯­ä¹Ÿå°±56000ä¸ª(ä½ ç»ˆäºæ˜ç™½å°å­¦è¯­æ–‡è€å¸ˆçš„ç”¨å¿ƒè‰¯è‹¦äº†)ã€‚æŒ‰äººä»¬çš„ç»éªŒç†è§£ï¼Œä¸¤å¥è¯æ„æ€ç›¸è¿‘å¹¶ä¸å¼ºæ±‚éå¾—æ¯ä¸ªå­—ã€è¯è¯­éƒ½ä¸€æ ·ã€‚æ¯”å¦‚<strong>â€œæˆ‘å¸å¯åŠç†æ­£è§„å‘ç¥¨ï¼Œ17%å¢å€¼ç¨å‘ç¥¨ç‚¹æ•°ä¼˜æƒ ï¼â€</strong>ï¼Œè¿™å¥è¯å°±æ¯”ä¹‹å‰é‚£å¥è¯å°‘äº†<strong>â€œï¼ˆä¿çœŸï¼‰â€</strong>è¿™ä¸ªè¯ï¼Œä½†æ˜¯æ„æ€åŸºæœ¬ä¸€æ ·ã€‚å¦‚æœæŠŠè¿™äº›æƒ…å†µä¹Ÿè€ƒè™‘è¿›æ¥ï¼Œé‚£æ ·æœ¬æ•°é‡å°±ä¼šå¢åŠ ï¼Œè¿™å°±æ–¹ä¾¿æˆ‘ä»¬è®¡ç®—äº†ã€‚</p><p>äºæ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥ä¸æ‹¿å¥å­ä½œä¸ºç‰¹å¾ï¼Œè€Œæ˜¯æ‹¿å¥å­é‡Œé¢çš„è¯è¯­ï¼ˆç»„åˆï¼‰ä½œä¸ºç‰¹å¾å»è€ƒè™‘ã€‚æ¯”å¦‚<strong>â€œæ­£è§„å‘ç¥¨â€</strong>å¯ä»¥ä½œä¸ºä¸€ä¸ªå•ç‹¬çš„è¯è¯­ï¼Œ<strong>â€œå¢å€¼ç¨â€</strong>ä¹Ÿå¯ä»¥ä½œä¸ºä¸€ä¸ªå•ç‹¬çš„è¯è¯­ç­‰ç­‰ã€‚</p><blockquote><p>å¥å­<strong>â€œæˆ‘å¸å¯åŠç†æ­£è§„å‘ç¥¨ï¼Œ17%å¢å€¼ç¨å‘ç¥¨ç‚¹æ•°ä¼˜æƒ ï¼â€å°±å¯ä»¥å˜æˆï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€,â€œä¿çœŸâ€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œç‚¹æ•°â€,â€œä¼˜æƒ â€)ï¼‰</strong>ã€‚</p></blockquote><p>äºæ˜¯ä½ æ¥è§¦åˆ°äº†ä¸­æ–‡NLPä¸­ï¼Œæœ€æœ€æœ€é‡è¦çš„æŠ€æœ¯ä¹‹ä¸€ï¼š<strong>åˆ†è¯</strong>ï¼ï¼ï¼ä¹Ÿå°±æ˜¯<strong>æŠŠä¸€æ•´å¥è¯æ‹†åˆ†æˆæ›´ç»†ç²’åº¦çš„è¯è¯­æ¥è¿›è¡Œè¡¨ç¤º</strong>ã€‚å¦å¤–ï¼Œåˆ†è¯ä¹‹å<strong>å»é™¤æ ‡ç‚¹ç¬¦å·ã€æ•°å­—ç”šè‡³æ— å…³æˆåˆ†(åœç”¨è¯)æ˜¯ç‰¹å¾é¢„å¤„ç†ä¸­çš„ä¸€é¡¹æŠ€æœ¯</strong>ã€‚</p><p><strong>ä¸­æ–‡åˆ†è¯æ˜¯ä¸€ä¸ªä¸“é—¨çš„æŠ€æœ¯é¢†åŸŸ(æˆ‘ä¸ä¼šå‘Šè¯‰ä½ æŸæœç´¢å¼•æ“å‚ç ç –å·¥æœ‰ä¸“é—¨åšåˆ†è¯çš„ï¼ï¼ï¼)ï¼Œä¸Šè¿‡ä¹‹å‰è¯¾ç¨‹çš„åŒå­¦éƒ½çŸ¥é“pythonæœ‰ä¸€ä¸ªéå¸¸æ–¹ä¾¿çš„åˆ†è¯å·¥å…·jiebaï¼Œå‡å®šæˆ‘ä»¬å·²ç»å®Œæˆåˆ†è¯å·¥ä½œï¼š</strong></p><p>æˆ‘ä»¬è§‚å¯Ÿï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€,â€œä¿çœŸâ€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œç‚¹æ•°â€,â€œä¼˜æƒ â€)ï¼Œ<strong>è¿™å¯ä»¥ç†è§£æˆä¸€ä¸ªå‘é‡ï¼šå‘é‡çš„æ¯ä¸€ç»´åº¦éƒ½è¡¨ç¤ºç€è¯¥ç‰¹å¾è¯åœ¨æ–‡æœ¬ä¸­çš„ç‰¹å®šä½ç½®å­˜åœ¨ã€‚è¿™ç§å°†ç‰¹å¾æ‹†åˆ†æˆæ›´å°çš„å•å…ƒï¼Œä¾æ®è¿™äº›æ›´çµæ´»ã€æ›´ç»†ç²’åº¦çš„ç‰¹å¾è¿›è¡Œåˆ¤æ–­çš„æ€ç»´æ–¹å¼ï¼Œåœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸æœºå™¨å­¦ä¹ ä¸­éƒ½æ˜¯éå¸¸å¸¸è§åˆæœ‰æ•ˆçš„ã€‚</strong></p><p>å› æ­¤è´å¶æ–¯å…¬å¼å°±å˜æˆäº†ï¼š</p><blockquote><p>P(â€œåƒåœ¾é‚®ä»¶â€|ï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€,â€œä¿çœŸâ€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œç‚¹æ•°â€,â€œä¼˜æƒ â€)ï¼‰ =P(ï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€,â€œä¿çœŸâ€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œç‚¹æ•°â€,â€œä¼˜æƒ â€)|â€åƒåœ¾é‚®ä»¶â€ï¼‰P(â€œåƒåœ¾é‚®ä»¶â€)P(ï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€,â€œä¿çœŸâ€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œç‚¹æ•°â€,â€œä¼˜æƒ â€))</p><p>P(â€œæ­£å¸¸é‚®ä»¶â€|ï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€,â€œä¿çœŸâ€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œç‚¹æ•°â€,â€œä¼˜æƒ â€)ï¼‰ =P(ï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€,â€œä¿çœŸâ€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œç‚¹æ•°â€,â€œä¼˜æƒ â€)|â€æ­£å¸¸é‚®ä»¶â€ï¼‰P(â€œæ­£å¸¸é‚®ä»¶â€)P(ï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€,â€œä¿çœŸâ€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œç‚¹æ•°â€,â€œä¼˜æƒ â€))</p></blockquote><h2 id="6-æ¡ä»¶ç‹¬ç«‹å‡è®¾"><a href="#6-æ¡ä»¶ç‹¬ç«‹å‡è®¾" class="headerlink" title="6. æ¡ä»¶ç‹¬ç«‹å‡è®¾"></a>6. æ¡ä»¶ç‹¬ç«‹å‡è®¾</h2><p>ä¸‹é¢æˆ‘ä»¬é©¬ä¸Šä¼šçœ‹åˆ°ä¸€ä¸ªéå¸¸ç®€å•ç²—æš´çš„å‡è®¾ã€‚</p><p>æ¦‚ç‡P(ï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€,â€œä¿çœŸâ€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œç‚¹æ•°â€,â€œä¼˜æƒ â€)|â€åƒåœ¾é‚®ä»¶â€ï¼‰ä¾æ—§ä¸å¤Ÿå¥½æ±‚ï¼Œæˆ‘ä»¬å¼•è¿›ä¸€ä¸ª<strong>å¾ˆæœ´ç´ çš„è¿‘ä¼¼</strong>ã€‚ä¸ºäº†è®©å…¬å¼æ˜¾å¾—æ›´åŠ ç´§å‡‘ï¼Œæˆ‘ä»¬ä»¤å­—æ¯Sè¡¨ç¤ºâ€œåƒåœ¾é‚®ä»¶â€,ä»¤å­—æ¯Hè¡¨ç¤ºâ€œæ­£å¸¸é‚®ä»¶â€ã€‚è¿‘ä¼¼å…¬å¼å¦‚ä¸‹ï¼š</p><blockquote><p>P(ï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€,â€œä¿çœŸâ€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œç‚¹æ•°â€,â€œä¼˜æƒ â€)|Sï¼‰<br>=P(â€œæˆ‘â€|Sï¼‰Ã—P(â€œå¸â€|Sï¼‰Ã—P(â€œå¯â€|Sï¼‰Ã—P(â€œåŠç†â€|Sï¼‰Ã—P(â€œæ­£è§„å‘ç¥¨â€|Sï¼‰ Ã—P(â€œä¿çœŸâ€|Sï¼‰Ã—P(â€œå¢å€¼ç¨â€|Sï¼‰Ã—P(â€œå‘ç¥¨â€|Sï¼‰Ã—P(â€œç‚¹æ•°â€|Sï¼‰Ã—P(â€œä¼˜æƒ â€|S)</p></blockquote><p>è¿™å°±æ˜¯ä¼ è¯´ä¸­çš„<strong>æ¡ä»¶ç‹¬ç«‹å‡è®¾</strong>ã€‚åŸºäºâ€œæ­£å¸¸é‚®ä»¶â€çš„æ¡ä»¶ç‹¬ç«‹å‡è®¾çš„å¼å­ä¸ä¸Šå¼ç±»ä¼¼ï¼Œæ­¤å¤„çœå»ã€‚æ¥ç€ï¼Œå°†æ¡ä»¶ç‹¬ç«‹å‡è®¾ä»£å…¥ä¸Šé¢ä¸¤ä¸ªç›¸åäº‹ä»¶çš„è´å¶æ–¯å…¬å¼ã€‚</p><p>äºæ˜¯æˆ‘ä»¬å°±åªéœ€è¦æ¯”è¾ƒä»¥ä¸‹ä¸¤ä¸ªå¼å­çš„å¤§å°ï¼š</p><blockquote><p>C=P(â€œæˆ‘â€|S)P(â€œå¸â€|S)P(â€œå¯â€|S)P(â€œåŠç†â€|S)P(â€œæ­£è§„å‘ç¥¨â€|S) Ã—P(â€œä¿çœŸâ€|S)P(â€œå¢å€¼ç¨â€|S)P(â€œå‘ç¥¨â€|S)P(â€œç‚¹æ•°â€|S)P(â€œä¼˜æƒ â€|S)P(â€œåƒåœ¾é‚®ä»¶â€) Câ¯â¯â¯â¯=P(â€œæˆ‘â€|H)P(â€œå¸â€|H)P(â€œå¯â€|H)P(â€œåŠç†â€|H)P(â€œæ­£è§„å‘ç¥¨â€|H) Ã—P(â€œä¿çœŸâ€|H)P(â€œå¢å€¼ç¨â€|H)P(â€œå‘ç¥¨â€|H)P(â€œç‚¹æ•°â€|H)P(â€œä¼˜æƒ â€|H)P(â€œæ­£å¸¸é‚®ä»¶â€)</p></blockquote><p>å‰(wo)å®³(cao)ï¼é…±ç´«å¤„ç†å<strong>å¼å­ä¸­çš„æ¯ä¸€é¡¹éƒ½ç‰¹åˆ«å¥½æ±‚</strong>ï¼åªéœ€è¦<strong>åˆ†åˆ«ç»Ÿè®¡å„ç±»é‚®ä»¶ä¸­è¯¥å…³é”®è¯å‡ºç°çš„æ¦‚ç‡</strong>å°±å¯ä»¥äº†ï¼ï¼ï¼æ¯”å¦‚ï¼š</p><blockquote><p>P(â€œå‘ç¥¨â€|Sï¼‰=åƒåœ¾é‚®ä»¶ä¸­æ‰€æœ‰â€œå‘ç¥¨â€çš„æ¬¡æ•°åƒåœ¾é‚®ä»¶ä¸­æ‰€æœ‰è¯è¯­çš„æ¬¡æ•°</p></blockquote><p>ç»Ÿè®¡æ¬¡æ•°éå¸¸æ–¹ä¾¿ï¼Œè€Œä¸”æ ·æœ¬æ•°é‡è¶³å¤Ÿå¤§ï¼Œç®—å‡ºæ¥çš„æ¦‚ç‡æ¯”è¾ƒæ¥è¿‘çœŸå®ã€‚äºæ˜¯åƒåœ¾é‚®ä»¶è¯†åˆ«çš„é—®é¢˜å°±å¯è§£äº†ã€‚</p><h2 id="7-æœ´ç´ è´å¶æ–¯-Naive-Bayes-ï¼Œâ€œNaiveâ€åœ¨ä½•å¤„ï¼Ÿ"><a href="#7-æœ´ç´ è´å¶æ–¯-Naive-Bayes-ï¼Œâ€œNaiveâ€åœ¨ä½•å¤„ï¼Ÿ" class="headerlink" title="7. æœ´ç´ è´å¶æ–¯(Naive Bayes)ï¼Œâ€œNaiveâ€åœ¨ä½•å¤„ï¼Ÿ"></a>7. æœ´ç´ è´å¶æ–¯(Naive Bayes)ï¼Œâ€œNaiveâ€åœ¨ä½•å¤„ï¼Ÿ</h2><p><strong>åŠ ä¸Šæ¡ä»¶ç‹¬ç«‹å‡è®¾çš„è´å¶æ–¯æ–¹æ³•å°±æ˜¯æœ´ç´ è´å¶æ–¯æ–¹æ³•ï¼ˆNaive Bayesï¼‰ã€‚</strong> Naiveçš„å‘éŸ³æ˜¯â€œä¹ƒä¸€æ±¡â€ï¼Œæ„æ€æ˜¯â€œæœ´ç´ çš„â€ã€â€œå¹¼ç¨šçš„â€ã€<strong>â€œè ¢è ¢çš„â€</strong>ã€‚å’³å’³ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œå¤§ç¥ä»¬å–åè¯´è¯¥æ–¹æ³•æ˜¯ä¸€ç§æ¯”è¾ƒèŒè ¢çš„æ–¹æ³•ï¼Œä¸ºå•¥ï¼Ÿ</p><p>å°†å¥å­ï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€) ä¸­çš„ ï¼ˆâ€œæˆ‘â€,â€œå¸â€ï¼‰ä¸ï¼ˆâ€œæ­£è§„å‘ç¥¨â€ï¼‰è°ƒæ¢ä¸€ä¸‹é¡ºåºï¼Œå°±å˜æˆäº†ä¸€ä¸ªæ–°çš„å¥å­ï¼ˆâ€œæ­£è§„å‘ç¥¨â€,â€œå¯â€,â€œåŠç†â€, â€œæˆ‘â€, â€œå¸â€)ã€‚æ–°å¥å­ä¸æ—§å¥å­çš„æ„æ€å®Œå…¨ä¸åŒã€‚<strong>ä½†ç”±äºä¹˜æ³•äº¤æ¢å¾‹ï¼Œæœ´ç´ è´å¶æ–¯æ–¹æ³•ä¸­ç®—å‡ºæ¥äºŒè€…çš„æ¡ä»¶æ¦‚ç‡å®Œå…¨ä¸€æ ·ï¼</strong>è®¡ç®—è¿‡ç¨‹å¦‚ä¸‹ï¼š</p><blockquote><p>P(ï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€)|S) =P(â€œæˆ‘â€|S)P(â€œå¸â€|S)P(â€œå¯â€|S)P(â€œåŠç†â€|S)P(â€œæ­£è§„å‘ç¥¨â€|S) =P(â€œæ­£è§„å‘ç¥¨â€|S)P(â€œå¯â€|S)P(â€œåŠç†â€|S)P(â€œæˆ‘â€|S)P(â€œå¸â€|Sï¼‰ =P(ï¼ˆâ€œæ­£è§„å‘ç¥¨â€,â€œå¯â€,â€œåŠç†â€,â€œæˆ‘â€,â€œå¸â€)|S)</p></blockquote><p><strong>ä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨æœ´ç´ è´å¶æ–¯çœ¼é‡Œï¼Œâ€œæˆ‘å¸å¯åŠç†æ­£è§„å‘ç¥¨â€ä¸â€œæ­£è§„å‘ç¥¨å¯åŠç†æˆ‘å¸â€å®Œå…¨ç›¸åŒã€‚æœ´ç´ è´å¶æ–¯å¤±å»äº†è¯è¯­ä¹‹é—´çš„é¡ºåºä¿¡æ¯ã€‚</strong>è¿™å°±ç›¸å½“äºæŠŠæ‰€æœ‰çš„è¯æ±‡æ‰”è¿›åˆ°ä¸€ä¸ªè¢‹å­é‡Œéšä¾¿æ…å’Œï¼Œè´å¶æ–¯éƒ½è®¤ä¸ºå®ƒä»¬ä¸€æ ·ã€‚å› æ­¤è¿™ç§æƒ…å†µä¹Ÿç§°ä½œ<strong>è¯è¢‹å­æ¨¡å‹(bag of words)</strong>ã€‚</p><p><img src="blob:file:///f3e451e8-1f8f-4c4c-b15f-25793dff88ca" alt="è¯è¢‹å­é…å›¾"></p><p>è¯è¢‹å­æ¨¡å‹ä¸äººä»¬çš„æ—¥å¸¸ç»éªŒå®Œå…¨ä¸åŒã€‚æ¯”å¦‚ï¼Œåœ¨æ¡ä»¶ç‹¬ç«‹å‡è®¾çš„æƒ…å†µä¸‹ï¼Œ<strong>â€œæ­¦æ¾æ‰“æ­»äº†è€è™â€ä¸â€œè€è™æ‰“æ­»äº†æ­¦æ¾â€è¢«å®ƒè®¤ä½œä¸€ä¸ªæ„æ€äº†ã€‚</strong>æ©ï¼Œæœ´ç´ è´å¶æ–¯å°±æ˜¯è¿™ä¹ˆå•çº¯å’Œç›´æ¥ï¼Œå¯¹æ¯”äºå…¶ä»–åˆ†ç±»å™¨ï¼Œå¥½åƒæ˜¯æ˜¾å¾—æœ‰é‚£ä¹ˆç‚¹èŒè ¢ã€‚</p><h2 id="8-ç®€å•é«˜æ•ˆï¼ŒåŠä¸é€†è¢­"><a href="#8-ç®€å•é«˜æ•ˆï¼ŒåŠä¸é€†è¢­" class="headerlink" title="8. ç®€å•é«˜æ•ˆï¼ŒåŠä¸é€†è¢­"></a>8. ç®€å•é«˜æ•ˆï¼ŒåŠä¸é€†è¢­</h2><p>è™½ç„¶è¯´æœ´ç´ è´å¶æ–¯æ–¹æ³•èŒè ¢èŒè ¢çš„ï¼Œä½†å®è·µè¯æ˜åœ¨åƒåœ¾é‚®ä»¶è¯†åˆ«çš„åº”ç”¨è¿˜<strong>ä»¤äººè¯§å¼‚åœ°å¥½</strong>ã€‚Paul Grahamå…ˆç”Ÿè‡ªå·±ç®€å•åšäº†ä¸€ä¸ªæœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ï¼Œ<strong>â€œ1000å°åƒåœ¾é‚®ä»¶èƒ½å¤Ÿè¢«è¿‡æ»¤æ‰995å°ï¼Œå¹¶ä¸”æ²¡æœ‰ä¸€ä¸ªè¯¯åˆ¤â€ã€‚</strong>ï¼ˆPaul Grahamã€Šé»‘å®¢ä¸ç”»å®¶ã€‹ï¼‰</p><p>é‚£ä¸ªâ€¦æ•ˆæœä¸ºå•¥å¥½å‘¢ï¼Ÿ</p><p>â€œæœ‰äººå¯¹æ­¤æå‡ºäº†ä¸€ä¸ªç†è®ºè§£é‡Šï¼Œå¹¶ä¸”å»ºç«‹äº†ä»€ä¹ˆæ—¶å€™æœ´ç´ è´å¶æ–¯çš„æ•ˆæœèƒ½å¤Ÿç­‰ä»·äºéæœ´ç´ è´å¶æ–¯çš„å……è¦æ¡ä»¶ï¼Œè¿™ä¸ªè§£é‡Šçš„æ ¸å¿ƒå°±æ˜¯ï¼šæœ‰äº›ç‹¬ç«‹å‡è®¾åœ¨å„ä¸ªåˆ†ç±»ä¹‹é—´çš„åˆ†å¸ƒéƒ½æ˜¯å‡åŒ€çš„æ‰€ä»¥å¯¹äºä¼¼ç„¶çš„ç›¸å¯¹å¤§å°ä¸äº§ç”Ÿå½±å“ï¼›å³ä¾¿ä¸æ˜¯å¦‚æ­¤ï¼Œä¹Ÿæœ‰å¾ˆå¤§çš„å¯èƒ½æ€§<strong>å„ä¸ªç‹¬ç«‹å‡è®¾æ‰€äº§ç”Ÿçš„æ¶ˆæå½±å“æˆ–ç§¯æå½±å“äº’ç›¸æŠµæ¶ˆï¼Œæœ€ç»ˆå¯¼è‡´ç»“æœå—åˆ°çš„å½±å“ä¸å¤§</strong>ã€‚å…·ä½“çš„æ•°å­¦å…¬å¼è¯·å‚è€ƒ<a href="http://www.cs.unb.ca/profs/hzhang/publications/FLAIRS04ZhangH.pdf" target="_blank" rel="noopener">è¿™ç¯‡ paper</a>ã€‚â€ï¼ˆåˆ˜æœªé¹ã€Šï¼šå¹³å‡¡è€Œåˆç¥å¥‡çš„è´å¶æ–¯æ–¹æ³•ã€‹ï¼‰</p><p>æ©ï¼Œè¿™ä¸ªåˆ†ç±»å™¨ä¸­æœ€ç®€å•ç›´æ¥çœ‹ä¼¼èŒè ¢çš„å°ç›†å‹ã€æœ´ç´ è´å¶æ–¯ã€ï¼Œå®é™…ä¸Šå´æ˜¯<strong>ç®€å•ã€å®ç”¨ã€ä¸”å¼ºå¤§</strong>çš„ã€‚</p><h2 id="9-å¤„ç†é‡å¤è¯è¯­çš„ä¸‰ç§æ–¹å¼"><a href="#9-å¤„ç†é‡å¤è¯è¯­çš„ä¸‰ç§æ–¹å¼" class="headerlink" title="9. å¤„ç†é‡å¤è¯è¯­çš„ä¸‰ç§æ–¹å¼"></a>9. å¤„ç†é‡å¤è¯è¯­çš„ä¸‰ç§æ–¹å¼</h2><p>æˆ‘ä»¬<strong>ä¹‹å‰çš„åƒåœ¾é‚®ä»¶å‘é‡ï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€,â€œä¿çœŸâ€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œç‚¹æ•°â€,â€œä¼˜æƒ â€)ï¼Œå…¶ä¸­æ¯ä¸ªè¯éƒ½ä¸é‡å¤ã€‚</strong>è€Œè¿™åœ¨ç°å®ä¸­å…¶å®å¾ˆå°‘è§ã€‚å› ä¸ºå¦‚æœæ–‡æœ¬é•¿åº¦å¢åŠ ï¼Œæˆ–è€…åˆ†è¯æ–¹æ³•æ”¹å˜ï¼Œ<strong>å¿…ç„¶ä¼šæœ‰è®¸å¤šè¯é‡å¤å‡ºç°</strong>ï¼Œå› æ­¤éœ€è¦å¯¹è¿™ç§æƒ…å†µè¿›è¡Œè¿›ä¸€æ­¥æ¢è®¨ã€‚æ¯”å¦‚ä»¥ä¸‹è¿™æ®µé‚®ä»¶ï¼š</p><blockquote><p>â€œä»£å¼€å‘ç¥¨ã€‚å¢å€¼ç¨å‘ç¥¨ï¼Œæ­£è§„å‘ç¥¨ã€‚â€ åˆ†è¯åä¸ºå‘é‡ï¼š ï¼ˆâ€œä»£å¼€â€,â€œå‘ç¥¨â€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œæ­£è§„â€,â€œå‘ç¥¨â€ï¼‰</p></blockquote><p>å…¶ä¸­â€œå‘ç¥¨â€é‡å¤äº†ä¸‰æ¬¡ã€‚</p><h3 id="9-1-å¤šé¡¹å¼æ¨¡å‹ï¼š"><a href="#9-1-å¤šé¡¹å¼æ¨¡å‹ï¼š" class="headerlink" title="9.1 å¤šé¡¹å¼æ¨¡å‹ï¼š"></a>9.1 å¤šé¡¹å¼æ¨¡å‹ï¼š</h3><p>å¦‚æœæˆ‘ä»¬è€ƒè™‘é‡å¤è¯è¯­çš„æƒ…å†µï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œ<strong>é‡å¤çš„è¯è¯­æˆ‘ä»¬è§†ä¸ºå…¶å‡ºç°å¤šæ¬¡</strong>ï¼Œç›´æ¥æŒ‰æ¡ä»¶ç‹¬ç«‹å‡è®¾çš„æ–¹å¼æ¨å¯¼ï¼Œåˆ™æœ‰</p><blockquote><p>P(ï¼ˆâ€œä»£å¼€â€,â€œå‘ç¥¨â€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œæ­£è§„â€,â€œå‘ç¥¨â€)|Sï¼‰ =P(â€œä»£å¼€â€â€|S)P(â€œå‘ç¥¨â€|S)P(â€œå¢å€¼ç¨â€|S)P(â€œå‘ç¥¨â€|S)P(â€œæ­£è§„â€|S)P(â€œå‘ç¥¨â€|Sï¼‰=P(â€œä»£å¼€â€â€|S)P3(â€œå‘ç¥¨â€|S)P(â€œå¢å€¼ç¨â€|S)P(â€œæ­£è§„â€|S) <strong>æ³¨æ„è¿™ä¸€é¡¹</strong>:P3(â€œå‘ç¥¨â€|Sï¼‰ã€‚</p></blockquote><p>åœ¨ç»Ÿè®¡è®¡ç®—P(â€œå‘ç¥¨â€|Sï¼‰æ—¶ï¼Œæ¯ä¸ªè¢«ç»Ÿè®¡çš„åƒåœ¾é‚®ä»¶æ ·æœ¬ä¸­é‡å¤çš„è¯è¯­ä¹Ÿç»Ÿè®¡å¤šæ¬¡ã€‚</p><blockquote><p>P(â€œå‘ç¥¨â€|Sï¼‰=æ¯å°åƒåœ¾é‚®ä»¶ä¸­å‡ºç°â€œå‘ç¥¨â€çš„æ¬¡æ•°çš„æ€»å’Œæ¯å°åƒåœ¾é‚®ä»¶ä¸­æ‰€æœ‰è¯å‡ºç°æ¬¡æ•°ï¼ˆè®¡ç®—é‡å¤æ¬¡æ•°ï¼‰çš„æ€»å’Œ</p></blockquote><p>ä½ çœ‹è¿™ä¸ªå¤šæ¬¡å‡ºç°çš„ç»“æœï¼Œå‡ºç°åœ¨æ¦‚ç‡çš„æŒ‡æ•°/æ¬¡æ–¹ä¸Šï¼Œå› æ­¤è¿™æ ·çš„æ¨¡å‹å«ä½œ<strong>å¤šé¡¹å¼æ¨¡å‹</strong>ã€‚</p><h3 id="9-2-ä¼¯åŠªåˆ©æ¨¡å‹"><a href="#9-2-ä¼¯åŠªåˆ©æ¨¡å‹" class="headerlink" title="9.2 ä¼¯åŠªåˆ©æ¨¡å‹"></a>9.2 ä¼¯åŠªåˆ©æ¨¡å‹</h3><p>å¦ä¸€ç§æ›´åŠ ç®€åŒ–çš„æ–¹æ³•æ˜¯<strong>å°†é‡å¤çš„è¯è¯­éƒ½è§†ä¸ºå…¶åªå‡ºç°1æ¬¡</strong>ï¼Œ</p><blockquote><p>P(ï¼ˆâ€œä»£å¼€â€,â€œå‘ç¥¨â€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œæ­£è§„â€,â€œå‘ç¥¨â€)|Sï¼‰ =P(â€œå‘ç¥¨â€|S)P(â€œä»£å¼€â€â€|S)P(â€œå¢å€¼ç¨â€|S)P(â€œæ­£è§„â€|Sï¼‰</p></blockquote><p>ç»Ÿè®¡è®¡ç®—P(â€œè¯è¯­â€|Sï¼‰æ—¶ä¹Ÿæ˜¯å¦‚æ­¤ã€‚</p><blockquote><p>P(â€œå‘ç¥¨â€|Sï¼‰=å‡ºç°â€œå‘ç¥¨â€çš„åƒåœ¾é‚®ä»¶çš„å°æ•°æ¯å°åƒåœ¾é‚®ä»¶ä¸­æ‰€æœ‰è¯å‡ºç°æ¬¡æ•°ï¼ˆå‡ºç°äº†åªè®¡ç®—ä¸€æ¬¡ï¼‰çš„æ€»å’Œ</p></blockquote><p>è¿™æ ·çš„æ¨¡å‹å«ä½œ<strong>ä¼¯åŠªåˆ©æ¨¡å‹</strong>ï¼ˆåˆç§°ä¸º<strong>äºŒé¡¹ç‹¬ç«‹æ¨¡å‹</strong>ï¼‰ã€‚è¿™ç§æ–¹å¼æ›´åŠ ç®€åŒ–ä¸æ–¹ä¾¿ã€‚å½“ç„¶å®ƒä¸¢å¤±äº†è¯é¢‘çš„ä¿¡æ¯ï¼Œå› æ­¤æ•ˆæœå¯èƒ½ä¼šå·®ä¸€äº›ã€‚</p><h3 id="9-3-æ··åˆæ¨¡å‹"><a href="#9-3-æ··åˆæ¨¡å‹" class="headerlink" title="9.3 æ··åˆæ¨¡å‹"></a>9.3 æ··åˆæ¨¡å‹</h3><p>ç¬¬ä¸‰ç§æ–¹å¼æ˜¯åœ¨è®¡ç®—å¥å­æ¦‚ç‡æ—¶ï¼Œä¸è€ƒè™‘é‡å¤è¯è¯­å‡ºç°çš„æ¬¡æ•°ï¼Œä½†æ˜¯åœ¨ç»Ÿè®¡è®¡ç®—è¯è¯­çš„æ¦‚ç‡P(â€œè¯è¯­â€|Sï¼‰æ—¶ï¼Œå´è€ƒè™‘é‡å¤è¯è¯­çš„å‡ºç°æ¬¡æ•°ï¼Œè¿™æ ·çš„æ¨¡å‹å¯ä»¥å«ä½œ<strong>æ··åˆæ¨¡å‹</strong>ã€‚</p><p>æˆ‘ä»¬é€šè¿‡ä¸‹å›¾å±•ç¤ºä¸‰ç§æ¨¡å‹çš„å…³ç³»ã€‚</p><p><img src="blob:file:///157f8870-f4d9-4b18-9922-0c1e7a18074b" alt="ä¸‰ç§å½¢æ€"></p><p>å…·ä½“å®è·µä¸­é‡‡ç”¨é‚£ç§æ¨¡å‹ï¼Œå…³é”®çœ‹å…·ä½“çš„ä¸šåŠ¡åœºæ™¯ï¼Œä¸€ä¸ªç®€å•ç»éªŒæ˜¯ï¼Œ<strong>å¯¹äºåƒåœ¾é‚®ä»¶è¯†åˆ«ï¼Œæ··åˆæ¨¡å‹æ›´å¥½äº›</strong>ã€‚</p><h2 id="10-å»é™¤åœç”¨è¯ä¸é€‰æ‹©å…³é”®è¯"><a href="#10-å»é™¤åœç”¨è¯ä¸é€‰æ‹©å…³é”®è¯" class="headerlink" title="10. å»é™¤åœç”¨è¯ä¸é€‰æ‹©å…³é”®è¯"></a>10. å»é™¤åœç”¨è¯ä¸é€‰æ‹©å…³é”®è¯</h2><p>æˆ‘ä»¬ç»§ç»­è§‚å¯Ÿ<strong>ï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€,â€œä¿çœŸâ€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œç‚¹æ•°â€,â€œä¼˜æƒ â€)</strong> è¿™å¥è¯ã€‚å…¶å®ï¼Œåƒ<strong>â€œæˆ‘â€ã€â€œå¯â€</strong>ä¹‹ç±»è¯å…¶å®éå¸¸ä¸­æ€§ï¼Œæ— è®ºå…¶æ˜¯å¦å‡ºç°åœ¨åƒåœ¾é‚®ä»¶ä¸­éƒ½æ— æ³•å¸®åŠ©åˆ¤æ–­çš„æœ‰ç”¨ä¿¡æ¯ã€‚æ‰€ä»¥å¯ä»¥ç›´æ¥ä¸è€ƒè™‘è¿™äº›å…¸å‹çš„è¯ã€‚è¿™äº›æ— åŠ©äºæˆ‘ä»¬åˆ†ç±»çš„è¯è¯­å«ä½œ<strong>â€œåœç”¨è¯â€ï¼ˆStop Wordsï¼‰</strong>ã€‚è¿™æ ·å¯ä»¥<strong>å‡å°‘æˆ‘ä»¬è®­ç»ƒæ¨¡å‹ã€åˆ¤æ–­åˆ†ç±»çš„æ—¶é—´</strong>ã€‚ äºæ˜¯ä¹‹å‰çš„å¥å­å°±å˜æˆäº†<strong>ï¼ˆâ€œå¸â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€,â€œä¿çœŸâ€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œç‚¹æ•°â€,â€œä¼˜æƒ â€)</strong> ã€‚</p><p>æˆ‘ä»¬è¿›ä¸€æ­¥åˆ†æã€‚ä»¥äººç±»çš„ç»éªŒï¼Œå…¶å®<strong>â€œæ­£è§„å‘ç¥¨â€ã€â€œå‘ç¥¨â€</strong>è¿™ç±»çš„è¯å¦‚æœå‡ºç°çš„è¯ï¼Œé‚®ä»¶ä½œä¸ºåƒåœ¾é‚®ä»¶çš„æ¦‚ç‡éå¸¸å¤§ï¼Œå¯ä»¥ä½œä¸ºæˆ‘ä»¬åŒºåˆ†åƒåœ¾é‚®ä»¶çš„<strong>â€œå…³é”®è¯â€</strong>ã€‚è€Œåƒ<strong>â€œå¸â€ã€â€œåŠç†â€ã€â€œä¼˜æƒ â€</strong>è¿™ç±»çš„è¯åˆ™æœ‰ç‚¹é¸¡è‚‹ï¼Œå¯èƒ½æœ‰åŠ©äºåˆ†ç±»ï¼Œä½†åˆä¸é‚£ä¹ˆå¼ºçƒˆã€‚å¦‚æœæƒ³çœäº‹åšä¸ªç®€å•çš„åˆ†ç±»å™¨çš„è¯ï¼Œåˆ™å¯ä»¥ç›´æ¥é‡‡ç”¨â€œå…³é”®è¯â€è¿›è¡Œç»Ÿè®¡ä¸åˆ¤æ–­ï¼Œå‰©ä¸‹çš„è¯å°±å¯ä»¥å…ˆä¸ç®¡äº†ã€‚äºæ˜¯ä¹‹å‰çš„åƒåœ¾é‚®ä»¶å¥å­å°±å˜æˆäº†<strong>ï¼ˆâ€œæ­£è§„å‘ç¥¨â€,â€œå‘ç¥¨â€)</strong> ã€‚è¿™æ ·å°±æ›´åŠ å‡å°‘äº†æˆ‘ä»¬è®­ç»ƒæ¨¡å‹ã€åˆ¤æ–­åˆ†ç±»çš„æ—¶é—´ï¼Œé€Ÿåº¦éå¸¸å¿«ã€‚</p><p><strong>â€œåœç”¨è¯â€å’Œâ€œå…³é”®è¯â€ä¸€èˆ¬éƒ½å¯ä»¥æå‰é äººå·¥ç»éªŒæŒ‡å®š</strong>ã€‚ä¸åŒçš„â€œåœç”¨è¯â€å’Œâ€œå…³é”®è¯â€è®­ç»ƒå‡ºæ¥çš„åˆ†ç±»å™¨çš„æ•ˆæœä¹Ÿä¼šæœ‰äº›å·®å¼‚ã€‚</p><h2 id="11-æµ…è°ˆå¹³æ»‘æŠ€æœ¯"><a href="#11-æµ…è°ˆå¹³æ»‘æŠ€æœ¯" class="headerlink" title="11. æµ…è°ˆå¹³æ»‘æŠ€æœ¯"></a>11. æµ…è°ˆå¹³æ»‘æŠ€æœ¯</h2><p>æˆ‘ä»¬æ¥è¯´ä¸ªé—®é¢˜(ä¸­æ–‡NLPé‡Œé—®é¢˜è¶…çº§å¤šï¼Œå“­çT_T)ï¼Œæ¯”å¦‚åœ¨è®¡ç®—ä»¥ä¸‹ç‹¬ç«‹æ¡ä»¶å‡è®¾çš„æ¦‚ç‡ï¼š</p><blockquote><p>P(ï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€)|S) =P(â€œæˆ‘â€|S)P(â€œå¸â€|S)P(â€œå¯â€|S)P(â€œåŠç†â€|S)P(â€œæ­£è§„å‘ç¥¨â€|Sï¼‰</p></blockquote><p>æˆ‘ä»¬æ‰«æä¸€ä¸‹è®­ç»ƒé›†ï¼Œå‘ç°<strong>â€œæ­£è§„å‘ç¥¨â€è¿™ä¸ªè¯ä»å‡ºç°è¿‡ï¼ï¼ï¼*ï¼Œäºæ˜¯P(â€œæ­£è§„å‘ç¥¨â€|Sï¼‰=0â€¦é—®é¢˜ä¸¥é‡äº†ï¼Œæ•´ä¸ªæ¦‚ç‡éƒ½å˜æˆ0äº†ï¼ï¼ï¼æœ´ç´ è´å¶æ–¯æ–¹æ³•é¢å¯¹ä¸€å †0ï¼Œå¾ˆå‡„æƒ¨åœ°å¤±æ•ˆäº†â€¦æ›´æ®‹é…·çš„æ˜¯</strong>è¿™ç§æƒ…å†µå…¶å®å¾ˆå¸¸è§<strong>ï¼Œå› ä¸ºå“ªæ€•è®­ç»ƒé›†å†å¤§ï¼Œä¹Ÿå¯èƒ½æœ‰è¦†ç›–ä¸åˆ°çš„è¯è¯­ã€‚æœ¬è´¨ä¸Šè¿˜æ˜¯</strong>æ ·æœ¬æ•°é‡å¤ªå°‘ï¼Œä¸æ»¡è¶³å¤§æ•°å®šå¾‹ï¼Œè®¡ç®—å‡ºæ¥çš„æ¦‚ç‡å¤±çœŸ**ã€‚ä¸ºäº†è§£å†³è¿™æ ·çš„é—®é¢˜ï¼Œä¸€ç§åˆ†ææ€è·¯å°±æ˜¯ç›´æ¥ä¸è€ƒè™‘è¿™æ ·çš„è¯è¯­ï¼Œä½†è¿™ç§æ–¹æ³•å°±ç›¸å½“äºé»˜è®¤ç»™P(â€œæ­£è§„å‘ç¥¨â€|Sï¼‰èµ‹å€¼ä¸º1ã€‚å…¶å®æ•ˆæœä¸å¤ªå¥½ï¼Œå¤§é‡çš„ç»Ÿè®¡ä¿¡æ¯ç»™æµªè´¹æ‰äº†ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥åˆ†æï¼Œæ—¢ç„¶å¯ä»¥é»˜è®¤èµ‹å€¼ä¸º1ï¼Œä¸ºä»€ä¹ˆä¸èƒ½é»˜è®¤èµ‹å€¼ä¸ºä¸€ä¸ªå¾ˆå°çš„æ•°ï¼Ÿè¿™å°±æ˜¯å¹³æ»‘æŠ€æœ¯çš„åŸºæœ¬æ€è·¯ï¼Œä¾æ—§ä¿æŒç€ä¸€è´¯çš„ä½œé£ï¼Œ<code>æœ´å®/åœŸ</code>ä½†æ˜¯<code>ç›´æ¥è€Œæœ‰æ•ˆ</code>ã€‚</p><p>å¯¹äºä¼¯åŠªåˆ©æ¨¡å‹ï¼ŒP(â€œæ­£è§„å‘ç¥¨â€|Sï¼‰çš„ä¸€ç§å¹³æ»‘ç®—æ³•æ˜¯ï¼š</p><blockquote><p>P(â€œæ­£è§„å‘ç¥¨â€|Sï¼‰=å‡ºç°â€œæ­£è§„å‘ç¥¨â€çš„åƒåœ¾é‚®ä»¶çš„å°æ•°+1æ¯å°åƒåœ¾é‚®ä»¶ä¸­æ‰€æœ‰è¯å‡ºç°æ¬¡æ•°ï¼ˆå‡ºç°äº†åªè®¡ç®—ä¸€æ¬¡ï¼‰çš„æ€»å’Œ+2</p></blockquote><p>å¯¹äºå¤šé¡¹å¼æ¨¡å‹ï¼ŒP(â€œæ­£è§„å‘ç¥¨â€| Sï¼‰çš„ä¸€ç§å¹³æ»‘ç®—æ³•æ˜¯ï¼š</p><blockquote><p>P(â€œå‘ç¥¨â€|Sï¼‰=æ¯å°åƒåœ¾é‚®ä»¶ä¸­å‡ºç°â€œå‘ç¥¨â€çš„æ¬¡æ•°çš„æ€»å’Œ+1æ¯å°åƒåœ¾é‚®ä»¶ä¸­æ‰€æœ‰è¯å‡ºç°æ¬¡æ•°ï¼ˆè®¡ç®—é‡å¤æ¬¡æ•°ï¼‰çš„æ€»å’Œ+è¢«ç»Ÿè®¡çš„è¯è¡¨çš„è¯è¯­æ•°é‡</p></blockquote><p>è¯´èµ·æ¥ï¼Œå¹³æ»‘æŠ€æœ¯çš„ç§ç±»å…¶å®éå¸¸å¤šï¼Œæœ‰å…´è¶£çš„è¯å›å¤´æˆ‘ä»¬ä¸“é—¨æ‹‰ä¸ªä¸“é¢˜è®²è®²å¥½äº†ã€‚è¿™é‡Œåªæä¸€ç‚¹ï¼Œå°±æ˜¯æ‰€æœ‰çš„<strong>å¹³æ»‘æŠ€æœ¯éƒ½æ˜¯ç»™æœªå‡ºç°åœ¨è®­ç»ƒé›†ä¸­çš„è¯è¯­ä¸€ä¸ªä¼°è®¡çš„æ¦‚ç‡ï¼Œè€Œç›¸åº”åœ°è°ƒä½å…¶ä»–å·²ç»å‡ºç°çš„è¯è¯­çš„æ¦‚ç‡</strong>ã€‚</p><p>å¹³æ»‘æŠ€æœ¯æ˜¯å› ä¸ºæ•°æ®é›†å¤ªå°è€Œäº§ç”Ÿçš„ç°å®éœ€æ±‚ã€‚<strong>å¦‚æœæ•°æ®é›†è¶³å¤Ÿå¤§ï¼Œå¹³æ»‘æŠ€æœ¯å¯¹ç»“æœçš„å½±å“å°†ä¼šå˜å°ã€‚</strong></p><h2 id="12-å†…å®¹å°ç»“"><a href="#12-å†…å®¹å°ç»“" class="headerlink" title="12. å†…å®¹å°ç»“"></a>12. å†…å®¹å°ç»“</h2><p>æˆ‘ä»¬æ‰¾äº†ä¸ªæœ€ç®€å•å¸¸è§çš„ä¾‹å­ï¼šåƒåœ¾é‚®ä»¶è¯†åˆ«ï¼Œè¯´æ˜äº†ä¸€ä¸‹æœ´ç´ è´å¶æ–¯è¿›è¡Œæ–‡æœ¬åˆ†ç±»çš„æ€è·¯è¿‡ç¨‹ã€‚åŸºæœ¬æ€è·¯æ˜¯å…ˆåŒºåˆ†å¥½è®­ç»ƒé›†ä¸æµ‹è¯•é›†ï¼Œå¯¹æ–‡æœ¬é›†åˆè¿›è¡Œåˆ†è¯ã€å»é™¤æ ‡ç‚¹ç¬¦å·ç­‰ç‰¹å¾é¢„å¤„ç†çš„æ“ä½œï¼Œç„¶åä½¿ç”¨æ¡ä»¶ç‹¬ç«‹å‡è®¾ï¼Œå°†åŸæ¦‚ç‡è½¬æ¢æˆè¯æ¦‚ç‡ä¹˜ç§¯ï¼Œå†è¿›è¡Œåç»­çš„å¤„ç†ã€‚</p><blockquote><p>è´å¶æ–¯å…¬å¼ + æ¡ä»¶ç‹¬ç«‹å‡è®¾ = æœ´ç´ è´å¶æ–¯æ–¹æ³•</p></blockquote><p>åŸºäºå¯¹é‡å¤è¯è¯­åœ¨è®­ç»ƒé˜¶æ®µä¸åˆ¤æ–­ï¼ˆæµ‹è¯•ï¼‰é˜¶æ®µçš„ä¸‰ç§ä¸åŒå¤„ç†æ–¹å¼ï¼Œæˆ‘ä»¬ç›¸åº”çš„æœ‰ä¼¯åŠªåˆ©æ¨¡å‹ã€å¤šé¡¹å¼æ¨¡å‹å’Œæ··åˆæ¨¡å‹ã€‚åœ¨è®­ç»ƒé˜¶æ®µï¼Œå¦‚æœæ ·æœ¬é›†åˆå¤ªå°å¯¼è‡´æŸäº›è¯è¯­å¹¶æœªå‡ºç°ï¼Œæˆ‘ä»¬å¯ä»¥é‡‡ç”¨å¹³æ»‘æŠ€æœ¯å¯¹å…¶æ¦‚ç‡ç»™ä¸€ä¸ªä¼°è®¡å€¼ã€‚è€Œä¸”å¹¶ä¸æ˜¯æ‰€æœ‰çš„è¯è¯­éƒ½éœ€è¦ç»Ÿè®¡ï¼Œæˆ‘ä»¬å¯ä»¥æŒ‰ç›¸åº”çš„â€œåœç”¨è¯â€å’Œâ€œå…³é”®è¯â€å¯¹æ¨¡å‹è¿›è¡Œè¿›ä¸€æ­¥ç®€åŒ–ï¼Œæé«˜è®­ç»ƒå’Œåˆ¤æ–­é€Ÿåº¦ã€‚</p><h2 id="13-ä¸ºä»€ä¹ˆä¸ç›´æ¥åŒ¹é…å…³é”®è¯æ¥è¯†åˆ«åƒåœ¾é‚®ä»¶ï¼Ÿ"><a href="#13-ä¸ºä»€ä¹ˆä¸ç›´æ¥åŒ¹é…å…³é”®è¯æ¥è¯†åˆ«åƒåœ¾é‚®ä»¶ï¼Ÿ" class="headerlink" title="13. ä¸ºä»€ä¹ˆä¸ç›´æ¥åŒ¹é…å…³é”®è¯æ¥è¯†åˆ«åƒåœ¾é‚®ä»¶ï¼Ÿ"></a>13. ä¸ºä»€ä¹ˆä¸ç›´æ¥åŒ¹é…å…³é”®è¯æ¥è¯†åˆ«åƒåœ¾é‚®ä»¶ï¼Ÿ</h2><p>æœ‰åŒå­¦å¯èƒ½ä¼šé—®ï¼šâ€œä½•å¿…è´¹è¿™ä¹ˆå¤§åŠ²ç®—é‚£ä¹ˆå¤šè¯çš„æ¦‚ç‡ï¼Ÿç›´æ¥çœ‹é‚®ä»¶ä¸­æœ‰æ²¡æœ‰â€˜ä»£å¼€å‘ç¥¨â€™ã€â€˜è½¬å”®å‘ç¥¨â€™ä¹‹ç±»çš„å…³é”®è¯ä¸å°±å¾—äº†ï¼Ÿå¦‚æœå…³é”®è¯æ¯”è¾ƒå¤šå°±è®¤ä¸ºæ˜¯åƒåœ¾é‚®ä»¶å‘—ã€‚â€</p><p>å…¶å®å…³é”®è¯åŒ¹é…çš„æ–¹æ³•å¦‚æœæœ‰æ•ˆçš„è¯çœŸä¸å¿…ç”¨æœ´ç´ è´å¶æ–¯ã€‚æ¯•ç«Ÿè¿™ç§æ–¹æ³•ç®€å•å˜›ï¼Œ<strong>å°±æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²åŒ¹é…</strong>ã€‚ä»å†å²æ¥çœ‹ï¼Œä¹‹å‰æ²¡æœ‰è´å¶æ–¯æ–¹æ³•çš„æ—¶å€™ä¸»è¦ä¹Ÿæ˜¯ç”¨å…³é”®è¯åŒ¹é…ã€‚<strong>ä½†æ˜¯è¿™ç§æ–¹æ³•å‡†ç¡®ç‡å¤ªä½</strong>ã€‚æˆ‘ä»¬åœ¨å·¥ä½œé¡¹ç›®ä¸­ä¹Ÿå°è¯•è¿‡ç”¨å…³é”®è¯åŒ¹é…çš„æ–¹æ³•å»è¿›è¡Œæ–‡æœ¬åˆ†ç±»ï¼Œå‘ç°å¤§é‡è¯¯æŠ¥ã€‚æ„Ÿè§‰å°±åƒæ‰”åˆ°åƒåœ¾ç®±çš„é‚®ä»¶99%éƒ½æ˜¯æ­£å¸¸çš„ï¼è¿™æ ·çš„æ•ˆæœä¸å¿ç›´è§†ã€‚è€ŒåŠ ä¸€ä¸ªæœ´ç´ è´å¶æ–¯æ–¹æ³•å°±å¯èƒ½æŠŠè¯¯æŠ¥ç‡æ‹‰ä½è¿‘ä¸€ä¸ªæ•°é‡çº§ï¼Œä½“éªŒå¥½å¾—ä¸è¦ä¸è¦çš„ã€‚</p><p><strong>å¦ä¸€ä¸ªåŸå› æ˜¯è¯è¯­ä¼šéšç€æ—¶é—´ä¸æ–­å˜åŒ–</strong>ã€‚å‘åƒåœ¾é‚®ä»¶çš„äººä¹Ÿä¸å‚»ï¼Œå½“ä»–ä»¬å‘ç°è‡ªå·±çš„é‚®ä»¶è¢«å¤§é‡å±è”½ä¹‹åï¼Œä¹Ÿä¼šè€ƒè™‘é‡‡ç”¨æ–°çš„æ–¹å¼ï¼Œ<strong>å¦‚å˜æ¢æ–‡å­—ã€è¯è¯­ã€å¥å¼ã€é¢œè‰²ç­‰æ–¹å¼æ¥ç»•è¿‡ååƒåœ¾é‚®ä»¶ç³»ç»Ÿ</strong>ã€‚æ¯”å¦‚å¯¹äºåƒåœ¾é‚®ä»¶â€œæˆ‘å¸å¯åŠç†æ­£è§„å‘ç¥¨ï¼Œ17%å¢å€¼ç¨å‘ç¥¨ç‚¹æ•°ä¼˜æƒ â€,ä»–ä»¬é‡‡ç”¨ç«æ˜Ÿæ–‡ï¼š<strong>â€œæ¶å¸å²¢åŠç†ãŠ£è¦é«®ç¥¨ï¼Œ17%å¢å€¤ç¨…é«®ç¥¨åš¸æ•¸å„ªè•™â€</strong>ï¼Œé‚£ä¹ˆå­—ç¬¦ä¸²åŒ¹é…çš„æ–¹æ³•åˆè¦é‡æ–°æ‰¾å‡ºè¿™äº›ç«æ˜Ÿæ–‡ï¼Œä¸€ä¸ªä¸€ä¸ªæ‰¾å‡ºå…³é”®è¯ï¼Œé‡æ–°å†™ä¸€äº›åŒ¹é…è§„åˆ™ã€‚æ›´å¯æ€•çš„æ˜¯ï¼Œè¿™äº›è§„åˆ™å¯èƒ½ç›¸äº’ä¹‹é—´çš„è€¦åˆå…³ç³»å¼‚å¸¸å¤æ‚ï¼Œè¦æŠŠå®ƒä»¬æ¢³ç†æ¸…æ¥šåˆæ˜¯å¤§ä¸€ä¸ªæ•°é‡çº§çš„å·¥ä½œé‡ã€‚ç­‰è¿™äº›è§„åˆ™å¤±æ•ˆäº†åˆè¦æ‰‹åŠ¨æ›´æ–°æ–°çš„è§„åˆ™â€¦â€¦<strong>æ— ç©·æ— å°½çŒ«é¼ æ¸¸æˆæœ€ç»ˆä¼šæŠŠçŒ«ç»™ç´¯æ­»</strong>ã€‚</p><p>è€Œæœ´ç´ è´å¶æ–¯æ–¹æ³•å´æ˜¾ç¤ºå‡ºæ— æ¯”çš„ä¼˜åŠ¿ã€‚å› ä¸ºå®ƒæ˜¯<strong>åŸºäºç»Ÿè®¡æ–¹æ³•</strong>çš„ï¼Œåªè¦è®­ç»ƒæ ·æœ¬ä¸­æœ‰æ›´æ–°çš„åƒåœ¾é‚®ä»¶çš„æ–°è¯è¯­ï¼Œå“ªæ€•å®ƒä»¬æ˜¯ç«æ˜Ÿæ–‡ï¼Œ<strong>éƒ½èƒ½è‡ªåŠ¨åœ°æŠŠå“ªäº›æ›´æ•æ„Ÿçš„è¯è¯­ï¼ˆå¦‚â€œé«®â€ã€â€œãŠ£â€ç­‰ï¼‰ç»™å‡¸æ˜¾å‡ºæ¥ï¼Œå¹¶æ ¹æ®ç»Ÿè®¡æ„ä¹‰ä¸Šçš„æ•æ„Ÿæ€§ç»™ä»–ä»¬åˆ†é…é€‚å½“çš„æƒé‡</strong> ï¼Œè¿™æ ·å°±ä¸éœ€è¦ä»€ä¹ˆäººå·¥äº†ï¼Œéå¸¸çœäº‹ã€‚<strong>ä½ åªéœ€è¦æ—¶ä¸æ—¶åœ°æ‹¿ä¸€äº›æœ€æ–°çš„æ ·æœ¬æ‰”åˆ°è®­ç»ƒé›†ä¸­ï¼Œé‡æ–°è®­ç»ƒä¸€æ¬¡å³å¯</strong>ã€‚</p><p>å°è¡¥å……ä¸€ä¸‹ï¼Œå¯¹äºç«æ˜Ÿæ–‡ã€åŒéŸ³å­—ç­‰æ›¿ä»£è¯­è¨€ï¼Œä¸€èˆ¬çš„åˆ†è¯æŠ€æœ¯å¯èƒ½ä¼šåˆ†å¾—ä¸å‡†ï¼Œæœ€ç»ˆå¯èƒ½åªæŠŠä¸€ä¸ªä¸€ä¸ªå­—ç»™åˆ†å‡ºæ¥ï¼Œæˆä¸ºâ€œåˆ†å­—â€ã€‚æ•ˆæœå¯èƒ½ä¸ä¼šå¤ªå¥½ã€‚ä¹Ÿå¯ä»¥ç”¨è¿‡n-gramä¹‹ç±»çš„è¯­è¨€æ¨¡å‹ï¼Œæ‹¿åˆ°æœ€å¸¸è§çŸ­è¯­ã€‚å½“ç„¶ï¼Œå¯¹äºè‹±æ–‡ç­‰å¤©ç”Ÿè‡ªå¸¦ç©ºæ ¼æ¥é—´éš”å•è¯çš„è¯­è¨€ï¼Œåˆ†è¯åˆ™ä¸æ˜¯ä»€ä¹ˆé—®é¢˜ï¼Œä½¿ç”¨æœ´ç´ è´å¶æ–¯æ–¹æ³•å°†ä¼šæ›´åŠ é¡ºç•…ã€‚</p><h2 id="14-å®é™…å·¥ç¨‹çš„tricks"><a href="#14-å®é™…å·¥ç¨‹çš„tricks" class="headerlink" title="14.å®é™…å·¥ç¨‹çš„tricks"></a>14.å®é™…å·¥ç¨‹çš„tricks</h2><p>åº”ç”¨æœ´ç´ è´å¶æ–¯æ–¹æ³•çš„è¿‡ç¨‹ä¸­ï¼Œä¸€äº›tricksèƒ½æ˜¾è‘—å¸®åŠ©å·¥ç¨‹è§£å†³é—®é¢˜ã€‚æˆ‘ä»¬æ¯•ç«Ÿç»éªŒæœ‰é™ï¼Œæ— æ³•å°†å®ƒä»¬å…¨éƒ½ç½—åˆ—å‡ºæ¥ï¼Œåªèƒ½å°±æ‰€çŸ¥çš„ä¸€ç‚¹ç‚¹ç»éªŒä¸å¤§å®¶åˆ†äº«ï¼Œæ¬¢è¿æ‰¹è¯„æŒ‡æ­£ã€‚</p><h3 id="14-1-trick1ï¼šå–å¯¹æ•°"><a href="#14-1-trick1ï¼šå–å¯¹æ•°" class="headerlink" title="14.1 trick1ï¼šå–å¯¹æ•°"></a>14.1 trick1ï¼šå–å¯¹æ•°</h3><p>æˆ‘ä»¬æåˆ°ç”¨æ¥è¯†åˆ«åƒåœ¾é‚®ä»¶çš„æ–¹æ³•æ˜¯æ¯”è¾ƒä»¥ä¸‹ä¸¤ä¸ªæ¦‚ç‡çš„å¤§å°ï¼ˆå­—æ¯Sè¡¨ç¤ºâ€œåƒåœ¾é‚®ä»¶â€,å­—æ¯Hè¡¨ç¤ºâ€œæ­£å¸¸é‚®ä»¶â€ï¼‰ï¼š</p><blockquote><p>C=P(â€œæˆ‘â€|S)P(â€œå¸â€|S)P(â€œå¯â€|S)P(â€œåŠç†â€|S)P(â€œæ­£è§„å‘ç¥¨â€|S)</p><p>Ã—P(â€œä¿çœŸâ€|S)P(â€œå¢å€¼ç¨â€|S)P(â€œå‘ç¥¨â€|S)P(â€œç‚¹æ•°â€|S)P(â€œä¼˜æƒ â€|S)P(â€œåƒåœ¾é‚®ä»¶â€)</p><p>Câ¯â¯â¯â¯=P(â€œæˆ‘â€|H)P(â€œå¸â€|H)P(â€œå¯â€|H)P(â€œåŠç†â€|H)P(â€œæ­£è§„å‘ç¥¨â€|H)</p><p>Ã—P(â€œä¿çœŸâ€|H)P(â€œå¢å€¼ç¨â€|H)P(â€œå‘ç¥¨â€|H)P(â€œç‚¹æ•°â€|H)P(â€œä¼˜æƒ â€|H)P(â€œæ­£å¸¸é‚®ä»¶â€)</p></blockquote><p>ä½†è¿™é‡Œè¿›è¡Œäº†<strong>å¾ˆå¤šä¹˜æ³•è¿ç®—ï¼Œè®¡ç®—çš„æ—¶é—´å¼€é”€æ¯”è¾ƒå¤§</strong>ã€‚å°¤å…¶æ˜¯å¯¹äºç¯‡å¹…æ¯”è¾ƒé•¿çš„é‚®ä»¶ï¼Œå‡ ä¸‡ä¸ªæ•°ç›¸ä¹˜èµ·æ¥è¿˜æ˜¯éå¸¸èŠ±æ—¶é—´çš„ã€‚å¦‚æœèƒ½<strong>æŠŠè¿™äº›ä¹˜æ³•å˜æˆåŠ æ³•åˆ™æ–¹ä¾¿å¾—å¤š</strong>ã€‚åˆšå¥½æ•°å­¦ä¸­çš„å¯¹æ•°å‡½æ•°logå°±å¯ä»¥å®ç°è¿™æ ·çš„åŠŸèƒ½ã€‚ä¸¤è¾¹åŒæ—¶å–å¯¹æ•°ï¼ˆæœ¬æ–‡ç»Ÿä¸€å–åº•æ•°ä¸º2ï¼‰ï¼Œåˆ™ä¸Šé¢çš„å…¬å¼å˜ä¸ºï¼š</p><blockquote><p>logC=logP(â€œæˆ‘â€|S)+logP(â€œå¸â€|S)+logP(â€œå¯â€|S)+logP(â€œåŠç†â€|S)+logP(â€œæ­£è§„å‘ç¥¨â€|S)</p><p>+logP(â€œä¿çœŸâ€|S)+logP(â€œå¢å€¼ç¨â€|S)+logP(â€œå‘ç¥¨â€|S)+logP(â€œç‚¹æ•°â€|S)+logP(â€œä¼˜æƒ â€|S)+logP(â€œåƒåœ¾é‚®ä»¶â€)</p><p>logCâ¯â¯â¯â¯=logP(â€œæˆ‘â€|H)+logP(â€œå¸â€|H)+logP(â€œå¯â€|H)+logP(â€œåŠç†â€|H)+logP(â€œæ­£è§„å‘ç¥¨â€|H)</p><p>+logP(â€œä¿çœŸâ€|H)+logP(â€œå¢å€¼ç¨â€|H)+logP(â€œå‘ç¥¨â€|H)+logP(â€œç‚¹æ•°â€|H)+logP(â€œä¼˜æƒ â€|H)+logP(â€œæ­£å¸¸é‚®ä»¶â€)</p></blockquote><p>æœ‰åŒå­¦å¯èƒ½è¦å«äº†ï¼šâ€œåšå¯¹æ•°è¿ç®—å²‚ä¸ä¼šä¹Ÿå¾ˆèŠ±æ—¶é—´ï¼Ÿâ€çš„ç¡®å¦‚æ­¤ï¼Œä½†æ˜¯å¯ä»¥åœ¨è®­ç»ƒé˜¶æ®µç›´æ¥è®¡ç®— logP ï¼Œç„¶åæŠŠä»–ä»¬å­˜åœ¨ä¸€å¼ å¤§çš„hashè¡¨é‡Œã€‚<strong>åœ¨åˆ¤æ–­çš„æ—¶å€™ç›´æ¥æå–hashè¡¨ä¸­å·²ç»è®¡ç®—å¥½çš„å¯¹æ•°æ¦‚ç‡ï¼Œç„¶åç›¸åŠ å³å¯ã€‚è¿™æ ·ä½¿å¾—åˆ¤æ–­æ‰€éœ€è¦çš„è®¡ç®—æ—¶é—´è¢«è½¬ç§»åˆ°äº†è®­ç»ƒé˜¶æ®µ</strong>ï¼Œå®æ—¶è¿è¡Œçš„æ—¶å€™é€Ÿåº¦å°±æ¯”ä¹‹å‰å¿«å¾—å¤šï¼Œè¿™å¯ä¸æ­¢å‡ ä¸ªæ•°é‡çº§çš„æå‡ã€‚</p><h3 id="14-2-trick2ï¼šè½¬æ¢ä¸ºæƒé‡"><a href="#14-2-trick2ï¼šè½¬æ¢ä¸ºæƒé‡" class="headerlink" title="14.2 trick2ï¼šè½¬æ¢ä¸ºæƒé‡"></a>14.2 trick2ï¼šè½¬æ¢ä¸ºæƒé‡</h3><p>å¯¹äºäºŒåˆ†ç±»ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥ç»§ç»­æé«˜åˆ¤æ–­çš„é€Ÿåº¦ã€‚æ—¢ç„¶è¦æ¯”è¾ƒlogC å’ŒlogCâ¯â¯â¯â¯ çš„å¤§å°ï¼Œé‚£å°±å¯ä»¥ç›´æ¥å°†ä¸Šä¸‹ä¸¤å¼ç›¸å‡ï¼Œå¹¶ç»§ç»­åŒ–ç®€ï¼š</p><blockquote><p>logCCâ¯â¯â¯â¯â¯=logP(â€œæˆ‘â€|S)P(â€œæˆ‘â€|H)+logP(â€œå¸â€|S)P(â€œå¸â€|H)+logP(â€œå¯â€|S)P(â€œå¯â€|H)+logP(â€œåŠç†â€|S)P(â€œåŠç†â€|H)+logP(â€œæ­£è§„å‘ç¥¨â€|S)P(â€œæ­£è§„å‘ç¥¨â€|H)</p><p>+logP(â€œä¿çœŸâ€|S)P(â€œä¿çœŸâ€|H)+logP(â€œå¢å€¼ç¨â€|S)P(â€œå¢å€¼ç¨â€|H)+logP(â€œå‘ç¥¨â€|S)P(â€œå‘ç¥¨â€|H)+logP(â€œç‚¹æ•°â€|S)P(â€œç‚¹æ•°â€|H)+logP(â€œä¼˜æƒ â€|S)P(â€œä¼˜æƒ â€|H)+logP(â€œæ­£å¸¸é‚®ä»¶â€|S)P(â€œæ­£å¸¸é‚®ä»¶â€)</p></blockquote><p><strong>logCCâ¯â¯â¯â¯â¯ å¦‚æœå¤§äº0åˆ™å±äºåƒåœ¾é‚®ä»¶ã€‚æˆ‘ä»¬å¯ä»¥æŠŠå…¶ä¸­æ¯ä¸€é¡¹ä½œä¸ºå…¶å¯¹åº”è¯è¯­çš„æƒé‡</strong>ï¼Œæ¯”å¦‚logP(â€œå‘ç¥¨â€|S)P(â€œå‘ç¥¨â€|H) å°±å¯ä»¥ä½œä¸ºè¯è¯­â€œå‘ç¥¨â€çš„æƒé‡ï¼Œæƒé‡è¶Šå¤§å°±è¶Šè¯´æ˜â€œå‘ç¥¨â€æ›´å¯èƒ½æ˜¯ä¸â€œåƒåœ¾é‚®ä»¶â€ç›¸å…³çš„ç‰¹å¾ã€‚<strong>è¿™æ ·å¯ä»¥æ ¹æ®æƒé‡çš„å¤§å°æ¥è¯„ä¼°å’Œç­›é€‰æ˜¾è‘—çš„ç‰¹å¾ï¼Œæ¯”å¦‚å…³é”®è¯ã€‚è€Œè¿™äº›æƒé‡å€¼å¯ä»¥ç›´æ¥æå‰è®¡ç®—å¥½è€Œå­˜åœ¨hashè¡¨ä¸­</strong> ã€‚åˆ¤æ–­çš„æ—¶å€™ç›´æ¥å°†æƒé‡æ±‚å’Œå³å¯ã€‚</p><p>å…³é”®è¯hashè¡¨çš„æ ·å­å¦‚ä¸‹ï¼Œå·¦åˆ—æ˜¯æƒé‡ï¼Œå³åˆ—æ˜¯å…¶å¯¹åº”çš„è¯è¯­ï¼Œæƒé‡è¶Šé«˜çš„è¯´æ˜è¶Šâ€œå…³é”®â€ï¼š</p><p><img src="blob:file:///6f29d16a-1075-45cb-9c7e-206aefcf4e4a" alt="hash"></p><h3 id="14-3-trick3ï¼šé€‰å–topkçš„å…³é”®è¯"><a href="#14-3-trick3ï¼šé€‰å–topkçš„å…³é”®è¯" class="headerlink" title="14.3 trick3ï¼šé€‰å–topkçš„å…³é”®è¯"></a>14.3 trick3ï¼šé€‰å–topkçš„å…³é”®è¯</h3><p>å‰æ–‡è¯´è¿‡å¯ä»¥é€šè¿‡æå‰é€‰å–å…³é”®è¯æ¥æé«˜åˆ¤æ–­çš„é€Ÿåº¦ã€‚æœ‰ä¸€ç§æ–¹æ³•å¯ä»¥çœç•¥æå‰é€‰å–å…³é”®è¯çš„æ­¥éª¤ï¼Œ<strong>å°±æ˜¯ç›´æ¥é€‰å–ä¸€æ®µæ–‡æœ¬ä¸­æƒé‡æœ€é«˜çš„Kä¸ªè¯è¯­ï¼Œå°†å…¶æƒé‡è¿›è¡ŒåŠ å’Œ</strong>ã€‚æ¯”å¦‚Paul Graham åœ¨ã€Šé»‘å®¢ä¸ç”»å®¶ã€‹ä¸­æ˜¯é€‰å–é‚®ä»¶ä¸­æƒé‡æœ€é«˜çš„15ä¸ªè¯è¯­è®¡ç®—çš„ã€‚</p><p>é€šè¿‡æƒé‡hashè¡¨å¯çŸ¥ï¼Œå¦‚æœæ˜¯æ‰€æœ‰è¯è¯­çš„æƒé‡ï¼Œåˆ™æƒé‡æœ‰æ­£æœ‰è´Ÿã€‚å¦‚æœåªé€‰æ‹©æƒé‡æœ€é«˜çš„Kä¸ªè¯è¯­ï¼Œåˆ™å®ƒä»¬çš„æƒé‡åŸºæœ¬éƒ½æ˜¯æ­£çš„ã€‚æ‰€ä»¥å°±ä¸èƒ½åƒä¹‹å‰é‚£æ ·åˆ¤æ–­logCCâ¯â¯â¯â¯â¯ æ˜¯å¦å¤§äº0æ¥åŒºåˆ†é‚®ä»¶äº†ã€‚è€Œè¿™<strong>éœ€è¦ä¾é ç»éªŒé€‰å®šä¸€ä¸ªæ­£æ•°çš„é˜ˆå€¼ï¼ˆé—¨æ§›å€¼ï¼‰</strong> ï¼Œä¾æ®logCCâ¯â¯â¯â¯â¯ ä¸è¯¥é—¨æ§›å€¼çš„å¤§å°æ¥è¯†åˆ«åƒåœ¾é‚®ä»¶ã€‚</p><p>å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œè“è‰²ç‚¹ä»£è¡¨åƒåœ¾é‚®ä»¶ï¼Œç»¿è‰²ç‚¹ä»£è¡¨æ­£å¸¸é‚®ä»¶ï¼Œæ¨ªåæ ‡ä¸ºè®¡ç®—å‡ºæ¥çš„logCCâ¯â¯â¯â¯â¯ å€¼ï¼Œä¸­é—´çš„çº¢çº¿ä»£è¡¨é˜ˆå€¼ã€‚</p><p><img src="blob:file:///fa290902-0e88-4f3b-8a65-79c442c05c05" alt="æƒé‡"></p><h3 id="14-4-trick4ï¼šåˆ†å‰²æ ·æœ¬"><a href="#14-4-trick4ï¼šåˆ†å‰²æ ·æœ¬" class="headerlink" title="14.4 trick4ï¼šåˆ†å‰²æ ·æœ¬"></a>14.4 trick4ï¼šåˆ†å‰²æ ·æœ¬</h3><p>é€‰å–topkä¸ªè¯è¯­çš„æ–¹æ³•å¯¹äºç¯‡å¹…å˜åŠ¨ä¸å¤§çš„é‚®ä»¶æ ·æœ¬æ¯”è¾ƒæœ‰æ•ˆã€‚ä½†æ˜¯å¯¹ç¯‡å¹…è¿‡å¤§æˆ–è€…è¿‡å°çš„é‚®ä»¶åˆ™ä¼šæœ‰åˆ¤æ–­è¯¯å·®ã€‚</p><p>æ¯”å¦‚è¿™ä¸ªåƒåœ¾é‚®ä»¶çš„ä¾‹å­ï¼šï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œæ­£è§„å‘ç¥¨â€,â€œä¿çœŸâ€,â€œå¢å€¼ç¨â€,â€œå‘ç¥¨â€,â€œç‚¹æ•°â€,â€œä¼˜æƒ â€)ã€‚åˆ†è¯å‡ºäº†10ä¸ªè¯è¯­ï¼Œå…¶ä¸­æœ‰â€œæ­£è§„å‘ç¥¨â€ã€â€œå‘ç¥¨â€2ä¸ªå…³é”®è¯ã€‚å…³é”®è¯çš„å¯†åº¦è¿˜æ˜¯è›®å¤§çš„ï¼Œåº”è¯¥ç®—æ˜¯æ•æ„Ÿé‚®ä»¶ã€‚ä½†å› ä¸ºé‡‡ç”¨æœ€é«˜15ä¸ªè¯è¯­çš„æƒé‡æ±‚å’Œï¼Œå¹¶ä¸”ç›¸åº”çš„é˜ˆå€¼æ˜¯åŸºäº15ä¸ªè¯çš„æƒ…å†µæœ‰æ•ˆï¼Œå¯èƒ½ç®—å‡ºæ¥çš„ç»“æœè¿˜å°äºä¹‹å‰çš„é˜ˆå€¼ï¼Œè¿™å°±é€ æˆæ¼åˆ¤äº†ã€‚</p><p>ç±»ä¼¼çš„ï¼Œå¦‚æœä¸€å°ç¨åŠ¡ä¸»é¢˜çš„é‚®ä»¶æœ‰1000ä¸ªè¯è¯­ï¼Œå…¶ä¸­åªæœ‰â€œæ­£è§„å‘ç¥¨â€ã€â€œå‘ç¥¨â€ã€â€œé¿ç¨æ–¹æ³•â€3ä¸ªæƒé‡æ¯”è¾ƒå¤§çš„è¯è¯­ï¼Œå®ƒä»¬åªæ˜¯åœ¨æ­£æ–‡è¡¨è¿°ä¸­é¡ºå¸¦æåˆ°çš„å†…å®¹ã€‚å…³é”®è¯çš„å¯†åº¦è¢«è¾ƒé•¿çš„ç¯‡å¹…ç¨€é‡Šäº†ï¼Œåº”è¯¥ç®—æ˜¯æ­£å¸¸é‚®ä»¶ã€‚ä½†æ˜¯å´è¢«é˜ˆå€¼åˆ¤æ–­æˆæ•æ„Ÿé‚®ä»¶ï¼Œé€ æˆè¯¯åˆ¤äº†ã€‚</p><p><strong>è¿™ä¸¤ç§æƒ…å†µéƒ½è¯´æ˜topkå…³é”®è¯çš„æ–¹æ³•éœ€è¦è€ƒè™‘ç¯‡å¹…çš„å½±å“</strong>ã€‚è¿™é‡Œæœ‰è®¸å¤šç§å¤„ç†æ–¹å¼ï¼Œ<strong>å®ƒä»¬çš„åŸºæœ¬æ€æƒ³éƒ½æ˜¯é€‰å–è¯è¯­çš„ä¸ªæ•°åŠå¯¹åº”çš„é˜ˆå€¼è¦ä¸ç¯‡å¹…çš„å¤§å°æˆæ­£æ¯”</strong>ï¼Œæœ¬æ–‡åªä»‹ç»å…¶ä¸­ä¸€ç§æ–¹æ–¹æ³•ï¼š</p><ul><li>å¯¹äºé•¿ç¯‡å¹…é‚®ä»¶ï¼ŒæŒ‰ä¸€å®šçš„å¤§å°ï¼Œæ¯”å¦‚æ¯500å­—ï¼Œå°†å…¶åˆ†å‰²æˆå°çš„æ–‡æœ¬æ®µè½ï¼Œå†å¯¹å°æ–‡æœ¬æ®µè½é‡‡ç”¨topkå…³é”®è¯çš„æ–¹æ³•ã€‚åªè¦å…¶ä¸­æœ‰ä¸€ä¸ªå°æ–‡æœ¬æ®µè½è¶…è¿‡é˜ˆå€¼å°±åˆ¤æ–­æ•´å°é‚®ä»¶æ˜¯åƒåœ¾é‚®ä»¶ã€‚</li><li>å¯¹äºè¶…çŸ­ç¯‡å¹…é‚®ä»¶ï¼Œæ¯”å¦‚50å­—ï¼Œå¯ä»¥æŒ‰ç¯‡å¹…ä¸æ ‡å‡†æ¯”è¾ƒç¯‡å¹…çš„æ¯”ä¾‹æ¥é€‰å–topkï¼Œä»¥ç¡®å®šåº”è¯¥åŒ¹é…å…³é”®è¯è¯­çš„ä¸ªæ•°ã€‚æ¯”å¦‚é€‰å– 50500Ã—15â‰ˆ2 ä¸ªè¯è¯­è¿›è¡ŒåŒ¹é…ï¼Œç›¸åº”çš„é˜ˆå€¼å¯ä»¥æ˜¯ä¹‹å‰é˜ˆå€¼çš„ 215 ã€‚ä»¥æ­¤æ¥åˆ¤æ–­åˆ™æ›´åˆç†ã€‚</li></ul><h3 id="14-5-trick5ï¼šä½ç½®æƒé‡"><a href="#14-5-trick5ï¼šä½ç½®æƒé‡" class="headerlink" title="14.5 trick5ï¼šä½ç½®æƒé‡"></a>14.5 trick5ï¼šä½ç½®æƒé‡</h3><p>åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å¯¹è¯è¯­æƒé‡æ±‚å’Œçš„è¿‡ç¨‹éƒ½æ²¡æœ‰è€ƒè™‘é‚®ä»¶ç¯‡ç« ç»“æ„çš„å› ç´ ã€‚æ¯”å¦‚â€œæ­£è§„å‘ç¥¨â€å¦‚æœå‡ºç°åœ¨æ ‡é¢˜ä¸­åº”è¯¥æ¯”å®ƒå‡ºç°åœ¨æ­£æ–‡ä¸­å¯¹åˆ¤æ–­æ•´ä¸ªé‚®ä»¶çš„å½±å“æ›´å¤§ï¼›è€Œå‡ºç°åœ¨æ®µé¦–å¥ä¸­åˆæ¯”å…¶å‡ºç°åœ¨æ®µè½æ­£æ–‡ä¸­å¯¹åˆ¤æ–­æ•´ä¸ªé‚®ä»¶çš„å½±å“æ›´å¤§ã€‚<strong>æ‰€ä»¥å¯ä»¥æ ¹æ®è¯è¯­å‡ºç°çš„ä½ç½®ï¼Œå¯¹å…¶æƒé‡å†ä¹˜ä»¥ä¸€ä¸ªæ”¾å¤§ç³»æ•°ï¼Œä»¥æ‰©å¤§å…¶å¯¹æ•´å°é‚®ä»¶çš„å½±å“ï¼Œæé«˜è¯†åˆ«å‡†ç¡®åº¦</strong>ã€‚</p><p>æ¯”å¦‚ä¸€å°é‚®ä»¶å…¶æ ‡é¢˜æ˜¯â€œæ­£è§„å‘ç¥¨â€ï¼ˆå‡è®¾æ ‡é¢˜çš„æ”¾å¤§ç³»æ•°ä¸º2ï¼‰ï¼Œæ®µé¦–å¥æ˜¯â€œå‘ç¥¨â€,â€œç‚¹æ•°â€,â€œä¼˜æƒ â€ï¼ˆå‡è®¾æ®µé¦–çš„æ”¾å¤§ç³»æ•°ä¸º1.5ï¼‰ï¼Œå‰©ä¸‹çš„å¥å­æ˜¯ï¼ˆâ€œæˆ‘â€,â€œå¸â€,â€œå¯â€,â€œåŠç†â€,â€œä¿çœŸâ€ï¼‰ã€‚åˆ™è®¡ç®—logCCâ¯â¯â¯â¯â¯ æ—¶çš„å…¬å¼å°±å¯ä»¥è°ƒæ•´ä¸ºï¼š</p><blockquote><p>logCCâ¯â¯â¯â¯â¯=2Ã—logP(â€œæ­£è§„å‘ç¥¨â€|S)P(â€œæ­£è§„å‘ç¥¨â€|H)+1.5Ã—logP(â€œå‘ç¥¨â€|S)P(â€œå‘ç¥¨â€|H)+1.5Ã—logP(â€œç‚¹æ•°â€|S)P(â€œç‚¹æ•°â€|H)+1.5Ã—logP(â€œä¼˜æƒ â€|S)P(â€œä¼˜æƒ â€|H)</p><p>+logP(â€œæˆ‘â€|S)P(â€œæˆ‘â€|H)+logP(â€œå¸â€|S)P(â€œå¸â€|H)+logP(â€œå¯â€|S)P(â€œå¯â€|H)+logP(â€œåŠç†â€|S)P(â€œåŠç†â€|H)+logP(â€œä¿çœŸâ€|S)P(â€œä¿çœŸâ€|H)+logP(â€œæ­£å¸¸é‚®ä»¶â€|S)P(â€œæ­£å¸¸é‚®ä»¶â€)</p></blockquote><h3 id="14-6-trick6ï¼šèœœç½"><a href="#14-6-trick6ï¼šèœœç½" class="headerlink" title="14.6 trick6ï¼šèœœç½"></a>14.6 trick6ï¼šèœœç½</h3><p>æˆ‘ä»¬é€šè¿‡è¾›è¾›è‹¦è‹¦çš„ç»Ÿè®¡ä¸è®¡ç®—ï¼Œå¥½ä¸å®¹æ˜“å¾—åˆ°äº†ä¸åŒè¯è¯­çš„æƒé‡ã€‚ç„¶è€Œè¿™å¹¶ä¸æ˜¯ä¸€åŠ³æ°¸é€¸çš„ã€‚æˆ‘ä»¬æˆ‘ä»¬ä¹‹å‰äº¤ä»£è¿‡ï¼Œ<strong>è¯è¯­åŠå…¶æƒé‡ä¼šéšç€æ—¶é—´ä¸æ–­å˜åŒ–ï¼Œéœ€è¦æ—¶ä¸æ—¶åœ°ç”¨æœ€æ–°çš„æ ·æœ¬æ¥è®­ç»ƒä»¥æ›´æ–°è¯è¯­åŠå…¶æƒé‡</strong>ã€‚</p><p>è€Œæœé›†æœ€æ–°åƒåœ¾é‚®ä»¶æœ‰ä¸€ä¸ªæŠ€å·§ï¼Œå°±æ˜¯éšä¾¿æ³¨å†Œä¸€äº›é‚®ç®±ï¼Œç„¶åå°†å®ƒä»¬å…¬å¸ƒåœ¨å„å¤§è®ºå›ä¸Šã€‚æ¥ä¸‹æ¥å°±åç­‰ä¸€ä¸ªæœˆï¼Œåˆ°æ—¶å€™æ”¶åˆ°çš„é‚®ä»¶å°±ç»å¤§éƒ¨åˆ†éƒ½æ˜¯åƒåœ¾é‚®ä»¶äº†ï¼ˆå¥½å¥¸è¯ˆï¼‰ã€‚å†æ‰¾ä¸€äº›æ­£å¸¸çš„é‚®ä»¶ï¼ŒåŸºæœ¬å°±èƒ½å¤Ÿè®­ç»ƒäº†ã€‚è¿™äº›ç”¨äºè‡ªåŠ¨æœé›†åƒåœ¾é‚®ä»¶çš„é‚®ç®±å«åšâ€œèœœç½â€ã€‚<strong>â€œèœœç½â€æ˜¯ç½‘ç»œå®‰å…¨é¢†åŸŸå¸¸ç”¨çš„æ‰‹æ®µï¼Œå› å…¶åŸç†ç±»ä¼¼è¯±æ•æ˜†è™«çš„è£…æœ‰èœœçš„ç½å­è€Œå¾—å</strong>ã€‚æ¯”å¦‚æ€æ¯’è½¯ä»¶å…¬å¸ä¼šåˆ©ç”¨èœœç½æ¥ç›‘è§†æˆ–è·å¾—è®¡ç®—æœºç½‘ç»œä¸­çš„ç—…æ¯’æ ·æœ¬ã€æ”»å‡»è¡Œä¸ºç­‰ã€‚</p><h2 id="15-è´å¶æ–¯æ–¹æ³•çš„æ€ç»´æ–¹å¼"><a href="#15-è´å¶æ–¯æ–¹æ³•çš„æ€ç»´æ–¹å¼" class="headerlink" title="15. è´å¶æ–¯æ–¹æ³•çš„æ€ç»´æ–¹å¼"></a>15. è´å¶æ–¯æ–¹æ³•çš„æ€ç»´æ–¹å¼</h2><p>è®²äº†è¿™ä¹ˆå¤štricksï¼Œä½†è¿™äº›æ‰‹æ®µéƒ½æ˜¯å»ºç«‹åœ¨è´å¶æ–¯æ–¹æ³•åŸºç¡€ä¹‹ä¸Šçš„ã€‚å› æ­¤æœ‰å¿…è¦æ¢è®¨ä¸€ä¸‹è´å¶æ–¯æ–¹æ³•çš„æ€ç»´æ–¹å¼ï¼Œä»¥ä¾¿æ›´å¥½åœ°åº”ç”¨è¿™ç§æ–¹æ³•è§£å†³å®é™…é—®é¢˜ã€‚</p><h3 id="15-1-é€†æ¦‚é—®é¢˜"><a href="#15-1-é€†æ¦‚é—®é¢˜" class="headerlink" title="15.1 é€†æ¦‚é—®é¢˜"></a>15.1 é€†æ¦‚é—®é¢˜</h3><p>æˆ‘ä»¬é‡æ–°çœ‹ä¸€çœ¼è´å¶æ–¯å…¬å¼ï¼š</p><blockquote><p>P(Y|X)=P(X|Y)P(Y)P(X)</p></blockquote><p>å…ˆä¸è€ƒè™‘å…ˆéªŒæ¦‚ç‡P(Y)ä¸P(X)ï¼Œè§‚å¯Ÿä¸¤ä¸ªåéªŒæ¦‚ç‡P(Y|X)ä¸P(X|Y)ï¼Œå¯è§è´å¶æ–¯å…¬å¼èƒ½å¤Ÿæ­ç¤º<strong>ä¸¤ä¸ªç›¸åæ–¹å‘çš„æ¡ä»¶æ¦‚ç‡ä¹‹é—´çš„è½¬æ¢å…³ç³»</strong>ã€‚</p><p>ä»è´å¶æ–¯å…¬å¼çš„å‘ç°å†å²æ¥çœ‹ï¼Œå…¶å°±æ˜¯ä¸ºäº†å¤„ç†æ‰€è°“â€œé€†æ¦‚â€é—®é¢˜è€Œè¯ç”Ÿçš„ã€‚æ¯”å¦‚P(Y|X) ä¸èƒ½é€šè¿‡ç›´æ¥è§‚æµ‹æ¥å¾—åˆ°ç»“æœï¼Œè€ŒP(X|Y) å´å®¹æ˜“é€šè¿‡ç›´æ¥è§‚æµ‹å¾—åˆ°ç»“æœï¼Œå°±å¯ä»¥é€šè¿‡è´å¶æ–¯å…¬å¼<strong>ä»é—´æ¥åœ°è§‚æµ‹å¯¹è±¡å»æ¨æ–­ä¸å¯ç›´æ¥è§‚æµ‹çš„å¯¹è±¡çš„æƒ…å†µ</strong>ã€‚</p><p>å¥½å§ï¼Œæˆ‘ä»¬è¯´äººè¯ã€‚åŸºäºé‚®ä»¶çš„æ–‡æœ¬å†…å®¹åˆ¤æ–­å…¶å±äºåƒåœ¾é‚®ä»¶çš„æ¦‚ç‡ä¸å¥½æ±‚ï¼ˆä¸å¯é€šè¿‡ç›´æ¥è§‚æµ‹ã€ç»Ÿè®¡å¾—åˆ°ï¼‰ï¼Œä½†æ˜¯åŸºäºå·²ç»æœé›†å¥½çš„åƒåœ¾é‚®ä»¶æ ·æœ¬ï¼Œå»ç»Ÿè®¡ï¼ˆç›´æ¥è§‚æµ‹ï¼‰å…¶æ–‡æœ¬å†…éƒ¨å„ä¸ªè¯è¯­çš„æ¦‚ç‡å´éå¸¸æ–¹ä¾¿ã€‚è¿™å°±å¯ä»¥ç”¨è´å¶æ–¯æ–¹æ³•ã€‚</p><p>å¼•ç”³ä¸€æ­¥ï¼ŒåŸºäºæ ·æœ¬ç‰¹å¾å»åˆ¤æ–­å…¶æ‰€å±æ ‡ç­¾çš„æ¦‚ç‡ä¸å¥½æ±‚ï¼Œä½†æ˜¯åŸºäºå·²ç»æœé›†å¥½çš„æ‰“ä¸Šæ ‡ç­¾çš„æ ·æœ¬ï¼ˆæœ‰ç›‘ç£ï¼‰ï¼Œå´å¯ä»¥ç›´æ¥ç»Ÿè®¡å±äºåŒä¸€æ ‡ç­¾çš„æ ·æœ¬å†…éƒ¨å„ä¸ªç‰¹å¾çš„æ¦‚ç‡åˆ†å¸ƒã€‚å› æ­¤è´å¶æ–¯æ–¹æ³•çš„ç†è®ºè§†è§’é€‚ç”¨äºä¸€åˆ‡åˆ†ç±»é—®é¢˜çš„æ±‚è§£ã€‚</p><h3 id="15-2-å¤„ç†å¤šåˆ†ç±»é—®é¢˜"><a href="#15-2-å¤„ç†å¤šåˆ†ç±»é—®é¢˜" class="headerlink" title="15.2 å¤„ç†å¤šåˆ†ç±»é—®é¢˜"></a>15.2 å¤„ç†å¤šåˆ†ç±»é—®é¢˜</h3><p>å‰é¢æˆ‘ä»¬ä¸€ç›´åœ¨æ¢è®¨äºŒåˆ†ç±»ï¼ˆåˆ¤æ–­é¢˜ï¼‰é—®é¢˜ï¼Œç°åœ¨å¯ä»¥å¼•ç”³åˆ°å¤šåˆ†ç±»ï¼ˆå•é€‰é¢˜ï¼‰é—®é¢˜äº†ã€‚</p><p>è¿˜æ˜¯ç”¨é‚®ä»¶åˆ†ç±»çš„ä¾‹å­ï¼Œè¿™æ˜¯ç°åœ¨ä¸åªè¦åˆ¤æ–­åƒåœ¾é‚®ä»¶ï¼Œè¿˜è¦å°†æ­£å¸¸é‚®ä»¶ç»†åˆ†ä¸ºç§äººé‚®ä»¶ã€å·¥ä½œé‚®ä»¶ã€‚ç°åœ¨æœ‰è¿™3ç±»é‚®ä»¶å„1ä¸‡å°ä½œä¸ºæ ·æœ¬ã€‚éœ€è¦è®­ç»ƒå‡ºä¸€ä¸ªè´å¶æ–¯åˆ†ç±»å™¨ã€‚è¿™é‡Œä¾æ¬¡ç”¨Y1,Y2,Y3è¡¨ç¤ºè¿™ä¸‰ç±»é‚®ä»¶ï¼Œç”¨Xè¡¨ç¤ºè¢«åˆ¤æ–­çš„é‚®ä»¶ã€‚å¥—ç”¨è´å¶æ–¯å…¬å¼æœ‰ï¼š</p><blockquote><p>P(Y1|X)=P(X|Y1)P(Y1)P(X)</p><p>P(Y2|X)=P(X|Y2)P(Y2)P(X)</p><p>P(Y3|X)=P(X|Y3)P(Y3)P(X)</p></blockquote><p>é€šè¿‡æ¯”è¾ƒ3ä¸ªæ¦‚ç‡å€¼çš„å¤§å°å³å¯å¾—åˆ°Xæ‰€å±çš„åˆ†ç±»ã€‚å‘ç°ä¸‰ä¸ªå¼å­çš„åˆ†æ¯P(X) ä¸€æ ·ï¼Œæ¯”è¾ƒå¤§å°æ—¶å¯ä»¥å¿½ç•¥ä¸è®¡ï¼Œäºæ˜¯å°±å¯ä»¥ç”¨ä¸‹é¢è¿™ä¸€ä¸ªå¼å­è¡¨è¾¾ä¸Šé¢3å¼ï¼š</p><blockquote><p>P(Yi|X)âˆP(X|Yi)P(Yi)ï¼›i=1,2,3</p></blockquote><p>å…¶ä¸­ âˆ è¡¨ç¤ºâ€œæ­£æ¯”äºâ€ã€‚è€ŒP(X|Yi) åˆ™æœ‰ä¸ªç‰¹åˆ«é«˜é€¼æ ¼çš„åå­—å«åšâ€œ<strong>ä¼¼ç„¶å‡½æ•°</strong>â€ã€‚æˆ‘ä»¬ä¸Šå¤§å­¦çš„æ—¶å€™ä¹Ÿè¢«è¿™ä¸ªåå­—æå¾—æ™•æ™•ä¹ä¹çš„ï¼Œå…¶å®å®ƒä¹Ÿæ˜¯ä¸ªæ¦‚ç‡ï¼Œç›´æ¥ç†è§£æˆ<strong>â€œP(Yi|X) çš„é€†åæ¡ä»¶æ¦‚ç‡â€</strong> å°±æ–¹ä¾¿äº†ã€‚</p><p>è¿™é‡Œåªæ˜¯ä»¥åƒåœ¾é‚®ä»¶3åˆ†ç±»é—®é¢˜ä¸¾äº†ä¸ªä¾‹å­ï¼Œ<strong>å¯¹äºä»»æ„å¤šåˆ†ç±»çš„é—®é¢˜éƒ½å¯ä»¥ç”¨è¿™æ ·çš„æ€è·¯å»ç†è§£ã€‚æ¯”å¦‚æ–°é—»åˆ†ç±»ã€æƒ…æ„Ÿå–œæ€’å“€ä¹åˆ†ç±»ç­‰ç­‰</strong>ã€‚</p><h3 id="15-3-å…ˆéªŒæ¦‚ç‡çš„é—®é¢˜"><a href="#15-3-å…ˆéªŒæ¦‚ç‡çš„é—®é¢˜" class="headerlink" title="15.3 å…ˆéªŒæ¦‚ç‡çš„é—®é¢˜"></a>15.3 å…ˆéªŒæ¦‚ç‡çš„é—®é¢˜</h3><p>åœ¨åƒåœ¾é‚®ä»¶çš„ä¾‹å­ä¸­ï¼Œå…ˆéªŒæ¦‚ç‡éƒ½ç›¸ç­‰ï¼ŒP(Y1)=P(Y2)=P(Y3)=10000/30000=1/3ï¼Œæ‰€ä»¥ä¸Šé¢æ˜¯å¼å­åˆå¯ä»¥è¿›ä¸€æ­¥åŒ–ç®€ï¼š</p><blockquote><p>P(Yi|X)âˆP(X|Yi)ï¼›i=1,2,3</p></blockquote><p>åªéœ€æ¯”è¾ƒå³è¾¹å¼å­ï¼ˆä¹Ÿå°±æ˜¯â€œä¼¼ç„¶å‡½æ•°â€ï¼‰çš„å¤§å°å°±å¯ä»¥äº†ã€‚è¿™ç§æ–¹æ³•å°±æ˜¯ä¼ è¯´ä¸­çš„<strong>æœ€å¤§ä¼¼ç„¶æ³•</strong>:ä¸è€ƒè™‘å…ˆéªŒæ¦‚ç‡è€Œç›´æ¥æ¯”è¾ƒä¼¼ç„¶å‡½æ•°ã€‚</p><p>å…³äºé€‰å‡ºæœ€ä½³åˆ†ç±»Yiæ˜¯å¦è¦è€ƒè™‘å…ˆéªŒæ¦‚ç‡P(Yi)çš„é—®é¢˜ï¼Œæ›¾ç»åœ¨é¢‘ç‡å­¦æ´¾å’Œè´å¶æ–¯å­¦æ´¾ä¹‹é—´äº§ç”Ÿäº†æ¿€çƒˆçš„æ•™æ´¾å†²çªã€‚ç»Ÿè®¡å­¦å®¶ï¼ˆé¢‘ç‡å­¦æ´¾ï¼‰è¯´ï¼šæˆ‘ä»¬è®©æ•°æ®è‡ªå·±è¯´è¯ã€‚è¨€ä¸‹ä¹‹æ„å°±æ˜¯è¦æ‘’å¼ƒå…ˆéªŒæ¦‚ç‡ã€‚è€Œè´å¶æ–¯å­¦æ´¾æ”¯æŒè€…åˆ™è¯´ï¼šæ•°æ®ä¼šæœ‰å„ç§å„æ ·çš„åå·®ï¼Œè€Œä¸€ä¸ª<strong>é è°±çš„å…ˆéªŒæ¦‚ç‡</strong>åˆ™å¯ä»¥å¯¹è¿™äº›éšæœºå™ªéŸ³åšåˆ°å¥å£®ã€‚å¯¹æ­¤æœ‰å…´è¶£çš„åŒå­¦å¯ä»¥æ‰¾æ›´å¤šèµ„æ–™è¿›è¡Œäº†è§£ï¼Œæœ¬æ–‡åœ¨æ­¤ä¸åšæ›´å¤šçš„å¼•ç”³ï¼ŒåªåŸºäºåƒåœ¾é‚®ä»¶è¯†åˆ«çš„ä¾‹å­è¿›è¡Œæ¢è®¨ã€‚</p><p>æ¯”å¦‚æˆ‘ä»¬åœ¨é‡‡é›†åƒåœ¾é‚®ä»¶æ ·æœ¬çš„æ—¶å€™ï¼Œä¸å°å¿ƒdeleteæ‰äº†ä¸€åŠçš„æ•°æ®ï¼Œå°±å‰©ä¸‹5000å°é‚®ä»¶ã€‚åˆ™è®¡ç®—å‡ºæ¥çš„å…ˆéªŒæ¦‚ç‡ä¸º:</p><blockquote><p>P(Y1)=5000/25000=1/5ï¼Œ</p><p>P(Y2)=P(Y3)=10000/25000=2/5</p></blockquote><p>å¦‚æœè¿˜ç”¨è´å¶æ–¯æ–¹æ³•,å°±è¦åœ¨ä¼¼ç„¶å‡½æ•°åé¢ä¹˜ä¸Šå…ˆéªŒæ¦‚ç‡ã€‚æ¯”å¦‚ä¹‹å‰ç”¨æœ€å¤§ä¼¼ç„¶æ³•ç®—å‡ºY1 åƒåœ¾é‚®ä»¶çš„æ¦‚ç‡å¤§ï¼Œä½†æ˜¯å› ä¸ºP(Y1)ç‰¹åˆ«å°ï¼Œç”¨è´å¶æ–¯æ–¹æ³•å¾—å‡ºçš„ç»“æœæ˜¯Y2 ç§äººé‚®ä»¶çš„æ¦‚ç‡å¤§ã€‚é‚£ç›¸ä¿¡å“ªä¸ªå‘¢ï¼Ÿå…¶å®ï¼Œæˆ‘ä»¬åˆ æ‰äº†éƒ¨åˆ†å¸¦æ ‡ç­¾çš„æ ·æœ¬ï¼Œä»è®¡ç®—ç»“æœçœ‹P(Y1)ï¼ŒP(Y2)ï¼ŒP(Y3)çš„æ¦‚ç‡åˆ†å¸ƒå˜åŒ–äº†ï¼Œä½†å®é™…ä¸Š<strong>è¿™ä¸‰ä¸ªç±»åˆ«çš„çœŸå®åˆ†å¸ƒåº”è¯¥æ˜¯ä¸€ä¸ªå®¢è§‚çš„çŠ¶æ€ï¼Œä¸åº”è¯¥å› ä¸ºæˆ‘ä»¬çš„è®¡ç®—æ–¹æ³•è€Œå‘ç”Ÿå˜åŒ–</strong>ã€‚æ‰€ä»¥æ˜¯æˆ‘ä»¬è®¡ç®—å‡ºæ¥çš„å…ˆéªŒæ¦‚ç‡å¤±çœŸï¼Œåº”è¯¥æ”¾å¼ƒè¿™æ ·è®¡ç®—å‡ºæ¥çš„å…ˆéªŒæ¦‚ç‡ï¼Œè€Œç”¨æœ€å¤§ä¼¼ç„¶æ³•ã€‚ä½†å³ä¾¿æˆ‘ä»¬ä¸åˆ æ‰ä¸€åŠåƒåœ¾é‚®ä»¶ï¼Œè¿™ä¸‰ç±»é‚®ä»¶çš„åˆ†å¸ƒå°±çœŸçš„æ˜¯1:1:1é‚£æ ·å¹³å‡å—ï¼Ÿé‚£ä¹Ÿæœªå¿…ã€‚<strong>æˆ‘ä»¬åªæ˜¯æŒ‰1:1:1è¿™æ ·çš„æ–¹å¼è¿›è¡Œäº†æŠ½æ ·è€Œå·²ï¼ŒçœŸæ­£åœ¨é‚®ç®±é‡Œæ”¶åˆ°çš„è¿™ä¸‰ç±»é‚®ä»¶çš„åˆ†å¸ƒå¯èƒ½å¹¶ä¸æ˜¯è¿™æ ·</strong>ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œ<strong>åœ¨æˆ‘ä»¬å¯¹äºå…ˆéªŒæ¦‚ç‡ä¸€æ— æ‰€çŸ¥æ—¶ï¼Œåªèƒ½å‡è®¾æ¯ç§çŒœæµ‹çš„å…ˆéªŒæ¦‚ç‡æ˜¯å‡ç­‰çš„ï¼ˆå…¶å®è¿™ä¹Ÿæ˜¯äººç±»ç»éªŒçš„ç»“æœï¼‰ï¼Œè¿™ä¸ªæ—¶å€™å°±åªæœ‰ç”¨æœ€å¤§ä¼¼ç„¶äº†</strong>ã€‚åœ¨ç°å®è¿ç”¨è¿‡ç¨‹ä¸­å¦‚æœå‘ç°æœ€å¤§ä¼¼ç„¶æ³•æœ‰åå·®ï¼Œå¯ä»¥è€ƒè™‘å¯¹ä¸åŒçš„ä¼¼ç„¶å‡½æ•°è®¾å®šä¸€äº›ç³»æ•°æˆ–è€…é˜ˆå€¼ï¼Œä½¿å…¶æ¥è¿‘çœŸå®æƒ…å†µã€‚</p><p>ä½†æ˜¯ï¼Œ<strong>å¦‚æœæˆ‘ä»¬æœ‰è¶³å¤Ÿçš„è‡ªä¿¡ï¼Œè®­ç»ƒé›†ä¸­è¿™ä¸‰ç±»çš„æ ·æœ¬åˆ†å¸ƒçš„ç¡®å¾ˆæ¥è¿‘çœŸå®çš„æƒ…å†µï¼Œè¿™æ—¶å°±åº”è¯¥ç”¨è´å¶æ–¯æ–¹æ³•</strong>ã€‚éš¾æ€ªå‰é¢çš„è´å¶æ–¯å­¦æ´¾å¼ºè°ƒçš„æ˜¯â€œé è°±çš„å…ˆéªŒæ¦‚ç‡â€ã€‚æ‰€ä»¥è¯´<strong>è´å¶æ–¯å­¦æ´¾çš„é€‚ç”¨èŒƒå›´æ›´å¹¿ï¼Œå…³é”®è¦å…ˆéªŒæ¦‚ç‡é è°±ï¼Œè€Œé¢‘ç‡å­¦æ´¾æœ‰æ•ˆçš„å‰æä¹Ÿæ˜¯ä»–ä»¬çš„å…ˆéªŒæ¦‚ç‡åŒæ ·æ˜¯ç»éªŒç»Ÿè®¡çš„ç»“æœ</strong>ã€‚</p><h2 id="16-æœ´ç´ -è´å¶æ–¯æ–¹æ³•çš„å¸¸è§åº”ç”¨"><a href="#16-æœ´ç´ -è´å¶æ–¯æ–¹æ³•çš„å¸¸è§åº”ç”¨" class="headerlink" title="16. (æœ´ç´ )è´å¶æ–¯æ–¹æ³•çš„å¸¸è§åº”ç”¨"></a>16. (æœ´ç´ )è´å¶æ–¯æ–¹æ³•çš„å¸¸è§åº”ç”¨</h2><p>è¯´äº†è¿™ä¹ˆå¤šç†è®ºçš„é—®é¢˜ï¼Œå’±ä»¬å°±å¯ä»¥æ¢è®¨ä¸€ä¸‹(æœ´ç´ )è´å¶æ–¯æ–¹æ³•åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„ä¸€äº›å¸¸è§åº”ç”¨äº†ã€‚ä»¥ä¸‹åªæ˜¯ä»åŸç†ä¸Šè¿›è¡Œæ¢è®¨ï¼Œå¯¹äºå…·ä½“çš„æŠ€æœ¯ç»†èŠ‚é¡¾åŠä¸å¤šã€‚</p><h3 id="16-1-è¤’è´¬åˆ†æ"><a href="#16-1-è¤’è´¬åˆ†æ" class="headerlink" title="16.1 è¤’è´¬åˆ†æ"></a>16.1 è¤’è´¬åˆ†æ</h3><p>ä¸€ä¸ªæ¯”è¾ƒå¸¸è§çš„åº”ç”¨åœºæ™¯æ˜¯æƒ…æ„Ÿè¤’è´¬åˆ†æã€‚æ¯”å¦‚ä½ è¦ç»Ÿè®¡å¾®åšä¸Šäººä»¬å¯¹ä¸€ä¸ªæ–°ä¸Šæ˜ ç”µå½±çš„è¤’è´¬ç¨‹åº¦è¯„ä»·ï¼šå¥½ç‰‡è¿˜æ˜¯çƒ‚ç‰‡ã€‚ä½†æ˜¯ä¸€æ¡ä¸€æ¡åœ°çœ‹å¾®åšæ˜¯æ ¹æœ¬çœ‹ä¸è¿‡æ¥ï¼Œåªèƒ½ç”¨è‡ªåŠ¨åŒ–çš„æ–¹æ³•ã€‚æˆ‘ä»¬å¯ä»¥æœ‰ä¸€ä¸ªå¾ˆç²—ç•¥çš„æ€è·¯ï¼š</p><ul><li>é¦–å…ˆæ˜¯ç”¨çˆ¬è™«å°†å¾®åšä¸Šæåˆ°è¿™ä¸ªç”µå½±åå­—çš„å¾®åšå…¨éƒ½æŠ“å–ä¸‹æ¥ï¼Œæ¯”å¦‚æœ‰10ä¸‡æ¡ã€‚</li><li>ç„¶åç”¨è®­ç»ƒå¥½çš„æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨åˆ†åˆ«åˆ¤æ–­è¿™äº›å¾®åšå¯¹ç”µå½±æ˜¯å¥½è¯„è¿˜æ˜¯å·®è¯„ã€‚</li><li>æœ€åç»Ÿè®¡å‡ºè¿™äº›å¥½è¯„çš„å½±è¯„å æ‰€æœ‰æ ·æœ¬ä¸­çš„æ¯”ä¾‹ï¼Œå°±èƒ½å½¢æˆå¾®åšç½‘å‹å¯¹è¿™ä¸ªç”µå½±ç»¼åˆè¯„ä»·çš„å¤§è‡´ä¼°è®¡ã€‚</li></ul><p>æ¥ä¸‹æ¥çš„æ ¸å¿ƒé—®é¢˜å°±æ˜¯è®­ç»ƒå‡ºä¸€ä¸ªé è°±çš„åˆ†ç±»å™¨ã€‚é¦–å…ˆéœ€è¦æœ‰æ‰“å¥½æ ‡ç­¾çš„æ–‡æœ¬ã€‚è¿™ä¸ªå¥½æ‰¾ï¼Œè±†ç“£å½±è¯„ä¸Šå°±æœ‰å¤§é‡ç½‘å‹å¯¹ä¹‹å‰ç”µå½±çš„è¯„ä»·ï¼Œå¹¶ä¸”å¯¹ç”µå½±è¿›è¡Œ1æ˜Ÿåˆ°5æ˜Ÿçš„è¯„ä»·ã€‚æˆ‘ä»¬å¯ä»¥è®¤ä¸º3æ˜Ÿä»¥ä¸Šçš„è¯„è®ºéƒ½æ˜¯å¥½è¯„ï¼Œ3æ˜Ÿä»¥ä¸‹çš„è¯„è®ºéƒ½æ˜¯å·®è¯„ã€‚è¿™æ ·å°±åˆ†åˆ«å¾—åˆ°äº†å¥½è¯„å·®è¯„ä¸¤ç±»çš„è¯­æ–™æ ·æœ¬ã€‚å‰©ä¸‹å°±å¯ä»¥ç”¨æœ´ç´ è´å¶æ–¯æ–¹æ³•è¿›è¡Œè®­ç»ƒäº†ã€‚åŸºæœ¬æ€è·¯å¦‚ä¸‹ï¼š</p><ul><li>è®­ç»ƒä¸æµ‹è¯•æ ·æœ¬ï¼šè±†ç“£å½±è¯„çš„ç½‘å‹è¯„è®ºï¼Œç”¨çˆ¬è™«æŠ“å–ä¸‹100ä¸‡æ¡ã€‚</li><li>æ ‡ç­¾ï¼š3æ˜Ÿä»¥ä¸Šçš„æ˜¯å¥½è¯„ï¼Œ3æ˜Ÿä»¥ä¸‹çš„æ˜¯å·®è¯„ã€‚</li><li>ç‰¹å¾ï¼šè±†ç“£è¯„è®ºåˆ†è¯åçš„è¯è¯­ã€‚ä¸€ä¸ªç®€å•çš„æ–¹æ³•æ˜¯åªé€‰æ‹©å…¶ä¸­çš„å½¢å®¹è¯ï¼Œç½‘ä¸Šæœ‰å¤§é‡çš„æƒ…ç»ªè¯åº“å¯ä»¥ä¸ºæˆ‘ä»¬æ‰€ç”¨ã€‚</li><li>ç„¶åå†ç”¨å¸¸è§„çš„æœ´ç´ è´å¶æ–¯æ–¹æ³•è¿›è¡Œè®­ç»ƒã€‚</li></ul><p>ä½†æ˜¯ç”±äºè‡ªç„¶è¯­è¨€çš„ç‰¹ç‚¹ï¼Œåœ¨æå–ç‰¹å¾çš„è¿‡ç¨‹å½“ä¸­ï¼Œæœ‰ä¸€äº›trickséœ€è¦æ³¨æ„ï¼š</p><ul><li><strong>å¯¹å¦å®šå¥è¿›è¡Œç‰¹åˆ«çš„å¤„ç†</strong>ã€‚æ¯”å¦‚è¿™å¥è¯â€œæˆ‘ä¸æ˜¯å¾ˆå–œæ¬¢éƒ¨ç”µå½±ï¼Œå› ä¸ºå®ƒè®©æˆ‘å¼€å¿ƒä¸èµ·æ¥ã€‚â€å…¶ä¸­ä¸¤ä¸ªå½¢å®¹è¯â€œå–œæ¬¢â€ã€â€œå¼€å¿ƒâ€éƒ½æ˜¯è¤’ä¹‰è¯ï¼Œä½†æ˜¯å› ä¸ºå¥å­çš„å¦å®šå¥ï¼Œæ‰€ä»¥æ•´ä½“æ˜¯è´¬ä¹‰çš„ã€‚æœ‰ä¸€ç§æ¯”è¾ƒç®€å•ç²—æš´çš„å¤„ç†æ–¹å¼ï¼Œå°±æ˜¯<strong>â€œå¯¹å¦å®šè¯ï¼ˆâ€œä¸â€ã€â€œéâ€ã€â€œæ²¡â€ç­‰ï¼‰ä¸å¥å°¾æ ‡ç‚¹ä¹‹é—´çš„æ‰€æœ‰å½¢å®¹è¯éƒ½é‡‡ç”¨å…¶å¦å®šå½¢å¼â€</strong> ã€‚åˆ™è¿™å¥è¯ä¸­æå–å‡ºæ¥çš„å½¢å®¹è¯å°±åº”è¯¥æ˜¯â€œä¸å–œæ¬¢â€å’Œâ€œä¸å¼€å¿ƒâ€ã€‚</li><li>ä¸€èˆ¬è¯´æ¥ï¼Œæœ€ç›¸å…³çš„æƒ…æ„Ÿè¯åœ¨ä¸€äº›æ–‡æœ¬ç‰‡æ®µä¸­ä»…ä»…å‡ºç°ä¸€æ¬¡ï¼Œè¯é¢‘æ¨¡å‹èµ·å¾—ä½œç”¨æœ‰é™ï¼Œç”šè‡³æ˜¯è´Ÿä½œç”¨ï¼Œ<strong>åˆ™ä½¿ç”¨ä¼¯åŠªåˆ©æ¨¡å‹ä»£æ›¿å¤šé¡¹å¼æ¨¡å‹</strong>ã€‚è¿™ç§æƒ…å†µåœ¨å¾®åšè¿™æ ·çš„å°ç¯‡å¹…æ–‡æœ¬ä¸­ä¼¼ä¹ä¸å¤ªæ˜æ˜¾ï¼Œä½†æ˜¯åœ¨åšå®¢ã€ç©ºé—´ã€è®ºå›ä¹‹ç±»å…è®¸é•¿ç¯‡å¹…æ–‡æœ¬å‡ºç°çš„å¹³å°ä¸­éœ€è¦æ³¨æ„ã€‚</li><li>å…¶å®ï¼Œå‰¯è¯å¯¹æƒ…æ„Ÿçš„è¯„ä»·æœ‰ä¸€å®šå½±å“ã€‚â€œä¸å¾ˆå–œæ¬¢â€ä¸â€œå¾ˆä¸å–œæ¬¢â€çš„ç¨‹åº¦å°±æœ‰å¾ˆå¤§å·®å¼‚ã€‚ä½†å¦‚æœæ˜¯æœ´ç´ è´å¶æ–¯æ–¹æ³•çš„è¯æ¯”è¾ƒéš¾å¤„ç†è¿™æ ·çš„æƒ…å†µã€‚æˆ‘ä»¬å¯ä»¥è€ƒè™‘ç”¨è¯­è¨€æ¨¡å‹æˆ–è€…åŠ å…¥è¯æ€§æ ‡æ³¨çš„ä¿¡æ¯è¿›è¡Œç»¼åˆåˆ¤æ–­ã€‚è¿™äº›å†…å®¹æˆ‘ä»¬å°†åœ¨ä¹‹åçš„æ–‡ç« è¿›è¡Œæ¢è®¨ã€‚</li></ul><p>å½“ç„¶ç»è¿‡ä»¥ä¸Šçš„å¤„ç†ï¼Œæƒ…æ„Ÿåˆ†æè¿˜æ˜¯ä¼šæœ‰ä¸€éƒ¨åˆ†è¯¯åˆ¤ã€‚è¿™é‡Œæ¶‰åŠåˆ°è®¸å¤šé—®é¢˜ï¼Œéƒ½æ˜¯æƒ…æ„Ÿåˆ†æçš„éš¾ç‚¹ï¼š</p><ul><li><strong>æƒ…ç»ªè¡¨è¾¾çš„å«è“„å¾®å¦™</strong>ï¼šâ€œå¯¼æ¼”ä½ å‡ºæ¥ï¼Œæˆ‘ä¿è¯ä¸æ‰“æ­»ä½ ã€‚â€ä½ è®©æœºå™¨æ€ä¹ˆåˆ¤æ–­æ˜¯è¤’è¿˜æ˜¯è´¬ï¼Ÿ</li><li><strong>è½¬æŠ˜æ€§è¡¨è¾¾</strong>ï¼šâ€œæˆ‘éå¸¸å–œæ¬¢è¿™äº›å¤§ç‰Œæ¼”å‘˜ï¼Œéå¸¸å´‡æ‹œè¿™ä¸ªå¯¼æ¼”ï¼Œéå¸¸èµèµè¿™ä¸ªå‰§æœ¬ï¼Œéå¸¸æ¬£èµä»–ä»¬çš„é¢„å‘Šç‰‡ï¼Œæˆ‘ç”šè‡³ä¸ºäº†è¿™éƒ¨å½±ç‰‡æ•´æ•´æœŸå¾…äº†ä¸€å¹´ï¼Œæœ€åè¿›äº†ç”µå½±é™¢å‘ç°è¿™æ˜¯ä¸ªå™©æ¢¦ã€‚â€ äº”ä¸ªè¤’ä¹‰çš„å½¢å®¹è¯ã€å‰¯è¯å¯¹ä¸€ä¸ªä¸é‚£ä¹ˆè´¬ä¹‰çš„è¯ã€‚æœºå™¨è‡ªç„¶åˆ¤æ–­æˆè¤’ä¹‰ï¼Œä½†è¿™å¥è¯æ˜¯å¦¥å¦¥çš„è´¬ä¹‰ã€‚</li></ul><h3 id="16-2-æ‹¼å†™çº é”™"><a href="#16-2-æ‹¼å†™çº é”™" class="headerlink" title="16.2 æ‹¼å†™çº é”™"></a>16.2 æ‹¼å†™çº é”™</h3><p>æ‹¼å†™çº é”™æœ¬è´¨ä¸Šä¹Ÿæ˜¯ä¸€ä¸ªåˆ†ç±»é—®é¢˜ã€‚ä½†æŒ‰ç…§é”™è¯¯ç±»å‹ä¸åŒï¼Œåˆåˆ†ä¸ºä¸¤ç§æƒ…å†µï¼š</p><ul><li>éè¯é”™è¯¯ï¼ˆNon-word Errorsï¼‰ï¼šæŒ‡é‚£äº›æ‹¼å†™é”™è¯¯åçš„è¯æœ¬èº«å°±ä¸åˆæ³•ï¼Œå¦‚å°†â€œwifiâ€å†™æˆâ€œwifyâ€ï¼›</li><li>çœŸè¯é”™è¯¯ï¼ˆReal-word Errorsï¼‰ï¼šæŒ‡é‚£äº›æ‹¼å†™é”™è¯¯åçš„è¯ä»ç„¶æ˜¯åˆæ³•çš„æƒ…å†µï¼Œå¦‚å°†â€œwifiâ€å†™æˆâ€œwifeâ€ã€‚</li></ul><p>çœŸè¯é”™è¯¯å¤æ‚ä¸€äº›ï¼Œæˆ‘ä»¬å°†åœ¨æ¥ä¸‹æ¥çš„æ–‡ç« ä¸­è¿›è¡Œæ¢è®¨ã€‚è€Œå¯¹äºéè¯é”™è¯¯ï¼Œå°±å¯ä»¥ç›´æ¥é‡‡ç”¨è´å¶æ–¯æ–¹æ³•ï¼Œå…¶åŸºæœ¬æ€è·¯å¦‚ä¸‹ï¼š</p><ul><li>æ ‡ç­¾ï¼šé€šè¿‡è®¡ç®—é”™è¯¯è¯è¯­çš„æœ€å°ç¼–è¾‘è·ç¦»ï¼ˆä¹‹å‰å’±ä»¬æåˆ°è¿‡çš„ï¼‰ï¼Œè·å–æœ€ç›¸ä¼¼çš„å€™é€‰è¯ï¼Œæ¯ä¸ªå€™é€‰è¯ä½œä¸ºä¸€ä¸ªåˆ†ç±»ã€‚</li><li>ç‰¹å¾ï¼šæ‹¼å†™é”™è¯¯çš„è¯æœ¬èº«ã€‚å› ä¸ºå®ƒå°±ä¸€ä¸ªç‰¹å¾ï¼Œæ‰€ä»¥æ²¡æœ‰ä»€ä¹ˆæ¡ä»¶ç‹¬ç«‹æ€§å‡è®¾ã€æœ´ç´ è´å¶æ–¯å•¥çš„ã€‚å®ƒå°±æ˜¯çº¯è€Œåˆçº¯çš„è´å¶æ–¯æ–¹æ³•ã€‚</li><li>åˆ¤åˆ«å…¬å¼:</li></ul><blockquote><p>P(å€™é€‰è¯i|é”™è¯¯è¯)âˆP(é”™è¯¯è¯|å€™é€‰è¯i)P(å€™é€‰è¯i)ï¼›i=1,2,3,â€¦</p></blockquote><ul><li>è®­ç»ƒæ ·æœ¬1ï¼šè¯¥åœºæ™¯ä¸‹çš„æ­£å¸¸ç”¨è¯è¯­æ–™åº“ï¼Œç”¨äºè®¡ç®—P(å€™é€‰è¯i)ã€‚</li></ul><blockquote><p>P(å€™é€‰è¯i)=å€™é€‰è¯å‡ºç°çš„æ¬¡æ•°æ‰€æœ‰è¯å‡ºç°çš„æ¬¡æ•°</p></blockquote><ul><li>è®­ç»ƒæ ·æœ¬2ï¼šè¯¥åœºæ™¯ä¸‹é”™è¯¯è¯ä¸æ­£ç¡®è¯å¯¹åº”å…³ç³»çš„è¯­æ–™åº“ï¼Œç”¨äºè®¡ç®—P(é”™è¯¯è¯|å€™é€‰è¯i)</li></ul><blockquote><p>P(é”™è¯¯è¯|å€™é€‰è¯i)=å€™é€‰è¯è¢«æ‹¼å†™æˆè¯¥â€œé”™è¯¯è¯â€çš„æ¬¡æ•°å€™é€‰è¯å‡ºç°çš„æ¬¡æ•°</p></blockquote><p>ç”±äºè‡ªç„¶è¯­è¨€çš„ç‰¹ç‚¹ï¼Œæœ‰ä¸€äº›trickséœ€è¦æ³¨æ„ï¼š</p><ul><li>æ®ç»Ÿè®¡ï¼Œ80%çš„æ‹¼å†™é”™è¯¯ç¼–è¾‘è·ç¦»ä¸º1ï¼Œå‡ ä¹æ‰€æœ‰çš„æ‹¼å†™é”™è¯¯ç¼–è¾‘è·ç¦»å°äºç­‰äº2ã€‚æˆ‘ä»¬<strong>åªé€‰æ‹©ç¼–è¾‘è·ç¦»ä¸º1æˆ–2çš„è¯ä½œä¸ºå€™é€‰è¯ï¼Œè¿™æ ·å°±å¯ä»¥å‡å°‘å¤§é‡ä¸å¿…è¦çš„è®¡ç®—</strong>ã€‚</li><li>ç”±äºæˆ‘ä»¬åªé€‰æ‹©ç¼–è¾‘è·ç¦»ä¸º1æˆ–2çš„è¯ï¼Œå…¶å·®åˆ«åªæ˜¯ä¸€ä¸¤ä¸ªå­—æ¯çº§åˆ«å·®åˆ«ã€‚å› æ­¤è®¡ç®—ä¼¼ç„¶å‡½æ•°çš„æ—¶å€™ï¼Œ<strong>å¯ä»¥åªç»Ÿè®¡å­—æ¯å±‚é¢çš„ç¼–è¾‘é”™è¯¯ï¼Œè¿™æ ·æœé›†çš„æ ·æœ¬æ›´å¤šï¼Œæ›´æ»¡è¶³å¤§æ•°å®šå¾‹ï¼Œä¹Ÿæ›´ç®€å•</strong>ã€‚å¯¹äºç¼–è¾‘è·ç¦»ä¸º1çš„ä¼¼ç„¶å‡½æ•°è®¡ç®—å…¬å¼å¯ä»¥è¿›åŒ–ä¸ºï¼š</li></ul><blockquote><p>P(é”™è¯¯è¯|å€™é€‰è¯i)=â§â©â¨âªâªâªâªâªâªå­—æ¯â€œxyâ€è¢«æ‹¼å†™æˆâ€œyâ€çš„æ¬¡æ•°å­—æ¯â€œxyâ€å‡ºç°çš„æ¬¡æ•°,å­—æ¯â€œxâ€è¢«æ‹¼å†™æˆâ€œxyâ€çš„æ¬¡æ•°å­—æ¯â€œxâ€å‡ºç°çš„æ¬¡æ•°,å­—æ¯â€œxâ€è¢«æ‹¼å†™æˆâ€œyâ€çš„æ¬¡æ•°å­—æ¯â€œxâ€å‡ºç°çš„æ¬¡æ•°,å­—æ¯â€œxyâ€è¢«æ‹¼å†™æˆâ€œyxçš„æ¬¡æ•°å­—æ¯â€œxyâ€å‡ºç°çš„æ¬¡æ•°,</p></blockquote><ul><li><strong>é”®ç›˜ä¸Šä¸´è¿‘çš„æŒ‰é”®æ›´å®¹æ˜“æ‹¼å†™é”™è¯¯ï¼Œæ®æ­¤å¯ä»¥å¯¹ä¸Šé¢è¿™ä¸ªæ¡ä»¶æ¦‚ç‡è¿›è¡ŒåŠ æƒ</strong>ã€‚</li></ul><p><img src="blob:file:///3ecb40bd-0f8b-4742-ac50-e0912d5c6cc0" alt="\[é”®ç›˜\]"></p><h2 id="17-å†…å®¹å°ç»“"><a href="#17-å†…å®¹å°ç»“" class="headerlink" title="17. å†…å®¹å°ç»“"></a>17. å†…å®¹å°ç»“</h2><p>ä»å‰é¢å¤§å®¶åŸºæœ¬å¯ä»¥çœ‹å‡ºï¼Œå·¥ç¨‹åº”ç”¨ä¸åŒäºå­¦æœ¯ç†è®ºï¼Œæœ‰è®¸å¤štrickséœ€è¦è€ƒè™‘ï¼Œè€Œç†è®ºæœ¬è´¨å°±æ˜¯ç¿»æ¥å€’å»æŠ˜è…¾è´å¶æ–¯å…¬å¼ï¼Œéƒ½å¿«ç©å‡ºèŠ±æ¥äº†ã€‚</p><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æœ´ç´ è´å¶æ–¯ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GPTæ¨¡å‹</title>
      <link href="/2020/05/30/GPT%E6%A8%A1%E5%9E%8B/"/>
      <url>/2020/05/30/GPT%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<p>æ–‡æœ¬åˆ†ç±»ï¼š</p><p>æ•°æ®é›†</p><p>THUCNews æ•°æ®é›†å­é›†,é“¾æ¥: <a href="https://pan.baidu.com/s/1hugrfRu" target="_blank" rel="noopener">https://pan.baidu.com/s/1hugrfRu</a> å¯†ç : qfud</p><p>Language Understanding</p><ul><li><p>intent classification</p></li><li><p>dialogue state tracking</p></li><li><p>sentiment classification</p></li></ul><p>Language Generation</p><ul><li>information, structured, sentiment â€“&gt; language</li></ul><h1 id="å¿…è¯»è®ºæ–‡"><a href="#å¿…è¯»è®ºæ–‡" class="headerlink" title="å¿…è¯»è®ºæ–‡"></a>å¿…è¯»è®ºæ–‡</h1><h1 id="GPT"><a href="#GPT" class="headerlink" title="GPT"></a>GPT</h1><p>Radford et. al., Improving Language Understanding by Generative Pre-Training</p><p><a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf" target="_blank" rel="noopener">https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf</a></p><p>è¿™ç¯‡æ–‡ç« æ¨å‡ºäº†generative pre-training + discriminative fine-tuningçš„æ–¹æ³•ï¼Œåæ¥ä¹Ÿè¢«BERTæ²¿ç”¨ã€‚task-aware input transformationä¹Ÿæ˜¯BERTå€Ÿç”¨çš„ä¸€ä¸ªç‚¹ã€‚å½“å¹´è¿™ç¯‡æ–‡ç« åˆšå‡ºæ¥çš„æ—¶å€™åˆ·æ¦œä¸€æ³¢ï¼Œä¸è¿‡ç¦»BERTå¤ªè¿‘ï¼Œå¯¼è‡´åæ¥å¤§å®¶éƒ½ä¸æ€ä¹ˆå…³å¿ƒè¿™ç¯‡æ–‡ç« äº†ã€‚</p><p><s>  a b c d e f </s></p><p>|        |  |  |  |  |  |</p><p>a       b c d e f  </p><p>1 0 0 0 0 0 0</p><p>1 1 0 0 0 0 0</p><p>1 1 1 0 0 0 0</p><p>1 1 1 1 0 0 0</p><p>1 1 1 1 1 0 0</p><p>1 1 1 1 1 1 0</p><h2 id="é¢„è®­ç»ƒ"><a href="#é¢„è®­ç»ƒ" class="headerlink" title="é¢„è®­ç»ƒ"></a>é¢„è®­ç»ƒ</h2><p>è¯­è¨€æ¨¡å‹objective</p><p><img src="https://uploader.shimo.im/f/jUXNKYwxjuUim5hM.png!thumbnail" alt="img"></p><p>Transformer Decoder</p><p><img src="https://uploader.shimo.im/f/2VVdkCN84SM8h2NA.png!thumbnail" alt="img"></p><p>è®­ç»ƒä½¿ç”¨BooksCorpusæ•°æ®é›†ï¼Œ7000æœ¬ä¹¦ã€‚</p><p>æ¨¡å‹å‚æ•°ï¼š</p><ul><li><p>12å±‚transformer decoder</p></li><li><p>768 hidden states, 12 attention heads</p></li><li><p>FFNå±‚æœ‰3072ç»´åº¦inner states</p></li></ul><h2 id="Fine-tuning"><a href="#Fine-tuning" class="headerlink" title="Fine tuning"></a>Fine tuning</h2><p>ä½¿ç”¨æœ€åä¸€å±‚æœ€åä¸€ä¸ªtokençš„representationæ¥åštask specificçš„æ¨¡å‹fine tuning</p><p><img src="https://uploader.shimo.im/f/sMzH5VF5BcQsk8pY.png!thumbnail" alt="img"></p><p>ä¾ç„¶ä½¿ç”¨Log loss</p><p><img src="https://uploader.shimo.im/f/odJ6a19y3swDAYcI.png!thumbnail" alt="img"></p><p>ä½œè€…å‘ç°åœ¨fine tuningçš„æ—¶å€™ç»§ç»­ä½¿ç”¨è¯­è¨€æ¨¡å‹çš„lossä¹Ÿæœ‰å¥½å¤„</p><p><img src="https://uploader.shimo.im/f/z2GX6ss3yL8CrvaN.png!thumbnail" alt="img"></p><h2 id="Task-specific-Input-Transformations"><a href="#Task-specific-Input-Transformations" class="headerlink" title="Task-specific Input Transformations"></a>Task-specific Input Transformations</h2><p>å››ç§é—®é¢˜æœ‰å››ç§ä¸åŒçš„æ–‡æœ¬è¡¨ç¤ºæ–¹æ³•</p><p><img src="https://uploader.shimo.im/f/e3Ep9QOmlzI2YmM8.png!thumbnail" alt="img"></p><p>Natural Language Inference</p><ul><li><p>åˆ¤æ–­ä¸¤å¥è¯çš„å…³ç³»ï¼Œentailment æ‰¿æ¥å…³ç³»ï¼Œcontradiction çŸ›ç›¾å…³ç³»ï¼Œneutral ä¸­ç«‹å…³ç³»</p></li><li><p>åœ¨å‡ ä¸ªNLIä»»åŠ¡ä¸Šéƒ½æœ‰ä¸å°çš„æå‡</p></li></ul><p>Question Answering and Common Sense Reasoning</p><p>Semantic Similarity è¯­ä¹‰ç›¸ä¼¼åº¦</p><ul><li><p>Microsoft Paraphrase Corpus</p></li><li><p>Quora Question Pairs</p></li></ul><p>åˆ†ç±»é—®é¢˜ </p><ul><li><p>Corpus of Lingustic Acceptabilityï¼Œåˆ¤æ–­ä¸€å¥è¯çš„è¯­æ³•æ˜¯ä¸æ˜¯æ­£ç¡®ã€‚</p></li><li><p>Stanford Sentiment Treebank æƒ…æ„Ÿåˆ†ç±»</p></li></ul><h1 id="GPT2"><a href="#GPT2" class="headerlink" title="GPT2"></a>GPT2</h1><p>Radford et. al., <a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" target="_blank" rel="noopener">Language Models are Unsupervised Multitask Learners</a></p><p><a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" target="_blank" rel="noopener">https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf</a></p><p>æ¯”GPTæ›´å¤§çš„è®­ç»ƒæ•°æ®é›†</p><ul><li>Common Crawlæ¥è‡ªç½‘é¡µçˆ¬å–ï¼Œåˆ é™¤äº†Wikipediaï¼Œæ€»å…±40GBæ•°æ®ã€‚</li></ul><p>evaluationä»»åŠ¡</p><ul><li><p>The Winograd Schema Challenge</p></li><li><p>LAMBADA dataset <a href="https://arxiv.org/pdf/1606.06031.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1606.06031.pdf</a></p></li></ul><p>å…³äºæ–‡æœ¬ç”Ÿæˆ</p><p><a href="https://arxiv.org/pdf/1904.09751.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1904.09751.pdf</a></p><h2 id="ä»£ç è§£è¯»"><a href="#ä»£ç è§£è¯»" class="headerlink" title="ä»£ç è§£è¯»"></a>ä»£ç è§£è¯»</h2><p>æˆ‘å¯¹ä»£ç æ·»åŠ äº†ä¸€äº›æ³¨é‡Š</p><p><a href="https://github.com/ZeweiChu/gpt-2/blob/master/src/model.py" target="_blank" rel="noopener">https://github.com/ZeweiChu/gpt-2/blob/master/src/model.py</a></p><p>huggingfaceä»£ç </p><p><a href="https://github.com/huggingface/transformers/blob/master/src/transformers/modeling_gpt2.py" target="_blank" rel="noopener">https://github.com/huggingface/transformers/blob/master/src/transformers/modeling_gpt2.py</a></p><p>è‡ªåŠ¨æ£€æµ‹</p><p>def attention_mask(nd, ns, *, dtype):</p><p>â€‹    â€œâ€â€1â€™s in the lower triangle, counting from the lower right corner.</p><p>â€‹    å·¦ä¸‹è§’çš„ä¸‰è§’å½¢éƒ½æ˜¯1ï¼Œå…¶ä½™æ˜¯0ï¼Œç”¨äºç”Ÿæˆmaskã€‚</p><p>â€‹    Same as tf.matrix_band_part(tf.ones([nd, ns]), -1, ns-nd), but doesnâ€™t produce garbage on TPUs.</p><p>â€‹    â€œâ€â€</p><p>â€‹    i = tf.range(nd)[:,None]</p><p>â€‹    j = tf.range(ns)</p><p>â€‹    m = i &gt;= j - ns + nd</p><p>â€‹    return tf.cast(m, dtype)</p><p>0 0 0 0 0</p><p>1 1 1 1 1</p><p>2 2 2 2 2</p><p>3 3 3 3 3</p><p>4 4 4 4 4</p><p>0 1 2 3 4 </p><p>1 0 0 0 0</p><p>1 1 0 0 0</p><p>1 1 1 0 0</p><p>1 1 1 1 0</p><p>1 1 1 1 1</p><p>w00 w01-inf w02-inf w03-inf w04-inf</p><p>w10 w11 w12-inf w13-inf w14-inf</p><p>w20 w21 w22 w23-inf w24-inf</p><p>w30 w31 w32 w33 w34-inf</p><p>w40 w41 w42 w43 w44</p><p>é˜…è¯»GPT2ä»£ç ï¼š<a href="https://github.com/ZeweiChu/gpt-2/blob/master/src/model.py" target="_blank" rel="noopener">https://github.com/ZeweiChu/gpt-2/blob/master/src/model.py</a></p><h1 id="Google-T5-Transformeré¢„è®­ç»ƒæ¨¡å‹å¤§æ€»ç»“"><a href="#Google-T5-Transformeré¢„è®­ç»ƒæ¨¡å‹å¤§æ€»ç»“" class="headerlink" title="Google T5: Transformeré¢„è®­ç»ƒæ¨¡å‹å¤§æ€»ç»“"></a>Google T5: Transformeré¢„è®­ç»ƒæ¨¡å‹å¤§æ€»ç»“</h1><p>è®ºæ–‡åœ°å€ï¼š<a href="https://arxiv.org/pdf/1910.10683.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1910.10683.pdf</a></p><p>ä»£ç +é¢„è®­ç»ƒæ¨¡å‹ï¼š<a href="https://github.com/google-research/text-to-text-transfer-transformer" target="_blank" rel="noopener">https://github.com/google-research/text-to-text-transfer-transformer</a></p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GPT </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BERTç³»åˆ—é¢„è®­ç»ƒæ¨¡å‹</title>
      <link href="/2020/05/30/BERT%E7%B3%BB%E5%88%97%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"/>
      <url>/2020/05/30/BERT%E7%B3%BB%E5%88%97%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<p>BERTï¼šMasked Language Modelingé¢„è®­ç»ƒæ¨¡å‹</p><p>è®ºæ–‡åœ°å€ï¼š<a href="https://arxiv.org/pdf/1810.04805.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1810.04805.pdf</a></p><p>ä¸­æ–‡ç¿»è¯‘ï¼š<a href="https://zhuanlan.zhihu.com/p/59775981" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/59775981</a></p><p> Language modelingé¢„è®­ç»ƒä»»åŠ¡</p><h2 id="Masked-Language-Model"><a href="#Masked-Language-Model" class="headerlink" title="Masked Language Model"></a>Masked Language Model</h2><p>å®Œå½¢å¡«ç©º</p><p>I study at Julyedu . </p><p>80% I study at [MASK] . </p><p>10% I study at Apple . </p><p>10% I study at Julyedu . </p><p>[CLS] I study at [MASK] .  [SEP] I love [MASK] language processing . [SEP]</p><p>â€“&gt; transformer encoder</p><p>o1, o2, o3, o4, o5, â€¦., o_n</p><p>o5 â€“&gt; Julyedu  cross entropy</p><p>o10 â€“&gt; natural cross entropy</p><p>o1 â€“&gt; True cross entropy</p><p>BERTè¯´ï¼šâ€œæˆ‘è¦ç”¨ transformer çš„ encodersâ€</p><p>Ernieä¸å±‘é“ï¼šâ€œå‘µå‘µï¼Œä½ ä¸èƒ½åƒBi-Lstmä¸€æ ·è€ƒè™‘æ–‡ç« â€</p><p>BERTè‡ªä¿¡å›ç­”é“ï¼šâ€œæˆ‘ä»¬ä¼šç”¨masksâ€</p><blockquote><p>è§£é‡Šä¸€ä¸‹Maskï¼š</p></blockquote><blockquote></blockquote><blockquote><p>è¯­è¨€æ¨¡å‹ä¼šæ ¹æ®å‰é¢å•è¯æ¥é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ï¼Œä½†æ˜¯self-attentionçš„æ³¨æ„åŠ›åªä¼šæ”¾åœ¨è‡ªå·±èº«ä¸Šï¼Œé‚£ä¹ˆè¿™æ ·100%é¢„æµ‹åˆ°è‡ªå·±ï¼Œæ¯«æ— æ„ä¹‰ï¼Œæ‰€ä»¥ç”¨Maskï¼ŒæŠŠéœ€è¦é¢„æµ‹çš„è¯ç»™æŒ¡ä½ã€‚</p></blockquote><p>å¦‚ä¸‹å›¾ï¼š</p><p><img src="https://uploader.shimo.im/f/jvcJ8SPeBEwszR8M.png!thumbnail" alt="img"></p><h2 id="Two-sentence-Tasks"><a href="#Two-sentence-Tasks" class="headerlink" title="Two-sentence Tasks"></a>Two-sentence Tasks</h2><p>æˆ‘ä»¬å›é¡¾ä¸€ä¸‹OpenAI transformerå¤„ç†ä¸åŒä»»åŠ¡çš„è¾“å…¥è½¬æ¢ï¼Œä½ ä¼šå‘ç°åœ¨æŸäº›ä»»åŠ¡ä¸Šæˆ‘ä»¬éœ€è¦2ä¸ªå¥å­ä½œä¸ºè¾“å…¥ï¼Œå¹¶åšä¸€äº›æ›´ä¸ºæ™ºèƒ½çš„åˆ¤æ–­ï¼Œæ¯”å¦‚æ˜¯å¦ç›¸ä¼¼ï¼Œæ¯”å¦‚ ç»™å‡ºä¸€ä¸ªç»´åŸºç™¾ç§‘çš„å†…å®¹ä½œä¸ºè¾“å…¥ï¼ŒåŒæ—¶åœ¨æ”¾å…¥ä¸€æ¡é’ˆå¯¹è¯¥æ¡ç›®çš„é—®é¢˜ï¼Œé‚£ä¹ˆæˆ‘ä»¬çš„ç®—æ³•æ¨¡å‹èƒ½å¤Ÿå¤„ç†è¿™ä¸ªé—®é¢˜å—ï¼Ÿ</p><p>ä¸ºäº†ä½¿BERTæ›´å¥½çš„å¤„ç†2ä¸ªå¥å­ä¹‹é—´çš„å…³ç³»ï¼Œé¢„è®­ç»ƒçš„è¿‡ç¨‹è¿˜æœ‰ä¸€ä¸ªé¢å¤–çš„ä»»åŠ¡ï¼šç»™å®š2ä¸ªå¥å­ï¼ˆAå’ŒBï¼‰,Aä¸Bæ˜¯å¦ç›¸ä¼¼ï¼Ÿï¼ˆ0æˆ–è€…1ï¼‰</p><h2 id="ç‰¹æ®ŠNLPä»»åŠ¡"><a href="#ç‰¹æ®ŠNLPä»»åŠ¡" class="headerlink" title="ç‰¹æ®ŠNLPä»»åŠ¡"></a>ç‰¹æ®ŠNLPä»»åŠ¡</h2><p>BERTçš„è®ºæ–‡ä¸ºæˆ‘ä»¬ä»‹ç»äº†å‡ ç§BERTå¯ä»¥å¤„ç†çš„NLPä»»åŠ¡ï¼š</p><ol><li><p>çŸ­æ–‡æœ¬ç›¸ä¼¼ </p></li><li><p>æ–‡æœ¬åˆ†ç±»</p></li><li><p>QAæœºå™¨äºº</p></li><li><p>è¯­ä¹‰æ ‡æ³¨</p></li></ol><p><img src="https://uploader.shimo.im/f/yKFxOevBvMQXvjnv.png!thumbnail" alt="img"></p><h2 id="BERTç”¨åšç‰¹å¾æå–"><a href="#BERTç”¨åšç‰¹å¾æå–" class="headerlink" title="BERTç”¨åšç‰¹å¾æå–"></a>BERTç”¨åšç‰¹å¾æå–</h2><p>å¾®è°ƒæ–¹æ³•å¹¶ä¸æ˜¯ä½¿ç”¨BERTçš„å”¯ä¸€æ–¹æ³•ï¼Œå°±åƒELMoä¸€æ ·ï¼Œä½ å¯ä»¥ä½¿ç”¨é¢„é€‰è®­ç»ƒå¥½çš„BERTæ¥åˆ›å»ºè¯­å¢ƒåŒ–è¯åµŒå…¥ã€‚ç„¶åä½ å¯ä»¥å°†è¿™äº›åµŒå…¥æä¾›ç»™ç°æœ‰çš„æ¨¡å‹ã€‚</p><p><img src="https://uploader.shimo.im/f/uKUkG73gELQGry4L.png!thumbnail" alt="img"></p><p>å“ªä¸ªå‘é‡æœ€é€‚åˆä½œä¸ºä¸Šä¸‹æ–‡åµŒå…¥ï¼Ÿ æˆ‘è®¤ä¸ºè¿™å–å†³äºä»»åŠ¡ã€‚ æœ¬æ–‡è€ƒå¯Ÿäº†å…­ç§é€‰æ‹©ï¼ˆä¸å¾®è°ƒæ¨¡å‹ç›¸æ¯”ï¼Œå¾—åˆ†ä¸º96.4ï¼‰ï¼š</p><p><img src="https://uploader.shimo.im/f/bfpUyWE9YCEP9IU2.png!thumbnail" alt="img"></p><ul><li><p>Feature Extractionï¼šç‰¹å¾æå–</p></li><li><p>Finetuneï¼šå¾®è°ƒ</p></li></ul><h1 id="å¦‚ä½•ä½¿ç”¨BERT"><a href="#å¦‚ä½•ä½¿ç”¨BERT" class="headerlink" title="å¦‚ä½•ä½¿ç”¨BERT"></a>å¦‚ä½•ä½¿ç”¨BERT</h1><h2 id="BERTæºç "><a href="#BERTæºç " class="headerlink" title="BERTæºç "></a>BERTæºç </h2><p>æŸ¥çœ‹<a href="https://github.com/google-research/bert" target="_blank" rel="noopener">BERTä»“åº“</a>ä¸­çš„ä»£ç ï¼š</p><ol><li><p>è¯¥æ¨¡å‹åœ¨modeling.pyï¼ˆBertModelç±»ï¼‰ä¸­æ„å»ºï¼Œä¸vanilla Transformerç¼–ç å™¨å®Œå…¨ç›¸åŒã€‚</p></li><li><p>run_classifier.pyæ˜¯å¾®è°ƒè¿‡ç¨‹çš„ä¸€ä¸ªç¤ºä¾‹ã€‚å®ƒè¿˜æ„å»ºäº†ç›‘ç£æ¨¡å‹çš„åˆ†ç±»å±‚ã€‚å¦‚æœè¦æ„å»ºè‡ªå·±çš„åˆ†ç±»å™¨ï¼Œè¯·æŸ¥çœ‹è¯¥æ–‡ä»¶ä¸­çš„create_model()æ–¹æ³•ã€‚</p></li><li><p>å¯ä»¥ä¸‹è½½å‡ ç§é¢„å…ˆè®­ç»ƒçš„æ¨¡å‹ã€‚æ¶µç›–102ç§è¯­è¨€çš„å¤šè¯­è¨€æ¨¡å‹ï¼Œè¿™äº›è¯­è¨€éƒ½æ˜¯åœ¨ç»´åŸºç™¾ç§‘çš„æ•°æ®åŸºç¡€ä¸Šè®­ç»ƒè€Œæˆçš„ã€‚</p></li><li><p>BERTä¸ä¼šå°†å•è¯è§†ä¸ºtokensã€‚ç›¸åï¼Œå®ƒæ³¨é‡WordPiecesã€‚ tokenization.pyæ˜¯å°†ä½ çš„å•è¯è½¬æ¢ä¸ºé€‚åˆBERTçš„wordPiecesçš„tokensizerã€‚</p></li></ol><p>å¯ä»¥æŸ¥çœ‹BERTçš„PyTorchå®ç° (<a href="https://github.com/huggingface/transformers)ã€‚" target="_blank" rel="noopener">https://github.com/huggingface/transformers)ã€‚</a> </p><ul><li><p>modeling: <a href="https://github.com/huggingface/transformers/blob/master/src/transformers/modeling_bert.py" target="_blank" rel="noopener">https://github.com/huggingface/transformers/blob/master/src/transformers/modeling_bert.py</a></p></li><li><p>BertEmbedding: wordpiece embedding + position embedding + token type embedding</p></li><li><p>BertSelfAttnetion: query, key, valueçš„å˜æ¢</p></li><li><p>BertSelfOutput: </p></li><li><p>BertIntermediate</p></li><li><p>BertOutput</p></li><li><p>BertForSequenceClassification</p></li><li><p>configuration: <a href="https://github.com/huggingface/transformers/blob/master/transformers/configuration_bert.py" target="_blank" rel="noopener">https://github.com/huggingface/transformers/blob/master/transformers/configuration_bert.py</a></p></li><li><p>tokenization: <a href="https://github.com/huggingface/transformers/blob/master/transformers/tokenization_bert.py" target="_blank" rel="noopener">https://github.com/huggingface/transformers/blob/master/transformers/tokenization_bert.py</a></p></li><li><p>DataProcessor: <a href="https://github.com/huggingface/transformers/blob/master/transformers/data/processors/glue.py#L194" target="_blank" rel="noopener">https://github.com/huggingface/transformers/blob/master/transformers/data/processors/glue.py#L194</a></p></li></ul><h2 id="BERTæ¨¡å‹çš„ä½¿ç”¨"><a href="#BERTæ¨¡å‹çš„ä½¿ç”¨" class="headerlink" title="BERTæ¨¡å‹çš„ä½¿ç”¨"></a>BERTæ¨¡å‹çš„ä½¿ç”¨</h2><ul><li>æ–‡æœ¬åˆ†ç±»ï¼š<a href="https://github.com/huggingface/transformers/blob/master/examples/run_glue.py" target="_blank" rel="noopener">https://github.com/huggingface/transformers/blob/master/examples/run_glue.py</a></li></ul><h1 id="BERTå‡çº§ç‰ˆ"><a href="#BERTå‡çº§ç‰ˆ" class="headerlink" title="BERTå‡çº§ç‰ˆ"></a>BERTå‡çº§ç‰ˆ</h1><h2 id="RoBERTaï¼šæ›´å¼ºå¤§çš„BERT"><a href="#RoBERTaï¼šæ›´å¼ºå¤§çš„BERT" class="headerlink" title="RoBERTaï¼šæ›´å¼ºå¤§çš„BERT"></a>RoBERTaï¼šæ›´å¼ºå¤§çš„BERT</h2><p>è®ºæ–‡åœ°å€ï¼š<a href="https://arxiv.org/pdf/1907.11692.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1907.11692.pdf</a></p><ul><li><p>åŠ å¤§è®­ç»ƒæ•°æ® 16GB -&gt; 160GBï¼Œæ›´å¤§çš„batch sizeï¼Œè®­ç»ƒæ—¶é—´åŠ é•¿</p></li><li><p>ä¸éœ€è¦NSP Loss: natural inference </p></li><li><p>ä½¿ç”¨æ›´é•¿çš„è®­ç»ƒ Sequence</p></li><li><p>Static vs. Dynamic Masking </p></li><li><p>æ¨¡å‹è®­ç»ƒæˆæœ¬åœ¨6ä¸‡ç¾é‡‘ä»¥ä¸Šï¼ˆä¼°ç®—ï¼‰</p></li></ul><h2 id="ALBERTï¼šå‚æ•°æ›´å°‘çš„BERT"><a href="#ALBERTï¼šå‚æ•°æ›´å°‘çš„BERT" class="headerlink" title="ALBERTï¼šå‚æ•°æ›´å°‘çš„BERT"></a>ALBERTï¼šå‚æ•°æ›´å°‘çš„BERT</h2><p>è®ºæ–‡åœ°å€ï¼š<a href="https://arxiv.org/pdf/1909.11942.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1909.11942.pdf</a></p><ul><li><p>ä¸€ä¸ªè½»é‡çº§çš„BERTæ¨¡å‹</p></li><li><p>æ ¸å¿ƒæ€æƒ³ï¼š</p></li><li><p>å…±äº«å±‚ä¸å±‚ä¹‹é—´çš„å‚æ•° ï¼ˆå‡å°‘æ¨¡å‹å‚æ•°ï¼‰</p></li><li><p>å¢åŠ å•å±‚å‘é‡ç»´åº¦</p></li></ul><h2 id="DistilBERTï¼šè½»é‡ç‰ˆBERT"><a href="#DistilBERTï¼šè½»é‡ç‰ˆBERT" class="headerlink" title="DistilBERTï¼šè½»é‡ç‰ˆBERT"></a>DistilBERTï¼šè½»é‡ç‰ˆBERT</h2><p>MNIST</p><p>0, 1, 2, 3, â€¦, 9</p><p>logits: [0.1, 0.6, â€¦, 0.01] q</p><p><strong>label: 2 [0, 0, 1, â€¦, 0] p</strong></p><p>loss: cross entropy loss -\sum_{i=1}^10 p_i*log q_i</p><p>loss: -log q_{label}</p><p>è®­ç»ƒä¸€ä¸ªStudent networkï¼Œmimic the behavior of the teacher network</p><p>teacher network: [0.1, 0.6, â€¦, 0.01] t</p><p><strong>student network</strong>: [s_1, s_2, .., s_10]</p><p>cross entropy loss: -sum_{i=1}^10 t_i * log s_i</p><p>4, 7</p><p><a href="https://arxiv.org/pdf/1910.01108.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1910.01108.pdf</a></p><ul><li><p>MLM, NSP</p></li><li><p>MLM: cross entropy loss: -\sum_{i=1}^k p_i log (q_i) = - log (q_{label})</p></li><li><p>teacher (MLM) = distribution</p></li><li><p>student: å­¦ä¹ distribution: -\sum_{i=1}^k p_teacher_i log (q_student_i)</p></li></ul><p>Patient Distillation</p><p><a href="https://arxiv.org/abs/1908.09355" target="_blank" rel="noopener">https://arxiv.org/abs/1908.09355</a></p><p><img src="https://uploader.shimo.im/f/FtKDArmN5UoEwpsF.png!thumbnail" alt="img"></p><h1 id="å‚è€ƒé˜…è¯»èµ„æ–™"><a href="#å‚è€ƒé˜…è¯»èµ„æ–™" class="headerlink" title="å‚è€ƒé˜…è¯»èµ„æ–™"></a>å‚è€ƒé˜…è¯»èµ„æ–™</h1><h3 id="BERT-Distillation"><a href="#BERT-Distillation" class="headerlink" title="BERT Distillation"></a>BERT Distillation</h3><p>å¯¹äºBERTæ¨¡å‹å‹ç¼©æ„Ÿå…´è¶£çš„åŒå­¦å¯ä»¥å‚è€ƒä»¥ä¸‹èµ„æ–™</p><ul><li>Patient Knowledge Distillation for BERT Model Compression  <a href="https://www.aclweb.org/anthology/D19-1441.pdf" target="_blank" rel="noopener">https://www.aclweb.org/anthology/D19-1441.pdf</a></li></ul><p>å…³äºBERTæ¨¡å‹å‹ç¼©çš„ä¸€å¥—æ–¹æ³•</p><h3 id="ELECTRA"><a href="#ELECTRA" class="headerlink" title="ELECTRA"></a>ELECTRA</h3><p><a href="https://openreview.net/pdf?id=r1xMH1BtvB" target="_blank" rel="noopener">https://openreview.net/pdf?id=r1xMH1BtvB</a></p><p>ä½¿ç”¨GANè®­ç»ƒBERTæ¨¡å‹</p><p><img src="https://uploader.shimo.im/f/PJ9RGb3HpgIA4WYN.png!thumbnail" alt="img"></p><ul><li><p>Generatoré’ˆå¯¹[MASK]ä½ç½®ç”Ÿæˆå•è¯ï¼ŒDiscriminatoråˆ¤æ–­è¿™äº›å•è¯æ˜¯ç”±Generator (ä»[MASK]) ç”Ÿæˆçš„è¿˜æ˜¯åŸæœ¬å°±å­˜åœ¨çš„ã€‚</p></li><li><p>Discriminatorè¢«ç”¨äºdownstream task finetuningã€‚</p></li></ul><h3 id="XLNet"><a href="#XLNet" class="headerlink" title="XLNet"></a>XLNet</h3><p>æˆ‘åœ¨ä¸Šä¸€æœŸNLPå°±ä¸šç­ä¸­ä»‹ç»äº†XLNetï¼Œä¸è¿‡ç”±äºè¿‘äº›æ—¥å­BERTçš„å„ç§åŠ å¼ºç‰ˆå±‚å‡ºä¸ç©·ï¼ŒXLNetæ˜¾å¾—å¹¶ä¸ç‰¹åˆ«çªå‡ºã€‚æ„Ÿå…´è¶£çš„åŒå­¦å¯ä»¥å‚è€ƒä¸Šä¸€æœŸçš„è¯¾ä»¶ï¼š<a href="https://shimo.im/docs/PHqcpWtYjJjW3yH3" target="_blank" rel="noopener">https://shimo.im/docs/PHqcpWtYjJjW3yH3</a></p><p>XLNetçš„ä»£ç å’Œé¢„è®­ç»ƒæ¨¡å‹ä¹Ÿå¯ä»¥åœ¨Huggingfaceçš„ç‰ˆæœ¬ä¸­æ‰¾åˆ°ã€‚</p><h3 id="NLPé¢„è®­ç»ƒæ¨¡å‹ä¸²è®²"><a href="#NLPé¢„è®­ç»ƒæ¨¡å‹ä¸²è®²" class="headerlink" title="NLPé¢„è®­ç»ƒæ¨¡å‹ä¸²è®²"></a>NLPé¢„è®­ç»ƒæ¨¡å‹ä¸²è®²</h3><p>æˆ‘ä¹‹å‰åœ¨ä¸ƒæœˆåœ¨çº¿çš„å…¬å¼€è¯¾ä¸­ä½¿ç”¨çš„PPT</p><p>NLPé¢„è®­ç»ƒæ¨¡å‹.pdf1.9MB</p><h3 id="å‚è€ƒé˜…è¯»ï¼šThe-Illustrated-BERT-ELMo-and-co"><a href="#å‚è€ƒé˜…è¯»ï¼šThe-Illustrated-BERT-ELMo-and-co" class="headerlink" title="å‚è€ƒé˜…è¯»ï¼šThe Illustrated BERT, ELMo, and co."></a>å‚è€ƒé˜…è¯»ï¼šThe Illustrated BERT, ELMo, and co.</h3><p><a href="https://shimo.im/docs/Y6q3gX8yGGjpWqXx" target="_blank" rel="noopener">https://shimo.im/docs/Y6q3gX8yGGjpWqXx</a></p><ul><li><p>é˜…è¯»BertSelfAttentionä»£ç  <a href="https://github.com/huggingface/transformers/blob/master/transformers/modeling_bert.py#L190" target="_blank" rel="noopener">https://github.com/huggingface/transformers/blob/master/transformers/modeling_bert.py#L190</a></p></li><li><p>é˜…è¯»run_glue.py <a href="https://github.com/huggingface/transformers/blob/master/examples/run_glue.py#L152" target="_blank" rel="noopener">https://github.com/huggingface/transformers/blob/master/examples/run_glue.py#L152</a></p></li><li><p>é˜…è¯»BertForSequenceClassification <a href="https://github.com/huggingface/transformers/blob/master/transformers/modeling_bert.py#L970" target="_blank" rel="noopener">https://github.com/huggingface/transformers/blob/master/transformers/modeling_bert.py#L970</a></p></li><li><p>é˜…è¯»glue.py <a href="https://github.com/huggingface/transformers/blob/master/transformers/data/processors/glue.py" target="_blank" rel="noopener">https://github.com/huggingface/transformers/blob/master/transformers/data/processors/glue.py</a> ç”¨æ¥åšæ–‡æœ¬é¢„å¤„ç†</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> BERT </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>é˜…è¯»ç†è§£</title>
      <link href="/2020/05/19/%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3/"/>
      <url>/2020/05/19/%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<p>NLPå½“ä¸­çš„é˜…è¯»ç†è§£(Reading Comprehension, Question Answering)ä»»åŠ¡ä¸»è¦æ˜¯ä»¥ä¸‹å½¢å¼ï¼šç»™å®šä¸€äº›èƒŒæ™¯çŸ¥è¯†ï¼Œä¸»è¦æ˜¯ä¸€ç¯‡æ–‡ç« ï¼Œæœ‰æ—¶å€™ä¹Ÿå¯èƒ½æ˜¯ä¸€äº›ç»“æ„åŒ–çš„çŸ¥è¯†å›¾è°±ï¼Œç„¶åå›ç­”ä¸è¯¥èƒŒæ™¯çŸ¥è¯†çš„ç›¸å…³é—®é¢˜ã€‚</p><p>å¸¸è§çš„é—®é¢˜å’Œç­”æ¡ˆå½¢å¼æœ‰ï¼š</p><ul><li><p>å®Œå½¢å¡«ç©ºï¼šåœ¨æ–‡ç« ä¸­ç»™å®šä¸€ä¸ªç©ºä½å’Œä¸€äº›å€™é€‰ç­”æ¡ˆï¼Œæˆ‘ä»¬éœ€è¦æŠŠä¸€ä¸ªå€™é€‰ç­”æ¡ˆå¡«å……è¿›å»ã€‚</p></li><li><p>ç®€ç­”é¢˜ï¼šç»™å®šä¸€ç¯‡æ–‡ç« å’Œä¸€ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦ä»æ–‡ç« ä¸­å»æ‰¾ç­”æ¡ˆï¼Œä¸”è¿™ä¸ªç­”æ¡ˆä¸€å®šåœ¨æ–‡ç« ä¸­å‡ºç°è¿‡ã€‚SQuAD</p></li><li><p>é€‰æ‹©é¢˜ï¼šç»™å®šä¸€ç¯‡æ–‡ç« ï¼Œä¸€ä¸ªé—®é¢˜å’Œä¸€äº›å€™é€‰ç­”æ¡ˆï¼Œé€‰æ‹©ä¸€ä¸ªæ­£ç¡®ç­”æ¡ˆã€‚</p></li></ul><p>è¿˜æœ‰ä¸€äº›åœ¨ä¸Šè¿°é—®ç­”ä»»åŠ¡åŸºç¡€ä¸Šçš„æ‹“å±•æƒ…å†µï¼Œä¾‹å¦‚æœ‰çš„ä»»åŠ¡éœ€è¦åœ¨å¤šç¯‡æ–‡ç« çš„åŸºç¡€ä¸Šä½œç­”ï¼Œæœ‰çš„QAä»»åŠ¡éœ€è¦æˆ‘ä»¬è‡ªå·±æ¥æ¨ç†å’Œæ’°å†™ç­”æ¡ˆ (open domain)ï¼Œæ— æ³•ç›´æ¥ä»æ–‡ä¸­æ‰¾åˆ°ç­”æ¡ˆã€‚</p><p>æ•´ä¸ªQAé¢†åŸŸçš„å‘å±•ä¸»è¦éƒ½æ˜¯ä¾é ä¸€äº›æ•°æ®é›†çš„æå‡ºå’Œè§£å†³æ¥æ¨åŠ¨çš„ã€‚å¾€å¾€æ˜¯æœ‰äººåˆ¶ä½œäº†ä¸€ä¸ªæ•°æ®é›†å’Œä¸€ä¸ªQAä»»åŠ¡ï¼Œç„¶åå¤§å®¶å¼€å§‹æ¯”èµ›è°èƒ½æ›´å¥½åœ°è§£å†³å®ƒã€‚</p><p>æˆ‘è®¤ä¸ºæœ€å¥½çš„å­¦ä¹ æ–¹æ³•æ˜¯å»äº†è§£è¿™äº›QAæ•°æ®é›†ï¼ˆ<a href="http://nlpprogress.com/english/question_answering.htmlï¼‰ï¼Œé’ˆå¯¹è‡ªå·±æ„Ÿå…´è¶£çš„æ•°æ®é›†å»å¯»æ‰¾ç›¸åº”çš„è§£å†³æ–¹æ¡ˆï¼Œåœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­äº†è§£QAçš„è§£å†³æ–¹æ³•ã€‚å°†æ¥å¦‚æœåœ¨å®é™…çš„åº”ç”¨åœºæ™¯ä¸­é‡åˆ°ç±»ä¼¼çš„QAä»»åŠ¡ï¼ˆä¾‹å¦‚ä¸€äº›å®¢æœæœºå™¨äººç­‰ï¼‰ï¼Œæˆ‘ä»¬å°±å¯ä»¥å¯»æ‰¾åˆ°æ¯”è¾ƒç›¸å…³çš„QAæ•°æ®é›†ï¼Œä½¿ç”¨åœ¨è¿™äº›æ•°æ®é›†ä¸Šæœ€å¥½çš„è§£å†³æ–¹æ¡ˆæ¥è§£å†³è‡ªå·±çš„ä»»åŠ¡ã€‚" target="_blank" rel="noopener">http://nlpprogress.com/english/question_answering.htmlï¼‰ï¼Œé’ˆå¯¹è‡ªå·±æ„Ÿå…´è¶£çš„æ•°æ®é›†å»å¯»æ‰¾ç›¸åº”çš„è§£å†³æ–¹æ¡ˆï¼Œåœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­äº†è§£QAçš„è§£å†³æ–¹æ³•ã€‚å°†æ¥å¦‚æœåœ¨å®é™…çš„åº”ç”¨åœºæ™¯ä¸­é‡åˆ°ç±»ä¼¼çš„QAä»»åŠ¡ï¼ˆä¾‹å¦‚ä¸€äº›å®¢æœæœºå™¨äººç­‰ï¼‰ï¼Œæˆ‘ä»¬å°±å¯ä»¥å¯»æ‰¾åˆ°æ¯”è¾ƒç›¸å…³çš„QAæ•°æ®é›†ï¼Œä½¿ç”¨åœ¨è¿™äº›æ•°æ®é›†ä¸Šæœ€å¥½çš„è§£å†³æ–¹æ¡ˆæ¥è§£å†³è‡ªå·±çš„ä»»åŠ¡ã€‚</a></p><h2 id><a href="#" class="headerlink" title=" "></a> </h2><h1 id="ä¸€äº›æœ‰åçš„é˜…è¯»ç†è§£æ•°æ®é›†å’Œæ¨¡å‹"><a href="#ä¸€äº›æœ‰åçš„é˜…è¯»ç†è§£æ•°æ®é›†å’Œæ¨¡å‹" class="headerlink" title="ä¸€äº›æœ‰åçš„é˜…è¯»ç†è§£æ•°æ®é›†å’Œæ¨¡å‹"></a>ä¸€äº›æœ‰åçš„é˜…è¯»ç†è§£æ•°æ®é›†å’Œæ¨¡å‹</h1><h2 id="SQuAD-1-0-2-0"><a href="#SQuAD-1-0-2-0" class="headerlink" title="SQuAD 1.0/2.0"></a>SQuAD 1.0/2.0</h2><p>ä»æ–‡ç« ä¸­æ‰¾ç­”æ¡ˆ</p><p><a href="https://aclweb.org/anthology/D16-1264" target="_blank" rel="noopener">https://aclweb.org/anthology/D16-1264</a></p><p><img src="https://uploader.shimo.im/f/yqtsScSwls8OkJWs.png!thumbnail" alt="img"></p><h3 id="BiDAFæ¨¡å‹"><a href="#BiDAFæ¨¡å‹" class="headerlink" title="BiDAFæ¨¡å‹"></a>BiDAFæ¨¡å‹</h3><p>Bi-Directional Attention Fflow for Machine Comprehension</p><p><a href="https://arxiv.org/pdf/1611.01603.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1611.01603.pdf</a></p><p>2017å¹´çš„æ¨¡å‹ï¼Œç”¨äºè§£å†³SQuADä¹‹ç±»çš„é—®é¢˜ã€‚åæ¥çš„å¾ˆå¤šæ¨¡å‹éƒ½å‚è€ƒäº†è¯¥æ¨¡å‹çš„è®¾è®¡æ€æƒ³</p><p><img src="https://uploader.shimo.im/f/hL8lQitMAxMtYJ5w.png!thumbnail" alt="img"></p><p>é¢„æµ‹ï¼š start_pos, end_pos</p><p>å…¶ä»–ç›¸å…³æ¨¡å‹</p><p>Document Reader (single model)</p><p>r-net (single model)</p><p>QANet (single)</p><p><a href="https://github.com/allenai/bi-att-flow" target="_blank" rel="noopener">https://github.com/allenai/bi-att-flow</a></p><p>MCTest</p><p><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/11/MCTest_EMNLP2013.pdf" target="_blank" rel="noopener">https://www.microsoft.com/en-us/research/wp-content/uploads/2016/11/MCTest_EMNLP2013.pdf</a></p><h3 id="BERTæ¨¡å‹"><a href="#BERTæ¨¡å‹" class="headerlink" title="BERTæ¨¡å‹"></a>BERTæ¨¡å‹</h3><p>æ¨¡å‹ <a href="https://arxiv.org/pdf/1810.04805.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1810.04805.pdf</a></p><p>ä»£ç  <a href="https://github.com/huggingface/transformers/blob/master/src/transformers/modeling_bert.py#L1402" target="_blank" rel="noopener">https://github.com/huggingface/transformers/blob/master/src/transformers/modeling_bert.py#L1402</a></p><p><a href="https://github.com/huggingface/transformers/blob/master/examples/run_squad.py" target="_blank" rel="noopener">https://github.com/huggingface/transformers/blob/master/examples/run_squad.py</a></p><h2 id="CNN-Daily-Mail"><a href="#CNN-Daily-Mail" class="headerlink" title="CNN/Daily Mail"></a>CNN/Daily Mail</h2><p>å®Œå½¢å¡«ç©ºç±»é—®é¢˜</p><p>Teaching Machines to Read and Comprehend</p><p><a href="https://arxiv.org/pdf/1506.03340.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1506.03340.pdf</a></p><p><img src="https://uploader.shimo.im/f/ppAcqx7DjtM3486H.png!thumbnail" alt="img"></p><h3 id="Attention-Sumæ¨¡å‹"><a href="#Attention-Sumæ¨¡å‹" class="headerlink" title="Attention Sumæ¨¡å‹"></a>Attention Sumæ¨¡å‹</h3><p><a href="https://arxiv.org/pdf/1603.01547.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1603.01547.pdf</a></p><p>Gated Attention Sumæ¨¡å‹æ˜¯è¯¥æ¨¡å‹çš„ä¸€ä¸ªæ‹“å±•å½¢å¼</p><p><a href="https://arxiv.org/abs/1606.01549" target="_blank" rel="noopener">https://arxiv.org/abs/1606.01549</a></p><h3 id="é™ˆä¸¹ç¦åœ¨CNN-Daily-Mailä¸Šçš„å·¥ä½œ"><a href="#é™ˆä¸¹ç¦åœ¨CNN-Daily-Mailä¸Šçš„å·¥ä½œ" class="headerlink" title="é™ˆä¸¹ç¦åœ¨CNN/Daily Mailä¸Šçš„å·¥ä½œ"></a>é™ˆä¸¹ç¦åœ¨CNN/Daily Mailä¸Šçš„å·¥ä½œ</h3><p>A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task</p><p><a href="https://www.aclweb.org/anthology/P16-1223" target="_blank" rel="noopener">https://www.aclweb.org/anthology/P16-1223</a></p><p><img src="https://uploader.shimo.im/f/BKipbLYDzic4bWbc.png!thumbnail" alt="img"></p><p>é¡ºä¾¿ä»‹ç»ä¸€ä¸‹ï¼Œ<a href="https://www.cs.princeton.edu/~danqic/" target="_blank" rel="noopener">é™ˆä¸¹ç¦</a>åœ¨QAé¢†åŸŸåšäº†å¾ˆå¤šå·¥ä½œï¼Œå¯¹QAæ„Ÿå…´è¶£çš„åŒå­¦å¯ä»¥å‚è€ƒå¥¹çš„åšå£«è®ºæ–‡ã€‚</p><p><a href="https://www.cs.princeton.edu/~danqic/" target="_blank" rel="noopener">https://www.cs.princeton.edu/~danqic/</a></p><p><a href="https://www.cs.princeton.edu/~danqic/papers/thesis.pdf" target="_blank" rel="noopener">https://www.cs.princeton.edu/~danqic/papers/thesis.pdf</a></p><p><a href="https://arxiv.org/pdf/1506.03340.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1506.03340.pdf</a></p><p><a href="https://arxiv.org/pdf/1603.01547.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1603.01547.pdf</a></p><p><a href="http://www.cs.cmu.edu/~bdhingra/papers/ga_reader.pdf" target="_blank" rel="noopener">http://www.cs.cmu.edu/~bdhingra/papers/ga_reader.pdf</a></p><p><a href="https://arxiv.org/pdf/1611.07954.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1611.07954.pdf</a></p><h2 id="RACEæ•°æ®é›†"><a href="#RACEæ•°æ®é›†" class="headerlink" title="RACEæ•°æ®é›†"></a>RACEæ•°æ®é›†</h2><p>RACE: Large-scale ReAding Comprehension Dataset From Examinations</p><p><a href="https://arxiv.org/pdf/1704.04683.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1704.04683.pdf</a></p><p>RACEæ•°æ®é›†æ¥è‡ªä¸­å›½çš„ä¸­é«˜è€ƒè‹±è¯­é˜…è¯»ç†è§£é¢˜ã€‚</p><p>ä»£ç ï¼š</p><p><a href="https://github.com/huggingface/transformers/blob/master/src/transformers/modeling_bert.py#L1204" target="_blank" rel="noopener">https://github.com/huggingface/transformers/blob/master/src/transformers/modeling_bert.py#L1204</a></p><p><a href="https://github.com/huggingface/transformers/blob/master/examples/utils_multiple_choice.py#L36" target="_blank" rel="noopener">https://github.com/huggingface/transformers/blob/master/examples/utils_multiple_choice.py#L36</a></p><p><a href="https://github.com/huggingface/transformers/blob/master/examples/run_multiple_choice.py" target="_blank" rel="noopener">https://github.com/huggingface/transformers/blob/master/examples/run_multiple_choice.py</a></p><p>SWAG</p><p>åæ¥å‡ºç°äº†å¾ˆå¤šçš„ä¸åŒæ–¹å‘çš„QAé—®é¢˜</p><ul><li><p>åŸºäºå¤šæ–‡æœ¬çš„ã€é•¿æ–‡ç« çš„é—®ç­”</p></li><li><p>narrative qa <a href="https://arxiv.org/pdf/1712.07040.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1712.07040.pdf</a></p></li><li><p>åŸºäºç»´åŸºç™¾ç§‘ï¼Œç»“åˆæ–‡æœ¬æœç´¢ç³»ç»Ÿçš„é—®ç­”</p></li><li><p>Dr QA <a href="https://arxiv.org/pdf/1704.00051.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1704.00051.pdf</a></p></li><li><p>åŸºäºèŠå¤©è®°å½•çš„é—®ç­” </p></li><li><p>QuAC : Question Answering in Context <a href="https://arxiv.org/pdf/1808.07036.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1808.07036.pdf</a></p></li></ul><p>å‚è€ƒä»¥ä¸‹é“¾æ¥</p><ul><li><p><a href="https://github.com/karthikncode/nlp-datasets#question-answering" target="_blank" rel="noopener">https://github.com/karthikncode/nlp-datasets#question-answering</a></p></li><li><p><a href="http://nlpprogress.com/english/question_answering.html" target="_blank" rel="noopener">http://nlpprogress.com/english/question_answering.html</a></p></li></ul><h2 id="åŸºäºå¤šæ–‡æœ¬çš„QAä»»åŠ¡"><a href="#åŸºäºå¤šæ–‡æœ¬çš„QAä»»åŠ¡" class="headerlink" title="åŸºäºå¤šæ–‡æœ¬çš„QAä»»åŠ¡"></a>åŸºäºå¤šæ–‡æœ¬çš„QAä»»åŠ¡</h2><p>HOTPOTQA: A Dataset for Diverse, Explainable Multi-hop Question Answering</p><p><a href="https://www.aclweb.org/anthology/D18-1259" target="_blank" rel="noopener">https://www.aclweb.org/anthology/D18-1259</a></p><p>HotpotQAçš„ä¸»è¦ç‰¹ç‚¹æ˜¯ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºå¤šæ–‡æœ¬çš„QAä»»åŠ¡ã€‚ç»™å®šä¸€ç³»åˆ—çš„æ–‡ç« å’Œä¸€ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦ç»™å‡ºè¯¥é—®é¢˜çš„ç­”æ¡ˆï¼Œå¹¶ä¸”å›ç­”æˆ‘ä»¬æ˜¯ä»å“ªäº›ç›¸å…³çš„å¥å­ä¸­å¾—åˆ°é—®é¢˜çš„ç­”æ¡ˆçš„ã€‚</p><p>å·²ç»å…¬å¼€çš„å¯å‚è€ƒè®ºæ–‡</p><p>Hierarchical Graph Network for Multi-hop Question Answering <a href="https://arxiv.org/pdf/1911.00484.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1911.00484.pdf</a></p><p>Select, Answer and Explain: Interpretable Multi-hop Reading Comprehension over Multiple Documents <a href="https://arxiv.org/pdf/1911.03631.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1911.03631.pdf</a></p><h2 id="CoQA-åŸºäºå¯¹è¯çš„é—®ç­”æ•°æ®é›†"><a href="#CoQA-åŸºäºå¯¹è¯çš„é—®ç­”æ•°æ®é›†" class="headerlink" title="CoQA åŸºäºå¯¹è¯çš„é—®ç­”æ•°æ®é›†"></a>CoQA åŸºäºå¯¹è¯çš„é—®ç­”æ•°æ®é›†</h2><p>leaderboard <a href="https://stanfordnlp.github.io/coqa/" target="_blank" rel="noopener">https://stanfordnlp.github.io/coqa/</a></p><p>è®ºæ–‡ <a href="https://arxiv.org/abs/1808.07042" target="_blank" rel="noopener">https://arxiv.org/abs/1808.07042</a></p><p>æœç‹—æœ‰ä¸€ä¸ªBERTæ¨¡å‹çš„å®ç°</p><p><a href="https://github.com/sogou/SMRCToolkit" target="_blank" rel="noopener">https://github.com/sogou/SMRCToolkit</a></p><p>è¿™ä½åŒå­¦ä¹Ÿå®ç°äº†ä¸€äº›æ¨¡å‹</p><p><a href="https://github.com/jayelm/dialog-qa" target="_blank" rel="noopener">https://github.com/jayelm/dialog-qa</a></p><h2 id="ä¸­æ–‡æ•°æ®é›†"><a href="#ä¸­æ–‡æ•°æ®é›†" class="headerlink" title="ä¸­æ–‡æ•°æ®é›†"></a>ä¸­æ–‡æ•°æ®é›†</h2><h3 id="æ³•ç ”æ¯-é˜…è¯»ç†è§£æ•°æ®é›†"><a href="#æ³•ç ”æ¯-é˜…è¯»ç†è§£æ•°æ®é›†" class="headerlink" title="æ³•ç ”æ¯ é˜…è¯»ç†è§£æ•°æ®é›†"></a>æ³•ç ”æ¯ é˜…è¯»ç†è§£æ•°æ®é›†</h3><p><a href="http://cail.cipsc.org.cn/" target="_blank" rel="noopener">http://cail.cipsc.org.cn/</a></p><h3 id="è®¯é£æ¯-ä¸­æ–‡é˜…è¯»ç†è§£è¯„æµ‹"><a href="#è®¯é£æ¯-ä¸­æ–‡é˜…è¯»ç†è§£è¯„æµ‹" class="headerlink" title="è®¯é£æ¯ ä¸­æ–‡é˜…è¯»ç†è§£è¯„æµ‹"></a>è®¯é£æ¯ ä¸­æ–‡é˜…è¯»ç†è§£è¯„æµ‹</h3><p><a href="https://hfl-rc.github.io/cmrc2017/" target="_blank" rel="noopener">https://hfl-rc.github.io/cmrc2017/</a></p><p><a href="https://hfl-rc.github.io/cmrc2018/" target="_blank" rel="noopener">https://hfl-rc.github.io/cmrc2018/</a></p><p><a href="https://hfl-rc.github.io/cmrc2019/" target="_blank" rel="noopener">https://hfl-rc.github.io/cmrc2019/</a></p><p>åŒå­¦ä»¬å¯ä»¥æ‰¾åˆ°è¿™ä¸‰æ¬¡æ¯”èµ›çš„æ•°æ®é›†å’Œç›¸åº”çš„è¡¨ç°æœ€å¥½çš„æ¨¡å‹ä»£ç è¿›è¡Œå­¦ä¹ ã€‚</p><p>KBQA</p><p><a href="http://tcci.ccf.org.cn/conference/2018/papers/EV51.pdf" target="_blank" rel="noopener">http://tcci.ccf.org.cn/conference/2018/papers/EV51.pdf</a></p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> QA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Transformeræ¨¡å‹è§£è¯»</title>
      <link href="/2020/05/18/Transformer%E6%A8%A1%E5%9E%8B%E8%A7%A3%E8%AF%BB/"/>
      <url>/2020/05/18/Transformer%E6%A8%A1%E5%9E%8B%E8%A7%A3%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<p>contextualized word vectors</p><p>RNN, LSTM</p><p>RNN(I study at Julyedu.) â€“&gt; RNN(I)-&gt;h1, RNN(study, h1)-&gt;h2, RNN(at, h2)-&gt;h3. </p><p>Encoder. æˆ‘å¯ä»¥åŒæ—¶è§‚çœ‹å…¨å±€ä¿¡æ¯ã€‚</p><p>query, keys, values</p><p>q1, q2, .., q5</p><p>k1, k2, k3, k4, k5</p><p>score(q, k1), score(q, k2), â€¦, score(q, k5)</p><p>v1, v2, v3, v4, v5</p><p>\sum_{i=1}^5 func(score_i) v_i</p><p>dot(a, b)</p><p>mean</p><p>var(dot(a, b))</p><p>dot(a, b) = a1<em>b1 + a2</em>b2. â€¦. </p><p>E(dot(a, b)) = n * E(ai*bi)</p><p>var(dot(a, b)) = E(dot(a, b)^2) - E(dot(a, b))^2</p><p>affine transformation</p><p>WX+b</p><p>Attention(Q, K, V ) = softmax(QKT âˆš dk )V</p><p>Q : seq_len, hid_size</p><p>K^T:  hid_size, seq_len</p><p>V: seq_len, hid_size</p><p>QK^T : seq_len, seq_len</p><p>QK^T V: seq_len, hid_size</p><p>[emb_w(x), emb_p(i)]W â€“&gt; </p><p>è¿‘ä¸¤å¹´æ¥ï¼ŒNLPé¢†åŸŸçš„æ¨¡å‹ç ”ç©¶å·²ç»è¢«transformeræ¨¡å‹ä»¥åŠå®ƒçš„å„ç§å˜ç§ç»™å é¢†äº†ã€‚Transformeræ¨¡å‹çš„ç«çˆ†æœ‰å¾ˆå¤šåŸå› ï¼Œä¾‹å¦‚ï¼š</p><ul><li><p>æ¨¡å‹ç®€å•æ˜“æ‡‚ï¼Œencoderå’Œdecoderæ¨¡å—é«˜åº¦ç›¸ä¼¼ä¸”é€šç”¨</p></li><li><p>ï¼ˆencoderï¼‰å®¹æ˜“å¹¶è¡Œï¼Œæ¨¡å‹è®­ç»ƒé€Ÿåº¦å¿«</p></li><li><p>æ•ˆæœæ‹”ç¾¤ï¼Œåœ¨NMTç­‰é¢†åŸŸéƒ½å–å¾—äº†state-of-the-artçš„æ•ˆæœ</p></li></ul><p>è®ºæ–‡åœ°å€</p><ul><li><a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">Attention Is All You Need</a> </li></ul><p>ä¸‹é¢çš„æ–‡ç« ç¿»è¯‘è‡ª</p><ul><li><p><a href="https://jalammar.github.io/illustrated-transformer/" target="_blank" rel="noopener">The Illustrated Transformer</a></p></li><li><p><a href="https://blog.csdn.net/yujianmin1990/article/details/85221271" target="_blank" rel="noopener">ä¸­æ–‡ç¿»è¯‘</a></p></li></ul><p>é«˜å±‹å»ºç“´åœ°è¯´ï¼ŒTransformeræ¨¡å‹æ‹¿åˆ°ä¸€ä¸ªåºåˆ—ï¼Œç”¨æ¥ç”Ÿæˆå¦ä¸€ä¸ªåºåˆ—ã€‚</p><p><img src="https://uploader.shimo.im/f/vkvOEopS6TMPw0SL.png!thumbnail" alt="img"></p><p>æ‰“å¼€è¿™ä¸ªé»‘ç®±ï¼Œæˆ‘ä»¬ä¼šçœ‹åˆ°å…¶ä¸­åŒ…å«äº†ä¸¤ä¸ªéƒ¨åˆ†ï¼Œencoderså’Œdecodersã€‚</p><p><img src="https://uploader.shimo.im/f/hraPVC4iek06oDwt.png!thumbnail" alt="img"></p><p>å…¶ä¸­encoderså’Œdecoderséƒ½æ˜¯ä¸¤ä¸ªå †å æ¶æ„ã€‚ä¸€å±‚ä¸€å±‚åŒè´¨çš„ç»“æ„å †å åˆ°ä¸€èµ·ï¼Œç»„æˆäº†ç¼–ç å™¨å’Œè§£ç å™¨ã€‚</p><p><img src="https://uploader.shimo.im/f/WFbnFyb8peoeJuXW.png!thumbnail" alt="img"></p><p>é¦–å…ˆæˆ‘ä»¬æ‰“å¼€æ¯ä¸ªencoderæ¥å‚è§‚ä¸€ä¸‹å…¶ä¸­åŒ…å«çš„å†…å®¹ï¼š</p><p><img src="https://uploader.shimo.im/f/c7oNzYNSIoceXYFZ.png!thumbnail" alt="img"></p><p>æ¯ä¸€ä¸ªencoderéƒ½åŒ…å«äº†ä¸€ä¸ªè‡ªæ³¨æ„åŠ›ï¼ˆself-attentionï¼‰å±‚å’Œä¸€ä¸ªFeed Forward Neural Networkã€‚</p><p>encoderçš„è¾“å…¥é¦–å…ˆä¼šç»è¿‡ä¸€ä¸ªself-attentionå±‚ã€‚self-attentionçš„ä½œç”¨æ˜¯è®©æ¯ä¸ªå•è¯å¯ä»¥çœ‹åˆ°è‡ªå·±å’Œå…¶ä»–å•è¯çš„å…³ç³»ï¼Œå¹¶ä¸”å°†è‡ªå·±è½¬æ¢æˆä¸€ä¸ªä¸æ‰€æœ‰å•è¯ç›¸å…³çš„ï¼Œ<strong>focusåœ¨è‡ªå·±èº«ä¸Šçš„è¯å‘é‡(?)</strong>ã€‚</p><p>self-attentionä¹‹åçš„è¾“å‡ºä¼šå†ç»è¿‡ä¸€å±‚feed-forwardç¥ç»ç½‘ç»œã€‚æ¯ä¸ªä½ç½®çš„è¾“å‡ºè¢«åŒæ ·çš„feed-forward networkå¤„ç†ã€‚</p><p>decoderä¹Ÿæœ‰åŒæ ·çš„self-attentionå’Œfeed-forwardç»“æ„ï¼Œä½†æ˜¯åœ¨è¿™ä¸¤å±‚ä¹‹é—´è¿˜æœ‰ä¸€å±‚encoder-decoder attentionå±‚ï¼Œå¸®åŠ©decoderå…³æ³¨åˆ°æŸä¸€äº›ç‰¹åˆ«éœ€è¦å…³æ³¨çš„encoderä½ç½®ã€‚</p><h2 id="Tensorçš„å˜åŒ–"><a href="#Tensorçš„å˜åŒ–" class="headerlink" title="Tensorçš„å˜åŒ–"></a>Tensorçš„å˜åŒ–</h2><p><img src="https://uploader.shimo.im/f/Hmbb5V4mEJkBYpFS.png!thumbnail" alt="img"></p><h2 id="ç¼–ç å™¨"><a href="#ç¼–ç å™¨" class="headerlink" title="ç¼–ç å™¨"></a>ç¼–ç å™¨</h2><p>ä¸‹é¢æˆ‘ä»¬æ¥è¯¦ç»†è§£è¯»ä¸€ä¸‹ç¼–ç å™¨çš„å·¥ä½œã€‚</p><p><img src="https://uploader.shimo.im/f/MzJmdqVJiSUz4DT9.png!thumbnail" alt="img"></p><h3 id="Self-Attentionæœºåˆ¶"><a href="#Self-Attentionæœºåˆ¶" class="headerlink" title="Self-Attentionæœºåˆ¶"></a>Self-Attentionæœºåˆ¶</h3><p>æˆ‘ä»¬è€ƒè™‘ç”¨Transformeræ¨¡å‹ç¿»è¯‘ä¸‹é¢è¿™ä¸€å¥è¯ï¼š</p><p>â€œThe animal didnâ€™t cross the street because it was too tiredâ€ã€‚</p><p>å½“æˆ‘ä»¬ç¿»è¯‘åˆ° it çš„æ—¶å€™ï¼Œæˆ‘ä»¬çŸ¥é“ it æŒ‡ä»£çš„æ˜¯ animal è€Œä¸æ˜¯ streetã€‚æ‰€ä»¥ï¼Œå¦‚æœæœ‰åŠæ³•å¯ä»¥è®© it å¯¹åº”ä½ç½®çš„ embedding é€‚å½“åŒ…å« animal çš„ä¿¡æ¯ï¼Œå°±ä¼šéå¸¸æœ‰ç”¨ã€‚self-attentionçš„å‡ºç°å°±æ˜¯ä¸ºäº†å®Œæˆè¿™ä¸€ä»»åŠ¡ã€‚</p><p>å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œself attnetionä¼šè®©å•è¯ it å’Œ æŸäº›å•è¯å‘ç”Ÿæ¯”è¾ƒå¼ºçš„è”ç³»ï¼Œå¾—åˆ°æ¯”è¾ƒæçš„attentionåˆ†æ•°ã€‚</p><p><img src="https://uploader.shimo.im/f/UsNXjO1OpN0usuAg.png!thumbnail" alt="img"></p><p>weight(The) = softmax(v(it) * v(The) / \sqrt(d))</p><p>weight(The) = softmx(Query(It) * Key(The) / \sqrt(d))</p><p>\sum_{word} weight(word) * Value(word)</p><h3 id="Self-attentionçš„ç»†èŠ‚"><a href="#Self-attentionçš„ç»†èŠ‚" class="headerlink" title="Self-attentionçš„ç»†èŠ‚"></a>Self-attentionçš„ç»†èŠ‚</h3><p>ä¸ºäº†å®ç° self-attentionï¼Œæ¯ä¸ªè¾“å…¥çš„ä½ç½®éœ€è¦äº§ç”Ÿä¸‰ä¸ªå‘é‡ï¼Œåˆ†åˆ«æ˜¯ <strong>Query å‘é‡ï¼ŒKey å‘é‡å’Œ Value å‘é‡</strong>ã€‚è¿™äº›å‘é‡éƒ½æ˜¯ç”±è¾“å…¥ embedding é€šè¿‡ä¸‰ä¸ª matrices ï¼ˆä¹Ÿå°±æ˜¯çº¿æ€§å˜åŒ–ï¼‰äº§ç”Ÿçš„ã€‚</p><p>æ³¨æ„åˆ°åœ¨Transformeræ¶æ„ä¸­ï¼Œè¿™äº›æ–°çš„å‘é‡æ¯”åŸæ¥çš„è¾“å…¥å‘é‡è¦å°ï¼ŒåŸæ¥çš„å‘é‡æ˜¯512ç»´ï¼Œè½¬å˜åçš„ä¸‰ä¸ªå‘é‡éƒ½æ˜¯64ç»´ã€‚</p><p><img src="https://uploader.shimo.im/f/MAqlj67rbPYBI7Ad.png!thumbnail" alt="img"></p><p>ç¬¬äºŒæ­¥æ˜¯<strong>è®¡ç®—åˆ†æ•°</strong>ã€‚å½“æˆ‘ä»¬åœ¨ç”¨self-attention encodeæŸä¸ªä½ç½®ä¸Šçš„æŸä¸ªå•è¯çš„æ—¶å€™ï¼Œæˆ‘ä»¬å¸Œæœ›çŸ¥é“è¿™ä¸ªå•è¯å¯¹åº”çš„å¥å­ä¸Šå…¶ä»–å•è¯çš„åˆ†æ•°ã€‚å…¶ä»–å•è¯æ‰€å¾—åˆ°çš„åˆ†æ•°è¡¨ç¤ºäº†å½“æˆ‘ä»¬encodeå½“å‰å•è¯çš„æ—¶å€™ï¼Œåº”è¯¥æ”¾å¤šå°‘çš„å…³æ³¨åº¦åœ¨å…¶ä½™çš„æ¯ä¸ªå•è¯ä¸Šã€‚åˆæˆ–è€…è¯´ï¼Œå…¶ä»–å•è¯å’Œæˆ‘å½“å‰çš„å•è¯æœ‰å¤šå¤§çš„ç›¸å…³æ€§æˆ–è€…ç›¸ä¼¼æ€§ã€‚</p><p>åœ¨transformeræ¨¡å‹ä¸­ï¼Œè¿™ä¸ªåˆ†æ•°æ˜¯ç”±query vectorå’Œkey vectoråšç‚¹ç§¯ï¼ˆdot productï¼‰æ‰€å¾—çš„ç»“æœã€‚æ‰€ä»¥è¯´ï¼Œå½“æˆ‘ä»¬åœ¨å¯¹ç¬¬ä¸€ä¸ªå•è¯åšself-attentionå¤„ç†çš„æ—¶å€™ï¼Œç¬¬ä¸€ä¸ªå•è¯çš„åˆ†æ•°æ˜¯q_1å’Œk_1çš„ç‚¹ç§¯ï¼Œç¬¬äºŒä¸ªåˆ†æ•°æ˜¯q_1å’Œk_2çš„åˆ†æ•°ã€‚</p><p><img src="https://uploader.shimo.im/f/kW9cJM4TjTc9xtMV.png!thumbnail" alt="img"></p><p>ç¬¬ä¸‰æ­¥å’Œç¬¬å››æ­¥æ˜¯å°†è¿™äº›åˆ†æ•°é™¤ä»¥8ã€‚8è¿™ä¸ªæ•°å­—æ˜¯64çš„å¼€æ–¹ï¼Œä¹Ÿå°±æ˜¯key vectorçš„ç»´åº¦çš„å¼€æ–¹ã€‚æ®è¯´è¿™ä¹ˆåšå¯ä»¥ç¨³å®šæ¨¡å‹çš„gradientã€‚ç„¶åæˆ‘ä»¬å°†è¿™äº›åˆ†æ•°ä¼ å…¥softmaxå±‚äº§ç”Ÿä¸€äº›ç¬¦åˆæ¦‚ç‡åˆ†å¸ƒçš„probability scoresã€‚</p><p><img src="https://uploader.shimo.im/f/6kTtVymp0XgZCDh0.png!thumbnail" alt="img"></p><p>softmax = exp(x_i) / sum exp(x_i)</p><p>è¿™äº›åˆ†æ•°å°±è¡¨ç¤ºäº†åœ¨å¤„ç†å½“å‰å•è¯çš„æ—¶å€™æˆ‘ä»¬åº”è¯¥åˆ†é…å¤šå°‘çš„å…³æ³¨åº¦ç»™å…¶ä»–å•è¯ã€‚</p><p>ç¬¬äº”æ­¥æ˜¯å°†æ¯ä¸ªvalue vectorä¹˜ä»¥å®ƒä»¬å„è‡ªçš„attention scoreã€‚ç¬¬å…­æ­¥æ˜¯æŠŠè¿™äº›weighted value vectorsç›¸åŠ ï¼Œæˆä¸ºå½“å‰å•è¯çš„vectorè¡¨ç¤ºã€‚</p><p><img src="https://uploader.shimo.im/f/FrqMNrQrlo0tLBgV.png!thumbnail" alt="img"></p><p>å¾—åˆ°äº†self-attentionç”Ÿæˆçš„è¯å‘é‡ä¹‹åï¼Œæˆ‘ä»¬å°±å¯ä»¥å°†å®ƒä»¬ä¼ å…¥feed-forward networkäº†ã€‚</p><h3 id="Self-Attentionä¸­çš„çŸ©é˜µè¿ç®—"><a href="#Self-Attentionä¸­çš„çŸ©é˜µè¿ç®—" class="headerlink" title="Self-Attentionä¸­çš„çŸ©é˜µè¿ç®—"></a>Self-Attentionä¸­çš„çŸ©é˜µè¿ç®—</h3><p>é¦–å…ˆï¼Œæˆ‘ä»¬è¦å¯¹æ¯ä¸€ä¸ªè¯å‘é‡è®¡ç®—Query, Keyå’ŒValueçŸ©é˜µã€‚æˆ‘ä»¬æŠŠå¥å­ä¸­çš„æ¯ä¸ªè¯å‘é‡æ‹¼æ¥åˆ°ä¸€èµ·å˜æˆä¸€ä¸ªçŸ©é˜µXï¼Œç„¶åä¹˜ä»¥ä¸åŒçš„çŸ©é˜µåšçº¿æ€§å˜æ¢ï¼ˆWQ, WK, WVï¼‰ã€‚</p><p><img src="https://uploader.shimo.im/f/xRsGTXMRHTQsNPiL.png!thumbnail" alt="img"></p><p>ç„¶åæˆ‘ä»¬å°±ç”¨çŸ©é˜µä¹˜æ³•å®ç°ä¸Šé¢ä»‹ç»è¿‡çš„Self-Attentionæœºåˆ¶äº†ã€‚</p><p><img src="https://uploader.shimo.im/f/S1IEPFyGeMUTWMBk.png!thumbnail" alt="img"></p><h3 id="Multi-headed-attention"><a href="#Multi-headed-attention" class="headerlink" title="Multi-headed attention"></a>Multi-headed attention</h3><p>åœ¨è®ºæ–‡å½“ä¸­ï¼Œæ¯ä¸ªembedding vectorå¹¶ä¸æ­¢äº§ç”Ÿä¸€ä¸ªkey, value, query vectorsï¼Œè€Œæ˜¯äº§ç”Ÿè‹¥å¹²ç»„è¿™æ ·çš„vectorsï¼Œç§°ä¹‹ä¸ºâ€multi-headedâ€ attentionã€‚è¿™ä¹ˆåšæœ‰å‡ ä¸ªå¥½å¤„ï¼š</p><ul><li><p>k: key, q: query, v: value</p></li><li><p>æ¨¡å‹æœ‰æ›´å¼ºçš„èƒ½åŠ›äº§ç”Ÿä¸åŒçš„attentionæœºåˆ¶ï¼Œfocusåœ¨ä¸åŒçš„å•è¯ä¸Šã€‚</p></li><li><p>attention layeræœ‰å¤šä¸ªä¸åŒçš„â€representation spaceâ€ã€‚</p></li></ul><p><img src="https://uploader.shimo.im/f/vQX0sIYIoqUNYO4J.png!thumbnail" alt="img"></p><p>æ¯ä¸ªattention headæœ€ç»ˆéƒ½äº§ç”Ÿäº†ä¸€ä¸ªmatrixè¡¨ç¤ºè¿™ä¸ªå¥å­ä¸­çš„æ‰€æœ‰è¯å‘é‡ã€‚åœ¨transformeræ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬äº§ç”Ÿäº†å…«ä¸ªmatricesã€‚æˆ‘ä»¬çŸ¥é“self attentionä¹‹åå°±æ˜¯ä¸€ä¸ªfeed-forward networkã€‚é‚£ä¹ˆæˆ‘ä»¬æ˜¯å¦éœ€è¦åš8æ¬¡feed-forward networkè¿ç®—å‘¢ï¼Ÿäº‹å®ä¸Šæ˜¯ä¸ç”¨çš„ã€‚æˆ‘ä»¬åªéœ€è¦å°†è¿™8ä¸ªmatricesæ‹¼æ¥åˆ°ä¸€èµ·ï¼Œç„¶ååšä¸€æ¬¡å‰å‘ç¥ç»ç½‘ç»œçš„è¿ç®—å°±å¯ä»¥äº†ã€‚</p><p><img src="https://uploader.shimo.im/f/E4AxOnUs2JgGJ0bW.png!thumbnail" alt="img"></p><p>ç»¼åˆèµ·æ¥ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ä¸‹é¢ä¸€å¼ å›¾è¡¨ç¤ºSelf-Attentionæ¨¡å—æ‰€åšçš„äº‹æƒ…ã€‚</p><p><img src="https://uploader.shimo.im/f/YmfWxTGsc48tTbfi.png!thumbnail" alt="img"></p><h3 id="Positional-Encoding"><a href="#Positional-Encoding" class="headerlink" title="Positional Encoding"></a>Positional Encoding</h3><p>thinking machine</p><p>w_1, w_2</p><p>p_1, p_2</p><p>positional_embedding = nn.Embedding(512, 300)</p><p>w_1 + p_1, w_2 + p_2, w_3 + p_3, â€¦, w_n + p_n</p><p>åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å®Œå…¨æ²¡æœ‰è€ƒè™‘å•è¯çš„é¡ºåºã€‚å³ä½¿æˆ‘ä»¬å°†å¥å­ä¸­å•è¯çš„é¡ºåºå®Œå…¨æ‰“ä¹±ï¼Œå¯¹äºtransformerè¿™ä¸ªæ¨¡å‹æ¥è¯´ï¼Œå¹¶æ²¡æœ‰ä»€ä¹ˆåŒºåˆ«ã€‚ä¸ºäº†åŠ å…¥å¥å­ä¸­å•è¯çš„é¡ºåºä¿¡æ¯ï¼Œæˆ‘ä»¬å¼•å…¥ä¸€ä¸ªæ¦‚å¿µå«åšpositional encodingã€‚</p><p><img src="https://uploader.shimo.im/f/1F6bv1ngvE4hEp99.png!thumbnail" alt="img"></p><p>å¦‚æœæˆ‘ä»¬å‡è®¾è¾“å…¥çš„embeddingæ˜¯4ä¸ªç»´åº¦çš„ï¼Œé‚£ä¹ˆä»–ä»¬çš„position encodingså¤§æ¦‚é•¿ä¸‹é¢è¿™æ ·ã€‚</p><p><img src="https://uploader.shimo.im/f/1p4K2IclsvwWGw0Z.png!thumbnail" alt="img"></p><p>ä¸‹é¢è¿™å¼ å›¾çš„æ¯ä¸€è¡Œè¡¨ç¤ºä¸€ä¸ªpositional encoding vectorã€‚ç¬¬ä¸€è¡Œè¡¨ç¤ºç¬¬ä¸€ä¸ªå•è¯çš„positional encodingï¼Œä»¥æ­¤ç±»æ¨ã€‚æ¯ä¸€è¡Œéƒ½æœ‰512ä¸ª-1åˆ°1ä¹‹é—´çš„æ•°å­—ã€‚æˆ‘ä»¬ç”¨é¢œè‰²æ ‡è®°äº†è¿™äº›vectorsã€‚</p><p><img src="https://uploader.shimo.im/f/HMQy3lipFooyu8rO.png!thumbnail" alt="img"></p><h3 id="Residuals"><a href="#Residuals" class="headerlink" title="Residuals"></a>Residuals</h3><p>å¦å¤–ä¸€ä¸ªç»†èŠ‚æ˜¯ï¼Œencoderä¸­çš„æ¯ä¸€å±‚éƒ½åŒ…å«äº†ä¸€ä¸ªresidual connectionå’Œlayer-normalizationã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚</p><p><img src="https://uploader.shimo.im/f/1qIGhKLQLYkHahSn.png!thumbnail" alt="img"></p><p>ä¸‹é¢è¿™å¼ å›¾æ˜¯æ›´è¯¦ç»†çš„vectorè¡¨ç¤ºã€‚</p><p><img src="https://uploader.shimo.im/f/ivgMtxCc8CsI7lAF.png!thumbnail" alt="img"></p><p>decoderä¹Ÿæ˜¯åŒæ ·çš„æ¶æ„ã€‚å¦‚æœæˆ‘ä»¬æŠŠencoderå’Œdecoderæ”¾åˆ°ä¸€èµ·ï¼Œä»–ä»¬å°±é•¿è¿™æ ·ã€‚</p><p><img src="https://uploader.shimo.im/f/TumXWzLQ6XMjJneZ.png!thumbnail" alt="img"></p><h2 id="è§£ç å™¨"><a href="#è§£ç å™¨" class="headerlink" title="è§£ç å™¨"></a>è§£ç å™¨</h2><p>encoderæœ€åä¸€å±‚ä¼šè¾“å‡ºattention vectors Kå’ŒVã€‚Kå’ŒVä¼šè¢«decoderç”¨ä½œè§£ç çš„åŸææ–™ã€‚</p><p><img src="https://uploader.shimo.im/f/3AgIt6lqzgADLwuf.png!thumbnail" alt="img"></p><p>åœ¨è§£ç çš„è¿‡ç¨‹ä¸­ï¼Œè§£ç å™¨æ¯ä¸€æ­¥ä¼šè¾“å‡ºä¸€ä¸ªtokenã€‚ä¸€ç›´å¾ªç¯å¾€å¤ï¼Œç›´åˆ°å®ƒè¾“å‡ºäº†ä¸€ä¸ªç‰¹æ®Šçš„end of sequence tokenï¼Œè¡¨ç¤ºè§£ç ç»“æŸäº†ã€‚</p><p><img src="https://uploader.shimo.im/f/ai444UV6eQ4E0f6O.png!thumbnail" alt="img"></p><p>decoderçš„self attentionæœºåˆ¶ä¸encoderç¨æœ‰ä¸åŒã€‚åœ¨decoderå½“ä¸­ï¼Œself attentionå±‚åªèƒ½çœ‹åˆ°ä¹‹å‰å·²ç»è§£ç çš„æ–‡å­—ã€‚æˆ‘ä»¬åªéœ€è¦æŠŠå½“å‰è¾“å‡ºä½ç½®ä¹‹åçš„å•è¯å…¨éƒ½maskæ‰ï¼ˆsoftmaxå±‚ä¹‹å‰å…¨éƒ½è®¾ç½®æˆ-infï¼‰å³å¯ã€‚</p><p>softmax(Q matmul K^T / sqrt(d)) matmul V</p><p>weights = Q matmul K^T: [seq_len, seq_len]</p><p>Masked Self Attention</p><p>q, k (<strong>100, 24</strong>, 35 - inf, 88 - inf, -55 - inf) â€“&gt; softmax â€“&gt; (0.9, 0.1, 0, 0, 0)</p><p>attention_mask</p><p>0, -inf, -inf, -inf</p><p>0, 0, -inf, -inf</p><p>0, 0, 0, -inf </p><p>0, 0, 0, 0</p><p>softmax(weights - attention_mask, -1)</p><p>è®­ç»ƒ</p><p>QKV, å¹¶è¡Œè®­ç»ƒ</p><p>é¢„æµ‹</p><p>ä¸€ä¸ªå•è¯ä¸€ä¸ªå•è¯è§£ç </p><p>Encoder-Decoder Attentionå±‚å’Œæ™®é€šçš„multiheaded self-attentionä¸€æ ·ï¼Œé™¤äº†å®ƒçš„Querieså®Œå…¨æ¥è‡ªä¸‹é¢çš„decoderå±‚ï¼Œç„¶åKeyå’ŒValueæ¥è‡ªencoderçš„è¾“å‡ºå‘é‡ã€‚</p><p>batch_size * seq_length * hidden_size </p><p>padding_mask</p><p>tgt_mask</p><h3 id="æœ€åçš„çº¿æ€§å±‚å’Œsoftmaxå±‚"><a href="#æœ€åçš„çº¿æ€§å±‚å’Œsoftmaxå±‚" class="headerlink" title="æœ€åçš„çº¿æ€§å±‚å’Œsoftmaxå±‚"></a>æœ€åçš„çº¿æ€§å±‚å’Œsoftmaxå±‚</h3><p>è§£ç å™¨æœ€åè¾“å‡ºæµ®ç‚¹å‘é‡ï¼Œå¦‚ä½•å°†å®ƒè½¬æˆè¯ï¼Ÿè¿™æ˜¯æœ€åçš„çº¿æ€§å±‚å’Œsoftmaxå±‚çš„ä¸»è¦å·¥ä½œã€‚</p><p>çº¿æ€§å±‚æ˜¯ä¸ªç®€å•çš„å…¨è¿æ¥å±‚ï¼Œå°†è§£ç å™¨çš„æœ€åè¾“å‡ºæ˜ å°„åˆ°ä¸€ä¸ªéå¸¸å¤§çš„logitså‘é‡ä¸Šã€‚å‡è®¾æ¨¡å‹å·²çŸ¥æœ‰1ä¸‡ä¸ªå•è¯ï¼ˆè¾“å‡ºçš„è¯è¡¨ï¼‰ä»è®­ç»ƒé›†ä¸­å­¦ä¹ å¾—åˆ°ã€‚é‚£ä¹ˆï¼Œlogitså‘é‡å°±æœ‰1ä¸‡ç»´ï¼Œæ¯ä¸ªå€¼è¡¨ç¤ºæ˜¯æŸä¸ªè¯çš„å¯èƒ½å€¾å‘å€¼ã€‚</p><p>softmaxå±‚å°†è¿™äº›åˆ†æ•°è½¬æ¢æˆæ¦‚ç‡å€¼ï¼ˆéƒ½æ˜¯æ­£å€¼ï¼Œä¸”åŠ å’Œä¸º1ï¼‰ï¼Œæœ€é«˜å€¼å¯¹åº”çš„ç»´ä¸Šçš„è¯å°±æ˜¯è¿™ä¸€æ­¥çš„è¾“å‡ºå•è¯ã€‚</p><p><img src="https://uploader.shimo.im/f/7ffWFIfMqOgtsK22.png!thumbnail" alt="img"></p><h2 id="æ¨¡å‹çš„è®­ç»ƒ"><a href="#æ¨¡å‹çš„è®­ç»ƒ" class="headerlink" title="æ¨¡å‹çš„è®­ç»ƒ"></a>æ¨¡å‹çš„è®­ç»ƒ</h2><p>ç°åœ¨æˆ‘ä»¬å·²ç»äº†è§£äº†ä¸€ä¸ªè®­ç»ƒå®Œæ¯•çš„Transformerçš„å‰å‘è¿‡ç¨‹ï¼Œé¡ºé“çœ‹ä¸‹è®­ç»ƒçš„æ¦‚å¿µä¹Ÿæ˜¯éå¸¸æœ‰ç”¨çš„ã€‚åœ¨è®­ç»ƒæ—¶ï¼Œæ¨¡å‹å°†ç»å†ä¸Šè¿°çš„å‰å‘è¿‡ç¨‹ï¼Œå½“æˆ‘ä»¬åœ¨æ ‡è®°è®­ç»ƒé›†ä¸Šè®­ç»ƒæ—¶ï¼Œå¯ä»¥å¯¹æ¯”é¢„æµ‹è¾“å‡ºä¸å®é™…è¾“å‡ºã€‚ä¸ºäº†å¯è§†åŒ–ï¼Œå‡è®¾è¾“å‡ºä¸€å…±åªæœ‰6ä¸ªå•è¯ï¼ˆâ€œaâ€, â€œamâ€, â€œiâ€, â€œthanksâ€, â€œstudentâ€, â€œâ€ï¼‰</p><p><img src="https://uploader.shimo.im/f/FNgjBBm5gbUGYgbs.png!thumbnail" alt="img"></p><p>æ¨¡å‹çš„è¯è¡¨æ˜¯åœ¨è®­ç»ƒä¹‹å‰çš„é¢„å¤„ç†ä¸­ç”Ÿæˆçš„</p><p>ä¸€æ—¦å®šä¹‰äº†è¯è¡¨ï¼Œæˆ‘ä»¬å°±èƒ½å¤Ÿæ„é€ ä¸€ä¸ªåŒç»´åº¦çš„å‘é‡æ¥è¡¨ç¤ºæ¯ä¸ªå•è¯ï¼Œæ¯”å¦‚one-hotç¼–ç ï¼Œä¸‹é¢ä¸¾ä¾‹ç¼–ç â€œamâ€ã€‚</p><p><img src="https://uploader.shimo.im/f/feV2TQAHPF0z3Rr2.png!thumbnail" alt="img"></p><p>ä¸¾ä¾‹é‡‡ç”¨one-hotç¼–ç è¾“å‡ºè¯è¡¨</p><p>ä¸‹é¢è®©æˆ‘ä»¬è®¨è®ºä¸‹æ¨¡å‹çš„lossæŸå¤±ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç”¨æ¥ä¼˜åŒ–çš„æŒ‡æ ‡ï¼ŒæŒ‡å¯¼å­¦ä¹ å¾—åˆ°ä¸€ä¸ªéå¸¸å‡†ç¡®çš„æ¨¡å‹ã€‚</p><h3 id="æŸå¤±å‡½æ•°"><a href="#æŸå¤±å‡½æ•°" class="headerlink" title="æŸå¤±å‡½æ•°"></a>æŸå¤±å‡½æ•°</h3><p>æˆ‘ä»¬ç”¨ä¸€ä¸ªç®€å•çš„ä¾‹å­æ¥ç¤ºèŒƒè®­ç»ƒï¼Œæ¯”å¦‚ç¿»è¯‘â€œmerciâ€ä¸ºâ€œthanksâ€ã€‚é‚£æ„å‘³ç€è¾“å‡ºçš„æ¦‚ç‡åˆ†å¸ƒæŒ‡å‘å•è¯â€œthanksâ€ï¼Œä½†æ˜¯ç”±äºæ¨¡å‹æœªè®­ç»ƒæ˜¯éšæœºåˆå§‹åŒ–çš„ï¼Œä¸å¤ªå¯èƒ½å°±æ˜¯æœŸæœ›çš„è¾“å‡ºã€‚</p><p><img src="https://uploader.shimo.im/f/aWNgQPklQh8odGQP.png!thumbnail" alt="img"></p><p>ç”±äºæ¨¡å‹å‚æ•°æ˜¯éšæœºåˆå§‹åŒ–çš„ï¼Œæœªè®­ç»ƒçš„æ¨¡å‹è¾“å‡ºéšæœºå€¼ã€‚æˆ‘ä»¬å¯ä»¥å¯¹æ¯”çœŸå®è¾“å‡ºï¼Œç„¶ååˆ©ç”¨è¯¯å·®åä¼ è°ƒæ•´æ¨¡å‹æƒé‡ï¼Œä½¿å¾—è¾“å‡ºæ›´æ¥è¿‘ä¸çœŸå®è¾“å‡ºã€‚å¦‚ä½•å¯¹æ¯”ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒå‘¢ï¼Ÿç®€å•é‡‡ç”¨ <a href="https://colah.github.io/posts/2015-09-Visual-Information/" target="_blank" rel="noopener">cross-entropy</a>æˆ–è€…<a href="https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained" target="_blank" rel="noopener">Kullback-Leibler divergence</a>ä¸­çš„ä¸€ç§ã€‚é‰´äºè¿™æ˜¯ä¸ªæå…¶ç®€å•çš„ä¾‹å­ï¼Œæ›´çœŸå®çš„æƒ…å†µæ˜¯ï¼Œä½¿ç”¨ä¸€ä¸ªå¥å­ä½œä¸ºè¾“å…¥ã€‚æ¯”å¦‚ï¼Œè¾“å…¥æ˜¯â€œje suis Ã©tudiantâ€ï¼ŒæœŸæœ›è¾“å‡ºæ˜¯â€œi am a studentâ€ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸‹ï¼Œæˆ‘ä»¬æœŸæœ›æ¨¡å‹è¾“å‡ºè¿ç»­çš„æ¦‚ç‡åˆ†å¸ƒæ»¡è¶³å¦‚ä¸‹æ¡ä»¶ï¼š</p><ol><li><p>æ¯ä¸ªæ¦‚ç‡åˆ†å¸ƒéƒ½ä¸è¯è¡¨åŒç»´åº¦</p></li><li><p>ç¬¬ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒå¯¹â€œiâ€å…·æœ‰æœ€é«˜çš„é¢„æµ‹æ¦‚ç‡å€¼ã€‚</p></li><li><p>ç¬¬äºŒä¸ªæ¦‚ç‡åˆ†å¸ƒå¯¹â€œamâ€å…·æœ‰æœ€é«˜çš„é¢„æµ‹æ¦‚ç‡å€¼ã€‚</p></li><li><p>ä¸€ç›´åˆ°ç¬¬äº”ä¸ªè¾“å‡ºæŒ‡å‘â€â€æ ‡è®°ã€‚</p></li></ol><p><img src="https://uploader.shimo.im/f/rAnz8qY0eHgt2OAe.png!thumbnail" alt="img"></p><p>å¯¹ä¸€ä¸ªå¥å­è€Œè¨€ï¼Œè®­ç»ƒæ¨¡å‹çš„ç›®æ ‡æ¦‚ç‡åˆ†å¸ƒ</p><p>åœ¨è¶³å¤Ÿå¤§çš„è®­ç»ƒé›†ä¸Šè®­ç»ƒè¶³å¤Ÿæ—¶é—´ä¹‹åï¼Œæˆ‘ä»¬æœŸæœ›äº§ç”Ÿçš„æ¦‚ç‡åˆ†å¸ƒå¦‚ä¸‹æ‰€ç¤ºï¼š</p><p><img src="https://uploader.shimo.im/f/IyKk2fNcC3k4tgBt.png!thumbnail" alt="img"></p><p>è®­ç»ƒå¥½ä¹‹åï¼Œæ¨¡å‹çš„è¾“å‡ºæ˜¯æˆ‘ä»¬æœŸæœ›çš„ç¿»è¯‘ã€‚å½“ç„¶ï¼Œè¿™å¹¶ä¸æ„å‘³ç€è¿™ä¸€è¿‡ç¨‹æ˜¯æ¥è‡ªè®­ç»ƒé›†ã€‚æ³¨æ„ï¼Œæ¯ä¸ªä½ç½®éƒ½èƒ½æœ‰å€¼ï¼Œå³ä¾¿ä¸è¾“å‡ºè¿‘ä¹æ— å…³ï¼Œè¿™ä¹Ÿæ˜¯softmaxå¯¹è®­ç»ƒæœ‰å¸®åŠ©çš„åœ°æ–¹ã€‚ç°åœ¨ï¼Œå› ä¸ºæ¨¡å‹æ¯æ­¥åªäº§ç”Ÿä¸€ç»„è¾“å‡ºï¼Œå‡è®¾æ¨¡å‹é€‰æ‹©æœ€é«˜æ¦‚ç‡ï¼Œæ‰”æ‰å…¶ä»–çš„éƒ¨åˆ†ï¼Œè¿™æ˜¯ç§äº§ç”Ÿé¢„æµ‹ç»“æœçš„æ–¹æ³•ï¼Œå«åšgreedy è§£ç ã€‚å¦å¤–ä¸€ç§æ–¹æ³•æ˜¯beam searchï¼Œæ¯ä¸€æ­¥ä»…ä¿ç•™æœ€å¤´éƒ¨é«˜æ¦‚ç‡çš„ä¸¤ä¸ªè¾“å‡ºï¼Œæ ¹æ®è¿™ä¿©è¾“å‡ºå†é¢„æµ‹ä¸‹ä¸€æ­¥ï¼Œå†ä¿ç•™å¤´éƒ¨é«˜æ¦‚ç‡çš„ä¸¤ä¸ªè¾“å‡ºï¼Œé‡å¤ç›´åˆ°é¢„æµ‹ç»“æŸ</p><h2 id="æ›´å¤šèµ„æ–™"><a href="#æ›´å¤šèµ„æ–™" class="headerlink" title="æ›´å¤šèµ„æ–™"></a>æ›´å¤šèµ„æ–™</h2><ul><li><p><a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">Attention Is All You Need</a> </p></li><li><p>Transformeråšå®¢æ–‡ç«  <a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html" target="_blank" rel="noopener">Transformer: A Novel Neural Network Architecture for Language Understanding</a></p></li><li><p><a href="https://ai.googleblog.com/2017/06/accelerating-deep-learning-research.html" target="_blank" rel="noopener">Tensor2Tensor announcement</a>.</p></li><li><p><a href="https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb" target="_blank" rel="noopener">Jupyter Notebook provided as part of the Tensor2Tensor repo</a></p></li><li><p><a href="https://github.com/tensorflow/tensor2tensor" target="_blank" rel="noopener">Tensor2Tensor repo</a>.</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Transformer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Transformer-XL</title>
      <link href="/2020/05/16/Transformer-XL/"/>
      <url>/2020/05/16/Transformer-XL/</url>
      
        <content type="html"><![CDATA[<h2 id="Transformer-XL-Attentive-Language-Models-Beyond-a-Fixed-Length-Context"><a href="#Transformer-XL-Attentive-Language-Models-Beyond-a-Fixed-Length-Context" class="headerlink" title="Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context"></a>Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context</h2><p><a href="https://arxiv.org/pdf/1901.02860.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1901.02860.pdf</a></p><p>ç›¸è¾ƒäºä¼ ç»Ÿtransformer decoderï¼Œå¼•å…¥ä¸¤ä¸ªæ–°æ¨¡å—</p><ul><li>segment-level recurrence mechanism</li></ul><p><img src="https://uploader.shimo.im/f/DpNe30kuahkbOeW5.png!thumbnail" alt="img"></p><ul><li><p>a novel positional encoding scheme</p></li><li><p>è€ƒè™‘æˆ‘ä»¬åœ¨attentionæœºåˆ¶ä¸­å¦‚ä½•ä½¿ç”¨positional encoding</p></li></ul><p>(E_{x_i}^T+U_i^T)W_q^TW_kE_{x_j}U_j</p><p><img src="https://uploader.shimo.im/f/5zNU9yZQtQMClNiY.png!thumbnail" alt="img"></p><ul><li><p>Rä»–ä»¬é‡‡ç”¨çš„æ˜¯transformerå½“ä¸­çš„positional encoding</p></li><li><p>uå’Œvæ˜¯éœ€è¦è®­ç»ƒçš„æ¨¡å‹å‚æ•°</p></li></ul><p>æœ€ç»ˆTransformer XLæ¨¡å‹</p><p><img src="https://uploader.shimo.im/f/Nm1uk49MIjUys1aK.png!thumbnail" alt="img"></p><p>ä»£ç </p><p><a href="https://github.com/kimiyoung/transformer-xl" target="_blank" rel="noopener">https://github.com/kimiyoung/transformer-xl</a></p><h2 id="XLNet-Generalized-Autoregressive-Pretraining-for-Language-Understanding"><a href="#XLNet-Generalized-Autoregressive-Pretraining-for-Language-Understanding" class="headerlink" title="XLNet: Generalized Autoregressive Pretraining for Language Understanding"></a>XLNet: Generalized Autoregressive Pretraining for Language Understanding</h2><p><a href="https://arxiv.org/pdf/1906.08237.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1906.08237.pdf</a></p><p>èƒŒæ™¯çŸ¥è¯†</p><ul><li><p>è‡ªå›å½’è¯­è¨€æ¨¡å‹ï¼ˆAutoregressive Language Modelï¼‰ï¼šé‡‡ç”¨ä»å·¦å¾€å³æˆ–ä»å³å¾€å·¦çš„è¯­è¨€æ¨¡å‹ï¼Œæ ¹æ®ä¸Šæ–‡é¢„æµ‹ä¸‹æ–‡ã€‚</p></li><li><p>ç¼ºç‚¹ï¼šåªåˆ©ç”¨äº†é¢„æµ‹å•è¯å·¦è¾¹æˆ–å³è¾¹çš„ä¿¡æ¯ï¼Œæ— æ³•åŒæ—¶åˆ©ç”¨ä¸¤è¾¹çš„ä¿¡æ¯ã€‚ELMoåœ¨ä¸€å®šç¨‹åº¦ä¸Šè§£å†³äº†è¿™ä¸ªé—®é¢˜ã€‚</p></li><li><p><img src="https://uploader.shimo.im/f/cpfGbeRfzf8c1ga8.png!thumbnail" alt="img"></p></li><li><p>è‡ªç¼–ç æ¨¡å‹ï¼ˆDenoising Auto Encoder, DAEï¼‰ï¼šåœ¨è¾“å…¥ä¸­éšæœºmaskä¸€äº›å•è¯ï¼Œåˆ©ç”¨ä¸Šä¸‹æ–‡æ¥é¢„æµ‹è¢«maskæ‰çš„å•è¯ã€‚BERTé‡‡ç”¨äº†è¿™ä¸€æ€è·¯ã€‚</p></li><li><p><img src="https://uploader.shimo.im/f/za1FnG3zHdsbm5gD.png!thumbnail" alt="img"></p></li></ul><p>ä¸¤ä¸ªæ¨¡å‹çš„é—®é¢˜</p><p><img src="https://uploader.shimo.im/f/A1rO6rAR1nAQqqvu.png!thumbnail" alt="img"></p><p>XLNetçš„ç›®æ ‡æ˜¯èåˆä»¥ä¸Šä¸¤ç§æ¨¡å‹çš„ä¼˜ç‚¹ï¼Œè§£å†³å®ƒä»¬å„è‡ªå­˜åœ¨çš„é—®é¢˜ã€‚</p><p>XLNetæ¨¡å‹ï¼šPermutation Language Modeling</p><p><img src="https://uploader.shimo.im/f/LdaKeEgG8XwH3iNj.png!thumbnail" alt="img"></p><p>Two-Stream Self-Attention</p><p><img src="https://uploader.shimo.im/f/TdQVsxOeYMoakBW0.png!thumbnail" alt="img"></p><p><img src="https://uploader.shimo.im/f/iLMqF1WinQI6wOsW.png!thumbnail" alt="img"></p><p>å‚è€ƒèµ„æ–™</p><p><a href="https://zhuanlan.zhihu.com/p/70257427" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/70257427</a></p><p>ä»£ç </p><p><a href="https://github.com/zihangdai/xlnet" target="_blank" rel="noopener">https://github.com/zihangdai/xlnet</a></p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Transformer-XL </tag>
            
            <tag> XLNet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>è‹±æ–‡ä¹¦ç±wordçº§åˆ«çš„æ–‡æœ¬ç”Ÿæˆä»£ç æ³¨é‡Š</title>
      <link href="/2020/05/12/%E8%8B%B1%E6%96%87%E4%B9%A6%E7%B1%8Dword%E7%BA%A7%E5%88%AB%E7%9A%84%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E4%BB%A3%E7%A0%81%E6%B3%A8%E9%87%8A/"/>
      <url>/2020/05/12/%E8%8B%B1%E6%96%87%E4%B9%A6%E7%B1%8Dword%E7%BA%A7%E5%88%AB%E7%9A%84%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E4%BB%A3%E7%A0%81%E6%B3%A8%E9%87%8A/</url>
      
        <content type="html"><![CDATA[<p><strong>å…ˆçœ‹ä¸˜å‰å°”çš„äººç‰©ä¼ è®°charçº§åˆ«çš„æ–‡æœ¬ç”Ÿæˆ</strong></p><p>ä¸¾ä¸ªå°å°çš„ä¾‹å­ï¼Œæ¥çœ‹çœ‹LSTMæ˜¯æ€ä¹ˆç©çš„</p><p>æˆ‘ä»¬è¿™é‡Œä¸å†ç”¨charçº§åˆ«ï¼Œæˆ‘ä»¬ç”¨wordçº§åˆ«æ¥åšã€‚æˆ‘ä»¬è¿™é‡Œçš„æ–‡æœ¬é¢„æµ‹å°±æ˜¯ï¼Œç»™äº†å‰é¢çš„å•è¯ä»¥åï¼Œä¸‹ä¸€ä¸ªå•è¯æ˜¯è°ï¼Ÿ</p><p>æ¯”å¦‚ï¼Œhello from the other, ç»™å‡º side</p><p>ç¬¬ä¸€æ­¥ï¼Œä¸€æ ·ï¼Œå…ˆå¯¼å…¥å„ç§åº“</p><h3 id="å¯¼å…¥æ•°æ®å¹¶åˆ†è¯"><a href="#å¯¼å…¥æ•°æ®å¹¶åˆ†è¯" class="headerlink" title="å¯¼å…¥æ•°æ®å¹¶åˆ†è¯"></a>å¯¼å…¥æ•°æ®å¹¶åˆ†è¯</h3><p>In [1]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dropout</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> LSTM</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ModelCheckpoint</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> gensim.models.word2vec <span class="keyword">import</span> Word2Vec</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Using TensorFlow backend.</span><br></pre></td></tr></table></figure><p>In [8]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># è¿è¡Œèµ„æºå……è¶³çš„å¯ä»¥è¯•è¯•ä¸‹é¢çš„ä»£ç </span></span><br><span class="line"><span class="comment"># raw_text = ''</span></span><br><span class="line"><span class="comment"># for file in os.listdir("./input/"):</span></span><br><span class="line"><span class="comment">#     # os.listdiråˆ—å‡ºè·¯å¾„ä¸‹çš„æ‰€æœ‰æ–‡ä»¶çš„åå­—</span></span><br><span class="line"><span class="comment">#     if file.endswith(".txt"): # å–å‡ºåç¼€.txtçš„æ–‡ä»¶</span></span><br><span class="line"><span class="comment">#         raw_text += open("./input/"+file, errors='ignore').read() + '\n\n'</span></span><br><span class="line">raw_text = open(<span class="string">'./input/Winston_Churchil.txt'</span>).read()</span><br><span class="line"><span class="comment"># æˆ‘ä»¬ä»ç”¨ä¸˜å‰å°”çš„è¯­æ–™ç”Ÿæˆæ–‡æœ¬</span></span><br><span class="line">raw_text = raw_text.lower()</span><br><span class="line">sentensor = nltk.data.load(<span class="string">'tokenizers/punkt/english.pickle'</span>)   </span><br><span class="line"><span class="comment"># åŠ è½½è‹±æ–‡çš„åˆ’åˆ†å¥å­çš„æ¨¡å‹</span></span><br><span class="line">sents = sentensor.tokenize(raw_text)</span><br><span class="line"><span class="comment"># .tokenizeå¯¹ä¸€æ®µæ–‡æœ¬è¿›è¡Œåˆ†å¥ï¼Œåˆ†æˆå„ä¸ªå¥å­ç»„æˆçš„åˆ—è¡¨ã€‚è¯¦è§£çœ‹ä¸‹è¿™ä¸ªåšå®¢ï¼Œè›®æœ‰æ„æ€çš„</span></span><br><span class="line"><span class="comment"># https://blog.csdn.net/ustbbsy/article/details/80053307</span></span><br><span class="line">print(sents[:<span class="number">2</span>])</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&apos;\ufeffproject gutenbergâ€™s real soldiers of fortune, by richard harding davis\n\nthis ebook is for the use of anyone anywhere at no cost and with\nalmost no restrictions whatsoever.&apos;, &apos;you may copy it, give it away or\nre-use it under the terms of the project gutenberg license included\nwith this ebook or online at www.gutenberg.org\n\n\ntitle: real soldiers of fortune\n\nauthor: richard harding davis\n\nposting date: february 22, 2009 [ebook #3029]\nlast updated: september 26, 2016\n\nlanguage: english\n\ncharacter set encoding: utf-8\n\n*** start of this project gutenberg ebook real soldiers of fortune ***\n\n\n\n\nproduced by david reed, and ronald j. wilson\n\n\n\n\n\nreal soldiers of fortune\n\n\nby richard harding davis\n\n\n\n\n\nmajor-general henry ronald douglas maciver\n\nany sunny afternoon, on fifth avenue, or at night in the _table dâ€™hote_\nrestaurants of university place, you may meet the soldier of fortune who\nof all his brothers in arms now living is the most remarkable.&apos;]</span><br></pre></td></tr></table></figure><p>In [9]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">corpus = []</span><br><span class="line"><span class="keyword">for</span> sen <span class="keyword">in</span> sents: <span class="comment"># é’ˆå¯¹æ¯ä¸ªå¥å­ï¼Œå†æ¬¡è¿›è¡Œåˆ†è¯ã€‚</span></span><br><span class="line">    corpus.append(nltk.word_tokenize(sen))</span><br><span class="line"></span><br><span class="line">print(len(corpus))</span><br><span class="line">print(corpus[:<span class="number">2</span>])</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1792</span><br><span class="line">[[&apos;\ufeffproject&apos;, &apos;gutenberg&apos;, &apos;â€™&apos;, &apos;s&apos;, &apos;real&apos;, &apos;soldiers&apos;, &apos;of&apos;, &apos;fortune&apos;, &apos;,&apos;, &apos;by&apos;, &apos;richard&apos;, &apos;harding&apos;, &apos;davis&apos;, &apos;this&apos;, &apos;ebook&apos;, &apos;is&apos;, &apos;for&apos;, &apos;the&apos;, &apos;use&apos;, &apos;of&apos;, &apos;anyone&apos;, &apos;anywhere&apos;, &apos;at&apos;, &apos;no&apos;, &apos;cost&apos;, &apos;and&apos;, &apos;with&apos;, &apos;almost&apos;, &apos;no&apos;, &apos;restrictions&apos;, &apos;whatsoever&apos;, &apos;.&apos;], [&apos;you&apos;, &apos;may&apos;, &apos;copy&apos;, &apos;it&apos;, &apos;,&apos;, &apos;give&apos;, &apos;it&apos;, &apos;away&apos;, &apos;or&apos;, &apos;re-use&apos;, &apos;it&apos;, &apos;under&apos;, &apos;the&apos;, &apos;terms&apos;, &apos;of&apos;, &apos;the&apos;, &apos;project&apos;, &apos;gutenberg&apos;, &apos;license&apos;, &apos;included&apos;, &apos;with&apos;, &apos;this&apos;, &apos;ebook&apos;, &apos;or&apos;, &apos;online&apos;, &apos;at&apos;, &apos;www.gutenberg.org&apos;, &apos;title&apos;, &apos;:&apos;, &apos;real&apos;, &apos;soldiers&apos;, &apos;of&apos;, &apos;fortune&apos;, &apos;author&apos;, &apos;:&apos;, &apos;richard&apos;, &apos;harding&apos;, &apos;davis&apos;, &apos;posting&apos;, &apos;date&apos;, &apos;:&apos;, &apos;february&apos;, &apos;22&apos;, &apos;,&apos;, &apos;2009&apos;, &apos;[&apos;, &apos;ebook&apos;, &apos;#&apos;, &apos;3029&apos;, &apos;]&apos;, &apos;last&apos;, &apos;updated&apos;, &apos;:&apos;, &apos;september&apos;, &apos;26&apos;, &apos;,&apos;, &apos;2016&apos;, &apos;language&apos;, &apos;:&apos;, &apos;english&apos;, &apos;character&apos;, &apos;set&apos;, &apos;encoding&apos;, &apos;:&apos;, &apos;utf-8&apos;, &apos;***&apos;, &apos;start&apos;, &apos;of&apos;, &apos;this&apos;, &apos;project&apos;, &apos;gutenberg&apos;, &apos;ebook&apos;, &apos;real&apos;, &apos;soldiers&apos;, &apos;of&apos;, &apos;fortune&apos;, &apos;***&apos;, &apos;produced&apos;, &apos;by&apos;, &apos;david&apos;, &apos;reed&apos;, &apos;,&apos;, &apos;and&apos;, &apos;ronald&apos;, &apos;j.&apos;, &apos;wilson&apos;, &apos;real&apos;, &apos;soldiers&apos;, &apos;of&apos;, &apos;fortune&apos;, &apos;by&apos;, &apos;richard&apos;, &apos;harding&apos;, &apos;davis&apos;, &apos;major-general&apos;, &apos;henry&apos;, &apos;ronald&apos;, &apos;douglas&apos;, &apos;maciver&apos;, &apos;any&apos;, &apos;sunny&apos;, &apos;afternoon&apos;, &apos;,&apos;, &apos;on&apos;, &apos;fifth&apos;, &apos;avenue&apos;, &apos;,&apos;, &apos;or&apos;, &apos;at&apos;, &apos;night&apos;, &apos;in&apos;, &apos;the&apos;, &apos;_table&apos;, &apos;d&apos;, &apos;â€™&apos;, &apos;hote_&apos;, &apos;restaurants&apos;, &apos;of&apos;, &apos;university&apos;, &apos;place&apos;, &apos;,&apos;, &apos;you&apos;, &apos;may&apos;, &apos;meet&apos;, &apos;the&apos;, &apos;soldier&apos;, &apos;of&apos;, &apos;fortune&apos;, &apos;who&apos;, &apos;of&apos;, &apos;all&apos;, &apos;his&apos;, &apos;brothers&apos;, &apos;in&apos;, &apos;arms&apos;, &apos;now&apos;, &apos;living&apos;, &apos;is&apos;, &apos;the&apos;, &apos;most&apos;, &apos;remarkable&apos;, &apos;.&apos;]]</span><br></pre></td></tr></table></figure><h1 id="word2vecç”Ÿæˆè¯å‘é‡"><a href="#word2vecç”Ÿæˆè¯å‘é‡" class="headerlink" title="word2vecç”Ÿæˆè¯å‘é‡"></a>word2vecç”Ÿæˆè¯å‘é‡</h1><p>In [45]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">w2v_model = Word2Vec(corpus, size=<span class="number">128</span>, window=<span class="number">5</span>, min_count=<span class="number">2</span>, workers=<span class="number">4</span>)</span><br><span class="line"><span class="comment"># Word2Vec()å‚æ•°çœ‹è¿™ä¸ªåšå®¢ï¼šhttps://www.cnblogs.com/pinard/p/7278324.html</span></span><br><span class="line"><span class="comment"># sizeï¼šè¯å‘é‡çš„ç»´åº¦</span></span><br><span class="line"><span class="comment"># windowï¼šå³è¯å‘é‡ä¸Šä¸‹æ–‡æœ€å¤§è·ç¦»ï¼Œwindowè¶Šå¤§ï¼Œåˆ™å’ŒæŸä¸€è¯è¾ƒè¿œçš„è¯ä¹Ÿä¼šäº§ç”Ÿä¸Šä¸‹æ–‡å…³ç³»ã€‚é»˜è®¤å€¼ä¸º5ã€‚</span></span><br><span class="line"><span class="comment"># min_countï¼šéœ€è¦è®¡ç®—è¯å‘é‡çš„æœ€å°è¯é¢‘ã€‚è¿™ä¸ªå€¼å¯ä»¥å»æ‰ä¸€äº›å¾ˆç”Ÿåƒ»çš„ä½é¢‘è¯ï¼Œé»˜è®¤æ˜¯5ã€‚å¦‚æœæ˜¯å°è¯­æ–™ï¼Œå¯ä»¥è°ƒä½è¿™ä¸ªå€¼ã€‚</span></span><br><span class="line"><span class="comment"># workersï¼šç”¨äºæ§åˆ¶è®­ç»ƒçš„å¹¶è¡Œæ•°ã€‚</span></span><br><span class="line"></span><br><span class="line">print(w2v_model[<span class="string">'office'</span>][:<span class="number">20</span>])</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[-0.03379476 -0.22743131 -0.17660786 -0.00957653 -0.10752155 -0.14298159</span><br><span class="line">  0.02914934 -0.08970737 -0.15872304 -0.05246524 -0.00084796 -0.05634443</span><br><span class="line"> -0.1461402   0.03880814 -0.12331649 -0.06511988 -0.08555544 -0.2300725</span><br><span class="line"> -0.0083805   0.02204316]</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/Users/yyg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).</span><br></pre></td></tr></table></figure><h3 id="æ„é€ è®­ç»ƒé›†"><a href="#æ„é€ è®­ç»ƒé›†" class="headerlink" title="æ„é€ è®­ç»ƒé›†"></a>æ„é€ è®­ç»ƒé›†</h3><p>In [46]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">raw_input = [item <span class="keyword">for</span> sublist <span class="keyword">in</span> corpus <span class="keyword">for</span> item <span class="keyword">in</span> sublist]</span><br><span class="line">print(len(raw_input)) <span class="comment"># åŸå§‹è¯­æ–™åº“é‡Œçš„è¯è¯­æ€»æ•°</span></span><br><span class="line">text_stream = []</span><br><span class="line">vocab = w2v_model.wv.vocab <span class="comment"># æŸ¥çœ‹w2v_modelç”Ÿæˆçš„è¯å‘é‡</span></span><br><span class="line"><span class="keyword">for</span> word <span class="keyword">in</span> raw_input:</span><br><span class="line">    <span class="keyword">if</span> word <span class="keyword">in</span> vocab:</span><br><span class="line">        text_stream.append(word)</span><br><span class="line">print(len(text_stream))  </span><br><span class="line"><span class="comment"># æŸ¥çœ‹å»æ‰ä½é¢‘è¯åçš„æ€»çš„è¯æ•°ï¼Œå› ä¸ºmin_countæŠŠä½é¢‘è¯å»æ‰äº†</span></span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">55562</span><br><span class="line">51876</span><br></pre></td></tr></table></figure><p>In [47]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å¤„ç†æ–¹å¼åŒcharçº§åˆ«çš„æ–‡æœ¬ç”Ÿæˆ</span></span><br><span class="line">seq_length = <span class="number">10</span> </span><br><span class="line">x = []</span><br><span class="line">y = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, len(text_stream) - seq_length):</span><br><span class="line">    given = text_stream[i:i + seq_length]</span><br><span class="line">    predict = text_stream[i + seq_length]</span><br><span class="line">    x.append([w2v_model[word] <span class="keyword">for</span> word <span class="keyword">in</span> given])</span><br><span class="line">    y.append(w2v_model[predict])</span><br><span class="line"></span><br><span class="line">x = np.reshape(x, (<span class="number">-1</span>, seq_length, <span class="number">128</span>))</span><br><span class="line">y = np.reshape(y, (<span class="number">-1</span>,<span class="number">128</span>))</span><br><span class="line">print(x.shape)</span><br><span class="line">print(y.shape)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/Users/yyg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).</span><br><span class="line">  </span><br><span class="line">/Users/yyg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).</span><br><span class="line">  if __name__ == &apos;__main__&apos;:</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(51866, 10, 128)</span><br><span class="line">(51866, 128)</span><br></pre></td></tr></table></figure><h3 id="æ„å»ºå’Œè®­ç»ƒæ¨¡å‹"><a href="#æ„å»ºå’Œè®­ç»ƒæ¨¡å‹" class="headerlink" title="æ„å»ºå’Œè®­ç»ƒæ¨¡å‹"></a>æ„å»ºå’Œè®­ç»ƒæ¨¡å‹</h3><p>In [53]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line">model.add(LSTM(<span class="number">256</span>, input_shape=(seq_length, <span class="number">128</span>),dropout=<span class="number">0.2</span>, recurrent_dropout=<span class="number">0.2</span>))</span><br><span class="line"><span class="comment"># ç¬¬ä¸€ä¸ªdropoutæ˜¯xå’Œhiddenä¹‹é—´çš„dropout</span></span><br><span class="line"><span class="comment"># ç¬¬äºŒä¸ªrecurrent_dropoutï¼Œè¿™é‡Œæˆ‘ç†è§£ä¸ºæ˜¯æ¨ªå‘ä¸åŒæ—¶åˆ»éšè—å±‚ä¹‹é—´çš„dropout</span></span><br><span class="line">model.add(Dropout(<span class="number">0.2</span>)) <span class="comment"># ç¬¬ä¸‰ä¸ªï¼Œè¿™é‡Œæˆ‘ç†è§£ä¸ºçºµå‘å±‚ä¸å±‚ä¹‹é—´çš„dropout</span></span><br><span class="line">model.add(Dense(<span class="number">128</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line">model.compile(loss=<span class="string">'mse'</span>, optimizer=<span class="string">'adam'</span>)</span><br><span class="line"><span class="comment"># æŸå¤±ç”¨çš„å‡æ–¹å·®æŸå¤±ï¼Œä¼˜åŒ–å™¨adam</span></span><br></pre></td></tr></table></figure><p>In [54]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.fit(x, y, nb_epoch=<span class="number">10</span>, batch_size=<span class="number">4096</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/Users/yyg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.</span><br><span class="line">  &quot;&quot;&quot;Entry point for launching an IPython kernel.</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Epoch 1/10</span><br><span class="line">51866/51866 [==============================] - 28s 539us/step - loss: 0.3177</span><br><span class="line">Epoch 2/10</span><br><span class="line">51866/51866 [==============================] - 28s 542us/step - loss: 0.1405</span><br><span class="line">Epoch 3/10</span><br><span class="line">51866/51866 [==============================] - 29s 560us/step - loss: 0.1329</span><br><span class="line">Epoch 4/10</span><br><span class="line">51866/51866 [==============================] - 30s 584us/step - loss: 0.1318</span><br><span class="line">Epoch 5/10</span><br><span class="line">51866/51866 [==============================] - 28s 548us/step - loss: 0.1313</span><br><span class="line">Epoch 6/10</span><br><span class="line">51866/51866 [==============================] - 30s 574us/step - loss: 0.1309</span><br><span class="line">Epoch 7/10</span><br><span class="line">51866/51866 [==============================] - 30s 570us/step - loss: 0.1306</span><br><span class="line">Epoch 8/10</span><br><span class="line">51866/51866 [==============================] - 29s 551us/step - loss: 0.1303</span><br><span class="line">Epoch 9/10</span><br><span class="line">51866/51866 [==============================] - 27s 524us/step - loss: 0.1299</span><br><span class="line">Epoch 10/10</span><br><span class="line">51866/51866 [==============================] - 27s 512us/step - loss: 0.1296</span><br></pre></td></tr></table></figure><p>Out[54]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;keras.callbacks.History at 0x1a32c9a2b0&gt;</span><br></pre></td></tr></table></figure><h3 id="é¢„æµ‹æ¨¡å‹"><a href="#é¢„æµ‹æ¨¡å‹" class="headerlink" title="é¢„æµ‹æ¨¡å‹"></a>é¢„æµ‹æ¨¡å‹</h3><p>In [55]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ä»£ç æ³¨é‡ŠåŒä¸˜å‰å°”çš„äººç‰©ä¼ è®°charçº§åˆ«çš„æ–‡æœ¬ç”Ÿæˆ</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_next</span><span class="params">(input_array)</span>:</span></span><br><span class="line">    x = np.reshape(input_array, (<span class="number">-1</span>,seq_length,<span class="number">128</span>))</span><br><span class="line">    y = model.predict(x)</span><br><span class="line">    <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">string_to_index</span><span class="params">(raw_input)</span>:</span></span><br><span class="line">    raw_input = raw_input.lower()</span><br><span class="line">    input_stream = nltk.word_tokenize(raw_input)</span><br><span class="line">    res = []</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> input_stream[(len(input_stream)-seq_length):]:</span><br><span class="line">        res.append(w2v_model[word])</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">y_to_word</span><span class="params">(y)</span>:</span></span><br><span class="line">    word = w2v_model.most_similar(positive=y, topn=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> word</span><br></pre></td></tr></table></figure><p>In [56]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_article</span><span class="params">(init, rounds=<span class="number">30</span>)</span>:</span></span><br><span class="line">    in_string = init.lower()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(rounds):</span><br><span class="line">        n = y_to_word(predict_next(string_to_index(in_string)))</span><br><span class="line">        in_string += <span class="string">' '</span> + n[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> in_string</span><br></pre></td></tr></table></figure><p>In [58]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">init = <span class="string">'His object in coming to New York was to engage officers for that service. He came at an  moment'</span></span><br><span class="line">article = generate_article(init)</span><br><span class="line">print(article) <span class="comment"># è¯­æ–™åº“è¾ƒå°ï¼Œå¯ä»¥çœ‹åˆ°é‡å¤äº†</span></span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/Users/yyg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).</span><br><span class="line">  if sys.path[0] == &apos;&apos;:</span><br><span class="line">/Users/yyg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).</span><br><span class="line">  app.launch_new_instance()</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">his object in coming to new york was to engage officers for that service. he came at an  moment battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery battery</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LSTM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>æ–‡æœ¬ç”Ÿæˆä»»åŠ¡</title>
      <link href="/2020/05/10/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E4%BB%BB%E5%8A%A1/"/>
      <url>/2020/05/10/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E4%BB%BB%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<p>ä¸»è¦è®¨è®º</p><ul><li><p>æ–‡æœ¬ç”Ÿæˆçš„æ–¹æ³•ï¼š<strong>inference</strong></p></li><li><p>å¢åŠ æ–‡æœ¬ç”Ÿæˆçš„å¤šæ ·æ€§ï¼š<strong>variational auto encoder</strong></p></li><li><p>å¯ä»¥<strong>æ§åˆ¶çš„æ–‡æœ¬ç”Ÿæˆã€æ–‡æœ¬é£æ ¼è¿ç§»</strong></p></li><li><p>Generative Adversarial Networks</p></li><li><p>Data to text</p></li></ul><p>log loss:</p><ul><li><p>[s1, s2, â€¦, s_n] â€“&gt; softmax(s) = exp(s_i) / sum_i exp(s_i)  </p></li><li><p>p_i log q_i</p></li></ul><h1 id="å…³äºæ–‡æœ¬ç”Ÿæˆ"><a href="#å…³äºæ–‡æœ¬ç”Ÿæˆ" class="headerlink" title="å…³äºæ–‡æœ¬ç”Ÿæˆ"></a>å…³äºæ–‡æœ¬ç”Ÿæˆ</h1><p>ä¹‹å‰çš„è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä¸»è¦è®¨è®ºäº†Natural Language Understandingï¼Œä¹Ÿå°±æ˜¯ç»™ä½ ä¸€æ®µæ–‡å­—ï¼Œå¦‚ä½•ä»å„ä¸ªæ–¹é¢å»ç†è§£å®ƒã€‚å¸¸è§çš„NLUä»»åŠ¡æœ‰ï¼šæ–‡æœ¬åˆ†ç±»ï¼Œæƒ…æ„Ÿåˆ†ç±»ï¼Œ<strong>å‘½åå®ä½“è¯†åˆ«ï¼ˆNamed Entity Recognition, NERï¼‰ï¼ŒRelation Extraction</strong>ç­‰ç­‰ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œä»æ–‡å­—ä¸­æå–å‡ºæˆ‘ä»¬æƒ³è¦äº†è§£çš„å…³é”®ä¿¡æ¯ã€‚</p><p>è¿™èŠ‚è¯¾æˆ‘ä»¬æ¥è®¨è®ºæ–‡æœ¬ç”Ÿæˆçš„ä¸€äº›æ–¹æ³•ã€‚</p><p>å¯¹äºæ–‡æœ¬ç”Ÿæˆï¼Œæˆ‘ä»¬å…³å¿ƒå“ªäº›é—®é¢˜ï¼Ÿ</p><ul><li><p>ä¸æ–‡æœ¬ç†è§£ç›¸åï¼Œæˆ‘ä»¬æœ‰ä¸€äº›æƒ³è¦è¡¨è¾¾çš„ä¿¡æ¯ï¼Œè¿™äº›ä¿¡æ¯å¯èƒ½æ¥è‡ªäºå¯¹è¯çš„å†å²ï¼Œå¯èƒ½æ¥è‡ªäºç»“æ„åŒ–çš„æ•°æ® (structured data, data-to-text generation)ã€‚ç°åœ¨æˆ‘ä»¬è¦è€ƒè™‘çš„æ˜¯å¦‚ä½•æŠŠè¿™äº›æˆ‘ä»¬æƒ³è¦è¡¨è¾¾çš„ä¿¡æ¯è½¬æ¢æˆè‡ªç„¶è¯­è¨€çš„æ–¹å¼ã€‚è¿™ä¸€ä»»åŠ¡åœ¨æ„å»ºèŠå¤©æœºå™¨äººä¸­æ˜¾å¾—å°¤ä¸ºé‡è¦ã€‚ç›®å‰çœ‹æ¥ï¼ŒåŸºäº<strong>æ¨¡æ¿ (template)</strong> çš„æ–¹æ³•ä»ç„¶æ˜¯æœ€ä¿é™©çš„ï¼Œä½†æ˜¯åœ¨ç ”ç©¶é¢†åŸŸä¸­ï¼Œäººä»¬è¶Šæ¥è¶Šå…³æ³¨<strong>åŸºäºç¥ç»ç½‘ç»œçš„æ–‡æœ¬ç”Ÿæˆæ–¹æ³•</strong>ã€‚</p></li><li><p>åŸºäºä¸Šæ–‡çš„æ–‡æœ¬è¡¥å…¨ä»»åŠ¡ï¼Œæ•…äº‹ç”Ÿæˆï¼Œç”Ÿæˆå¼èŠå¤©æœºå™¨äºº</p></li><li><p>äººä»¬ä¸€ç›´å¸Œæœ›è®¡ç®—æœºå¯ä»¥å®Œæˆä¸€äº›äººç±»æ‰å¯ä»¥å®Œæˆçš„åˆ›é€ æ€§ä»»åŠ¡ï¼Œä¾‹å¦‚ä½œç”»ã€‚AIä½œç”»å®é™…ä¸Šå·²ç»ä¸æ˜¯ä»€ä¹ˆæ–°é—»äº†ï¼ŒPortrait of Edmond de Belamyï¼Œä¸€å¹…AIåˆ›ä½œçš„ç”»åƒï¼Œæ‹å–å‡ºäº†43.2ä¸‡ç¾é‡‘çš„é«˜ä»·ã€‚</p></li><li><p>é‚£ä¹ˆAIèƒ½ä¸èƒ½å†™æ–‡ç« è®²æ•…äº‹å‘¢ï¼Ÿå…³äºæ–‡æœ¬ç”Ÿæˆçš„ç ”ç©¶ç›¸å¯¹æ¥è¯´æ²¡æœ‰ç‰¹åˆ«å®¢è§‚çš„è¯„ä»·æŒ‡æ ‡ï¼Œæ‰€ä»¥å¾ˆå¤šæ—¶å€™äººä»¬ä¼šæŒ‰ç…§è‡ªå·±çš„ä¸»è§‚è¯„ä»·æ¥åˆ¤æ–­æ¨¡å‹çš„å¥½åã€‚ä¾‹å¦‚ç»™å®šæ•…äº‹çš„ä¸Šæ–‡ï¼ŒAIç³»ç»Ÿèƒ½ä¸èƒ½å¾ˆå¥½åœ°è¡¥å…¨è¿™ä¸ªæ•…äº‹å‘¢ï¼Ÿ</p></li><li><p>æ–‡æœ¬è¡¥å…¨è¿™ä¸ªä»»åŠ¡æœ¬è´¨ä¸Šå°±æ˜¯è®­ç»ƒä¸€ä¸ªè¯­è¨€æ¨¡å‹ï¼Œå½“ç„¶ä¹Ÿæœ‰äººå°è¯•ä½¿ç”¨Seq2Seqçš„æ–¹æ³•åšæ–‡æœ¬ç”Ÿæˆã€‚ç›®å‰çœ‹æ¥æœ€å¼ºçš„æ¨¡å‹æ˜¯åŸºäºGPT-2é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ã€‚å¾ˆå¤šç ”ç©¶è€…ä½¿ç”¨GPT-2æ¥è¿›è¡Œæ–‡æœ¬ç”Ÿæˆç›¸å…³çš„å®éªŒã€‚ç”±äºè®­ç»ƒGPT-2è¿™æ ·è§„æ¨¡çš„è¯­è¨€æ¨¡å‹éœ€è¦å¤§é‡çš„ç®—åŠ›å’Œæ•°æ®èµ„æºï¼Œæ‰€ä»¥å¤§éƒ¨åˆ†çš„ç ”ç©¶éƒ½å…³æ³¨åœ¨å¦‚ä½•ä½¿ç”¨æ¨¡å‹ï¼Œä¹Ÿå°±æ˜¯inferenceçš„æ­¥éª¤ï¼Œè€Œä¸åœ¨äºæ¨¡å‹çš„è®­ç»ƒç¯èŠ‚ã€‚</p></li></ul><h2 id="Greedy-Decoding"><a href="#Greedy-Decoding" class="headerlink" title="Greedy Decoding"></a>Greedy Decoding</h2><p><strong>autoregressive</strong>: åŸºäºä¹‹å‰ç”Ÿæˆçš„æ–‡å­—æ¥ç”Ÿæˆåç»­çš„æ–‡å­—? </p><p>P(y_i | y_1, â€¦ y_{i-1})</p><p>parallel generation</p><p>å¤§éƒ¨åˆ†åŸºäºç¥ç»ç½‘ç»œçš„æ–‡æœ¬ç”Ÿæˆæ¨¡å‹é‡‡ç”¨çš„æ˜¯ä¸€ç§æ¡ä»¶è¯­è¨€æ¨¡å‹çš„æ–¹æ³•ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬æœ‰ä¸€äº›å…ˆå†³æ¡ä»¶ï¼Œä¾‹å¦‚ auto encoder ä¸­çš„éšå‘é‡ï¼Œç„¶åæˆ‘ä»¬åŸºäºè¿™ä¸ªéšå‘é‡æ¥ç”Ÿæˆå¥å­ã€‚</p><p>å¤§éƒ¨åˆ†è¯­è¨€æ¨¡å‹çš„åŸºæœ¬å‡è®¾æ˜¯ä»å·¦å¾€å³çš„æ¡ä»¶æ¦‚ç‡æ¨¡å‹ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œç»™å®šäº†å•è¯1è‡³n-1ï¼Œæˆ‘ä»¬å¸Œæœ›ç”Ÿæˆç¬¬nä¸ªå•è¯ã€‚å‡è®¾æˆ‘ä»¬ç°åœ¨é‡‡ç”¨ä¸€ä¸ªåŸºäºLSTMçš„è¯­è¨€æ¨¡å‹ï¼Œåœ¨å½“å‰ç¬¬iä¸ªä½ç½®ä¸Šï¼Œæˆ‘ä»¬é¢„æµ‹ä¸‹ä¸€ä¸ªç”Ÿæˆå•è¯çš„æ¦‚ç‡åˆ†å¸ƒä¸º p = (p_1, <strong>p_2</strong>, â€¦ p_|V|)ï¼Œé‚£ä¹ˆåœ¨å½“å‰ä½ç½®ä¸Šæˆ‘ä»¬åº”è¯¥ç”Ÿæˆä»€ä¹ˆå•è¯å‘¢ï¼Ÿ</p><p>argmax_i p_i = 2</p><p>ä¸€ä¸ªæœ€ç®€å•çš„æ–¹æ³•æ˜¯ä½¿ç”¨Greedy Decodingï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬ç›´æ¥é‡‡ç”¨ argmax_i (p_i) å³å¯ã€‚å½“ç„¶ï¼ŒåŒå­¦ä»¬å¾ˆå®¹æ˜“è”æƒ³åˆ°ï¼Œè¿™ç§decodingçš„æ–¹æ³•æ˜¯æœ‰é—®é¢˜çš„ï¼Œå› ä¸ºæ¯æ¬¡éƒ½é€‰æ‹©æœ€å¤§æ¦‚ç‡çš„å•è¯å¹¶ä¸èƒ½ä¿è¯æˆ‘ä»¬ç”Ÿæˆå‡ºæ¥çš„å¥å­çš„æ€»ä½“æ¦‚ç‡åˆ†å¸ƒæ˜¯æœ€å¤§çš„ã€‚äº‹å®ä¸Šï¼Œå¤§éƒ¨åˆ†æ—¶å€™è¿™æ ·ç”Ÿæˆçš„å¥å­å…¶å®æ˜¯ä¸å¥½çš„ã€‚ç„¶è€Œæˆ‘ä»¬æ²¡æœ‰åŠæ³•éå†æ‰€æœ‰å¯èƒ½çš„å¥å­ï¼šé¦–å…ˆå¥å­çš„é•¿åº¦æ˜¯ä¸ç¡®å®šçš„ï¼›å³ä½¿æˆ‘ä»¬å‡å®šè‡ªå·±çŸ¥é“å¥å­çš„é•¿åº¦ lï¼Œå¦‚æœåœ¨æ¯ä¸ªä½ç½®ä¸Šè€ƒè™‘æ¯ä¸ªå¯èƒ½çš„å•è¯ï¼Œæˆ‘ä»¬éœ€è¦è€ƒè™‘ |V|^l ç§å¯èƒ½çš„æƒ…å†µï¼Œåœ¨è®¡ç®—èµ„æºä¸Šä¹Ÿæ˜¯ä¸ç°å®çš„ã€‚</p><p>ä¸€ç§å¦¥åçš„æ–¹æ³•æ˜¯é‡‡ç”¨ <strong>Beam Search</strong> ï¼ˆ<a href="https://shimo.im/docs/rHwdq8wd8txyXjP6ï¼‰ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨decodingçš„æ¯ä¸ªæ­¥éª¤ï¼Œæˆ‘ä»¬éƒ½ä¿ç•™ç€" target="_blank" rel="noopener">https://shimo.im/docs/rHwdq8wd8txyXjP6ï¼‰ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨decodingçš„æ¯ä¸ªæ­¥éª¤ï¼Œæˆ‘ä»¬éƒ½ä¿ç•™ç€</a> <strong>top K</strong> ä¸ªå¯èƒ½çš„å€™é€‰å•è¯ï¼Œç„¶ååˆ°äº†ä¸‹ä¸€ä¸ªæ­¥éª¤çš„æ—¶å€™ï¼Œæˆ‘ä»¬å¯¹è¿™ K ä¸ªå•è¯éƒ½åšä¸‹ä¸€æ­¥ decodingï¼Œåˆ†åˆ«é€‰å‡º top Kï¼Œç„¶åå¯¹è¿™ K^2 ä¸ªå€™é€‰å¥å­å†æŒ‘é€‰å‡º <strong>top K ä¸ªå¥å­</strong>ã€‚ä»¥æ­¤ç±»æ¨ä¸€ç›´åˆ° decoding ç»“æŸä¸ºæ­¢ã€‚å½“ç„¶ Beam Search æœ¬è´¨ä¸Šä¹Ÿæ˜¯ä¸€ä¸ª greedy decoding çš„æ–¹æ³•ï¼Œæ‰€ä»¥æˆ‘ä»¬æ— æ³•ä¿è¯è‡ªå·±ä¸€å®šå¯ä»¥å¾—åˆ°æœ€å¥½çš„ decoding ç»“æœã€‚</p><p>p(x_1, x_2, â€¦, x_n) = log (p(x_1) * p(x_2 | x_1) â€¦ p(x_n | x_1, â€¦, x_{n-1})) / n</p><p><strong>Greedy Decoding</strong>çš„é—®é¢˜</p><ul><li><p>å®¹æ˜“å‡ºç°å¾ˆæ— èŠçš„å›ç­”ï¼šI donâ€™t know. </p></li><li><p>å®¹æ˜“é‡å¤è‡ªå·±ï¼šI donâ€™t know. I donâ€™t know. I donâ€™t know. I donâ€™t know. I donâ€™t know. I donâ€™t know. </p></li><li><p>Beam search K = 200</p></li></ul><h2 id="Sampling"><a href="#Sampling" class="headerlink" title="Sampling"></a>Sampling</h2><p>argmax ä¸ä¸€å®šæ˜¯æœ€å¥½çš„</p><p>vocab(y_i) = [<strong>0.9</strong>, 0.05, 0.01, 0.01, 0.01, â€¦., 0.01]  softmax(logits/temperature)</p><p>sample(vocab(y_i))</p><p>sampleå¾ˆå¤šä¸ªå¥å­ï¼Œç„¶åç”¨å¦ä¸€ä¸ªæ¨¡å‹æ¥æ‰“åˆ†ï¼Œæ‰¾å‡ºæœ€ä½³generated text</p><p>sampling over the full vocabularyï¼šæˆ‘ä»¬å¯ä»¥åœ¨ç”Ÿæˆæ–‡æœ¬çš„æ—¶å€™å¼•å…¥ä¸€äº›éšæœºæ€§ã€‚ä¾‹å¦‚ç°åœ¨è¯­è¨€æ¨¡å‹å‘Šè¯‰æˆ‘ä»¬ä¸‹ä¸€ä¸ªå•è¯åœ¨æ•´ä¸ªå•è¯è¡¨ä¸Šçš„æ¦‚ç‡åˆ†å¸ƒæ˜¯ p = (p_1, p_2, â€¦ p_|V|)ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±å¯ä»¥æŒ‰ç…§è¿™ä¸ªæ¦‚ç‡åˆ†å¸ƒè¿›è¡Œéšæœºé‡‡æ ·ï¼Œç„¶åå†³å®šä¸‹ä¸€ä¸ªå•è¯ç”Ÿæˆä»€ä¹ˆã€‚é‡‡æ ·ç›¸å¯¹äºgreedyæ–¹æ³•çš„å¥½å¤„æ˜¯ï¼Œæˆ‘ä»¬ç”Ÿæˆçš„æ–‡å­—å¼€å§‹æœ‰äº†ä¸€äº›éšæœºæ€§ï¼Œä¸ä¼šæ€»æ˜¯ç”Ÿæˆå¾ˆæœºæ¢°çš„å›å¤äº†ã€‚</p><p>1 - 0.98^n</p><p>Samplingçš„é—®é¢˜</p><ul><li><p>ç”Ÿæˆçš„è¯å®¹æ˜“ä¸è¿è´¯ï¼Œä¸Šä¸‹æ–‡æ¯”è¾ƒçŸ›ç›¾ã€‚</p></li><li><p>å®¹æ˜“ç”Ÿæˆå¥‡æ€ªçš„è¯ï¼Œå‡ºç°<strong>ç½•è§è¯</strong>ã€‚</p></li></ul><p>top-k sampling å¯ä»¥ç¼“è§£ç”Ÿæˆç½•è§å•è¯çš„é—®é¢˜ã€‚æ¯”å¦‚è¯´ï¼Œæˆ‘ä»¬å¯ä»¥æ¯æ¬¡åªåœ¨æ¦‚ç‡æœ€é«˜çš„50ä¸ªå•è¯ä¸­æŒ‰ç…§æ¦‚ç‡åˆ†å¸ƒåšé‡‡æ ·ã€‚</p><p>æˆ‘åªä¿ç•™top-kä¸ªprobabilityçš„å•è¯ï¼Œç„¶ååœ¨è¿™äº›å•è¯ä¸­æ ¹æ®æ¦‚ç‡åšsampling</p><h2 id="Neucleus-Sampling"><a href="#Neucleus-Sampling" class="headerlink" title="Neucleus Sampling"></a>Neucleus Sampling</h2><h3 id="The-Curious-Case-of-Neural-Text-Degeneration"><a href="#The-Curious-Case-of-Neural-Text-Degeneration" class="headerlink" title="The Curious Case of Neural Text Degeneration"></a>The Curious Case of Neural Text Degeneration</h3><p><a href="https://arxiv.org/pdf/1904.09751.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1904.09751.pdf</a></p><p><img src="https://uploader.shimo.im/f/8IjYXmjBFmAwnJy3.png!thumbnail" alt="img"></p><p>è¿™ç¯‡æ–‡ç« åœ¨å‰äº›æ—¥å­å¼•èµ·äº†ä¸å°çš„å…³æ³¨ã€‚æ–‡ç« æå‡ºäº†ä¸€ç§åšsamplingçš„æ–¹æ³•ï¼Œå«åš Neucleus Samplingã€‚</p><p>Neucleus Samplingçš„åŸºæœ¬æ€æƒ³æ˜¯ï¼Œæˆ‘ä»¬ä¸åšbeam searchï¼Œè€Œæ˜¯åštop p samplingã€‚</p><p>è®¾ç½®ä¸€ä¸ªthresholdï¼Œp=0.95</p><p>top-k sampling å’Œ neucleus sampling çš„ä»£ç ï¼š<a href="https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317" target="_blank" rel="noopener">https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317</a></p><h1 id="Variational-Auto-Encoder-VAE"><a href="#Variational-Auto-Encoder-VAE" class="headerlink" title="Variational Auto Encoder (VAE)"></a>Variational Auto Encoder (VAE)</h1><h2 id="Auto-Encoder-è‡ªç¼–ç å™¨"><a href="#Auto-Encoder-è‡ªç¼–ç å™¨" class="headerlink" title="Auto Encoder è‡ªç¼–ç å™¨"></a>Auto Encoder è‡ªç¼–ç å™¨</h2><p>NLPä¸­çš„ä¸€ä¸ªé‡è¦é—®é¢˜æ˜¯è·å¾—ä¸€ç§è¯­è¨€çš„è¡¨ç¤ºï¼Œæ— è®ºæ˜¯å•è¯çš„è¡¨ç¤ºè¿˜æ˜¯å¥å­çš„è¡¨ç¤ºã€‚ä¸ºäº†è·å¾—å¥å­çš„è¡¨ç¤ºï¼Œä¸€ç§ç›´è§‚çš„æ€è·¯æ˜¯è®­ç»ƒä¸€ä¸ªauto encoderï¼Œä¹Ÿå°±æ˜¯è¯´ä¸€ä¸ªencoderç”¨æ¥ç¼–ç ä¸€ä¸ªå¥å­ï¼ŒæŠŠä¸€ä¸ªå¥å­è½¬æ¢æˆä¸€ä¸ªvectorï¼›å¦ä¸€ä¸ªdecoderç”¨æ¥è§£ç ä¸€ä¸ªå¥å­ï¼Œä¹Ÿå°±æ˜¯è¯´æŠŠä¸€ä¸ªvectorè§£ç æˆä¸€ä¸ªå¥å­ã€‚auto encoder äº‹å®ä¸Šæ˜¯ä¸€ç§æ•°æ®å‹ç¼©çš„æ–¹æ³•ã€‚</p><p>Encoder(text) â€“&gt; vector</p><p>Decoder(vector) â€“&gt; text</p><p>Encoderï¼šå¾—åˆ°å¾ˆå¥½çš„æ–‡æœ¬è¡¨ç¤ºï¼Œè¿™ä¸ªæ–‡æœ¬è¡¨ç¤ºä½ å¯ç”¨ç”¨äºä»»ä½•å…¶ä»–çš„ä»»åŠ¡ã€‚</p><p>Decoder: conditional language model</p><p>generalizeèƒ½åŠ›ä¸ä¸€å®šå¥½ã€‚è¿‡æ‹Ÿåˆã€‚</p><p>é¢„æœŸï¼šå¸Œæœ›ç±»ä¼¼çš„å¥å­ï¼Œèƒ½å¤Ÿå˜æˆæ¯”è¾ƒç›¸è¿‘çš„vectorã€‚ä¸ç±»ä¼¼çš„å¥å­ï¼Œèƒ½å¤Ÿè·ç¦»æ¯”è¾ƒè¿œã€‚</p><p>Decoder(0,200,-23, 122) â€“&gt; text?</p><p>æˆ‘çˆ±[MASK]ç„¶è¯­[MASK]å¤„ç† â€“&gt; vector â€“&gt; æˆ‘çˆ±è‡ªç„¶è¯­è¨€å¤„ç†</p><p>åœ¨ auto encoder çš„åŸºç¡€ä¸Šåˆè¡ç”Ÿå‡ºäº†å„ç§ç±»å‹çš„ auto encoderï¼Œä¾‹å¦‚ <strong>denoising</strong> auto encoder ï¼ˆ<a href="https://www.cs.toronto.edu/~larocheh/publications/icml-2008-denoising-autoencoders.pdfï¼‰ã€‚denoising" target="_blank" rel="noopener">https://www.cs.toronto.edu/~larocheh/publications/icml-2008-denoising-autoencoders.pdfï¼‰ã€‚denoising</a> auto encoder çš„åŸºæœ¬æ€æƒ³æ˜¯è¦åŠ å¼º auto encoder çš„ robustnessã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬å¸Œæœ›æŠŠè¾“å…¥å¥å­çš„ä¸€éƒ¨åˆ†ç»™â€œæ±¡æŸ“â€ (corrupt) äº†ï¼Œä½†æ˜¯æˆ‘ä»¬å¸Œæœ›åœ¨ç»è¿‡ç¼–ç å’Œè§£ç çš„è¿‡ç¨‹ä¹‹åï¼Œæˆ‘ä»¬èƒ½å¤Ÿå¾—åˆ°åŸæ¥çš„æ­£ç¡®çš„å¥å­ã€‚äº‹å®ä¸Š BERT çš„ masking å°±æ˜¯ä¸€ç§â€œæ±¡æŸ“â€çš„æ‰‹æ®µã€‚</p><p>Encoder(corrupt(text)) â€“&gt; vector</p><p>Decoder(vector) â€“&gt; text</p><p>éšæœºäº§ç”Ÿä¸€ä¸ªvector â€“&gt; decoder â€“&gt; ç”Ÿæˆä¸€ä¸ªå¥å­</p><p>mapping </p><p>N(0, 1) â€“&gt; å„ç§å„æ ·çš„æ–‡å­—</p><p>ä»ä¸€ä¸ªåˆ†å¸ƒå»ç”Ÿæˆä¸€äº›ä¸œè¥¿</p><p>ä¸ºäº†è®­ç»ƒå‡ºå¯ä»¥ç”¨æ¥sampleæ–‡å­—çš„æ¨¡å‹ï¼Œäººä»¬å‘æ˜äº†variational auto encoder (VAE)ã€‚VAEä¸æ™®é€šauto encoderçš„ä¸åŒä¹‹å¤„åœ¨äºï¼Œæˆ‘ä»¬æ·»åŠ äº†ä¸€ä¸ªconstraintï¼Œå¸Œæœ›encoderç¼–ç çš„æ¯ä¸ªå¥å­éƒ½èƒ½å¤Ÿå±€é™åœ¨æŸäº›ç‰¹å®šçš„ä½ç½®ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥è¦æ±‚æ¯ä¸ªå¥å­çš„encodingåœ¨ç©ºé—´ä¸Šæ»¡è¶³ä¸€ä¸ªå¤šç»´æ ‡å‡†é«˜æ–¯åˆ†å¸ƒã€‚</p><p><strong>vector ~ N(0, 1)</strong></p><h2 id="ä»€ä¹ˆæ˜¯VAEï¼Ÿ"><a href="#ä»€ä¹ˆæ˜¯VAEï¼Ÿ" class="headerlink" title="ä»€ä¹ˆæ˜¯VAEï¼Ÿ"></a>ä»€ä¹ˆæ˜¯VAEï¼Ÿ</h2><p>ç½‘ä¸Šæœ‰å¾ˆå¤šVAEçš„è®ºæ–‡ï¼Œåšå®¢ï¼Œå»ºè®®æ„Ÿå…´è¶£çš„åŒå­¦å¯ä»¥é€‰æ‹©æ€§é˜…è¯»ã€‚æˆ‘ä»¬è¿™èŠ‚è¯¾ä¸ä¼šè®¨è®ºå¤ªå¤šçš„æ•°å­¦å…¬å¼ï¼Œè€Œæ˜¯ä»æ¯”è¾ƒhigh levelçš„å±‚é¢ä»‹ç»ä¸€ä¸‹VAEæ¨¡å‹ä»¥åŠå®ƒæ‰€è§£å†³çš„ä¸€äº›é—®é¢˜ã€‚</p><p>ç®€å•æ¥è¯´ï¼ŒVAEæœ¬è´¨ä¸Šæ˜¯ä¸€ç§ç”Ÿæˆæ¨¡å‹ï¼Œæˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿé€šè¿‡éšå‘é‡zç”Ÿæˆæ•°æ®æ ·æœ¬xã€‚åœ¨æ–‡æœ¬ç”Ÿæˆçš„é—®é¢˜ä¸­ï¼Œè¿™ä¸ªxå¾€å¾€è¡¨ç¤ºçš„æ˜¯ä¸€äº›æ–‡æœ¬/å¥å­ç­‰å†…å®¹ã€‚</p><p><img src="https://uploader.shimo.im/f/OoUmk9RItWAALQ69.png!thumbnail" alt="img"></p><p>ä¸‹é¢æ˜¯ Kingma åœ¨ <strong>VAE</strong> è®ºæ–‡ä¸­å®šä¹‰çš„ä¼˜åŒ–ç›®æ ‡ã€‚</p><p>æ–‡æœ¬â€“&gt; å‘é‡è¡¨ç¤º â€“&gt; æ–‡æœ¬</p><p>auto encoder: sentence â€“&gt; vector â€“&gt; sentence</p><p>Loss = -log P_{sentence}(dec(enc(sentence)))</p><p><img src="https://uploader.shimo.im/f/1HQEntdhGB8sSbbd.png!thumbnail" alt="img"></p><p>z -&gt; zâ€™ -&gt; decoder(z) â€“&gt; ä¸€ä¸ªå¥å­</p><p><strong>crossentropyloss(decoder(encoder(x)), x)</strong></p><p><strong>æˆ‘ä»¬å¯¹zæ²¡æœ‰ä»»ä½•çš„çº¦æŸæ¡ä»¶</strong></p><p>q: encoder</p><p>p: decoder</p><p>KL divergence: è®¡ç®—ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒçš„å·®å€¼</p><p>z: æŠŠå¥å­å˜æˆä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒ</p><p>z: (\mu, \sigma) â€“&gt; æ­£æ€åˆ†å¸ƒçš„å‚æ•°</p><p>ç”¨zåšé‡‡æ ·</p><p>KL Divergenceçš„å®šä¹‰</p><p><img src="https://uploader.shimo.im/f/YQtU3e2EeBc0e4VH.png!thumbnail" alt="img"></p><p>sampling</p><p>N(0,1): sampling: 0.1, 0.05, 0.2, -0.1, -100</p><p>æˆ‘ä»¬å¯ä»¥å‘ç°ï¼ŒVAEæ¨¡å‹æœ¬è´¨ä¸Šå°±æ˜¯è¦æœ€å¤§åŒ–æ ·æœ¬çš„ç”Ÿæˆæ¦‚ç‡ï¼Œå¹¶ä¸”æœ€å°åŒ–æ ·æœ¬encodeä¹‹åçš„å‚æ•°è¡¨ç¤ºä¸æŸç§åˆ†å¸ƒ(æ­£æ€åˆ†å¸ƒ)çš„KLæ•£åº¦ã€‚ä¹‹æ‰€ä»¥æˆ‘ä»¬ä¼šé™åˆ¶æ•°æ®è¢«ç¼–ç åçš„å‘é‡æœä»æŸä¸ªå±€éƒ¨çš„æ­£æ€åˆ†å¸ƒï¼Œæ˜¯å› ä¸ºæˆ‘ä»¬ä¸å¸Œæœ›è¿™äº›æ•°æ®è¢«ç¼–ç ä¹‹åæ‚ä¹±åœ°æ•£å¸ƒåœ¨ä¸€ä¸ªç©ºé—´ä¸Šï¼Œè€Œæ˜¯å¸Œæœ›ä¿¡æ¯èƒ½å¤Ÿå¾—åˆ°ä¸€å®šç¨‹åº¦ä¸Šçš„å‹ç¼©ã€‚ä¹‹æ‰€ä»¥è®©ä»–ä»¬æœä»ä¸€ä¸ªåˆ†å¸ƒè€Œä¸æ˜¯ä¸€äº›å›ºå®šçš„å€¼ï¼Œæ˜¯å› ä¸ºæˆ‘ä»¬å¸Œæœ›æ¨¡å‹ä¸­èƒ½å¤Ÿæœ‰ä¸€äº›éšæœºæ€§ï¼Œå¥½è®©æ¨¡å‹çš„è§£ç å™¨èƒ½å¤Ÿç”Ÿæˆå„ç§å„æ ·çš„å¥å­ã€‚</p><p>æœ‰äº†è¿™ä¸ªVAEæ¨¡å‹çš„æ¶æ„ä¹‹åï¼Œäººä»¬å°±å¯ä»¥åœ¨å„ç§ä»»åŠ¡ä¸Šç©å‡ºå„ç§ä¸åŒçš„èŠ±æ ·äº†ã€‚</p><p>ä¾‹å¦‚å¯¹äºå›¾åƒæ¥è¯´ï¼Œè¿™é‡Œçš„<img src="https://uploader.shimo.im/f/FSNiIgsmVLc0HyUH.png!thumbnail" alt="img">å’Œ<img src="https://uploader.shimo.im/f/XpeVKp5c144d4RWl.png!thumbnail" alt="img">å¯èƒ½æ˜¯CNNæ¨¡å‹ï¼Œå¯¹äºè‡ªç„¶è¯­è¨€æ¥è¯´ï¼Œå®ƒä»¬å¯èƒ½æ˜¯ä¸€äº›RNN/LSTMä¹‹ç±»çš„æ¨¡å‹ã€‚</p><p>ä¸‹é¢æˆ‘ä»¬æ¥çœ‹ä¸€äº›VAEåœ¨NLPé¢†åŸŸçš„å…·ä½“æ¨¡å‹ã€‚</p><h3 id="Generating-Sentences-from-a-Continuous-Space"><a href="#Generating-Sentences-from-a-Continuous-Space" class="headerlink" title="Generating Sentences from a Continuous Space"></a>Generating Sentences from a Continuous Space</h3><p><a href="https://arxiv.org/pdf/1511.06349.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1511.06349.pdf</a></p><p><img src="https://uploader.shimo.im/f/LeCZ7dpW9JcvYC6T.png!thumbnail" alt="img"></p><p><img src="https://uploader.shimo.im/f/qAE9oBPi2Lg7LJro.png!thumbnail" alt="img"></p><p>ä»ä¸Šå›¾å¯ä»¥çœ‹åˆ°ï¼Œè¿™ç¯‡è®ºæ–‡çš„æ€è·¯éå¸¸ç®€å•ï¼Œå°±æ˜¯æŠŠä¸€ä¸ªå¥å­ç”¨RNNç¼–ç èµ·æ¥ï¼Œç¼–ç ä¹‹åå¾—åˆ°çš„éšå‘é‡è¾“å‡ºä¸¤ä¸ªä¿¡æ¯\muå’Œ\simgaï¼Œåˆ†åˆ«è¡¨ç¤ºä¸€ä¸ªæ­£å¤ªåˆ†å¸ƒçš„å¹³å‡å€¼å’Œæ ‡å‡†å·®ã€‚ç„¶åè¿™ä¸ªåˆ†å¸ƒåº”è¯¥å°½å¯èƒ½åœ°æ¥è¿‘æ ‡å‡†æ­£æ€åˆ†å¸ƒï¼Œåœ¨KLæ•£åº¦çš„è¡¨ç¤ºä¸‹ã€‚å¹¶ä¸”å¦‚æœæˆ‘ä»¬ç”¨è¿™ä¸ªåˆ†å¸ƒå»é‡‡æ ·å¾—åˆ°æ–°çš„å‘é‡è¡¨ç¤ºï¼Œé‚£ä¹ˆdecoderåº”è¯¥è¦å°½å¯èƒ½å¥½åœ°å¤åŸæˆ‘ä»¬åŸæ¥çš„è¿™ä¸ªå¥å­ã€‚</p><p>å…·ä½“çš„å®éªŒç»†èŠ‚æˆ‘ä»¬å°±ä¸å±•å¼€äº†ï¼Œä½†æ˜¯æˆ‘ä»¬çœ‹ä¸€äº›è®ºæ–‡ä¸­å±•ç¤ºçš„ç”Ÿæˆçš„å¥å­ã€‚</p><p><img src="https://uploader.shimo.im/f/WTJqo8usWYYxMR8k.png!thumbnail" alt="img"></p><p>ä¸‹é¢çœ‹çœ‹VAEå½“ä¸­ç¼–ç çš„ç©ºé—´æ˜¯å¦å…·æœ‰æŸç§è¿ç»­æ€§ã€‚</p><p><img src="https://uploader.shimo.im/f/uLmDTf81yPUZJbae.png!thumbnail" alt="img"></p><p>ä»£ç é˜…è¯»ï¼š</p><ul><li><p><a href="https://github.com/timbmg/Sentence-VAE/blob/master/model.py" target="_blank" rel="noopener">https://github.com/timbmg/Sentence-VAE/blob/master/model.py</a></p></li><li><p><strong>ç»ƒä¹ </strong>ï¼šè¿™ä»½ä»£ç å·²ç»ä¸€å¹´å¤šæ²¡æœ‰æ›´æ–°äº†ï¼Œæ„Ÿå…´è¶£çš„åŒå­¦å¯ä»¥æŠŠå®ƒæ›´æ–°åˆ°æœ€æ–°ç‰ˆæœ¬çš„PyTorchä¸Šï¼Œä½œä¸ºå†™ä»£ç ç»ƒä¹ ï¼Œå¹¶ä¸”åœ¨è‡ªå·±çš„æ•°æ®é›†ä¸Šåšä¸€äº›å®éªŒï¼Œçœ‹çœ‹èƒ½å¦å¾—åˆ°ä¸è®ºæ–‡ä¸­ç±»ä¼¼çš„æ•ˆæœï¼ˆsentence interpolationï¼‰ã€‚</p></li></ul><p>GAN: generative adversarial networks</p><ul><li><p>generator: G(z) â€“&gt; x ä¸€å¼ é€¼çœŸçš„æ±½è½¦ç…§ç‰‡</p></li><li><p>discriminator: D(x) â€“&gt; è¿™ä¸ªåˆ°åº•æ˜¯ä¸æ˜¯ä¸€å¼ æ±½è½¦çš„ç…§ç‰‡ äºŒåˆ†ç±»</p></li></ul><p>Discriminatorçš„ç›®æ ‡</p><p>D(G(z)) â€“&gt; False</p><p>D(true photo) â€“&gt; True</p><p>Generator çš„ç›®æ ‡ D(G(z)) â€“&gt; True</p><h2 id="å¯æ§åˆ¶çš„æ–‡æœ¬ç”Ÿæˆ"><a href="#å¯æ§åˆ¶çš„æ–‡æœ¬ç”Ÿæˆ" class="headerlink" title="å¯æ§åˆ¶çš„æ–‡æœ¬ç”Ÿæˆ"></a>å¯æ§åˆ¶çš„æ–‡æœ¬ç”Ÿæˆ</h2><h3 id="Toward-Controlled-Generation-of-Text"><a href="#Toward-Controlled-Generation-of-Text" class="headerlink" title="Toward Controlled Generation of Text"></a>Toward Controlled Generation of Text</h3><p><a href="https://arxiv.org/pdf/1703.00955.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1703.00955.pdf</a></p><ul><li><p>Controlled Text Generation: æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„ä¸€äº›ç‰¹å¾</p></li><li><p>Learning disentangled latent representations: å¯¹äºæ–‡æœ¬ä¸åŒçš„ç‰¹å¾æœ‰ä¸åŒçš„å‘é‡è¡¨ç¤º</p></li></ul><p>æ¨¡å‹</p><p><img src="https://uploader.shimo.im/f/NejrcnoWDRgz7k58.png!thumbnail" alt="img"></p><p>To model and control the attributes of interest in an interpretable way, we augment the unstructured variables z with a set of structured variables c each of which targets a salient and independent semantic feature of sentences.</p><p>è¿™ç¯‡æ–‡ç« è¯•å›¾è§£å†³è¿™æ ·ä¸€ä¸ªé—®é¢˜ï¼Œèƒ½ä¸èƒ½æŠŠä¸€å¥è¯ç¼–ç æˆå‡ ä¸ªå‘é‡(zå’Œc)ã€‚zå’Œcåˆ†åˆ«åŒ…å«äº†ä¸€äº›ä¸åŒçš„å…³äºå¥å­çš„ä¿¡æ¯ã€‚</p><p><img src="https://uploader.shimo.im/f/LWIaBAzxmwkLY0pj.png!thumbnail" alt="img"></p><p>æ¨¡å‹åŒ…å«å‡ ä¸ªéƒ¨åˆ†ï¼Œä¸€ä¸ªgeneratorå¯ä»¥åŸºäºè‹¥å¹²ä¸ªå‘é‡(zå’Œc)ç”Ÿæˆå¥å­ï¼Œå‡ ä¸ªencoderå¯ä»¥ä»å¥å­ç”Ÿæˆzå’Œcçš„åˆ†å¸ƒï¼Œå‡ ä¸ªdiscriminatorç”¨æ¥åˆ¤æ–­æ¨¡å‹ç¼–ç å‡ºçš„å‘é‡(c)æ˜¯å¦ç¬¦åˆexampleçš„æ­£ç¡®åˆ†ç±»ã€‚è¿™ä¸ªæ¨¡å‹çš„å¥½å¤„æ˜¯ï¼Œæˆ‘ä»¬åœ¨æŸç§ç¨‹åº¦ä¸Šåˆ†ç¦»äº†å¥å­çš„ä¿¡æ¯ã€‚ä¾‹å¦‚å¦‚æœå‘é‡cç”¨æ¥è¡¨ç¤ºçš„æ˜¯å¥å­çš„æƒ…æ„Ÿæ­£è´Ÿï¼Œé‚£ä¹ˆæ¨¡å‹å°±å…·å¤‡äº†ç”Ÿæˆæ­£é¢æƒ…æ„Ÿçš„å¥å­å’Œè´Ÿé¢æƒ…æ„Ÿå¥å­çš„èƒ½åŠ›ã€‚</p><p><img src="https://uploader.shimo.im/f/IGw674vLSf4tiqHe.png!thumbnail" alt="img"></p><p>å‚è€ƒä»£ç </p><p><a href="https://github.com/wiseodd/controlled-text-generation" target="_blank" rel="noopener">https://github.com/wiseodd/controlled-text-generation</a></p><p>æ›´å¤šé˜…è¯»</p><p>VAEè®ºæ–‡ï¼šAuto-Encoding Variational Bayes <a href="https://arxiv.org/pdf/1312.6114.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1312.6114.pdf</a></p><p>An Introduction to Variational Autoencoders <a href="https://arxiv.org/pdf/1906.02691.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1906.02691.pdf</a></p><p>Stype Transfer</p><p>æ–‡æœ¬ â€“&gt; å†…å®¹zï¼Œé£æ ¼c</p><p>z, æ¢ä¸€ä¸ªé£æ ¼câ€™ â€“&gt; åŒæ ·å†…å®¹ï¼Œä¸åŒé£æ ¼çš„æ–‡æœ¬</p><h1 id="æ–‡æœ¬ç”Ÿæˆçš„åº”ç”¨ï¼šæ–‡æœ¬é£æ ¼è¿ç§»"><a href="#æ–‡æœ¬ç”Ÿæˆçš„åº”ç”¨ï¼šæ–‡æœ¬é£æ ¼è¿ç§»" class="headerlink" title="æ–‡æœ¬ç”Ÿæˆçš„åº”ç”¨ï¼šæ–‡æœ¬é£æ ¼è¿ç§»"></a>æ–‡æœ¬ç”Ÿæˆçš„åº”ç”¨ï¼šæ–‡æœ¬é£æ ¼è¿ç§»</h1><h3 id="Style-Transfer-from-Non-Parallel-Text-by-Cross-Alignment"><a href="#Style-Transfer-from-Non-Parallel-Text-by-Cross-Alignment" class="headerlink" title="Style Transfer from Non-Parallel Text by Cross-Alignment"></a>Style Transfer from Non-Parallel Text by Cross-Alignment</h3><p>è®ºæ–‡ï¼š<a href="https://papers.nips.cc/paper/7259-style-transfer-from-non-parallel-text-by-cross-alignment.pdf" target="_blank" rel="noopener">https://papers.nips.cc/paper/7259-style-transfer-from-non-parallel-text-by-cross-alignment.pdf</a></p><p>ä»£ç ï¼š<a href="https://github.com/shentianxiao/language-style-transfer/blob/master/code/style_transfer.py" target="_blank" rel="noopener">https://github.com/shentianxiao/language-style-transfer/blob/master/code/style_transfer.py</a></p><p>style transfer å…¶å®ä¹Ÿæ˜¯controlled text generationçš„ä¸€ç§ï¼Œåªæ˜¯å®ƒcontrolçš„æ˜¯æ–‡æœ¬çš„é£æ ¼ã€‚æ–‡æœ¬é£æ ¼æœ‰å¾ˆå¤šç§ï¼Œä¾‹å¦‚æƒ…æ„Ÿçš„æ­£è´Ÿé¢ï¼Œæ–‡ç« æ˜¯éšæ„çš„è¿˜æ˜¯ä¸¥è‚ƒçš„ã€‚</p><p><img src="https://uploader.shimo.im/f/2BUGTCxcajoerOmj.png!thumbnail" alt="img"></p><p><img src="https://uploader.shimo.im/f/fE6u9Ap33JIRO8So.png!thumbnail" alt="img"></p><p>ä¸€ä¸ªå¾ˆå¥½çš„repoï¼Œæ€»ç»“äº†æ–‡æœ¬é£æ ¼è¿ç§»é¢†åŸŸçš„paper</p><p><a href="https://github.com/fuzhenxin/Style-Transfer-in-Text" target="_blank" rel="noopener">https://github.com/fuzhenxin/Style-Transfer-in-Text</a></p><h1 id="Generative-Adversarial-Networks-GAN-åœ¨NLPä¸Šçš„åº”ç”¨"><a href="#Generative-Adversarial-Networks-GAN-åœ¨NLPä¸Šçš„åº”ç”¨" class="headerlink" title="Generative Adversarial Networks (GAN) åœ¨NLPä¸Šçš„åº”ç”¨"></a>Generative Adversarial Networks (GAN) åœ¨NLPä¸Šçš„åº”ç”¨</h1><p>æœ€æ—©Ian Goodfellowçš„å…³äºGANçš„æ–‡ç« ï¼Œå…¶åŸºæœ¬åšæ³•å°±æ˜¯ä¸€ä¸ª<strong>generator</strong>å’Œä¸€ä¸ª<strong>discriminator</strong>(è¾…åŠ©è§’è‰²)ï¼Œç„¶åè®©ä¸¤ä¸ªæ¨¡å‹äº’ç›¸ç«äº‰å¯¹æŠ—ï¼Œåœ¨å¯¹æŠ—çš„è¿‡ç¨‹ä¸­é€æ¸æå‡å„è‡ªçš„æ¨¡å‹èƒ½åŠ›ã€‚è€Œå…¶ä¸­çš„generatorå°±æ˜¯æˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿæœ€ç»ˆoptimizeå¹¶ä¸”è¢«æ‹¿æ¥ä½¿ç”¨çš„æ¨¡å‹ã€‚</p><p>æ—©æœŸGANä¸»è¦æˆåŠŸåº”ç”¨éƒ½åœ¨äºå›¾åƒé¢†åŸŸã€‚å…¶å…³é”®åŸå› åœ¨äºï¼Œå›¾åƒçš„æ¯ä¸ªåƒç´ éƒ½æ˜¯ä¸‰ä¸ªè¿ç»­çš„RGBæ•°å€¼ã€‚discriminatorå¦‚æœç»™å›¾åƒè®¡ç®—ä¸€ä¸ªæ¦‚ç‡åˆ†æ•°ï¼Œå½“æˆ‘ä»¬åœ¨ä¼˜åŒ–generatorå¸Œæœ›æé«˜è¿™ä¸ªåˆ†æ•°çš„æ—¶å€™ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨Back Propagationç®—æ³•è®¡ç®—æ¢¯åº¦ï¼Œç„¶ååšæ¢¯åº¦ä¸Šå‡/ä¸‹é™æ¥å®Œæˆæˆ‘ä»¬æƒ³è¦ä¼˜åŒ–çš„ç›®æ ‡ã€‚</p><p>discriminator: äºŒåˆ†ç±»é—®é¢˜ å›¾ç‰‡â€“&gt;åˆ†ç±»</p><p>D(G(z)) â€“&gt; cross entropyloss â€“&gt; backprop åˆ°generator</p><p>æ–‡æœ¬â€“&gt; </p><p>LSTM â€“&gt; P_vocab() â€“&gt; <strong>argmax æ–‡å­—</strong> â€“&gt; discriminator</p><p>LSTM â€“&gt; P_vocab() â€“&gt; discriminator</p><p>è€Œæ–‡æœ¬ç”Ÿæˆæ˜¯ä¸€ä¸ªä¸åŒçš„é—®é¢˜ï¼Œå…¶ç‰¹æ®Šä¹‹å¤„åœ¨äºæˆ‘ä»¬åœ¨åšæ–‡æœ¬ç”Ÿæˆçš„æ—¶å€™æœ‰ä¸€æ­¥<strong>argmax</strong>çš„æ“ä½œï¼Œä¹Ÿå°±æ˜¯è¯´å½“æˆ‘ä»¬åšinferenceç”Ÿæˆæ–‡å­—çš„æ—¶å€™ï¼Œåœ¨è¾“å‡ºå±‚ä½¿ç”¨äº†argmaxæˆ–è€…samplingçš„æ“ä½œã€‚å½“æˆ‘ä»¬æŠŠargmaxæˆ–è€…samplingå¾—åˆ°çš„æ–‡å­—ä¼ ç»™discriminatoræ‰“åˆ†çš„æ—¶å€™ï¼Œæˆ‘ä»¬æ— æ³•ç”¨è¿™ä¸ªåˆ†æ•°åš<strong>back propagation</strong>å¯¹ç”Ÿæˆå™¨åšä¼˜åŒ–æ“ä½œã€‚</p><p>çœŸæ­£çš„sample â€“&gt; one hot vector ([1, 0, 0, 0, 0, 0])</p><p>é¢„æµ‹ä¸€ä¸ªè¾“å‡ºå•è¯çš„æ—¶å€™ï¼š([0.8, 0.1, 0, 0.05, 0, 0.05]) â€“&gt; gumbel_softmax â€“&gt; discriminatoråˆ¤æ–­ä¸€ä¸‹</p><p>ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œäººä»¬å¤§è‡´èµ°äº†ä¸¤æ¡è·¯çº¿ï¼Œä¸€æ¡æ˜¯å°†æ™®é€šçš„argmaxè½¬å˜æˆå¯å¯¼çš„Gumbel-softmaxï¼Œç„¶åæˆ‘ä»¬å°±å¯ä»¥åŒæ—¶ä¼˜åŒ–generatorå’Œdiscriminatoräº†ã€‚</p><p>é¢„æµ‹ä¸€ä¸ªè¾“å‡ºå•è¯çš„æ—¶å€™ï¼š([0.8, 0.1, 0, 0.05, 0, 0.05]) â€“&gt; gumbel_softmax â€“&gt; discriminatoråˆ¤æ–­ä¸€ä¸‹</p><p><a href="https://arxiv.org/pdf/1611.04051.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1611.04051.pdf</a></p><p><a href="https://www.zhihu.com/question/62631725" target="_blank" rel="noopener">https://www.zhihu.com/question/62631725</a></p><p>å¦å¤–ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨<strong>Reinforcement Learning</strong>ä¸­çš„<strong>Policy Gradient</strong>æ¥ä¼°ç®—æ¨¡å‹çš„gradientï¼Œå¹¶åšä¼˜åŒ–ã€‚</p><p>æ ¹æ®å½“å‰çš„policyæ¥<strong>sample</strong> stepsã€‚</p><p>NLPï¼š policyå°±æ˜¯æˆ‘ä»¬çš„<strong>è¯­è¨€æ¨¡å‹</strong>ï¼Œä¹Ÿå°±æ˜¯è¯´æ ¹æ®å½“å‰çš„hidden state, å†³å®šæˆ‘ä¸‹ä¸€æ­¥è¦ç”Ÿæˆä»€ä¹ˆå•è¯ã€‚</p><p>P_vocab â€“&gt; argmax</p><p>P_vocab â€“&gt; sampling</p><p>backpropagation â€“&gt; æ²¡æœ‰åŠæ³•æ›´æ–°æ¨¡å‹</p><p>æ–‡æœ¬ç¿»è¯‘ â€“ ä¼˜åŒ–<strong>BLEU?</strong></p><p>è®­ç»ƒï¼Ÿ cross entropy loss</p><p>policy gradientç›´æ¥ä¼˜åŒ–BLEU</p><p>å¯ä»¥ä¸å¯ä»¥æ‰¾ä¸ªæ–¹æ³•ä¼°ç®—gradientã€‚</p><p>Policy: å½“å‰æ‰§è¡Œçš„ç­–ç•¥,åœ¨æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ä¸­ï¼Œè¿™ä¸ªPolicyä¸€èˆ¬å°±æ˜¯æŒ‡æˆ‘ä»¬çš„decoder(LSTM)</p><p>Policy Gradient: æ ¹æ®å½“å‰çš„policyæ‰§è¡Œä»»åŠ¡ï¼Œç„¶åå¾—åˆ°rewardï¼Œå¹¶ä¼°ç®—æ¯ä¸ªå‚æ•°çš„gradient, SGD</p><p>è¿™é‡Œå°±æ¶‰åŠåˆ°ä¸€äº›Reinforcement Learningå½“ä¸­çš„åŸºæœ¬çŸ¥è¯†ã€‚æˆ‘ä»¬å¯ä»¥è®¤ä¸ºä¸€ä¸ªè¯­è¨€æ¨¡å‹ï¼Œä¾‹å¦‚LSTMï¼Œæ˜¯åœ¨åšä¸€è¿ä¸²è¿ç»­çš„å†³ç­–ã€‚æ¯ä¸€ä¸ªdecodingçš„æ­¥éª¤ï¼Œæ¯ä¸ªhidden stateå¯¹åº”ä¸€ä¸ª<strong>çŠ¶æ€state</strong>ï¼Œæ¯ä¸ªè¾“å‡ºå¯¹åº”ä¸€ä¸ª<strong>observation</strong>ã€‚å¦‚æœæˆ‘ä»¬æ¯æ¬¡è¾“å‡ºä¸€ä¸ªæ–‡å­—çš„æ—¶å€™ä½¿ç”¨samplingçš„æ–¹æ³•ï¼ŒReinforcement Learningæœ‰ä¸€å¥—æˆç†Ÿçš„ç®—æ³•å¯ä»¥å¸®åŠ©æˆ‘ä»¬ä¼°ç®—æ¨¡å‹çš„æ¢¯åº¦ï¼Œè¿™ç§ç®—æ³•å«åšpolicy gradientã€‚å¦‚æœé‡‡ç”¨è¿™ç§æ–¹æ³•ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥å¯¹æ¨¡å‹è¿›è¡Œä¼˜åŒ–ã€‚</p><p><a href="https://arxiv.org/pdf/1609.05473.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1609.05473.pdf</a></p><p>è¿™ä¸€å¥—policy gradientçš„åšæ³•åœ¨å¾ˆå¤šæ–‡æœ¬ç”Ÿæˆï¼ˆä¾‹å¦‚ç¿»è¯‘ï¼Œimage captioningï¼‰çš„ä¼˜åŒ–é—®é¢˜ä¸Šä¹Ÿç»å¸¸è§åˆ°ã€‚</p><p>ç¿»è¯‘ï¼šä¼˜åŒ–BLEU</p><p>Improved Image Captioning via Policy Gradient optimization of SPIDEr</p><p><a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Liu_Improved_Image_Captioning_ICCV_2017_paper.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_ICCV_2017/papers/Liu_Improved_Image_Captioning_ICCV_2017_paper.pdf</a></p><p>è¿˜æœ‰ä¸€äº›æ–¹æ³•æ˜¯ï¼Œæˆ‘ä»¬ä¸åšæœ€ç»ˆçš„æ–‡æœ¬é‡‡æ ·ï¼Œæˆ‘ä»¬ç›´æ¥ä½¿ç”¨æ¨¡å‹è¾“å‡ºçš„åœ¨å•è¯è¡¨ä¸Šçš„è¾“å‡ºåˆ†å¸ƒï¼Œæˆ–è€…æ˜¯ä½¿ç”¨LSTMä¸­çš„ä¸€äº›hidden vectoræ¥ä¼ ç»™discriminatorï¼Œå¹¶ç›´æ¥ä¼˜åŒ–è¯­è¨€æ¨¡å‹ã€‚</p><p>æˆ‘ä¸ªäººçš„çœ‹æ³•æ˜¯GANåœ¨æ–‡æœ¬ç”Ÿæˆä¸Šçš„ä½œç”¨å¤§å°è¿˜ä¸æ˜ç¡®ï¼Œä¸€éƒ¨åˆ†åŸå› åœ¨äºæˆ‘ä»¬æ²¡æœ‰ä¸€ç§å¾ˆå¥½çš„æœºåˆ¶å»è¯„ä¼°æ–‡æœ¬ç”Ÿæˆçš„å¥½åã€‚æˆ‘ä»¬çœ‹åˆ°å¾ˆå¤šè®ºæ–‡å…¶å®å¯¹æ¨¡å‹çš„å¥½åæ²¡æœ‰æ˜ç¡®çš„è¯„ä»·ï¼Œå¾ˆå¤šæ—¶å€™æ˜¯éšæœºäº§ç”Ÿå‡ ä¸ªå¥å­ï¼Œç„¶åç”±ä½œè€…æ¥è¯„ä»·ä¸€ä¸‹ç”Ÿæˆå¥å­çš„å¥½åã€‚</p><h1 id="Data-to-text"><a href="#Data-to-text" class="headerlink" title="Data-to-text"></a>Data-to-text</h1><p><img src="https://uploader.shimo.im/f/Fo4ylW4dnbgm68U9.png!thumbnail" alt="img"></p><ul><li><p>Content selection: é€‰æ‹©ä»€ä¹ˆæ•°æ®éœ€è¦è¿›å…¥åˆ°æˆ‘ä»¬çš„æ–‡æœ¬ä¹‹ä¸­</p></li><li><p>Sentence planning: å†³å®šå¥å­çš„ç»“æ„</p></li><li><p>Surface realization: æŠŠå¥å­ç»“æ„è½¬åŒ–æˆå…·ä½“çš„å­—ç¬¦ä¸²</p></li></ul><p><img src="https://uploader.shimo.im/f/9QQQLucVUMsIVS6P.png!thumbnail" alt="img"></p><p>é—®é¢˜å®šä¹‰</p><ul><li><p>è¾“å…¥: A table of recordsã€‚æ¯ä¸ªrecordåŒ…å«å››ä¸ªfeatures: type, entity, value, home or away</p></li><li><p>è¾“å‡º: ä¸€æ®µæ–‡å­—æè¿°</p></li></ul><h2 id="ç›¸å…³èµ„æ–™"><a href="#ç›¸å…³èµ„æ–™" class="headerlink" title="ç›¸å…³èµ„æ–™"></a>ç›¸å…³èµ„æ–™</h2><p><a href="https://github.com/Morde-kaiser/LearningNotes/blob/master/GAN-Overview-Chinese.pdf" target="_blank" rel="noopener">https://github.com/Morde-kaiser/LearningNotes/blob/master/GAN-Overview-Chinese.pdf</a></p><p>William Wangå…³äºGAN in NLPçš„slides: <a href="http://sameersingh.org/files/ppts/naacl19-advnlp-part1-william-slides.pdf" target="_blank" rel="noopener">http://sameersingh.org/files/ppts/naacl19-advnlp-part1-william-slides.pdf</a></p><p>è¿™ç¯‡åšæ–‡ä¹Ÿè®²çš„å¾ˆå¥½</p><p><a href="https://zhuanlan.zhihu.com/p/29168803" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/29168803</a></p><p>å‚è€ƒè¯¥çŸ¥ä¹ä¸“æ æ–‡ç«  <a href="https://zhuanlan.zhihu.com/p/36880287" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/36880287</a></p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> inference </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BERT&amp;ELMo&amp;co</title>
      <link href="/2020/05/09/%E5%B8%B8%E8%A7%81%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"/>
      <url>/2020/05/09/%E5%B8%B8%E8%A7%81%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="ã€è¯‘ã€‘The-Illustrated-BERT-ELMo-and-co"><a href="#ã€è¯‘ã€‘The-Illustrated-BERT-ELMo-and-co" class="headerlink" title="ã€è¯‘ã€‘The Illustrated BERT, ELMo, and co."></a>ã€è¯‘ã€‘The Illustrated BERT, ELMo, and co.</h2><p><a href="https://www.mihaileric.com/posts/deep-contextualized-word-representations-elmo/" target="_blank" rel="noopener">ELMo: Contextualized Word Vectors</a></p><p>æœ¬æ–‡ç”±Adam Liuæˆæƒè½¬è½½ï¼Œæºé“¾æ¥ <a href="https://blog.csdn.net/qq_41664845/article/details/84787969#comments" target="_blank" rel="noopener">https://blog.csdn.net/qq_41664845/article/details/84787969</a></p><p>åŸæ–‡é“¾æ¥ï¼šThe Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)</p><p>ä½œè€…ï¼šJay Alammar</p><p>ä¿®æ”¹ï¼šè¤šåˆ™ä¼Ÿ <a href="mailto:zeweichu@gmail.com" target="_blank" rel="noopener">zeweichu@gmail.com</a></p><p>BERTè®ºæ–‡åœ°å€ï¼šBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding <a href="https://arxiv.org/abs/1810.04805" target="_blank" rel="noopener">https://arxiv.org/abs/1810.04805</a></p><h1 id="å‰è¨€"><a href="#å‰è¨€" class="headerlink" title="å‰è¨€"></a>å‰è¨€</h1><p>2018å¹´å¯è°“æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰çš„å…ƒå¹´ï¼Œåœ¨æˆ‘ä»¬å¦‚ä½•ä»¥æœ€èƒ½æ•æ‰æ½œåœ¨è¯­ä¹‰å…³ç³»çš„æ–¹å¼  æ¥è¾…åŠ©è®¡ç®—æœºå¯¹çš„å¥å­æ¦‚å¿µæ€§çš„ç†è§£ è¿™æ–¹é¢å–å¾—äº†æå¤§çš„å‘å±•è¿›æ­¥ã€‚æ­¤å¤–ï¼Œ NLPé¢†åŸŸçš„ä¸€äº›å¼€æºç¤¾åŒºå·²ç»å‘å¸ƒäº†å¾ˆå¤šå¼ºå¤§çš„ç»„ä»¶ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨è‡ªå·±çš„æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­å…è´¹çš„ä¸‹è½½ä½¿ç”¨ã€‚ï¼ˆå¯ä»¥è¯´ä»Šå¹´æ˜¯NLPçš„ImageNetæ—¶åˆ»ï¼Œå› ä¸ºè¿™å’Œå‡ å¹´å‰è®¡ç®—æœºè§†è§‰çš„å‘å±•å¾ˆç›¸ä¼¼ï¼‰</p><p><img src="https://uploader.shimo.im/f/Z0tgsQt24GAoKjkj.png!thumbnail" alt="img"></p><p>ä¸Šå›¾ä¸­ï¼Œæœ€æ–°å‘å¸ƒçš„BERTæ˜¯ä¸€ä¸ªNLPä»»åŠ¡çš„é‡Œç¨‹ç¢‘å¼æ¨¡å‹ï¼Œå®ƒçš„å‘å¸ƒåŠ¿å¿…ä¼šå¸¦æ¥ä¸€ä¸ªNLPçš„æ–°æ—¶ä»£ã€‚BERTæ˜¯ä¸€ä¸ªç®—æ³•æ¨¡å‹ï¼Œå®ƒçš„å‡ºç°æ‰“ç ´äº†å¤§é‡çš„è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡çš„è®°å½•ã€‚åœ¨BERTçš„è®ºæ–‡å‘å¸ƒä¸ä¹…åï¼ŒGoogleçš„ç ”å‘å›¢é˜Ÿè¿˜å¼€æ”¾äº†è¯¥æ¨¡å‹çš„ä»£ç ï¼Œå¹¶æä¾›äº†ä¸€äº›åœ¨å¤§é‡æ•°æ®é›†ä¸Šé¢„è®­ç»ƒå¥½çš„ç®—æ³•æ¨¡å‹ä¸‹è½½æ–¹å¼ã€‚Gooleå¼€æºè¿™ä¸ªæ¨¡å‹ï¼Œå¹¶æä¾›é¢„è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œè¿™ä½¿å¾—æ‰€æœ‰äººéƒ½å¯ä»¥é€šè¿‡å®ƒæ¥æ„å»ºä¸€ä¸ªæ¶‰åŠNLPçš„ç®—æ³•æ¨¡å‹ï¼ŒèŠ‚çº¦äº†å¤§é‡è®­ç»ƒè¯­è¨€æ¨¡å‹æ‰€éœ€çš„æ—¶é—´ï¼Œç²¾åŠ›ï¼ŒçŸ¥è¯†å’Œèµ„æºã€‚</p><p><img src="https://uploader.shimo.im/f/6xxJC31NvvYDCGFQ.png!thumbnail" alt="img"></p><p>BERTé›†æˆäº†æœ€è¿‘ä¸€æ®µæ—¶é—´å†…NLPé¢†åŸŸä¸­çš„ä¸€äº›é¡¶å°–çš„æ€æƒ³ï¼ŒåŒ…æ‹¬ä½†ä¸é™äº Semi-supervised Sequence Learning (by Andrew Dai and Quoc Le), ELMo (by Matthew Peters and researchers from AI2 and UW CSE), ULMFiT (by fast.ai founder Jeremy Howard and Sebastian Ruder), and the OpenAI transformer (by OpenAI researchers Radford, Narasimhan, Salimans, and Sutskever), and the Transformer (Vaswani et al).ã€‚</p><p>ä½ éœ€è¦æ³¨æ„ä¸€äº›äº‹æƒ…æ‰èƒ½æ°å½“çš„ç†è§£BERTçš„å†…å®¹ï¼Œä¸è¿‡ï¼Œåœ¨ä»‹ç»æ¨¡å‹æ¶‰åŠçš„æ¦‚å¿µä¹‹å‰å¯ä»¥ä½¿ç”¨BERTçš„æ–¹æ³•ã€‚ </p><h2 id="ç¤ºä¾‹ï¼šå¥å­åˆ†ç±»"><a href="#ç¤ºä¾‹ï¼šå¥å­åˆ†ç±»" class="headerlink" title="ç¤ºä¾‹ï¼šå¥å­åˆ†ç±»"></a>ç¤ºä¾‹ï¼šå¥å­åˆ†ç±»</h2><p>ä½¿ç”¨BERTæœ€ç®€å•çš„æ–¹æ³•å°±æ˜¯åšä¸€ä¸ªæ–‡æœ¬åˆ†ç±»æ¨¡å‹ï¼Œè¿™æ ·çš„æ¨¡å‹ç»“æ„å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p><p><img src="https://uploader.shimo.im/f/8T7zkJ6MWgwE98oi.png!thumbnail" alt="img"></p><p>ä¸ºäº†è®­ç»ƒä¸€ä¸ªè¿™æ ·çš„æ¨¡å‹ï¼Œï¼ˆä¸»è¦æ˜¯è®­ç»ƒä¸€ä¸ªåˆ†ç±»å™¨ï¼‰ï¼Œåœ¨è®­ç»ƒé˜¶æ®µBERTæ¨¡å‹å‘ç”Ÿçš„å˜åŒ–å¾ˆå°ã€‚è¯¥è®­ç»ƒè¿‡ç¨‹ç§°ä¸ºå¾®è°ƒï¼Œå¹¶ä¸”æºäº Semi-supervised Sequence Learning å’Œ ULMFiT.ã€‚</p><p>ä¸ºäº†æ›´æ–¹ä¾¿ç†è§£ï¼Œæˆ‘ä»¬ä¸‹é¢ä¸¾ä¸€ä¸ªåˆ†ç±»å™¨çš„ä¾‹å­ã€‚åˆ†ç±»å™¨æ˜¯å±äºç›‘ç£å­¦ä¹ é¢†åŸŸçš„ï¼Œè¿™æ„å‘³ç€ä½ éœ€è¦ä¸€äº›æ ‡è®°çš„æ•°æ®æ¥è®­ç»ƒè¿™äº›æ¨¡å‹ã€‚å¯¹äºåƒåœ¾é‚®ä»¶åˆ†ç±»å™¨çš„ç¤ºä¾‹ï¼Œæ ‡è®°çš„æ•°æ®é›†ç”±é‚®ä»¶çš„å†…å®¹å’Œé‚®ä»¶çš„ç±»åˆ«2éƒ¨åˆ†ç»„æˆï¼ˆç±»åˆ«åˆ†ä¸ºâ€œåƒåœ¾é‚®ä»¶â€æˆ–â€œéåƒåœ¾é‚®ä»¶â€ï¼‰ã€‚</p><h1 id="æ¨¡å‹æ¶æ„"><a href="#æ¨¡å‹æ¶æ„" class="headerlink" title="æ¨¡å‹æ¶æ„"></a>æ¨¡å‹æ¶æ„</h1><p>ç°åœ¨æ‚¨å·²ç»äº†è§£äº†å¦‚ä½•ä½¿ç”¨BERTçš„ç¤ºä¾‹ï¼Œè®©æˆ‘ä»¬ä»”ç»†äº†è§£ä¸€ä¸‹ä»–çš„å·¥ä½œåŸç†ã€‚</p><p><img src="https://uploader.shimo.im/f/1jNYmPwPIDEzhsLv.png!thumbnail" alt="img"></p><p>BERTçš„è®ºæ–‡ä¸­ä»‹ç»äº†2ç§ç‰ˆæœ¬ï¼š</p><ul><li><p>BERT BASE - ä¸OpenAI Transformerçš„å°ºå¯¸ç›¸å½“ï¼Œä»¥ä¾¿æ¯”è¾ƒæ€§èƒ½</p></li><li><p>BERT LARGE - ä¸€ä¸ªéå¸¸åºå¤§çš„æ¨¡å‹ï¼Œå®ƒå®Œæˆäº†æœ¬æ–‡ä»‹ç»çš„æœ€å…ˆè¿›çš„ç»“æœã€‚</p></li></ul><p>BERTçš„åŸºç¡€é›†æˆå•å…ƒæ˜¯Transformerçš„Encoderã€‚å…³äºTransformerçš„ä»‹ç»å¯ä»¥é˜…è¯»ä½œè€…ä¹‹å‰çš„æ–‡ç« ï¼šThe Illustrated Transformerï¼Œè¯¥æ–‡ç« è§£é‡Šäº†Transformeræ¨¡å‹ - BERTçš„åŸºæœ¬æ¦‚å¿µä»¥åŠæˆ‘ä»¬æ¥ä¸‹æ¥è¦è®¨è®ºçš„æ¦‚å¿µã€‚</p><p>2ä¸ªBERTçš„æ¨¡å‹éƒ½æœ‰ä¸€ä¸ªå¾ˆå¤§çš„ç¼–ç å™¨å±‚æ•°ï¼Œï¼ˆè®ºæ–‡é‡Œé¢å°†æ­¤ç§°ä¸ºTransformer Blocksï¼‰ - åŸºç¡€ç‰ˆæœ¬å°±æœ‰12å±‚ï¼Œè¿›é˜¶ç‰ˆæœ¬æœ‰24å±‚ã€‚åŒæ—¶å®ƒä¹Ÿæœ‰å¾ˆå¤§çš„å‰é¦ˆç¥ç»ç½‘ç»œï¼ˆ 768å’Œ1024ä¸ªéšè—å±‚ç¥ç»å…ƒï¼‰ï¼Œè¿˜æœ‰å¾ˆå¤šattention headsï¼ˆ12-16ä¸ªï¼‰ã€‚è¿™è¶…è¿‡äº†Transformerè®ºæ–‡ä¸­çš„å‚è€ƒé…ç½®å‚æ•°ï¼ˆ6ä¸ªç¼–ç å™¨å±‚ï¼Œ512ä¸ªéšè—å±‚å•å…ƒï¼Œå’Œ8ä¸ªæ³¨æ„å¤´ï¼‰</p><h2 id="æ¨¡å‹è¾“å…¥"><a href="#æ¨¡å‹è¾“å…¥" class="headerlink" title="æ¨¡å‹è¾“å…¥"></a>æ¨¡å‹è¾“å…¥</h2><p>è¾“å…¥çš„ç¬¬ä¸€ä¸ªå­—ç¬¦ä¸º[CLS]ï¼Œåœ¨è¿™é‡Œå­—ç¬¦[CLS]è¡¨è¾¾çš„æ„æ€å¾ˆç®€å• - Classification ï¼ˆåˆ†ç±»ï¼‰ã€‚</p><p>BERTä¸Transformer çš„ç¼–ç æ–¹å¼ä¸€æ ·ã€‚å°†å›ºå®šé•¿åº¦çš„å­—ç¬¦ä¸²ä½œä¸ºè¾“å…¥ï¼Œæ•°æ®ç”±ä¸‹è€Œä¸Šä¼ é€’è®¡ç®—ï¼Œæ¯ä¸€å±‚éƒ½ç”¨åˆ°äº†self attentionï¼Œå¹¶é€šè¿‡å‰é¦ˆç¥ç»ç½‘ç»œä¼ é€’å…¶ç»“æœï¼Œå°†å…¶äº¤ç»™ä¸‹ä¸€ä¸ªç¼–ç å™¨ã€‚</p><p><img src="https://uploader.shimo.im/f/4VwjFpmDltoJInZh.png!thumbnail" alt="img"></p><p>è¿™æ ·çš„æ¶æ„ï¼Œä¼¼ä¹æ˜¯æ²¿ç”¨äº†Transformer çš„æ¶æ„ï¼ˆé™¤äº†å±‚æ•°ï¼Œä¸è¿‡è¿™æ˜¯æˆ‘ä»¬å¯ä»¥è®¾ç½®çš„å‚æ•°ï¼‰ã€‚é‚£ä¹ˆBERTä¸Transformer ä¸åŒä¹‹å¤„åœ¨å“ªé‡Œå‘¢ï¼Ÿå¯èƒ½åœ¨æ¨¡å‹çš„è¾“å‡ºä¸Šï¼Œæˆ‘ä»¬å¯ä»¥å‘ç°ä¸€äº›ç«¯å€ªã€‚</p><h2 id="æ¨¡å‹è¾“å‡º"><a href="#æ¨¡å‹è¾“å‡º" class="headerlink" title="æ¨¡å‹è¾“å‡º"></a>æ¨¡å‹è¾“å‡º</h2><p>æ¯ä¸ªä½ç½®è¿”å›çš„è¾“å‡ºéƒ½æ˜¯ä¸€ä¸ªéšè—å±‚å¤§å°çš„å‘é‡ï¼ˆåŸºæœ¬ç‰ˆæœ¬BERTä¸º768ï¼‰ã€‚ä»¥æ–‡æœ¬åˆ†ç±»ä¸ºä¾‹ï¼Œæˆ‘ä»¬é‡ç‚¹å…³æ³¨ç¬¬ä¸€ä¸ªä½ç½®ä¸Šçš„è¾“å‡ºï¼ˆç¬¬ä¸€ä¸ªä½ç½®æ˜¯åˆ†ç±»æ ‡è¯†[CLS]ï¼‰ ã€‚å¦‚ä¸‹å›¾</p><p>è¯¥å‘é‡ç°åœ¨å¯ä»¥ç”¨ä½œæˆ‘ä»¬é€‰æ‹©çš„åˆ†ç±»å™¨çš„è¾“å…¥ï¼Œåœ¨è®ºæ–‡ä¸­æŒ‡å‡ºä½¿ç”¨å•å±‚ç¥ç»ç½‘ç»œä½œä¸ºåˆ†ç±»å™¨å°±å¯ä»¥å–å¾—å¾ˆå¥½çš„æ•ˆæœã€‚åŸç†å¦‚ä¸‹ï¼š</p><p><img src="https://uploader.shimo.im/f/X6bsq7gTFDERfO9s.png!thumbnail" alt="img"></p><p>ä¾‹å­ä¸­åªæœ‰åƒåœ¾é‚®ä»¶å’Œéåƒåœ¾é‚®ä»¶ï¼Œå¦‚æœä½ æœ‰æ›´å¤šçš„labelï¼Œä½ åªéœ€è¦å¢åŠ è¾“å‡ºç¥ç»å…ƒçš„ä¸ªæ•°å³å¯ï¼Œå¦å¤–æŠŠæœ€åçš„æ¿€æ´»å‡½æ•°æ¢æˆsoftmaxå³å¯ã€‚</p><h2 id="Parallels-with-Convolutional-Netsï¼ˆBERT-VSå·ç§¯ç¥ç»ç½‘ç»œï¼‰"><a href="#Parallels-with-Convolutional-Netsï¼ˆBERT-VSå·ç§¯ç¥ç»ç½‘ç»œï¼‰" class="headerlink" title="Parallels with Convolutional Netsï¼ˆBERT VSå·ç§¯ç¥ç»ç½‘ç»œï¼‰"></a>Parallels with Convolutional Netsï¼ˆBERT VSå·ç§¯ç¥ç»ç½‘ç»œï¼‰</h2><p>å¯¹äºé‚£äº›å…·æœ‰è®¡ç®—æœºè§†è§‰èƒŒæ™¯çš„äººæ¥è¯´ï¼Œè¿™ä¸ªçŸ¢é‡åˆ‡æ¢åº”è¯¥è®©äººè”æƒ³åˆ°VGGNetç­‰ç½‘ç»œçš„å·ç§¯éƒ¨åˆ†ä¸ç½‘ç»œæœ«ç«¯çš„å®Œå…¨è¿æ¥çš„åˆ†ç±»éƒ¨åˆ†ä¹‹é—´å‘ç”Ÿçš„äº‹æƒ…ã€‚ä½ å¯ä»¥è¿™æ ·ç†è§£ï¼Œå®è´¨ä¸Šè¿™æ ·ç†è§£ä¹Ÿå¾ˆæ–¹ä¾¿ã€‚</p><p><img src="https://uploader.shimo.im/f/SIlXQTqB9vM4DEDi.png!thumbnail" alt="img"></p><h1 id="è¯åµŒå…¥çš„æ–°æ—¶ä»£ã€œ"><a href="#è¯åµŒå…¥çš„æ–°æ—¶ä»£ã€œ" class="headerlink" title="è¯åµŒå…¥çš„æ–°æ—¶ä»£ã€œ"></a>è¯åµŒå…¥çš„æ–°æ—¶ä»£ã€œ</h1><p>BERTçš„å¼€æºéšä¹‹è€Œæ¥çš„æ˜¯ä¸€ç§è¯åµŒå…¥çš„æ›´æ–°ã€‚åˆ°ç›®å‰ä¸ºæ­¢ï¼Œè¯åµŒå…¥å·²ç»æˆä¸ºNLPæ¨¡å‹å¤„ç†è‡ªç„¶è¯­è¨€çš„ä¸»è¦ç»„æˆéƒ¨åˆ†ã€‚è¯¸å¦‚Word2vecå’ŒGlove ç­‰æ–¹æ³•å·²ç»å¹¿æ³›çš„ç”¨äºå¤„ç†è¿™äº›é—®é¢˜ï¼Œåœ¨æˆ‘ä»¬ä½¿ç”¨æ–°çš„è¯åµŒå…¥ä¹‹å‰ï¼Œæˆ‘ä»¬æœ‰å¿…è¦å›é¡¾ä¸€ä¸‹å…¶å‘å±•ã€‚</p><h2 id="Word-Embedding-Recap"><a href="#Word-Embedding-Recap" class="headerlink" title="Word Embedding Recap"></a>Word Embedding Recap</h2><p>ä¸ºäº†è®©æœºå™¨å¯ä»¥å­¦ä¹ åˆ°æ–‡æœ¬çš„ç‰¹å¾å±æ€§ï¼Œæˆ‘ä»¬éœ€è¦ä¸€äº›å°†æ–‡æœ¬æ•°å€¼åŒ–çš„è¡¨ç¤ºçš„æ–¹å¼ã€‚Word2vecç®—æ³•é€šè¿‡ä½¿ç”¨ä¸€ç»„å›ºå®šç»´åº¦çš„å‘é‡æ¥è¡¨ç¤ºå•è¯ï¼Œè®¡ç®—å…¶æ–¹å¼å¯ä»¥æ•è·åˆ°å•è¯çš„è¯­ä¹‰åŠå•è¯ä¸å•è¯ä¹‹é—´çš„å…³ç³»ã€‚ä½¿ç”¨Word2vecçš„å‘é‡åŒ–è¡¨ç¤ºæ–¹å¼å¯ä»¥ç”¨äºåˆ¤æ–­å•è¯æ˜¯å¦ç›¸ä¼¼ï¼Œå¯¹ç«‹ï¼Œæˆ–è€…è¯´åˆ¤æ–­â€œç”·äººâ€˜ä¸â€™å¥³äººâ€çš„å…³ç³»å°±å¦‚åŒâ€œå›½ç‹â€ä¸â€œç‹åâ€ã€‚ï¼ˆè¿™äº›è¯æ˜¯ä¸æ˜¯å¬è…»äº†ã€œ emmmæ°´æ–‡å¿…å¤‡ï¼‰ã€‚å¦å¤–è¿˜èƒ½æ•è·åˆ°ä¸€äº›è¯­æ³•çš„å…³ç³»ï¼Œè¿™ä¸ªåœ¨è‹±è¯­ä¸­å¾ˆå®ç”¨ã€‚ä¾‹å¦‚â€œhadâ€ä¸â€œhasâ€çš„å…³ç³»å¦‚åŒâ€œwasâ€ä¸â€œisâ€çš„å…³ç³»ã€‚</p><p>è¿™æ ·çš„åšæ³•ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å¤§é‡çš„æ–‡æœ¬æ•°æ®æ¥é¢„è®­ç»ƒä¸€ä¸ªè¯åµŒå…¥æ¨¡å‹ï¼Œè€Œè¿™ä¸ªè¯åµŒå…¥æ¨¡å‹å¯ä»¥å¹¿æ³›ç”¨äºå…¶ä»–NLPçš„ä»»åŠ¡ï¼Œè¿™æ˜¯ä¸ªå¥½ä¸»æ„ï¼Œè¿™ä½¿å¾—ä¸€äº›åˆåˆ›å…¬å¸æˆ–è€…è®¡ç®—èµ„æºä¸è¶³çš„å…¬å¸ï¼Œä¹Ÿèƒ½é€šè¿‡ä¸‹è½½å·²ç»å¼€æºçš„è¯åµŒå…¥æ¨¡å‹æ¥å®ŒæˆNLPçš„ä»»åŠ¡ã€‚</p><h2 id="ELMoï¼šè¯­å¢ƒé—®é¢˜"><a href="#ELMoï¼šè¯­å¢ƒé—®é¢˜" class="headerlink" title="ELMoï¼šè¯­å¢ƒé—®é¢˜"></a>ELMoï¼šè¯­å¢ƒé—®é¢˜</h2><p>ä¸Šé¢ä»‹ç»çš„è¯åµŒå…¥æ–¹å¼æœ‰ä¸€ä¸ªå¾ˆæ˜æ˜¾çš„é—®é¢˜ï¼Œå› ä¸ºä½¿ç”¨é¢„è®­ç»ƒå¥½çš„è¯å‘é‡æ¨¡å‹ï¼Œé‚£ä¹ˆæ— è®ºä¸Šä¸‹æ–‡çš„è¯­å¢ƒå…³ç³»å¦‚ä½•ï¼Œæ¯ä¸ªå•è¯éƒ½åªæœ‰ä¸€ä¸ªå”¯ä¸€çš„ä¸”å·²ç»å›ºå®šä¿å­˜çš„å‘é‡åŒ–å½¢å¼â€œã€‚Wait a minute â€œ - å‡ºè‡ª(Peters et. al., 2017, McCann et. al., 2017, and yet again Peters et. al., 2018 in the ELMo paper )</p><blockquote><p>â€œ Wait a minute â€è¿™æ˜¯ä¸€ä¸ªæ¬§ç¾æ—¥å¸¸æ¢—ï¼Œç¤ºä¾‹ï¼š</p></blockquote><blockquote><p>â€‹                         æˆ‘ï¼šå…„å¼Ÿï¼Œä½ è®¤çœŸå­¦ä¹ æ·±åº¦ï¼Œæ²¡å‡†èƒ½æ‹¿80Wå¹´è–ªå•Šã€‚</p></blockquote><blockquote><p>â€‹                         ä½ ï¼šWait a minuteï¼Œè¿™ä¹ˆå¥½ï¼Œä½ ä¸ºå•¥ä¸åšã€‚ </p></blockquote><p>è¿™å’Œä¸­æ–‡çš„åŒéŸ³å­—å…¶å®ä¹Ÿç±»ä¼¼ï¼Œç”¨è¿™ä¸ªä¸¾ä¸€ä¸ªä¾‹å­å§ï¼Œ â€˜é•¿â€™ è¿™ä¸ªå­—ï¼Œåœ¨ â€˜é•¿åº¦â€™ è¿™ä¸ªè¯ä¸­è¡¨ç¤ºåº¦é‡ï¼Œåœ¨ â€˜é•¿é«˜â€™ è¿™ä¸ªè¯ä¸­è¡¨ç¤ºå¢åŠ ã€‚é‚£ä¹ˆä¸ºä»€ä¹ˆæˆ‘ä»¬ä¸é€šè¿‡â€é•¿â€™å‘¨å›´æ˜¯åº¦æˆ–è€…æ˜¯é«˜æ¥åˆ¤æ–­å®ƒçš„è¯»éŸ³æˆ–è€…å®ƒçš„è¯­ä¹‰å‘¢ï¼Ÿå—–å˜ï¼Œè¿™ä¸ªé—®é¢˜å°±æ´¾ç”Ÿå‡ºè¯­å¢ƒåŒ–çš„è¯åµŒå…¥æ¨¡å‹ã€‚</p><p><img src="https://uploader.shimo.im/f/AahBpyq3tDodAsMn.png!thumbnail" alt="img"></p><p>EMLoæ”¹å˜Word2vecç±»çš„å°†å•è¯å›ºå®šä¸ºæŒ‡å®šé•¿åº¦çš„å‘é‡çš„å¤„ç†æ–¹å¼ï¼Œå®ƒæ˜¯åœ¨ä¸ºæ¯ä¸ªå•è¯åˆ†é…è¯å‘é‡ä¹‹å‰å…ˆæŸ¥çœ‹æ•´ä¸ªå¥å­ï¼Œç„¶åä½¿ç”¨bi-LSTMæ¥è®­ç»ƒå®ƒå¯¹åº”çš„è¯å‘é‡ã€‚</p><p><img src="https://uploader.shimo.im/f/IPV3LOYXmr8m8GN7.png!thumbnail" alt="img"></p><p>ELMoä¸ºè§£å†³NLPçš„è¯­å¢ƒé—®é¢˜ä½œå‡ºäº†é‡è¦çš„è´¡çŒ®ï¼Œå®ƒçš„LSTMå¯ä»¥ä½¿ç”¨ä¸æˆ‘ä»¬ä»»åŠ¡ç›¸å…³çš„å¤§é‡æ–‡æœ¬æ•°æ®æ¥è¿›è¡Œè®­ç»ƒï¼Œç„¶åå°†è®­ç»ƒå¥½çš„æ¨¡å‹ç”¨ä½œå…¶ä»–NLPä»»åŠ¡çš„è¯å‘é‡çš„åŸºå‡†ã€‚</p><p>ELMoçš„ç§˜å¯†æ˜¯ä»€ä¹ˆï¼Ÿ</p><p>ELMoä¼šè®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œè¿™ä¸ªæ¨¡å‹æ¥å—ä¸€ä¸ªå¥å­æˆ–è€…å•è¯çš„è¾“å…¥,è¾“å‡ºæœ€æœ‰å¯èƒ½å‡ºç°åœ¨åé¢çš„ä¸€ä¸ªå•è¯ã€‚æƒ³æƒ³è¾“å…¥æ³•ï¼Œå¯¹å•¦ï¼Œå°±æ˜¯è¿™æ ·çš„é“ç†ã€‚è¿™ä¸ªåœ¨NLPä¸­æˆ‘ä»¬ä¹Ÿç§°ä½œLanguage Modelingã€‚è¿™æ ·çš„æ¨¡å‹å¾ˆå®¹æ˜“å®ç°ï¼Œå› ä¸ºæˆ‘ä»¬æ‹¥æœ‰å¤§é‡çš„æ–‡æœ¬æ•°æ®ä¸”æˆ‘ä»¬å¯ä»¥åœ¨ä¸éœ€è¦æ ‡ç­¾çš„æƒ…å†µä¸‹å»å­¦ä¹ ã€‚</p><p><img src="https://uploader.shimo.im/f/7z7sv9ALI24kQSst.png!thumbnail" alt="img"></p><p>ä¸Šå›¾ä»‹ç»äº†ELMoé¢„è®­ç»ƒçš„è¿‡ç¨‹çš„æ­¥éª¤çš„ä¸€éƒ¨åˆ†ï¼š</p><p>æˆ‘ä»¬éœ€è¦å®Œæˆä¸€ä¸ªè¿™æ ·çš„ä»»åŠ¡ï¼šè¾“å…¥â€œLets stick toâ€ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªæœ€å¯èƒ½å‡ºç°çš„å•è¯ï¼Œå¦‚æœåœ¨è®­ç»ƒé˜¶æ®µä½¿ç”¨å¤§é‡çš„æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œé‚£ä¹ˆåœ¨é¢„æµ‹é˜¶æ®µæˆ‘ä»¬å¯èƒ½å‡†ç¡®çš„é¢„æµ‹å‡ºæˆ‘ä»¬æœŸå¾…çš„ä¸‹ä¸€ä¸ªå•è¯ã€‚æ¯”å¦‚è¾“å…¥â€œæœºå™¨â€ï¼Œåœ¨â€˜â€™å­¦ä¹ â€˜å’Œâ€˜ä¹°èœâ€™ä¸­å®ƒæœ€æœ‰å¯èƒ½çš„è¾“å‡ºä¼šæ˜¯â€˜å­¦ä¹ â€™è€Œä¸æ˜¯â€˜ä¹°èœâ€™ã€‚</p><p>ä»ä¸Šå›¾å¯ä»¥å‘ç°ï¼Œæ¯ä¸ªå±•å¼€çš„LSTMéƒ½åœ¨æœ€åä¸€æ­¥å®Œæˆé¢„æµ‹ã€‚</p><p>å¯¹äº†çœŸæ­£çš„ELMoä¼šæ›´è¿›ä¸€æ­¥ï¼Œå®ƒä¸ä»…èƒ½åˆ¤æ–­ä¸‹ä¸€ä¸ªè¯ï¼Œè¿˜èƒ½é¢„æµ‹å‰ä¸€ä¸ªè¯ã€‚ï¼ˆBi-Lstmï¼‰</p><p><img src="https://uploader.shimo.im/f/HWw1FQCwDbUJkIi5.png!thumbnail" alt="img"></p><p>ELMoé€šè¿‡ä¸‹å›¾çš„æ–¹å¼å°†hidden statesï¼ˆçš„åˆå§‹çš„åµŒå…¥ï¼‰ç»„åˆå’‹å­ä¸€èµ·æ¥æç‚¼å‡ºå…·æœ‰è¯­å¢ƒæ„ä¹‰çš„è¯åµŒå…¥æ–¹å¼ï¼ˆå…¨è¿æ¥ååŠ æƒæ±‚å’Œï¼‰</p><p><img src="https://uploader.shimo.im/f/ZldUQJvmyjsiR5fx.png!thumbnail" alt="img"></p><p>ELMo pretrained embeddingå¯ä»¥åœ¨AllenNLPçš„repoä¸‹æ‰¾åˆ°</p><p><a href="https://github.com/allenai/allennlp/blob/master/tutorials/how_to/elmo.md" target="_blank" rel="noopener">https://github.com/allenai/allennlp/blob/master/tutorials/how_to/elmo.md</a></p><p>é¡ºä¾¿è¯´ä¸€ä¸‹AllenNLPæœ‰ä¸ªéå¸¸ä¸é”™çš„å…³äºNLPçš„æ•™ç¨‹</p><p><a href="https://github.com/allenai/writing-code-for-nlp-research-emnlp2018" target="_blank" rel="noopener">https://github.com/allenai/writing-code-for-nlp-research-emnlp2018</a></p><p>ELMoçš„å‡ ä½ä½œè€…éƒ½æ˜¯NLPåœˆå†…çš„çŸ¥åäººå£«</p><ul><li><p><a href="https://people.cs.umass.edu/~miyyer/" target="_blank" rel="noopener">Mohit Iyyer: UMass</a></p></li><li><p><a href="https://www.cs.washington.edu/people/faculty/lsz/" target="_blank" rel="noopener">Luke Zettlemoyer: UWashington</a></p></li><li><p><a href="https://matt-gardner.github.io/" target="_blank" rel="noopener">Matt Gardner: Allan AI</a></p></li></ul><h3 id="æ›´å¤šELMoçš„æ¨¡å‹å›¾ç‰‡"><a href="#æ›´å¤šELMoçš„æ¨¡å‹å›¾ç‰‡" class="headerlink" title="æ›´å¤šELMoçš„æ¨¡å‹å›¾ç‰‡"></a>æ›´å¤šELMoçš„æ¨¡å‹å›¾ç‰‡</h3><p><img src="https://uploader.shimo.im/f/khgCdxx0pNIaAVe3.png!thumbnail" alt="img"></p><p>å›¾ç‰‡æ¥æºï¼ˆ<a href="https://tsenghungchen.github.io/posts/elmo/ï¼‰" target="_blank" rel="noopener">https://tsenghungchen.github.io/posts/elmo/ï¼‰</a></p><p><img src="https://uploader.shimo.im/f/TId9a8gwTE0DTjua.png!thumbnail" alt="img"></p><p>å›¾ç‰‡æ¥æºï¼ˆ<a href="https://www.mihaileric.com/posts/deep-contextualized-word-representations-elmo/ï¼‰" target="_blank" rel="noopener">https://www.mihaileric.com/posts/deep-contextualized-word-representations-elmo/ï¼‰</a></p><h2 id="ULM-FiTï¼šNLPé¢†åŸŸåº”ç”¨è¿ç§»å­¦ä¹ "><a href="#ULM-FiTï¼šNLPé¢†åŸŸåº”ç”¨è¿ç§»å­¦ä¹ " class="headerlink" title="ULM-FiTï¼šNLPé¢†åŸŸåº”ç”¨è¿ç§»å­¦ä¹ "></a>ULM-FiTï¼šNLPé¢†åŸŸåº”ç”¨è¿ç§»å­¦ä¹ </h2><p>ULM-FiTæœºåˆ¶è®©æ¨¡å‹çš„é¢„è®­ç»ƒå‚æ•°å¾—åˆ°æ›´å¥½çš„åˆ©ç”¨ã€‚æ‰€åˆ©ç”¨çš„å‚æ•°ä¸ä»…é™äºembeddingsï¼Œä¹Ÿä¸ä»…é™äºè¯­å¢ƒembeddingï¼ŒULM-FiTå¼•å…¥äº†Language Modelå’Œä¸€ä¸ªæœ‰æ•ˆå¾®è°ƒè¯¥Language Modelæ¥æ‰§è¡Œå„ç§NLPä»»åŠ¡çš„æµç¨‹ã€‚è¿™ä½¿å¾—NLPä»»åŠ¡ä¹Ÿèƒ½åƒè®¡ç®—æœºè§†è§‰ä¸€æ ·æ–¹ä¾¿çš„ä½¿ç”¨è¿ç§»å­¦ä¹ ã€‚</p><h2 id="The-Transformerï¼šè¶…è¶ŠLSTMçš„ç»“æ„"><a href="#The-Transformerï¼šè¶…è¶ŠLSTMçš„ç»“æ„" class="headerlink" title="The Transformerï¼šè¶…è¶ŠLSTMçš„ç»“æ„"></a>The Transformerï¼šè¶…è¶ŠLSTMçš„ç»“æ„</h2><p>Transformerè®ºæ–‡å’Œä»£ç çš„å‘å¸ƒï¼Œä»¥åŠå…¶åœ¨æœºå™¨ç¿»è¯‘ç­‰ä»»åŠ¡ä¸Šå–å¾—çš„ä¼˜å¼‚æˆæœï¼Œè®©ä¸€äº›ç ”ç©¶äººå‘˜è®¤ä¸ºå®ƒæ˜¯LSTMçš„æ›¿ä»£å“ï¼Œäº‹å®ä¸Šå´æ˜¯Transformeræ¯”LSTMæ›´å¥½çš„å¤„ç†long-term dependanciesï¼ˆé•¿ç¨‹ä¾èµ–ï¼‰é—®é¢˜ã€‚Transformer Encodingå’ŒDecodingçš„ç»“æ„éå¸¸é€‚åˆæœºå™¨ç¿»è¯‘ï¼Œä½†æ˜¯æ€ä¹ˆåˆ©ç”¨ä»–æ¥åšæ–‡æœ¬åˆ†ç±»çš„ä»»åŠ¡å‘¢ï¼Ÿå®é™…ä¸Šä½ åªç”¨ä½¿ç”¨å®ƒæ¥é¢„è®­ç»ƒå¯ä»¥é’ˆå¯¹å…¶ä»–ä»»åŠ¡å¾®è°ƒçš„è¯­è¨€æ¨¡å‹å³å¯ã€‚</p><h2 id="OpenAI-Transformerï¼šç”¨äºè¯­è¨€æ¨¡å‹çš„Transformerè§£ç å™¨é¢„è®­ç»ƒ"><a href="#OpenAI-Transformerï¼šç”¨äºè¯­è¨€æ¨¡å‹çš„Transformerè§£ç å™¨é¢„è®­ç»ƒ" class="headerlink" title="OpenAI Transformerï¼šç”¨äºè¯­è¨€æ¨¡å‹çš„Transformerè§£ç å™¨é¢„è®­ç»ƒ"></a>OpenAI Transformerï¼šç”¨äºè¯­è¨€æ¨¡å‹çš„Transformerè§£ç å™¨é¢„è®­ç»ƒ</h2><p>äº‹å®è¯æ˜ï¼Œæˆ‘ä»¬å¹¶ä¸éœ€è¦ä¸€ä¸ªå®Œæ•´çš„transformerç»“æ„æ¥ä½¿ç”¨è¿ç§»å­¦ä¹ å’Œä¸€ä¸ªå¾ˆå¥½çš„è¯­è¨€æ¨¡å‹æ¥å¤„ç†NLPä»»åŠ¡ã€‚æˆ‘ä»¬åªéœ€è¦Transformerçš„è§£ç å™¨å°±è¡Œäº†ã€‚The decoder is a good choice because itâ€™s a natural choice for language modeling (predicting the next word) since itâ€™s built to mask future tokens â€“ a valuable feature when itâ€™s generating a translation word by word.</p><p><img src="https://uploader.shimo.im/f/cBZwrEweFIQLuP0O.png!thumbnail" alt="img"></p><p>è¯¥æ¨¡å‹å †å äº†åäºŒä¸ªDecoderå±‚ã€‚ ç”±äºåœ¨è¯¥è®¾ç½®ä¸­æ²¡æœ‰Encoderï¼Œå› æ­¤è¿™äº›Decoderå°†ä¸å…·æœ‰Transformer Decoderå±‚å…·æœ‰çš„Encoder - Decoder attentionå±‚ã€‚ ç„¶è€Œï¼Œå–è€Œä»£ä¹‹çš„æ˜¯ä¸€ä¸ªself attentionå±‚ï¼ˆmasked so it doesnâ€™t peak at future tokensï¼‰ã€‚</p><p>é€šè¿‡è¿™ç§ç»“æ„è°ƒæ•´ï¼Œæˆ‘ä»¬å¯ä»¥ç»§ç»­åœ¨ç›¸ä¼¼çš„è¯­è¨€æ¨¡å‹ä»»åŠ¡ä¸Šè®­ç»ƒæ¨¡å‹ï¼šä½¿ç”¨å¤§é‡çš„æœªæ ‡è®°æ•°æ®é›†è®­ç»ƒï¼Œæ¥é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ã€‚ä¸¾ä¸ªåˆ—å­ï¼šä½ é‚£7000æœ¬ä¹¦å–‚ç»™ä½ çš„æ¨¡å‹ï¼Œï¼ˆä¹¦ç±æ˜¯æå¥½çš„è®­ç»ƒæ ·æœ¬~æ¯”åšå®¢å’Œæ¨æ–‡å¥½å¾ˆå¤šã€‚ï¼‰è®­ç»ƒæ¡†æ¶å¦‚ä¸‹ï¼š</p><p><img src="https://uploader.shimo.im/f/KdcfSdkeNBIb5iRT.png!thumbnail" alt="img"></p><h2 id="Transfer-Learning-to-Downstream-Tasks"><a href="#Transfer-Learning-to-Downstream-Tasks" class="headerlink" title="Transfer Learning to Downstream Tasks"></a>Transfer Learning to Downstream Tasks</h2><p>é€šè¿‡OpenAIçš„transformerçš„é¢„è®­ç»ƒå’Œä¸€äº›å¾®è°ƒåï¼Œæˆ‘ä»¬å°±å¯ä»¥å°†è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œç”¨äºå…¶ä»–ä¸‹æ¸¸NLPä»»åŠ¡å•¦ã€‚ï¼ˆæ¯”å¦‚è®­ç»ƒä¸€ä¸ªè¯­è¨€æ¨¡å‹ï¼Œç„¶åæ‹¿ä»–çš„hidden stateæ¥åšåˆ†ç±»ã€‚ï¼‰ï¼Œä¸‹é¢å°±ä»‹ç»ä¸€ä¸‹è¿™ä¸ªéªšæ“ä½œã€‚ï¼ˆè¿˜æ˜¯å¦‚ä¸Šé¢ä¾‹å­ï¼šåˆ†ä¸ºåƒåœ¾é‚®ä»¶å’Œéåƒåœ¾é‚®ä»¶ï¼‰</p><p><img src="https://uploader.shimo.im/f/7x6X4ngskaEUd6sY.png!thumbnail" alt="img"></p><p>OpenAIè®ºæ–‡æ¦‚è¿°äº†è®¸å¤šTransformerä½¿ç”¨è¿ç§»å­¦ä¹ æ¥å¤„ç†ä¸åŒç±»å‹NLPä»»åŠ¡çš„ä¾‹å­ã€‚å¦‚ä¸‹å›¾ä¾‹å­æ‰€ç¤ºï¼š</p><p><img src="https://uploader.shimo.im/f/P4V9NbGQz9Q2k213.png!thumbnail" alt="img"></p><h2 id="BERT-From-Decoders-to-Encoders"><a href="#BERT-From-Decoders-to-Encoders" class="headerlink" title="BERT: From Decoders to Encoders"></a>BERT: From Decoders to Encoders</h2><p>OpenAI transformerä¸ºæˆ‘ä»¬æä¾›äº†åŸºäºTransformerçš„ç²¾å¯†çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚ä½†æ˜¯ä»LSTMåˆ°Transformerçš„è¿‡æ¸¡ä¸­ï¼Œæˆ‘ä»¬å‘ç°å°‘äº†äº›ä¸œè¥¿ã€‚ELMoçš„è¯­è¨€æ¨¡å‹æ˜¯åŒå‘çš„ï¼Œä½†æ˜¯OpenAIçš„transformeræ˜¯å‰å‘è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ã€‚æˆ‘ä»¬èƒ½å¦è®©æˆ‘ä»¬çš„Transformeræ¨¡å‹ä¹Ÿå…·æœ‰Bi-Lstmçš„ç‰¹æ€§å‘¢ï¼Ÿ</p><p>R-BERTï¼šâ€œHold my beerâ€</p><h2 id="Masked-Language-Model"><a href="#Masked-Language-Model" class="headerlink" title="Masked Language Model"></a>Masked Language Model</h2><p>BERTè¯´ï¼šâ€œæˆ‘è¦ç”¨ transformer çš„ encodersâ€</p><p>Ernieä¸å±‘é“ï¼šâ€œå‘µå‘µï¼Œä½ ä¸èƒ½åƒBi-Lstmä¸€æ ·è€ƒè™‘æ–‡ç« â€</p><p>BERTè‡ªä¿¡å›ç­”é“ï¼šâ€œæˆ‘ä»¬ä¼šç”¨masksâ€</p><blockquote><p>è§£é‡Šä¸€ä¸‹Maskï¼š</p></blockquote><blockquote></blockquote><blockquote><p>è¯­è¨€æ¨¡å‹ä¼šæ ¹æ®å‰é¢å•è¯æ¥é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ï¼Œä½†æ˜¯self-attentionçš„æ³¨æ„åŠ›åªä¼šæ”¾åœ¨è‡ªå·±èº«ä¸Šï¼Œé‚£ä¹ˆè¿™æ ·100%é¢„æµ‹åˆ°è‡ªå·±ï¼Œæ¯«æ— æ„ä¹‰ï¼Œæ‰€ä»¥ç”¨Maskï¼ŒæŠŠéœ€è¦é¢„æµ‹çš„è¯ç»™æŒ¡ä½ã€‚</p></blockquote><p>å¦‚ä¸‹å›¾ï¼š</p><p><img src="https://uploader.shimo.im/f/jvcJ8SPeBEwszR8M.png!thumbnail" alt="img"></p><h2 id="Two-sentence-Tasks"><a href="#Two-sentence-Tasks" class="headerlink" title="Two-sentence Tasks"></a>Two-sentence Tasks</h2><p>æˆ‘ä»¬å›é¡¾ä¸€ä¸‹OpenAI transformerå¤„ç†ä¸åŒä»»åŠ¡çš„è¾“å…¥è½¬æ¢ï¼Œä½ ä¼šå‘ç°åœ¨æŸäº›ä»»åŠ¡ä¸Šæˆ‘ä»¬éœ€è¦2ä¸ªå¥å­ä½œä¸ºè¾“å…¥ï¼Œå¹¶åšä¸€äº›æ›´ä¸ºæ™ºèƒ½çš„åˆ¤æ–­ï¼Œæ¯”å¦‚æ˜¯å¦ç›¸ä¼¼ï¼Œæ¯”å¦‚ ç»™å‡ºä¸€ä¸ªç»´åŸºç™¾ç§‘çš„å†…å®¹ä½œä¸ºè¾“å…¥ï¼ŒåŒæ—¶åœ¨æ”¾å…¥ä¸€æ¡é’ˆå¯¹è¯¥æ¡ç›®çš„é—®é¢˜ï¼Œé‚£ä¹ˆæˆ‘ä»¬çš„ç®—æ³•æ¨¡å‹èƒ½å¤Ÿå¤„ç†è¿™ä¸ªé—®é¢˜å—ï¼Ÿ</p><p>ä¸ºäº†ä½¿BERTæ›´å¥½çš„å¤„ç†2ä¸ªå¥å­ä¹‹é—´çš„å…³ç³»ï¼Œé¢„è®­ç»ƒçš„è¿‡ç¨‹è¿˜æœ‰ä¸€ä¸ªé¢å¤–çš„ä»»åŠ¡ï¼šç»™å®š2ä¸ªå¥å­ï¼ˆAå’ŒBï¼‰,Aä¸Bæ˜¯å¦ç›¸ä¼¼ï¼Ÿï¼ˆ0æˆ–è€…1ï¼‰</p><h2 id="ç‰¹æ®ŠNLPä»»åŠ¡"><a href="#ç‰¹æ®ŠNLPä»»åŠ¡" class="headerlink" title="ç‰¹æ®ŠNLPä»»åŠ¡"></a>ç‰¹æ®ŠNLPä»»åŠ¡</h2><p>BERTçš„è®ºæ–‡ä¸ºæˆ‘ä»¬ä»‹ç»äº†å‡ ç§BERTå¯ä»¥å¤„ç†çš„NLPä»»åŠ¡ï¼š</p><ol><li><p>çŸ­æ–‡æœ¬ç›¸ä¼¼ </p></li><li><p>æ–‡æœ¬åˆ†ç±»</p></li><li><p>QAæœºå™¨äºº</p></li><li><p>è¯­ä¹‰æ ‡æ³¨</p></li></ol><p><img src="https://uploader.shimo.im/f/yKFxOevBvMQXvjnv.png!thumbnail" alt="img"></p><h2 id="BERTç”¨åšç‰¹å¾æå–"><a href="#BERTç”¨åšç‰¹å¾æå–" class="headerlink" title="BERTç”¨åšç‰¹å¾æå–"></a>BERTç”¨åšç‰¹å¾æå–</h2><p>å¾®è°ƒæ–¹æ³•å¹¶ä¸æ˜¯ä½¿ç”¨BERTçš„å”¯ä¸€æ–¹æ³•ï¼Œå°±åƒELMoä¸€æ ·ï¼Œä½ å¯ä»¥ä½¿ç”¨é¢„é€‰è®­ç»ƒå¥½çš„BERTæ¥åˆ›å»ºè¯­å¢ƒåŒ–è¯åµŒå…¥ã€‚ç„¶åä½ å¯ä»¥å°†è¿™äº›åµŒå…¥æä¾›ç»™ç°æœ‰çš„æ¨¡å‹ã€‚</p><p><img src="https://uploader.shimo.im/f/uKUkG73gELQGry4L.png!thumbnail" alt="img"></p><p>å“ªä¸ªå‘é‡æœ€é€‚åˆä½œä¸ºä¸Šä¸‹æ–‡åµŒå…¥ï¼Ÿ æˆ‘è®¤ä¸ºè¿™å–å†³äºä»»åŠ¡ã€‚ æœ¬æ–‡è€ƒå¯Ÿäº†å…­ç§é€‰æ‹©ï¼ˆä¸å¾®è°ƒæ¨¡å‹ç›¸æ¯”ï¼Œå¾—åˆ†ä¸º96.4ï¼‰ï¼š</p><p><img src="https://uploader.shimo.im/f/bfpUyWE9YCEP9IU2.png!thumbnail" alt="img"></p><h1 id="å¦‚ä½•ä½¿ç”¨BERT"><a href="#å¦‚ä½•ä½¿ç”¨BERT" class="headerlink" title="å¦‚ä½•ä½¿ç”¨BERT"></a>å¦‚ä½•ä½¿ç”¨BERT</h1><p>ä½¿ç”¨BERTçš„æœ€ä½³æ–¹å¼æ˜¯é€šè¿‡ BERT FineTuning with Cloud TPUs (<a href="https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb" target="_blank" rel="noopener">https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb</a>) è°·æ­Œäº‘ä¸Šæ‰˜ç®¡çš„ç¬”è®°ã€‚å¦‚æœä½ æœªä½¿ç”¨è¿‡è°·æ­Œäº‘TPUå¯ä»¥è¯•è¯•çœ‹ï¼Œè¿™æ˜¯ä¸ªä¸é”™çš„å°è¯•ã€‚å¦å¤–BERTä¹Ÿé€‚ç”¨äºTPUï¼ŒCPUå’ŒGPU</p><p>ä¸‹ä¸€æ­¥æ˜¯æŸ¥çœ‹BERTä»“åº“ä¸­çš„ä»£ç ï¼š</p><ol><li><p>è¯¥æ¨¡å‹åœ¨modeling.pyï¼ˆBertModelç±»ï¼‰ä¸­æ„å»ºï¼Œä¸vanilla Transformerç¼–ç å™¨å®Œå…¨ç›¸åŒã€‚</p></li><li><p>run_classifier.pyæ˜¯å¾®è°ƒè¿‡ç¨‹çš„ä¸€ä¸ªç¤ºä¾‹ã€‚å®ƒè¿˜æ„å»ºäº†ç›‘ç£æ¨¡å‹çš„åˆ†ç±»å±‚ã€‚å¦‚æœè¦æ„å»ºè‡ªå·±çš„åˆ†ç±»å™¨ï¼Œè¯·æŸ¥çœ‹è¯¥æ–‡ä»¶ä¸­çš„create_model()æ–¹æ³•ã€‚</p></li><li><p>å¯ä»¥ä¸‹è½½å‡ ç§é¢„å…ˆè®­ç»ƒçš„æ¨¡å‹ã€‚æ¶µç›–102ç§è¯­è¨€çš„å¤šè¯­è¨€æ¨¡å‹ï¼Œè¿™äº›è¯­è¨€éƒ½æ˜¯åœ¨ç»´åŸºç™¾ç§‘çš„æ•°æ®åŸºç¡€ä¸Šè®­ç»ƒè€Œæˆçš„ã€‚</p></li><li><p>BERTä¸ä¼šå°†å•è¯è§†ä¸ºtokensã€‚ç›¸åï¼Œå®ƒæ³¨é‡WordPiecesã€‚ tokenization.pyæ˜¯å°†ä½ çš„å•è¯è½¬æ¢ä¸ºé€‚åˆBERTçš„wordPiecesçš„tokensizerã€‚</p></li></ol><p>æˆ‘è‡ªå·±ç»™BERTçš„ä»£ç å¢åŠ äº†ä¸€äº›æ³¨è§£</p><p><a href="https://github.com/ZeweiChu/bert/blob/master/modeling.py" target="_blank" rel="noopener">https://github.com/ZeweiChu/bert/blob/master/modeling.py</a></p><p>é‡ç‚¹å…³æ³¨å…¶ä¸­çš„ï¼š</p><ul><li><p>attention_layer: <a href="https://github.com/ZeweiChu/bert/blob/master/modeling.py#L638" target="_blank" rel="noopener">https://github.com/ZeweiChu/bert/blob/master/modeling.py#L638</a></p></li><li><p>transformer_model: <a href="https://github.com/ZeweiChu/bert/blob/master/modeling.py#L868" target="_blank" rel="noopener">https://github.com/ZeweiChu/bert/blob/master/modeling.py#L868</a></p></li></ul><p>BERTçš„å¾ˆå¤šä»»åŠ¡åŸºäºGLUE benchmark</p><p><a href="https://gluebenchmark.com/tasks/" target="_blank" rel="noopener">https://gluebenchmark.com/tasks/</a></p><p><a href="https://openreview.net/pdf?id=rJ4km2R5t7" target="_blank" rel="noopener">https://openreview.net/pdf?id=rJ4km2R5t7</a></p><p>æœ€è¿‘è¿˜æœ‰ä¸€ä¸ªSuperGLUE</p><p><a href="https://w4ngatang.github.io/static/papers/superglue.pdf" target="_blank" rel="noopener">https://w4ngatang.github.io/static/papers/superglue.pdf</a></p><p>æ‚¨è¿˜å¯ä»¥æŸ¥çœ‹BERTçš„PyTorchå®ç° (<a href="https://github.com/huggingface/pytorch-transformers)ã€‚" target="_blank" rel="noopener">https://github.com/huggingface/pytorch-transformers)ã€‚</a> AllenNLPåº“ä½¿ç”¨æ­¤å®ç°å…è®¸å°†BERTåµŒå…¥ä¸ä»»ä½•æ¨¡å‹ä¸€èµ·ä½¿ç”¨ã€‚</p><p>æœ€è¿‘NVIDIAå¼€æºäº†ä»–ä»¬53åˆ†é’Ÿè®­ç»ƒBERTçš„ä»£ç </p><p><a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/LanguageModeling/BERT" target="_blank" rel="noopener">https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/LanguageModeling/BERT</a></p><hr><h1 id="å‚è€ƒæ–‡çŒ®"><a href="#å‚è€ƒæ–‡çŒ®" class="headerlink" title="å‚è€ƒæ–‡çŒ®"></a>å‚è€ƒæ–‡çŒ®</h1><p>BERTå…¨æ–‡ç¿»è¯‘æˆä¸­æ–‡</p><p><a href="https://zhuanlan.zhihu.com/p/59775981" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/59775981</a></p><p>å›¾è§£ BERT æ¨¡å‹ï¼šä»é›¶å¼€å§‹æ„å»º BERT</p><p><a href="https://flashgene.com/archives/20062.html" target="_blank" rel="noopener">https://flashgene.com/archives/20062.html</a></p><p>NLPå¿…è¯»ï¼šååˆ†é’Ÿè¯»æ‡‚è°·æ­ŒBERTæ¨¡å‹</p><p><a href="https://zhuanlan.zhihu.com/p/51413773" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/51413773</a></p><p>BERT Explained: State of the art language model for NLP</p><p><a href="https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270" target="_blank" rel="noopener">https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270</a></p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> BERT </tag>
            
            <tag> ELMo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>å¤§è§„æ¨¡æ— ç›‘ç£é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ä¸åº”ç”¨ä¸Š</title>
      <link href="/2020/05/01/%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%97%A0%E7%9B%91%E7%9D%A3%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%BA%94%E7%94%A8%E4%B8%8A/"/>
      <url>/2020/05/01/%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%97%A0%E7%9B%91%E7%9D%A3%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%BA%94%E7%94%A8%E4%B8%8A/</url>
      
        <content type="html"><![CDATA[<h3 id="Subword-Modeling"><a href="#Subword-Modeling" class="headerlink" title="Subword Modeling"></a>Subword Modeling</h3><p>ä»¥å•è¯ä½œä¸ºæ¨¡å‹çš„åŸºæœ¬å•ä½æœ‰ä¸€äº›é—®é¢˜ï¼š</p><ul><li><p>å•è¯é‡æœ‰é™ï¼Œæˆ‘ä»¬ä¸€èˆ¬ä¼šæŠŠå•è¯é‡å›ºå®šåœ¨50k-300kï¼Œç„¶åæ²¡æœ‰è§è¿‡çš„å•è¯åªèƒ½ç”¨<strong>UNK</strong>è¡¨ç¤º</p></li><li><p>zipf distribution: given some corpus of natural language utterances, the frequency of any word is inversely proportional to its rank in the frequency table. Thus the most frequent word will occur approximately twice as often as the second most frequent word, three times as often as the third most frequent word, etc.: the rank-frequency distribution is an inverse relation. </p></li><li><p>æ¨¡å‹å‚æ•°é‡å¤ªå¤§ï¼Œ100K * 300 = 30Mä¸ªå‚æ•°ï¼Œä»…ä»…æ˜¯embeddingå±‚</p></li><li><p>å¯¹äºå¾ˆå¤šè¯­è¨€ï¼Œä¾‹å¦‚è‹±è¯­æ¥è¯´ï¼Œå¾ˆå¤šæ—¶å€™å•è¯æ˜¯ç”±å‡ ä¸ªsubwordæ‹¼æ¥è€Œæˆçš„</p></li><li><p>å¯¹äºä¸­æ–‡æ¥è¯´ï¼Œå¾ˆå¤šå¸¸ç”¨çš„æ¨¡å‹ä¼šé‡‡ç”¨åˆ†è¯åå¾—åˆ°çš„è¯è¯­ä½œä¸ºæ¨¡å‹çš„åŸºæœ¬å•å…ƒï¼ŒåŒæ ·å­˜åœ¨ä¸Šè¿°é—®é¢˜</p></li></ul><p>å¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼š</p><ul><li><p>ä½¿ç”¨subword informationï¼Œä¾‹å¦‚å­—æ¯ä½œä¸ºè¯­è¨€çš„åŸºæœ¬å•å…ƒ Char-CNN</p></li><li><p>ç”¨wordpiece</p></li></ul><h2 id="è§£å†³æ–¹æ¡ˆï¼šcharacter-level-modeling"><a href="#è§£å†³æ–¹æ¡ˆï¼šcharacter-level-modeling" class="headerlink" title="è§£å†³æ–¹æ¡ˆï¼šcharacter level modeling"></a>è§£å†³æ–¹æ¡ˆï¼šcharacter level modeling</h2><ul><li>ä½¿ç”¨å­—æ¯ä½œä¸ºæ¨¡å‹çš„åŸºæœ¬è¾“å…¥å•å…ƒ</li></ul><h3 id="Ling-et-al-Finding-Function-in-Form-Compositional-Character-Models-for-Open-Vocabulary-Word-Representation"><a href="#Ling-et-al-Finding-Function-in-Form-Compositional-Character-Models-for-Open-Vocabulary-Word-Representation" class="headerlink" title="Ling et. al, Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation"></a>Ling et. al, <a href="https://aclweb.org/anthology/D15-1176" target="_blank" rel="noopener">Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation</a></h3><p>ç”¨BiLSTMæŠŠå•è¯ä¸­çš„æ¯ä¸ªå­—æ¯encodeåˆ°ä¸€èµ·</p><p><img src="https://uploader.shimo.im/f/V49ti0noVOsqeLRH.png!thumbnail" alt="img"></p><h3 id="Yoon-Kim-et-al-Character-Aware-Neural-Language-Models"><a href="#Yoon-Kim-et-al-Character-Aware-Neural-Language-Models" class="headerlink" title="Yoon Kim et. al, Character-Aware Neural Language Models"></a>Yoon Kim et. al, <a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/viewFile/12489/12017" target="_blank" rel="noopener">Character-Aware Neural Language Models</a></h3><p><img src="https://uploader.shimo.im/f/bsR8NzGROvs0scpq.png!thumbnail" alt="img"></p><p>æ ¹æ®ä»¥ä¸Šæ¨¡å‹ç¤ºæ„å›¾æ€è€ƒä»¥ä¸‹é—®é¢˜ï¼š</p><ul><li><p>character emebddingçš„çš„ç»´åº¦æ˜¯å¤šå°‘ï¼Ÿ4</p></li><li><p>æœ‰å‡ ä¸ªcharacter 4-gramçš„filterï¼Ÿfilter-size=4? çº¢è‰²çš„ 5ä¸ªfilter</p></li><li><p>max-over-time pooling: 3-gram 4ç»´ï¼Œ 2-gram 3ç»´ 4-gram 55ç»´</p></li><li><p>ä¸ºä»€ä¹ˆä¸åŒçš„filter (kernel size)é•¿åº¦ä¼šå¯¼è‡´ä¸åŒé•¿åº¦çš„feature map?  seq_length - kernel_size + 1</p></li></ul><p>fastText</p><ul><li>ä¸word2vecç±»ä¼¼ï¼Œä½†æ˜¯æ¯ä¸ªå•è¯æ˜¯å®ƒçš„character n-gram embeddings + word emebdding</li></ul><h2 id="è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨subwordä½œä¸ºæ¨¡å‹çš„åŸºæœ¬å•å…ƒ"><a href="#è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨subwordä½œä¸ºæ¨¡å‹çš„åŸºæœ¬å•å…ƒ" class="headerlink" title="è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨subwordä½œä¸ºæ¨¡å‹çš„åŸºæœ¬å•å…ƒ"></a>è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨subwordä½œä¸ºæ¨¡å‹çš„åŸºæœ¬å•å…ƒ</h2><h3 id="Botha-amp-Blunsom-2014-Composional-Morphology-for-Word-Representations-and-Language-Modelling"><a href="#Botha-amp-Blunsom-2014-Composional-Morphology-for-Word-Representations-and-Language-Modelling" class="headerlink" title="Botha &amp; Blunsom (2014): Composional Morphology for Word Representations    and    Language Modelling"></a>Botha &amp; Blunsom (2014): <a href="http://proceedings.mlr.press/v32/botha14.pdf" target="_blank" rel="noopener">Composional Morphology for Word Representations    and    Language Modelling</a></h3><p><img src="https://uploader.shimo.im/f/FplKX422O5owOuVV.png!thumbnail" alt="img"></p><p>subword embedding</p><p><img src="https://uploader.shimo.im/f/3nQUw9cZGvwNSCyx.png!thumbnail" alt="img"></p><h3 id="Byte-Pair-Encoding-éœ€è¦çŸ¥é“ä»€ä¹ˆæ˜¯BPE"><a href="#Byte-Pair-Encoding-éœ€è¦çŸ¥é“ä»€ä¹ˆæ˜¯BPE" class="headerlink" title="Byte Pair Encoding (éœ€è¦çŸ¥é“ä»€ä¹ˆæ˜¯BPE)"></a>Byte Pair Encoding (éœ€è¦çŸ¥é“ä»€ä¹ˆæ˜¯BPE)</h3><p><a href="https://www.aclweb.org/anthology/P16-1162" target="_blank" rel="noopener">Neural Machine Translation of Rare Words with Subword Units</a></p><p>å…³äºä»€ä¹ˆæ˜¯BPEå¯ä»¥å‚è€ƒä¸‹é¢çš„æ–‡ç« </p><p><a href="https://www.cnblogs.com/huangyc/p/10223075.html" target="_blank" rel="noopener">https://www.cnblogs.com/huangyc/p/10223075.html</a></p><p><a href="https://leimao.github.io/blog/Byte-Pair-Encoding/" target="_blank" rel="noopener">https://leimao.github.io/blog/Byte-Pair-Encoding/</a></p><ul><li><p>é¦–å…ˆå®šä¹‰æ‰€æœ‰å¯èƒ½çš„åŸºæœ¬å­—ç¬¦ï¼ˆabcdeâ€¦ï¼‰</p></li><li><p>ç„¶åå¼€å§‹å¾ªç¯æ•°å‡ºæœ€ç»å¸¸å‡ºç°çš„pairsï¼ŒåŠ å…¥åˆ°æˆ‘ä»¬çš„å€™é€‰å­—ç¬¦ï¼ˆåŸºæœ¬ç»„æˆå•å…ƒï¼‰ä¸­å»</p></li></ul><p>a, b, c, d, â€¦, z, A, B, â€¦., Z.. !, @, ?, st, est, lo, low, </p><p>æ§åˆ¶å•è¯è¡¨çš„å¤§å°</p><ul><li>æˆ‘åªè¦ç¡®å®šiterationçš„æ¬¡æ•° 30000ä¸ªiteartionï¼Œ30000+åŸå§‹å­—æ¯è¡¨å½“ä¸­çš„å­—æ¯æ•° ä¸ªå•è¯</li></ul><p>happiest</p><p>h a p p i est</p><p>LSTM</p><p>emb(h), emb(a), emb(p), emb(p), emb(i), emb(est)</p><p>happ, iest</p><p>emb(happ), emb(iest)</p><p><img src="https://uploader.shimo.im/f/0zx2ooI2uzoWLfOg.png!thumbnail" alt="img"></p><p><a href="https://www.aclweb.org/anthology/P16-1162.pdf" target="_blank" rel="noopener">https://www.aclweb.org/anthology/P16-1162.pdf</a></p><h2 id="ä¸­æ–‡è¯å‘é‡"><a href="#ä¸­æ–‡è¯å‘é‡" class="headerlink" title="ä¸­æ–‡è¯å‘é‡"></a>ä¸­æ–‡è¯å‘é‡</h2><h3 id="Meng-et-al-Is-Word-Segmentation-Necessary-for-Deep-Learning-of-Chinese-Representations"><a href="#Meng-et-al-Is-Word-Segmentation-Necessary-for-Deep-Learning-of-Chinese-Representations" class="headerlink" title="Meng et. al, Is Word Segmentation Necessary for Deep Learning of Chinese Representations?"></a>Meng et. al, <a href="https://arxiv.org/pdf/1905.05526.pdf" target="_blank" rel="noopener">Is Word Segmentation Necessary for Deep Learning of Chinese Representations?</a></h3><p>ç®€å•æ¥è¯´ï¼Œè¿™ç¯‡æ–‡ç« çš„ä½œè€…ç”Ÿæˆé€šè¿‡ä»–ä»¬çš„å®éªŒå‘ç°Chinese Word Segmentationå¯¹äºè¯­è¨€æ¨¡å‹ã€æ–‡æœ¬åˆ†ç±»ï¼Œç¿»è¯‘å’Œæ–‡æœ¬å…³ç³»åˆ†ç±»å¹¶æ²¡æœ‰ä»€ä¹ˆå¸®åŠ©ï¼Œç›´æ¥ä½¿ç”¨å•ä¸ªå­—ä½œä¸ºæ¨¡å‹çš„è¾“å…¥å¯ä»¥è¾¾åˆ°æ›´å¥½çš„æ•ˆæœã€‚</p><blockquote><p>We benchmark neural word-based models which rely on word segmentation against neural char-based models which do not involve word segmentation in four end-to-end NLP benchmark tasks: language modeling, machine translation, sentence matching/paraphrase and text classification. Through direct comparisons between these two types of models, we find that charbased models consistently outperform wordbased models.</p></blockquote><blockquote></blockquote><blockquote><p>word-based models are more vulnerable to data sparsity and the presence of out-of-vocabulary (OOV) words, and thus more prone to overfitting</p></blockquote><p>Jiwei Li</p><p><a href="https://nlp.stanford.edu/~bdlijiwei/" target="_blank" rel="noopener">https://nlp.stanford.edu/~bdlijiwei/</a></p><h3 id="ä¸­æ–‡åˆ†è¯å·¥å…·"><a href="#ä¸­æ–‡åˆ†è¯å·¥å…·" class="headerlink" title="ä¸­æ–‡åˆ†è¯å·¥å…·"></a>ä¸­æ–‡åˆ†è¯å·¥å…·</h3><p>å»ºè®®åŒå­¦ä»¬å¯ä»¥åœ¨è‡ªå·±çš„é¡¹ç›®ä¸­å°è¯•ä»¥ä¸‹å·¥å…·</p><ul><li><p>åŒ—å¤§ä¸­æ–‡åˆ†è¯å·¥å…· </p></li><li><p><a href="https://github.com/lancopku/pkuseg-python" target="_blank" rel="noopener">https://github.com/lancopku/pkuseg-python</a> </p></li><li><p>æœºå™¨ä¹‹å¿ƒæŠ¥é“ <a href="https://www.jiqizhixin.com/articles/2019-01-09-12" target="_blank" rel="noopener">https://www.jiqizhixin.com/articles/2019-01-09-12</a></p></li><li><p>æ¸…ååˆ†è¯å·¥å…· <a href="https://github.com/thunlp/THULAC-Python" target="_blank" rel="noopener">https://github.com/thunlp/THULAC-Python</a></p></li><li><p>ç»“å·´ <a href="https://github.com/fxsjy/jieba" target="_blank" rel="noopener">https://github.com/fxsjy/jieba</a></p></li></ul><h1 id="é¢„è®­ç»ƒå¥å­-æ–‡æ¡£å‘é‡"><a href="#é¢„è®­ç»ƒå¥å­-æ–‡æ¡£å‘é‡" class="headerlink" title="é¢„è®­ç»ƒå¥å­/æ–‡æ¡£å‘é‡"></a>é¢„è®­ç»ƒå¥å­/æ–‡æ¡£å‘é‡</h1><p>æ—¢ç„¶æœ‰è¯å‘é‡ï¼Œé‚£ä¹ˆæˆ‘ä»¬æ˜¯å¦å¯ä»¥æ›´è¿›ä¸€æ­¥ï¼ŒæŠŠå¥å­ç”šè‡³ä¸€æ•´ä¸ªæ–‡æ¡£ä¹Ÿç¼–ç æˆä¸€ä¸ªå‘é‡å‘¢ï¼Ÿ</p><p>åœ¨ä¹‹å‰çš„è¯¾ç¨‹ä¸­æˆ‘ä»¬å·²ç»æ¶‰åŠåˆ°äº†ä¸€äº›å¥å­çº§åˆ«çš„ä»»åŠ¡ï¼Œä¾‹å¦‚æ–‡æœ¬åˆ†ç±»ï¼Œå¸¸å¸¸å°±æ˜¯æŠŠä¸€å¥æˆ–è€…è‹¥å¹²å¥æ–‡æœ¬åˆ†ç±»æˆä¸€å®šçš„ç±»åˆ«ã€‚æ­¤ç±»æ¨¡å‹çš„ä¸€èˆ¬å®ç°æ–¹å¼æ˜¯é¦–å…ˆæŠŠæ–‡æœ¬ç¼–ç æˆæŸç§æ–‡æœ¬è¡¨ç¤ºæ–¹å¼ï¼Œä¾‹å¦‚averaged word embeddingsï¼Œæˆ–è€…åŒå‘LSTMå¤´å°¾æ‹¼æ¥ï¼Œæˆ–è€…CNNæ¨¡å‹ç­‰ç­‰ã€‚</p><p>æ–‡æœ¬åˆ†ç±»</p><ul><li><p>æ–‡æœ¬é€šè¿‡æŸç§æ–¹å¼å˜æˆä¸€ä¸ªå‘é‡</p></li><li><p>WORDAVG</p></li><li><p>LSTM</p></li><li><p>CNN</p></li><li><p>æœ€åæ˜¯ä¸€ä¸ªlinear layer 300ç»´å¥å­å‘é‡ â€“ã€‹ 2 æƒ…æ„Ÿåˆ†ç±»</p></li></ul><p>çŒ«å›¾ç‰‡/ç‹—å›¾ç‰‡</p><p>å›¾ç‰‡ â€“&gt; <strong>ResNet</strong> â€“&gt; 2048ç»´å‘é‡ â€“&gt; (2, 2048) â€“&gt; 2ç»´å‘é‡ binary cross entropy loss</p><p><strong>ResNet</strong> é¢„è®­ç»ƒæ¨¡å‹</p><p>æ–‡æœ¬ â€“&gt; TextResNet â€“&gt; 2048ç»´å‘é‡</p><p>apply to any downstream tasks</p><p>TextResNetï¼šLSTMæ¨¡å‹</p><p>ä¸åŒçš„ä»»åŠ¡ï¼ˆä¾‹å¦‚ä¸åŒçš„æ–‡æœ¬åˆ†ç±»ï¼šæƒ…æ„Ÿåˆ†ç±»ï¼Œè¯é¢˜åˆ†ç±»ï¼‰è™½ç„¶æœ€ç»ˆçš„è¾“å‡ºä¸åŒï¼Œä½†æ˜¯å¾€å¾€æ‹¥æœ‰ç€ç›¸ä¼¼ç”šè‡³å®Œå…¨ä¸€æ ·çš„ç¼–ç å±‚ã€‚å¦‚æœæˆ‘ä»¬èƒ½å¤Ÿé¢„è®­ç»ƒä¸€ä¸ªéå¸¸å¥½çš„ç¼–ç å±‚ï¼Œé‚£ä¹ˆåç»­æ¨¡å‹çš„è´Ÿæ‹…å°±å¯ä»¥åœ¨ä¸€å®šç¨‹åº¦ä¸Šå¾—åˆ°é™ä½ã€‚è¿™æ ·çš„æ€æƒ³å¾ˆå¤šæ˜¯æ¥è‡ªå›¾åƒå¤„ç†çš„ç›¸å…³å·¥ä½œã€‚ä¾‹å¦‚äººä»¬åœ¨å„ç±»å›¾åƒä»»åŠ¡ä¸­å‘ç°ï¼Œå¦‚æœä½¿ç”¨åœ¨ImageNetä¸Šé¢„è®­ç»ƒè¿‡çš„æ·±å±‚CNNç½‘ç»œï¼ˆä¾‹å¦‚ResNetï¼‰ï¼ŒåªæŠŠæœ€ç»ˆçš„è¾“å‡ºå±‚æ›¿æ¢æˆè‡ªå·±éœ€è¦çš„æ ·å­ï¼Œå¾€å¾€å¯ä»¥å–å¾—éå¸¸å¥½çš„æ•ˆæœï¼Œä¸”å¯ä»¥åœ¨å°‘é‡æ•°æ®çš„æƒ…å†µä¸‹è®­ç»ƒå‡ºä¼˜è´¨çš„æ¨¡å‹ã€‚</p><p>åœ¨å¥å­/æ–‡æœ¬å‘é‡é¢„è®­ç»ƒçš„é¢†åŸŸæ¶Œç°å‡ºäº†ä¸€ç³»åˆ—çš„å·¥ä½œï¼Œä¸‹é¢æˆ‘ä»¬é€‰å–ä¸€äº›æœ‰ä»£è¡¨æ€§çš„å·¥ä½œä¾›å¤§å®¶å­¦ä¹ å‚è€ƒã€‚</p><h2 id="Skip-Thought"><a href="#Skip-Thought" class="headerlink" title="Skip-Thought"></a>Skip-Thought</h2><p>Kiros et. al, <a href="https://papers.nips.cc/paper/5950-skip-thought-vectors.pdf" target="_blank" rel="noopener">Skip-Thought Vectors</a></p><p>skip-gram: distributional semantics of words ç”¨ä¸­å¿ƒè¯â€“ã€‹å‘¨å›´è¯</p><p>skip-thought: distributional semantics of sentences ç”¨ä¸­å¿ƒå¥â€“ã€‹å‘¨å›´å¥</p><p>ä¸¤ä¸ªå¥å­å¦‚æœæ€»æ˜¯åœ¨åŒä¸€ä¸ªç¯å¢ƒä¸‹å‡ºç°ï¼Œé‚£ä¹ˆè¿™ä¸¤ä¸ªå¥å­å¯èƒ½æœ‰æŸç§å«ä¹‰ä¸Šçš„è”ç³»</p><p>å¦‚ä½•æŠŠå¥å­mapæˆä¸€ä¸ªå‘é‡ï¼šcompositional modelï¼ŒRNN, LSTM, CNN, WordAvg, <strong>GRU</strong></p><p>Skip-thought æ¨¡å‹çš„æ€æƒ³éå¸¸ç®€å•ï¼Œæˆ‘ä»¬è®­ç»ƒä¸€ä¸ªåŸºäºGRUçš„æ¨¡å‹ä½œä¸ºå¥å­çš„ç¼–ç å™¨ã€‚äº‹å®ä¸ŠSkip-thoughtè¿™ä¸ªåå­—ä¸Skip-gramæœ‰ç€åƒä¸ä¸‡ç¼•çš„è”ç³»ï¼Œå®ƒä»¬åŸºäºä¸€ä¸ªå…±åŒçš„æ€æƒ³ï¼Œå°±æ˜¯ä¸€å¥è¯ï¼ˆä¸€ä¸ªå•è¯ï¼‰çš„å«ä¹‰ä¸å®ƒæ‰€å¤„çš„ç¯å¢ƒï¼ˆcontextï¼Œå‘¨å›´å¥å­/å•è¯ï¼‰é«˜åº¦ç›¸å…³ã€‚</p><p>å¦‚ä¸‹å›¾æ‰€ç¤ºï¼ŒSkipthoughté‡‡ç”¨ä¸€ä¸ªGRU encoderï¼Œä½¿ç”¨ç¼–ç å™¨æœ€åä¸€ä¸ªhidden stateæ¥è¡¨ç¤ºæ•´ä¸ªå¥å­ã€‚ç„¶åä½¿ç”¨è¿™ä¸ªhidden stateä½œä¸ºåˆå§‹çŠ¶æ€æ¥è§£ç å®ƒä¹‹å‰å’Œä¹‹åçš„å¥å­ã€‚</p><p>decoder: ä¸¤ä¸ªconditionalè¯­è¨€æ¨¡å‹ã€‚</p><p>åŸºäºä¸­å¿ƒå¥çš„å¥å­å‘é‡ï¼Œä¼˜åŒ–conditional log likelihood</p><p><img src="https://uploader.shimo.im/f/keW15vUeJX4E7gam.png!thumbnail" alt="img"></p><p>ä¸€ä¸ªencoder GRU</p><p><img src="https://uploader.shimo.im/f/XbXbCNlxSpk5PLuh.png!thumbnail" alt="img"></p><p>ä¸¤ä¸ªdecoder GRU</p><p><img src="https://uploader.shimo.im/f/atuHcc6hYNIE2QOd.png!thumbnail" alt="img"></p><p>è®­ç»ƒç›®æ ‡</p><p><img src="https://uploader.shimo.im/f/XCVPs561UVADzFkO.png!thumbnail" alt="img"></p><p>ç„¶åæˆ‘ä»¬å°±å¯ä»¥æŠŠencoderå½“åšfeature extractoräº†ã€‚</p><p>ç±»ä¼¼çš„å·¥ä½œè¿˜æœ‰<a href="https://arxiv.org/pdf/1602.03483.pdf" target="_blank" rel="noopener">FastSent</a>ã€‚FastSentç›´æ¥ä½¿ç”¨è¯å‘é‡ä¹‹å’Œæ¥è¡¨ç¤ºæ•´ä¸ªå¥å­ï¼Œç„¶åç”¨è¯¥å¥å­å‘é‡æ¥è§£ç å‘¨å›´å¥å­ä¸­çš„å•ä¸ªå•è¯ä»¬ã€‚</p><h2 id="InferSent"><a href="#InferSent" class="headerlink" title="InferSent"></a>InferSent</h2><p><a href="https://www.aclweb.org/anthology/D17-1070" target="_blank" rel="noopener">Supervised Learning of Universal Sentence Representations from Natural Language Inference Data</a></p><p>Natural Language Inference (NLI)</p><ul><li><p>ç»™å®šä¸¤ä¸ªå¥å­ï¼Œåˆ¤æ–­è¿™ä¸¤ä¸ªå¥å­ä¹‹é—´çš„å…³ç³»</p></li><li><p>entailment æ‰¿æ¥å…³ç³»</p></li><li><p>neutral æ²¡æœ‰å…³ç³»</p></li><li><p>contradiction çŸ›ç›¾</p></li><li><p>(non_entailment)</p></li></ul><h3 id="SNLIä»»åŠ¡"><a href="#SNLIä»»åŠ¡" class="headerlink" title="SNLIä»»åŠ¡"></a>SNLIä»»åŠ¡</h3><p>ç»™å®šä¸¤ä¸ªå¥å­ï¼Œé¢„æµ‹è¿™ä¸¤ä¸ªå¥å­çš„å…³ç³»æ˜¯entailment, contradictionï¼Œè¿˜æ˜¯neutral  </p><p>ä¸€ä¸ªç®€å•æœ‰æ•ˆçš„æ¨¡å‹</p><p><img src="https://uploader.shimo.im/f/bdClv9vmULUCXgcc.png!thumbnail" alt="img"></p><p>Encoderæ˜¯BiLSTM + max pooling</p><p><img src="https://uploader.shimo.im/f/Uiw1y8KX5pEw5Lri.png!thumbnail" alt="img"></p><p>æ¨¡å‹æ•ˆæœ</p><p><img src="https://uploader.shimo.im/f/kzvejsQ7DMI3369N.png!thumbnail" alt="img"></p><h2 id="SentEval"><a href="#SentEval" class="headerlink" title="SentEval"></a>SentEval</h2><p><a href="https://www.aclweb.org/anthology/L18-1269" target="_blank" rel="noopener">SentEval: An Evaluation Toolkit for Universal Sentence Representations</a></p><p>ä¸€ä¸ªéå¸¸é€šç”¨çš„benchmarkï¼Œç”¨æ¥è¯„ä¼°å¥å­embeddingæ˜¯å¦èƒ½å¤Ÿå¾ˆå¥½åœ°åº”ç”¨äºdownstream tasksã€‚</p><p>Github: <a href="https://github.com/facebookresearch/SentEval" target="_blank" rel="noopener">https://github.com/facebookresearch/SentEval</a></p><h2 id="Document-Vector"><a href="#Document-Vector" class="headerlink" title="Document Vector"></a>Document Vector</h2><p>äº‹å®ä¸Šç ”ç©¶è€…åœ¨å¥å­å‘é‡ä¸Šçš„å„ç§å°è¯•æ˜¯ä¸å¤ªæˆåŠŸçš„ã€‚ä¸»è¦ä½“ç°åœ¨è¿™äº›é¢„è®­ç»ƒå‘é‡å¹¶ä¸èƒ½éå¸¸å¥½åœ°æå‡æ¨¡å‹åœ¨å„ç§ä¸‹æ¸¸ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼Œäººä»¬å¤§å¤šæ•°æ—¶å€™è¿˜æ˜¯ä»å¤´å¼€å§‹è®­ç»ƒæ¨¡å‹ã€‚</p><p>åœ¨document vectorä¸Šçš„å°è¯•å°±æ›´ä¸å°½å¦‚äººæ„äº†ï¼Œå› ä¸ºä¸€ä¸ªæ–‡æœ¬å¾€å¾€åŒ…å«éå¸¸ä¸°å¯Œçš„ä¿¡æ¯ï¼Œè€Œä¸€ä¸ªå‘é‡èƒ½å¤Ÿç¼–ç çš„ä¿¡æ¯é‡å®åœ¨å¤ªå°ã€‚</p><p>Learning Deep Structured Semantic Models for Web Search using Clickthrough Data</p><p><a href="https://www.microsoft.com/en-us/research/publication/learning-deep-structured-semantic-models-for-web-search-using-clickthrough-data/" target="_blank" rel="noopener">https://www.microsoft.com/en-us/research/publication/learning-deep-structured-semantic-models-for-web-search-using-clickthrough-data/</a></p><p>Hierarchical Attention Networks for Document Classification</p><p><a href="https://www.cs.cmu.edu/~./hovy/papers/16HLT-hierarchical-attention-networks.pdf" target="_blank" rel="noopener">https://www.cs.cmu.edu/~./hovy/papers/16HLT-hierarchical-attention-networks.pdf</a></p><h1 id="ELMo-BERT"><a href="#ELMo-BERT" class="headerlink" title="ELMo, BERT"></a><a href="https://shimo.im/docs/Y6q3gX8yGGjpWqXx" target="_blank" rel="noopener">ELMo, BERT</a></h1><p>ELMO paper: <a href="https://arxiv.org/pdf/1802.05365.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1802.05365.pdf</a></p><h1 id="Transformerä¸­çš„Encoder"><a href="#Transformerä¸­çš„Encoder" class="headerlink" title="Transformerä¸­çš„Encoder"></a><a href="https://shimo.im/docs/gPwkqCXrkJyRW89V" target="_blank" rel="noopener">Transformerä¸­çš„Encoder</a></h1>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> BERT </tag>
            
            <tag> Transformer </tag>
            
            <tag> ELMo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>word2vec</title>
      <link href="/2020/04/24/word2vec/"/>
      <url>/2020/04/24/word2vec/</url>
      
        <content type="html"><![CDATA[<h4 id="word2vec"><a href="#word2vec" class="headerlink" title="word2vec"></a>word2vec</h4><ul><li>æœ‰ä¸€ä¸ªå¾ˆå¤§çš„è¯è¡¨åº“</li><li>åœ¨è¯è¡¨ä¸­çš„æ¯ä¸ªè¯éƒ½å¯ä»¥é€šè¿‡å‘é‡è¡¨å¾</li><li>æœ‰ä¸€ä¸ªä¸­å¿ƒè¯cï¼Œæœ‰ä¸€ä¸ªè¾“å‡ºè¯o</li><li>ç”¨è¯cå’Œoçš„ç›¸ä¼¼åº¦æ¥è®¡ç®—ä»–ä»¬ä¹‹é—´åŒæ—¶å‡ºç°çš„æ¦‚ç‡</li><li>è°ƒæ•´è¿™ä¸ªè¯å‘é‡æ¥è·å¾—æœ€å¤§è¾“å‡ºæ¦‚ç‡</li></ul>]]></content>
      
      
      <categories>
          
          <category> word2vec </category>
          
      </categories>
      
      
        <tags>
            
            <tag> skip-gram </tag>
            
            <tag> cbow </tag>
            
            <tag> hierarchical softmax </tag>
            
            <tag> negative sampling </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ç‰¹å¾å·¥ç¨‹ä¸æ¨¡å‹è°ƒä¼˜</title>
      <link href="/2020/04/20/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E4%B8%8E%E6%A8%A1%E5%9E%8B%E8%B0%83%E4%BC%98/"/>
      <url>/2020/04/20/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E4%B8%8E%E6%A8%A1%E5%9E%8B%E8%B0%83%E4%BC%98/</url>
      
        <content type="html"><![CDATA[<h2 id="æœºå™¨å­¦ä¹ ç‰¹å¾å·¥ç¨‹"><a href="#æœºå™¨å­¦ä¹ ç‰¹å¾å·¥ç¨‹" class="headerlink" title="æœºå™¨å­¦ä¹ ç‰¹å¾å·¥ç¨‹"></a>æœºå™¨å­¦ä¹ ç‰¹å¾å·¥ç¨‹</h2><h3 id="æœºå™¨å­¦ä¹ æµç¨‹ä¸æ¦‚å¿µ"><a href="#æœºå™¨å­¦ä¹ æµç¨‹ä¸æ¦‚å¿µ" class="headerlink" title="æœºå™¨å­¦ä¹ æµç¨‹ä¸æ¦‚å¿µ"></a>æœºå™¨å­¦ä¹ æµç¨‹ä¸æ¦‚å¿µ</h3><p><img src="https://s1.ax1x.com/2020/04/24/JBncGV.jpg" alt></p><h3 id="æœºå™¨å­¦ä¹ å»ºæ¨¡æµç¨‹"><a href="#æœºå™¨å­¦ä¹ å»ºæ¨¡æµç¨‹" class="headerlink" title="æœºå™¨å­¦ä¹ å»ºæ¨¡æµç¨‹"></a>æœºå™¨å­¦ä¹ å»ºæ¨¡æµç¨‹</h3><p><img src="https://s1.ax1x.com/2020/04/24/JBn2xU.png" alt></p><h3 id="æœºå™¨å­¦ä¹ ç‰¹å¾å·¥ç¨‹ä¸€è§ˆ"><a href="#æœºå™¨å­¦ä¹ ç‰¹å¾å·¥ç¨‹ä¸€è§ˆ" class="headerlink" title="æœºå™¨å­¦ä¹ ç‰¹å¾å·¥ç¨‹ä¸€è§ˆ"></a>æœºå™¨å­¦ä¹ ç‰¹å¾å·¥ç¨‹ä¸€è§ˆ</h3><p><img src="https://s1.ax1x.com/2020/04/24/JBnOMD.jpg" alt></p><h3 id="æœºå™¨å­¦ä¹ ç‰¹å¾å·¥ç¨‹ä»‹ç»"><a href="#æœºå™¨å­¦ä¹ ç‰¹å¾å·¥ç¨‹ä»‹ç»" class="headerlink" title="æœºå™¨å­¦ä¹ ç‰¹å¾å·¥ç¨‹ä»‹ç»"></a>æœºå™¨å­¦ä¹ ç‰¹å¾å·¥ç¨‹ä»‹ç»</h3><p><img src="https://s1.ax1x.com/2020/04/24/JBnjqH.jpg" alt></p><h3 id="ç‰¹å¾æ¸…æ´—"><a href="#ç‰¹å¾æ¸…æ´—" class="headerlink" title="ç‰¹å¾æ¸…æ´—"></a>ç‰¹å¾æ¸…æ´—</h3><p><img src="https://s1.ax1x.com/2020/04/24/JBumon.jpg" alt><br><img src="https://s1.ax1x.com/2020/04/24/JBuKJ0.jpg" alt><br><img src="https://s1.ax1x.com/2020/04/24/JBu3yF.jpg" alt></p><h3 id="æ•°å€¼å‹æ•°æ®ä¸Šçš„ç‰¹å¾å·¥ç¨‹"><a href="#æ•°å€¼å‹æ•°æ®ä¸Šçš„ç‰¹å¾å·¥ç¨‹" class="headerlink" title="æ•°å€¼å‹æ•°æ®ä¸Šçš„ç‰¹å¾å·¥ç¨‹"></a>æ•°å€¼å‹æ•°æ®ä¸Šçš„ç‰¹å¾å·¥ç¨‹</h3><p>æ•°å€¼å‹æ•°æ®é€šå¸¸ä»¥æ ‡é‡çš„å½¢å¼è¡¨ç¤ºæ•°æ®ï¼Œæè¿°è§‚æµ‹å€¼ã€è®°å½•æˆ–è€…æµ‹é‡å€¼ã€‚æœ¬æ–‡çš„æ•°å€¼å‹æ•°æ®æ˜¯æŒ‡è¿ç»­å‹æ•°æ®è€Œä¸æ˜¯ç¦»æ•£å‹æ•°æ®ï¼Œè¡¨ç¤ºä¸åŒç±»ç›®çš„æ•°æ®å°±æ˜¯åè€…ã€‚æ•°å€¼å‹æ•°æ®ä¹Ÿå¯ä»¥ç”¨å‘é‡æ¥è¡¨ç¤ºï¼Œå‘é‡çš„æ¯ä¸ªå€¼æˆ–åˆ†é‡ä»£è¡¨ä¸€ä¸ªç‰¹å¾ã€‚æ•´æ•°å’Œæµ®ç‚¹æ•°æ˜¯è¿ç»­å‹æ•°å€¼æ•°æ®ä¸­æœ€å¸¸è§ä¹Ÿæ˜¯æœ€å¸¸ä½¿ç”¨çš„æ•°å€¼å‹æ•°æ®ç±»å‹ã€‚å³ä½¿æ•°å€¼å‹æ•°æ®å¯ä»¥ç›´æ¥è¾“å…¥åˆ°æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­ï¼Œä½ ä»éœ€è¦åœ¨å»ºæ¨¡å‰è®¾è®¡ä¸åœºæ™¯ã€é—®é¢˜å’Œé¢†åŸŸç›¸å…³çš„ç‰¹å¾ã€‚å› æ­¤ä»éœ€è¦ç‰¹å¾å·¥ç¨‹ã€‚è®©æˆ‘ä»¬åˆ©ç”¨ python æ¥çœ‹çœ‹åœ¨æ•°å€¼å‹æ•°æ®ä¸Šåšç‰¹å¾å·¥ç¨‹çš„ä¸€äº›ç­–ç•¥ã€‚æˆ‘ä»¬é¦–å…ˆåŠ è½½ä¸‹é¢ä¸€äº›å¿…è¦çš„ä¾èµ–ï¼ˆé€šå¸¸åœ¨ <a href="http://jupyter.org/" target="_blank" rel="noopener"><strong>Jupyter</strong> </a> botebook ä¸Šï¼‰ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt; <span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">&gt;</span><br><span class="line">&gt; <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">&gt;</span><br><span class="line">&gt; <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">&gt;</span><br><span class="line">&gt; <span class="keyword">import</span> scipy.stats <span class="keyword">as</span> spstats</span><br><span class="line">&gt;</span><br><span class="line">&gt; %matplotlib inline</span><br></pre></td></tr></table></figure><p>åŸå§‹åº¦é‡</p><p>æ­£å¦‚æˆ‘ä»¬å…ˆå‰æåˆ°çš„ï¼Œæ ¹æ®ä¸Šä¸‹æ–‡å’Œæ•°æ®çš„æ ¼å¼ï¼ŒåŸå§‹æ•°å€¼å‹æ•°æ®é€šå¸¸å¯ç›´æ¥è¾“å…¥åˆ°æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­ã€‚åŸå§‹çš„åº¦é‡æ–¹æ³•é€šå¸¸ç”¨æ•°å€¼å‹å˜é‡æ¥ç›´æ¥è¡¨ç¤ºä¸ºç‰¹å¾ï¼Œè€Œä¸éœ€è¦ä»»ä½•å½¢å¼çš„å˜æ¢æˆ–ç‰¹å¾å·¥ç¨‹ã€‚é€šå¸¸è¿™äº›ç‰¹å¾å¯ä»¥è¡¨ç¤ºä¸€äº›å€¼æˆ–æ€»æ•°ã€‚è®©æˆ‘ä»¬åŠ è½½å››ä¸ªæ•°æ®é›†ä¹‹ä¸€çš„ <a href="https://www.kaggle.com/abcsds/pokemon/data" target="_blank" rel="noopener">Pokemon </a>æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†ä¹Ÿåœ¨ <a href="https://www.kaggle.com/abcsds/pokemon/data" target="_blank" rel="noopener">Kaggle </a>ä¸Šå…¬å¸ƒäº†ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">poke_df = pd.read_csv(<span class="string">'datasets/Pokemon.csv'</span>, encoding=<span class="string">'utf-8'</span>) </span><br><span class="line"></span><br><span class="line">poke_df.head()</span><br></pre></td></tr></table></figure><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5f55514768e.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸Šç¯‡ - è¿ç»­æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><h5 id="æˆ‘ä»¬çš„Pokemonæ•°æ®é›†æˆªå›¾"><a href="#æˆ‘ä»¬çš„Pokemonæ•°æ®é›†æˆªå›¾" class="headerlink" title="æˆ‘ä»¬çš„Pokemonæ•°æ®é›†æˆªå›¾"></a>æˆ‘ä»¬çš„Pokemonæ•°æ®é›†æˆªå›¾</h5><p>Pokemon æ˜¯ä¸€ä¸ªå¤§å‹å¤šåª’ä½“æ¸¸æˆï¼ŒåŒ…å«äº†å„ç§å£è¢‹å¦–æ€ªï¼ˆPokemonï¼‰è§’è‰²ã€‚ç®€è€Œè¨€ä¹‹ï¼Œä½ å¯ä»¥è®¤ä¸ºä»–ä»¬æ˜¯å¸¦æœ‰è¶…èƒ½åŠ›çš„åŠ¨ç‰©ï¼è¿™äº›æ•°æ®é›†ç”±è¿™äº›å£è¢‹å¦–æ€ªè§’è‰²æ„æˆï¼Œæ¯ä¸ªè§’è‰²å¸¦æœ‰å„ç§ç»Ÿè®¡ä¿¡æ¯ã€‚</p><h4 id="æ•°å€¼"><a href="#æ•°å€¼" class="headerlink" title="æ•°å€¼"></a>æ•°å€¼</h4><p>å¦‚æœä½ ä»”ç»†åœ°è§‚å¯Ÿä¸Šå›¾ä¸­è¿™äº›æ•°æ®ï¼Œä½ ä¼šçœ‹åˆ°å‡ ä¸ªä»£è¡¨æ•°å€¼å‹åŸå§‹å€¼çš„å±æ€§ï¼Œå®ƒå¯ä»¥è¢«ç›´æ¥ä½¿ç”¨ã€‚ä¸‹é¢çš„è¿™è¡Œä»£ç æŒ‘å‡ºäº†å…¶ä¸­ä¸€äº›é‡ç‚¹ç‰¹å¾ã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">poke_df[[&apos;HP&apos;, &apos;Attack&apos;, &apos;Defense&apos;]].head()</span><br></pre></td></tr></table></figure><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5f557552811.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸Šç¯‡ - è¿ç»­æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><h5 id="å¸¦ï¼ˆè¿ç»­å‹ï¼‰æ•°å€¼æ•°æ®çš„ç‰¹å¾"><a href="#å¸¦ï¼ˆè¿ç»­å‹ï¼‰æ•°å€¼æ•°æ®çš„ç‰¹å¾" class="headerlink" title="å¸¦ï¼ˆè¿ç»­å‹ï¼‰æ•°å€¼æ•°æ®çš„ç‰¹å¾"></a>å¸¦ï¼ˆè¿ç»­å‹ï¼‰æ•°å€¼æ•°æ®çš„ç‰¹å¾</h5><p>è¿™æ ·ï¼Œä½ å¯ä»¥ç›´æ¥å°†è¿™äº›å±æ€§ä½œä¸ºç‰¹å¾ï¼Œå¦‚ä¸Šå›¾æ‰€ç¤ºã€‚è¿™äº›ç‰¹å¾åŒ…æ‹¬ Pokemon çš„ HPï¼ˆè¡€é‡ï¼‰ï¼ŒAttackï¼ˆæ”»å‡»ï¼‰å’Œ Defenseï¼ˆé˜²å¾¡ï¼‰çŠ¶æ€ã€‚äº‹å®ä¸Šï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥åŸºäºè¿™äº›å­—æ®µè®¡ç®—å‡ºä¸€äº›åŸºæœ¬çš„ç»Ÿè®¡é‡ã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">poke_df[[&apos;HP&apos;, &apos;Attack&apos;, &apos;Defense&apos;]].describe()</span><br></pre></td></tr></table></figure><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5f559f61c14.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸Šç¯‡ - è¿ç»­æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><p><strong>æ•°å€¼ç‰¹å¾å½¢å¼çš„åŸºæœ¬æè¿°æ€§ç»Ÿè®¡é‡</strong></p><p>è¿™æ ·ä½ å°±å¯¹ç‰¹å¾ä¸­çš„ç»Ÿè®¡é‡å¦‚æ€»æ•°ã€å¹³å‡å€¼ã€æ ‡å‡†å·®å’Œå››åˆ†ä½æ•°æœ‰äº†ä¸€ä¸ªå¾ˆå¥½çš„å°è±¡ã€‚</p><h4 id="è®°æ•°"><a href="#è®°æ•°" class="headerlink" title="è®°æ•°"></a>è®°æ•°</h4><p>åŸå§‹åº¦é‡çš„å¦ä¸€ç§å½¢å¼åŒ…æ‹¬ä»£è¡¨é¢‘ç‡ã€æ€»æ•°æˆ–ç‰¹å¾å±æ€§å‘ç”Ÿæ¬¡æ•°çš„ç‰¹å¾ã€‚è®©æˆ‘ä»¬çœ‹çœ‹ <a href="https://labrosa.ee.columbia.edu/millionsong/" target="_blank" rel="noopener"><strong>millionsong</strong></a> <strong>æ•°æ®é›†</strong>ä¸­çš„ä¸€ä¸ªä¾‹å­ï¼Œå…¶æè¿°äº†æŸä¸€æ­Œæ›²è¢«å„ç§ç”¨æˆ·æ”¶å¬çš„æ€»æ•°æˆ–é¢‘æ•°ã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">popsong_df = pd.read_csv(&apos;datasets/song_views.csv&apos;,encoding=&apos;utf-8&apos;)</span><br><span class="line"></span><br><span class="line">popsong_df.head(10)</span><br></pre></td></tr></table></figure><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5f55bf6176f.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸Šç¯‡ - è¿ç»­æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><h5 id="æ•°å€¼ç‰¹å¾å½¢å¼çš„æ­Œæ›²æ”¶å¬æ€»æ•°"><a href="#æ•°å€¼ç‰¹å¾å½¢å¼çš„æ­Œæ›²æ”¶å¬æ€»æ•°" class="headerlink" title="æ•°å€¼ç‰¹å¾å½¢å¼çš„æ­Œæ›²æ”¶å¬æ€»æ•°"></a>æ•°å€¼ç‰¹å¾å½¢å¼çš„æ­Œæ›²æ”¶å¬æ€»æ•°</h5><p>æ ¹æ®è¿™å¼ æˆªå›¾ï¼Œæ˜¾è€Œæ˜“è§ listen_count å­—æ®µå¯ä»¥ç›´æ¥ä½œä¸ºåŸºäºæ•°å€¼å‹ç‰¹å¾çš„é¢‘æ•°æˆ–æ€»æ•°ã€‚</p><h4 id="äºŒå€¼åŒ–"><a href="#äºŒå€¼åŒ–" class="headerlink" title="äºŒå€¼åŒ–"></a>äºŒå€¼åŒ–</h4><p>åŸºäºè¦è§£å†³çš„é—®é¢˜æ„å»ºæ¨¡å‹æ—¶ï¼Œé€šå¸¸åŸå§‹é¢‘æ•°æˆ–æ€»æ•°å¯èƒ½ä¸æ­¤ä¸ç›¸å…³ã€‚æ¯”å¦‚å¦‚æœæˆ‘è¦å»ºç«‹ä¸€ä¸ªæ¨èç³»ç»Ÿç”¨æ¥æ¨èæ­Œæ›²ï¼Œæˆ‘åªå¸Œæœ›çŸ¥é“ä¸€ä¸ªäººæ˜¯å¦æ„Ÿå…´è¶£æˆ–æ˜¯å¦å¬è¿‡æŸæ­Œæ›²ã€‚æˆ‘ä¸éœ€è¦çŸ¥é“ä¸€é¦–æ­Œè¢«å¬è¿‡çš„æ¬¡æ•°ï¼Œå› ä¸ºæˆ‘æ›´å…³å¿ƒçš„æ˜¯ä¸€ä¸ªäººæ‰€å¬è¿‡çš„å„ç§å„æ ·çš„æ­Œæ›²ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼ŒäºŒå€¼åŒ–çš„ç‰¹å¾æ¯”åŸºäºè®¡æ•°çš„ç‰¹å¾æ›´åˆé€‚ã€‚æˆ‘ä»¬äºŒå€¼åŒ– listen_count å­—æ®µå¦‚ä¸‹ã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt; watched = np.array(popsong_df[&apos;listen_count&apos;])</span><br><span class="line">&gt;</span><br><span class="line">&gt; watched[watched &gt;= 1] = 1</span><br><span class="line">&gt;</span><br><span class="line">&gt; popsong_df[&apos;watched&apos;] = watched</span><br></pre></td></tr></table></figure><p>ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨ scikit-learn ä¸­ preprocessing æ¨¡å—çš„ Binarizer ç±»æ¥æ‰§è¡ŒåŒæ ·çš„ä»»åŠ¡ï¼Œè€Œä¸ä¸€å®šä½¿ç”¨ numpy æ•°ç»„ã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import Binarizer</span><br><span class="line"></span><br><span class="line">bn = Binarizer(threshold=0.9)</span><br><span class="line"></span><br><span class="line">pd_watched =bn.transform([popsong_df[&apos;listen_count&apos;]])[0]</span><br><span class="line"></span><br><span class="line">popsong_df[&apos;pd_watched&apos;] = pd_watched</span><br><span class="line"></span><br><span class="line">popsong_df.head(11)</span><br></pre></td></tr></table></figure><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5f56505e8ff.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸Šç¯‡ - è¿ç»­æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><h5 id="æ­Œæ›²æ”¶å¬æ€»æ•°çš„äºŒå€¼åŒ–ç»“æ„"><a href="#æ­Œæ›²æ”¶å¬æ€»æ•°çš„äºŒå€¼åŒ–ç»“æ„" class="headerlink" title="æ­Œæ›²æ”¶å¬æ€»æ•°çš„äºŒå€¼åŒ–ç»“æ„"></a>æ­Œæ›²æ”¶å¬æ€»æ•°çš„äºŒå€¼åŒ–ç»“æ„</h5><p>ä½ å¯ä»¥ä»ä¸Šé¢çš„æˆªå›¾ä¸­æ¸…æ¥šåœ°çœ‹åˆ°ï¼Œä¸¤ä¸ªæ–¹æ³•å¾—åˆ°äº†ç›¸åŒçš„ç»“æœã€‚å› æ­¤æˆ‘ä»¬å¾—åˆ°äº†ä¸€ä¸ªäºŒå€¼åŒ–çš„ç‰¹å¾æ¥è¡¨ç¤ºä¸€é¦–æ­Œæ˜¯å¦è¢«æ¯ä¸ªç”¨æˆ·å¬è¿‡ï¼Œå¹¶ä¸”å¯ä»¥åœ¨ç›¸å…³çš„æ¨¡å‹ä¸­ä½¿ç”¨å®ƒã€‚</p><h4 id="æ•°æ®èˆå…¥"><a href="#æ•°æ®èˆå…¥" class="headerlink" title="æ•°æ®èˆå…¥"></a>æ•°æ®èˆå…¥</h4><p>å¤„ç†è¿ç»­å‹æ•°å€¼å±æ€§å¦‚æ¯”ä¾‹æˆ–ç™¾åˆ†æ¯”æ—¶ï¼Œæˆ‘ä»¬é€šå¸¸ä¸éœ€è¦é«˜ç²¾åº¦çš„åŸå§‹æ•°å€¼ã€‚å› æ­¤é€šå¸¸æœ‰å¿…è¦å°†è¿™äº›é«˜ç²¾åº¦çš„ç™¾åˆ†æ¯”èˆå…¥ä¸ºæ•´æ•°å‹æ•°å€¼ã€‚è¿™äº›æ•´æ•°å¯ä»¥ç›´æ¥ä½œä¸ºåŸå§‹æ•°å€¼ç”šè‡³åˆ†ç±»å‹ç‰¹å¾ï¼ˆåŸºäºç¦»æ•£ç±»çš„ï¼‰ä½¿ç”¨ã€‚è®©æˆ‘ä»¬è¯•ç€å°†è¿™ä¸ªè§‚å¿µåº”ç”¨åˆ°ä¸€ä¸ªè™šæ‹Ÿæ•°æ®é›†ä¸Šï¼Œè¯¥æ•°æ®é›†æè¿°äº†åº“å­˜é¡¹å’Œä»–ä»¬çš„æµè¡Œåº¦ç™¾åˆ†æ¯”ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">items_popularity =pd.read_csv(<span class="string">'datasets/item_popularity.csv'</span>,encoding=<span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line">items_popularity[<span class="string">'popularity_scale_10'</span>] = np.array(np.round((items_popularity[<span class="string">'pop_percent'</span>] * <span class="number">10</span>)),dtype=<span class="string">'int'</span>)</span><br><span class="line"></span><br><span class="line">items_popularity[<span class="string">'popularity_scale_100'</span>] = np.array(np.round((items_popularity[<span class="string">'pop_percent'</span>] * <span class="number">100</span>)),dtype=<span class="string">'int'</span>)</span><br><span class="line"></span><br><span class="line">items_popularity</span><br></pre></td></tr></table></figure><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5f566e30ad2.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸Šç¯‡ - è¿ç»­æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><h5 id="ä¸åŒå°ºåº¦ä¸‹æµè¡Œåº¦èˆå…¥ç»“æœ"><a href="#ä¸åŒå°ºåº¦ä¸‹æµè¡Œåº¦èˆå…¥ç»“æœ" class="headerlink" title="ä¸åŒå°ºåº¦ä¸‹æµè¡Œåº¦èˆå…¥ç»“æœ"></a>ä¸åŒå°ºåº¦ä¸‹æµè¡Œåº¦èˆå…¥ç»“æœ</h5><p>åŸºäºä¸Šé¢çš„è¾“å‡ºï¼Œä½ å¯èƒ½çŒœåˆ°æˆ‘ä»¬è¯•äº†ä¸¤ç§ä¸åŒçš„èˆå…¥æ–¹å¼ã€‚è¿™äº›ç‰¹å¾è¡¨æ˜é¡¹ç›®æµè¡Œåº¦çš„ç‰¹å¾ç°åœ¨æ—¢æœ‰ 1-10 çš„å°ºåº¦ä¹Ÿæœ‰ 1-100 çš„å°ºåº¦ã€‚åŸºäºè¿™ä¸ªåœºæ™¯æˆ–é—®é¢˜ä½ å¯ä»¥ä½¿ç”¨è¿™äº›å€¼åŒæ—¶ä½œä¸ºæ•°å€¼å‹æˆ–åˆ†ç±»å‹ç‰¹å¾ã€‚</p><h4 id="ç›¸å…³æ€§"><a href="#ç›¸å…³æ€§" class="headerlink" title="ç›¸å…³æ€§"></a>ç›¸å…³æ€§</h4><p>é«˜çº§æœºå™¨å­¦ä¹ æ¨¡å‹é€šå¸¸ä¼šå¯¹ä½œä¸ºè¾“å…¥ç‰¹å¾å˜é‡å‡½æ•°çš„è¾“å‡ºå“åº”å»ºæ¨¡ï¼ˆç¦»æ•£ç±»åˆ«æˆ–è¿ç»­æ•°å€¼ï¼‰ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªç®€å•çš„çº¿æ€§å›å½’æ–¹ç¨‹å¯ä»¥è¡¨ç¤ºä¸º</p><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5f56ab22fb7.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸Šç¯‡ - è¿ç»­æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><p>å…¶ä¸­è¾“å…¥ç‰¹å¾ç”¨å˜é‡è¡¨ç¤ºä¸º</p><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5f56c69ac66.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸Šç¯‡ - è¿ç»­æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><p>æƒé‡æˆ–ç³»æ•°å¯ä»¥åˆ†åˆ«è¡¨ç¤ºä¸º</p><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5f56de74ee7.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸Šç¯‡ - è¿ç»­æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><p>ç›®æ ‡æ˜¯é¢„æµ‹å“åº” <strong>*y*</strong>.</p><p>åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œä»…ä»…æ ¹æ®å•ä¸ªçš„ã€åˆ†ç¦»çš„è¾“å…¥ç‰¹å¾ï¼Œè¿™ä¸ªç®€å•çš„çº¿æ€§æ¨¡å‹æè¿°äº†è¾“å‡ºä¸è¾“å…¥ä¹‹é—´çš„å…³ç³»ã€‚</p><p>ç„¶è€Œï¼Œåœ¨ä¸€äº›çœŸå®åœºæ™¯ä¸­ï¼Œæœ‰å¿…è¦è¯•ç€æ•è·è¿™äº›è¾“å…¥ç‰¹å¾é›†ä¸€éƒ¨åˆ†çš„ç‰¹å¾å˜é‡ä¹‹é—´çš„ç›¸å…³æ€§ã€‚ä¸Šè¿°å¸¦æœ‰ç›¸å…³ç‰¹å¾çš„çº¿æ€§å›å½’æ–¹ç¨‹çš„å±•å¼€å¼å¯ä»¥ç®€å•è¡¨ç¤ºä¸º</p><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5f5701419ee.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸Šç¯‡ - è¿ç»­æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><p>æ­¤å¤„ç‰¹å¾å¯è¡¨ç¤ºä¸º</p><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5f57162d4f7.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸Šç¯‡ - è¿ç»­æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><p>è¡¨ç¤ºäº†ç›¸å…³ç‰¹å¾ã€‚ç°åœ¨è®©æˆ‘ä»¬è¯•ç€åœ¨ Pokemon æ•°æ®é›†ä¸Šè®¾è®¡ä¸€äº›ç›¸å…³ç‰¹å¾ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">atk_def = poke_df[[<span class="string">'Attack'</span>, <span class="string">'Defense'</span>]]</span><br><span class="line"></span><br><span class="line">atk_def.head()</span><br></pre></td></tr></table></figure><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5f572bad2cc.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸Šç¯‡ - è¿ç»­æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><p>ä»è¾“å‡ºæ•°æ®æ¡†ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ä»¬æœ‰ä¸¤ä¸ªæ•°å€¼å‹ï¼ˆè¿ç»­çš„ï¼‰ç‰¹å¾ï¼ŒAttack å’Œ Defenceã€‚ç°åœ¨æˆ‘ä»¬å¯ä»¥åˆ©ç”¨ scikit-learn å»ºç«‹äºŒåº¦ç‰¹å¾ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">pf = PolynomialFeatures(degree=<span class="number">2</span>,</span><br><span class="line"></span><br><span class="line">interaction_only=<span class="literal">False</span>,include_bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">res = pf.fit_transform(atk_def)</span><br><span class="line"></span><br><span class="line">res</span><br><span class="line"></span><br><span class="line">**Output**</span><br><span class="line"></span><br><span class="line">**------**</span><br><span class="line"></span><br><span class="line">array([[ <span class="number">49.</span>, <span class="number">49.</span>, <span class="number">2401.</span>, <span class="number">2401.</span>, <span class="number">2401.</span>],</span><br><span class="line"></span><br><span class="line">  [ <span class="number">62.</span>, <span class="number">63.</span>, <span class="number">3844.</span>, <span class="number">3906.</span>, <span class="number">3969.</span>],</span><br><span class="line"></span><br><span class="line">  [ <span class="number">82.</span>, <span class="number">83.</span>, <span class="number">6724.</span>, <span class="number">6806.</span>, <span class="number">6889.</span>],</span><br><span class="line"></span><br><span class="line">  ...,</span><br><span class="line"></span><br><span class="line">  [ <span class="number">110.</span>, <span class="number">60.</span>, <span class="number">12100.</span>, <span class="number">6600.</span>, <span class="number">3600.</span>],</span><br><span class="line"></span><br><span class="line">  [ <span class="number">160.</span>, <span class="number">60.</span>, <span class="number">25600.</span>, <span class="number">9600.</span>, <span class="number">3600.</span>],</span><br><span class="line"></span><br><span class="line">[ <span class="number">110.</span>, <span class="number">120.</span>, <span class="number">12100.</span>, <span class="number">13200.</span>, <span class="number">14400.</span>]])</span><br></pre></td></tr></table></figure><p>ä¸Šé¢çš„ç‰¹å¾çŸ©é˜µä¸€å…±æè¿°äº† 5 ä¸ªç‰¹å¾ï¼Œå…¶ä¸­åŒ…æ‹¬æ–°çš„ç›¸å…³ç‰¹å¾ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸Šè¿°çŸ©é˜µä¸­æ¯ä¸ªç‰¹å¾çš„åº¦ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.DataFrame(pf.powers_, columns=[<span class="string">'Attack_degree'</span>,<span class="string">'Defense_degree'</span>])</span><br></pre></td></tr></table></figure><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5f575a65683.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸Šç¯‡ - è¿ç»­æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><p>åŸºäºè¿™ä¸ªè¾“å‡ºï¼Œç°åœ¨æˆ‘ä»¬å¯ä»¥é€šè¿‡æ¯ä¸ªç‰¹å¾çš„åº¦çŸ¥é“å®ƒå®é™…ä¸Šä»£è¡¨ä»€ä¹ˆã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œç°åœ¨æˆ‘ä»¬å¯ä»¥å¯¹æ¯ä¸ªç‰¹å¾è¿›è¡Œå‘½åå¦‚ä¸‹ã€‚è¿™ä»…ä»…æ˜¯ä¸ºäº†ä¾¿äºç†è§£ï¼Œä½ å¯ä»¥ç»™è¿™äº›ç‰¹å¾å–æ›´å¥½çš„ã€å®¹æ˜“ä½¿ç”¨å’Œç®€å•çš„åå­—ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">intr_features = pd.DataFrame(res, columns=[<span class="string">'Attack'</span>,<span class="string">'Defense'</span>,<span class="string">'Attack^2'</span>,<span class="string">'Attack x Defense'</span>,<span class="string">'Defense^2'</span>])</span><br><span class="line"></span><br><span class="line">intr_features.head(<span class="number">5</span>)</span><br></pre></td></tr></table></figure><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5f576e91376.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸Šç¯‡ - è¿ç»­æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><h5 id="æ•°å€¼å‹ç‰¹å¾åŠå…¶ç›¸å…³ç‰¹å¾"><a href="#æ•°å€¼å‹ç‰¹å¾åŠå…¶ç›¸å…³ç‰¹å¾" class="headerlink" title="æ•°å€¼å‹ç‰¹å¾åŠå…¶ç›¸å…³ç‰¹å¾"></a>æ•°å€¼å‹ç‰¹å¾åŠå…¶ç›¸å…³ç‰¹å¾</h5><p>å› æ­¤ä¸Šè¿°æ•°æ®ä»£è¡¨äº†æˆ‘ä»¬åŸå§‹çš„ç‰¹å¾ä»¥åŠå®ƒä»¬çš„ç›¸å…³ç‰¹å¾ã€‚</p><h4 id="åˆ†åŒºé—´å¤„ç†æ•°æ®"><a href="#åˆ†åŒºé—´å¤„ç†æ•°æ®" class="headerlink" title="åˆ†åŒºé—´å¤„ç†æ•°æ®"></a>åˆ†åŒºé—´å¤„ç†æ•°æ®</h4><p>å¤„ç†åŸå§‹ã€è¿ç»­çš„æ•°å€¼å‹ç‰¹å¾é—®é¢˜é€šå¸¸ä¼šå¯¼è‡´è¿™äº›ç‰¹å¾å€¼çš„åˆ†å¸ƒè¢«ç ´åã€‚è¿™è¡¨æ˜æœ‰äº›å€¼ç»å¸¸å‡ºç°è€Œå¦ä¸€äº›å€¼å‡ºç°éå¸¸å°‘ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œå¦ä¸€ä¸ªé—®é¢˜æ˜¯è¿™äº›ç‰¹å¾çš„å€¼çš„å˜åŒ–èŒƒå›´ã€‚æ¯”å¦‚æŸä¸ªéŸ³ä¹è§†é¢‘çš„è§‚çœ‹æ€»æ•°ä¼šéå¸¸å¤§ï¼ˆ<a href="https://www.youtube.com/watch?v=kJQP7kiw5Fk" target="_blank" rel="noopener">Despacito</a>ï¼Œè¯´ä½ å‘¢ï¼‰è€Œä¸€äº›å€¼ä¼šéå¸¸å°ã€‚ç›´æ¥ä½¿ç”¨è¿™äº›ç‰¹å¾ä¼šäº§ç”Ÿå¾ˆå¤šé—®é¢˜ï¼Œåè€Œä¼šå½±å“æ¨¡å‹è¡¨ç°ã€‚å› æ­¤å‡ºç°äº†å¤„ç†è¿™äº›é—®é¢˜çš„æŠ€å·§ï¼ŒåŒ…æ‹¬åˆ†åŒºé—´æ³•å’Œå˜æ¢ã€‚</p><p>åˆ†åŒºé—´ï¼ˆBiningï¼‰ï¼Œä¹Ÿå«åšé‡åŒ–ï¼Œç”¨äºå°†è¿ç»­å‹æ•°å€¼ç‰¹å¾è½¬æ¢ä¸ºç¦»æ•£å‹ç‰¹å¾ï¼ˆç±»åˆ«ï¼‰ã€‚å¯ä»¥è®¤ä¸ºè¿™äº›ç¦»æ•£å€¼æˆ–æ•°å­—æ˜¯ç±»åˆ«æˆ–åŸå§‹çš„è¿ç»­å‹æ•°å€¼è¢«åˆ†åŒºé—´æˆ–åˆ†ç»„ä¹‹åçš„æ•°ç›®ã€‚æ¯ä¸ªä¸åŒçš„åŒºé—´å¤§å°ä»£è¡¨æŸç§å¯†åº¦ï¼Œå› æ­¤ä¸€ä¸ªç‰¹å®šèŒƒå›´çš„è¿ç»­å‹æ•°å€¼ä¼šè½åœ¨é‡Œé¢ã€‚å¯¹æ•°æ®åšåˆ†åŒºé—´çš„å…·ä½“æŠ€å·§åŒ…æ‹¬ç­‰å®½åˆ†åŒºé—´ä»¥åŠè‡ªé€‚åº”åˆ†åŒºé—´ã€‚æˆ‘ä»¬ä½¿ç”¨ä» <a href="https://github.com/freeCodeCamp/2016-new-coder-survey" target="_blank" rel="noopener">2016 å¹´ FreeCodeCamp å¼€å‘è€…å’Œç¼–ç å‘˜è°ƒæŸ¥æŠ¥å‘Š</a>ä¸­æŠ½å–å‡ºæ¥çš„ä¸€ä¸ªå­é›†ä¸­çš„æ•°æ®ï¼Œæ¥è®¨è®ºå„ç§é’ˆå¯¹ç¼–ç å‘˜å’Œè½¯ä»¶å¼€å‘è€…çš„å±æ€§ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fcc_survey_df =pd.read_csv(<span class="string">'datasets/fcc_2016_coder_survey_subset.csv'</span>,encoding=<span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line">fcc_survey_df[[<span class="string">'ID.x'</span>, <span class="string">'EmploymentField'</span>, <span class="string">'Age'</span>,<span class="string">'Income'</span>]].head()</span><br></pre></td></tr></table></figure><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5f578e01139.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸Šç¯‡ - è¿ç»­æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><h5 id="æ¥è‡ªFCCç¼–ç å‘˜è°ƒæŸ¥æ•°æ®é›†çš„æ ·æœ¬å±æ€§"><a href="#æ¥è‡ªFCCç¼–ç å‘˜è°ƒæŸ¥æ•°æ®é›†çš„æ ·æœ¬å±æ€§" class="headerlink" title="æ¥è‡ªFCCç¼–ç å‘˜è°ƒæŸ¥æ•°æ®é›†çš„æ ·æœ¬å±æ€§"></a>æ¥è‡ªFCCç¼–ç å‘˜è°ƒæŸ¥æ•°æ®é›†çš„æ ·æœ¬å±æ€§</h5><p>å¯¹äºæ¯ä¸ªå‚åŠ è°ƒæŸ¥çš„ç¼–ç å‘˜æˆ–å¼€å‘è€…ï¼ŒID.x å˜é‡åŸºæœ¬ä¸Šæ˜¯ä¸€ä¸ªå”¯ä¸€çš„æ ‡è¯†ç¬¦è€Œå…¶ä»–å­—æ®µæ˜¯å¯è‡ªæˆ‘è§£é‡Šçš„ã€‚</p><h4 id="ç­‰å®½åˆ†åŒºé—´"><a href="#ç­‰å®½åˆ†åŒºé—´" class="headerlink" title="ç­‰å®½åˆ†åŒºé—´"></a>ç­‰å®½åˆ†åŒºé—´</h4><p>å°±åƒåå­—è¡¨æ˜çš„é‚£æ ·ï¼Œåœ¨ç­‰å®½åˆ†åŒºé—´æ–¹æ³•ä¸­ï¼Œæ¯ä¸ªåŒºé—´éƒ½æ˜¯å›ºå®šå®½åº¦çš„ï¼Œé€šå¸¸å¯ä»¥é¢„å…ˆåˆ†ææ•°æ®è¿›è¡Œå®šä¹‰ã€‚åŸºäºä¸€äº›é¢†åŸŸçŸ¥è¯†ã€è§„åˆ™æˆ–çº¦æŸï¼Œæ¯ä¸ªåŒºé—´æœ‰ä¸ªé¢„å…ˆå›ºå®šçš„å€¼çš„èŒƒå›´ï¼Œåªæœ‰å¤„äºèŒƒå›´å†…çš„æ•°å€¼æ‰è¢«åˆ†é…åˆ°è¯¥åŒºé—´ã€‚åŸºäºæ•°æ®èˆå…¥æ“ä½œçš„åˆ†åŒºé—´æ˜¯ä¸€ç§æ–¹å¼ï¼Œä½ å¯ä»¥ä½¿ç”¨æ•°æ®èˆå…¥æ“ä½œæ¥å¯¹åŸå§‹å€¼è¿›è¡Œåˆ†åŒºé—´ï¼Œæˆ‘ä»¬å‰é¢å·²ç»è®²è¿‡ã€‚</p><p>ç°åœ¨æˆ‘ä»¬åˆ†æç¼–ç å‘˜è°ƒæŸ¥æŠ¥å‘Šæ•°æ®é›†çš„ Age ç‰¹å¾å¹¶çœ‹çœ‹å®ƒçš„åˆ†å¸ƒã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots()</span><br><span class="line"></span><br><span class="line">fcc_survey_df[<span class="string">'Age'</span>].hist(color=<span class="string">'#A9C5D3'</span>,edgecolor=<span class="string">'black'</span>,grid=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">ax.set_title(<span class="string">'Developer Age Histogram'</span>, fontsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line">ax.set_xlabel(<span class="string">'Age'</span>, fontsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line">ax.set_ylabel(<span class="string">'Frequency'</span>, fontsize=<span class="number">12</span>)</span><br></pre></td></tr></table></figure><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5f57b05846b.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸Šç¯‡ - è¿ç»­æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><h5 id="æè¿°å¼€å‘è€…å¹´é¾„åˆ†å¸ƒçš„ç›´æ–¹å›¾"><a href="#æè¿°å¼€å‘è€…å¹´é¾„åˆ†å¸ƒçš„ç›´æ–¹å›¾" class="headerlink" title="æè¿°å¼€å‘è€…å¹´é¾„åˆ†å¸ƒçš„ç›´æ–¹å›¾"></a>æè¿°å¼€å‘è€…å¹´é¾„åˆ†å¸ƒçš„ç›´æ–¹å›¾</h5><p>ä¸Šé¢çš„ç›´æ–¹å›¾è¡¨æ˜ï¼Œå¦‚é¢„æœŸé‚£æ ·ï¼Œå¼€å‘è€…å¹´é¾„åˆ†å¸ƒä»¿ä½›å¾€å·¦ä¾§å€¾æ–œï¼ˆä¸Šå¹´çºªçš„å¼€å‘è€…åå°‘ï¼‰ã€‚ç°åœ¨æˆ‘ä»¬æ ¹æ®ä¸‹é¢çš„æ¨¡å¼ï¼Œå°†è¿™äº›åŸå§‹å¹´é¾„å€¼åˆ†é…åˆ°ç‰¹å®šçš„åŒºé—´ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Age Range: Bin</span><br><span class="line"></span><br><span class="line">\---------------</span><br><span class="line"></span><br><span class="line"><span class="number">0</span> - <span class="number">9</span> : <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="number">10</span> - <span class="number">19</span> : <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="number">20</span> - <span class="number">29</span> : <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="number">30</span> - <span class="number">39</span> : <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="number">40</span> - <span class="number">49</span> : <span class="number">4</span></span><br><span class="line"></span><br><span class="line"><span class="number">50</span> - <span class="number">59</span> : <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="number">60</span> - <span class="number">69</span> : <span class="number">6</span></span><br><span class="line"></span><br><span class="line"><span class="meta">... </span><span class="keyword">and</span> so on</span><br></pre></td></tr></table></figure><p>æˆ‘ä»¬å¯ä»¥ç®€å•åœ°ä½¿ç”¨æˆ‘ä»¬å…ˆå‰å­¦ä¹ åˆ°çš„æ•°æ®èˆå…¥éƒ¨åˆ†çŸ¥è¯†ï¼Œå…ˆå°†è¿™äº›åŸå§‹å¹´é¾„å€¼é™¤ä»¥ 10ï¼Œç„¶åé€šè¿‡ floor å‡½æ•°å¯¹åŸå§‹å¹´é¾„æ•°å€¼è¿›è¡Œæˆªæ–­ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fcc_survey_df[<span class="string">'Age_bin_round'</span>] = np.array(np.floor(np.array(fcc_survey_df[<span class="string">'Age'</span>]) / <span class="number">10.</span>))</span><br><span class="line"></span><br><span class="line">fcc_survey_df[[<span class="string">'ID.x'</span>, <span class="string">'Age'</span>,<span class="string">'Age_bin_round'</span>]].iloc[<span class="number">1071</span>:<span class="number">1076</span>]</span><br></pre></td></tr></table></figure><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5f57d916a6f.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸Šç¯‡ - è¿ç»­æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><h5 id="é€šè¿‡èˆå…¥æ³•åˆ†åŒºé—´"><a href="#é€šè¿‡èˆå…¥æ³•åˆ†åŒºé—´" class="headerlink" title="é€šè¿‡èˆå…¥æ³•åˆ†åŒºé—´"></a>é€šè¿‡èˆå…¥æ³•åˆ†åŒºé—´</h5><p>ä½ å¯ä»¥çœ‹åˆ°åŸºäºæ•°æ®èˆå…¥æ“ä½œçš„æ¯ä¸ªå¹´é¾„å¯¹åº”çš„åŒºé—´ã€‚ä½†æ˜¯å¦‚æœæˆ‘ä»¬éœ€è¦æ›´çµæ´»çš„æ“ä½œæ€ä¹ˆåŠï¼Ÿå¦‚æœæˆ‘ä»¬æƒ³åŸºäºæˆ‘ä»¬çš„è§„åˆ™æˆ–é€»è¾‘ï¼Œç¡®å®šæˆ–ä¿®æ”¹åŒºé—´çš„å®½åº¦æ€ä¹ˆåŠï¼ŸåŸºäºå¸¸ç”¨èŒƒå›´çš„åˆ†åŒºé—´æ–¹æ³•å°†å¸®åŠ©æˆ‘ä»¬å®Œæˆè¿™ä¸ªã€‚è®©æˆ‘ä»¬æ¥å®šä¹‰ä¸€äº›é€šç”¨å¹´é¾„æ®µä½ï¼Œä½¿ç”¨ä¸‹é¢çš„æ–¹å¼æ¥å¯¹å¼€å‘è€…å¹´é¾„åˆ†åŒºé—´ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Age Range : Bin</span><br><span class="line"></span><br><span class="line">\---------------</span><br><span class="line"></span><br><span class="line"><span class="number">0</span> - <span class="number">15</span> : <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="number">16</span> - <span class="number">30</span> : <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="number">31</span> - <span class="number">45</span> : <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="number">46</span> - <span class="number">60</span> : <span class="number">4</span></span><br><span class="line"></span><br><span class="line"><span class="number">61</span> - <span class="number">75</span> : <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="number">75</span> - <span class="number">100</span> : <span class="number">6</span></span><br></pre></td></tr></table></figure><p>åŸºäºè¿™äº›å¸¸ç”¨çš„åˆ†åŒºé—´æ–¹å¼ï¼Œæˆ‘ä»¬ç°åœ¨å¯ä»¥å¯¹æ¯ä¸ªå¼€å‘è€…å¹´é¾„å€¼çš„åŒºé—´æ‰“æ ‡ç­¾ï¼Œæˆ‘ä»¬å°†å­˜å‚¨åŒºé—´çš„èŒƒå›´å’Œç›¸åº”çš„æ ‡ç­¾ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">bin_ranges = [<span class="number">0</span>, <span class="number">15</span>, <span class="number">30</span>, <span class="number">45</span>, <span class="number">60</span>, <span class="number">75</span>, <span class="number">100</span>]</span><br><span class="line"></span><br><span class="line">bin_names = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line"></span><br><span class="line">fcc_survey_df[<span class="string">'Age_bin_custom_range'</span>] = pd.cut(np.array(fcc_survey_df[<span class="string">'Age'</span>]),bins=bin_ranges)</span><br><span class="line"></span><br><span class="line">fcc_survey_df[<span class="string">'Age_bin_custom_label'</span>] = pd.cut(np.array(fcc_survey_df[<span class="string">'Age'</span>]),bins=bin_ranges, labels=bin_names)</span><br><span class="line"></span><br><span class="line">\<span class="comment"># view the binned features</span></span><br><span class="line"></span><br><span class="line">fcc_survey_df[[<span class="string">'ID.x'</span>, <span class="string">'Age'</span>, <span class="string">'Age_bin_round'</span>,<span class="string">'Age_bin_custom_range'</span>,<span class="string">'Age_bin_custom_label'</span>]].iloc[<span class="number">10</span>a71:<span class="number">1076</span>]</span><br></pre></td></tr></table></figure><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5f58143c35f.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸Šç¯‡ - è¿ç»­æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><h5 id="å¼€å‘è€…å¹´é¾„çš„å¸¸ç”¨åˆ†åŒºé—´æ–¹å¼"><a href="#å¼€å‘è€…å¹´é¾„çš„å¸¸ç”¨åˆ†åŒºé—´æ–¹å¼" class="headerlink" title="å¼€å‘è€…å¹´é¾„çš„å¸¸ç”¨åˆ†åŒºé—´æ–¹å¼"></a>å¼€å‘è€…å¹´é¾„çš„å¸¸ç”¨åˆ†åŒºé—´æ–¹å¼</h5><h4 id="è‡ªé€‚åº”åˆ†åŒºé—´"><a href="#è‡ªé€‚åº”åˆ†åŒºé—´" class="headerlink" title="è‡ªé€‚åº”åˆ†åŒºé—´"></a>è‡ªé€‚åº”åˆ†åŒºé—´</h4><p>ä½¿ç”¨ç­‰å®½åˆ†åŒºé—´çš„ä¸è¶³ä¹‹å¤„åœ¨äºï¼Œæˆ‘ä»¬æ‰‹åŠ¨å†³å®šäº†åŒºé—´çš„å€¼èŒƒå›´ï¼Œè€Œç”±äºè½åœ¨æŸä¸ªåŒºé—´ä¸­çš„æ•°æ®ç‚¹æˆ–å€¼çš„æ•°ç›®æ˜¯ä¸å‡åŒ€çš„ï¼Œå› æ­¤å¯èƒ½ä¼šå¾—åˆ°ä¸è§„åˆ™çš„åŒºé—´ã€‚ä¸€äº›åŒºé—´ä¸­çš„æ•°æ®å¯èƒ½ä¼šéå¸¸çš„å¯†é›†ï¼Œä¸€äº›åŒºé—´ä¼šéå¸¸ç¨€ç–ç”šè‡³æ˜¯ç©ºçš„ï¼è‡ªé€‚åº”åˆ†åŒºé—´æ–¹æ³•æ˜¯ä¸€ä¸ªæ›´å®‰å…¨çš„ç­–ç•¥ï¼Œåœ¨è¿™äº›åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬è®©æ•°æ®è‡ªå·±è¯´è¯ï¼è¿™æ ·ï¼Œæˆ‘ä»¬ä½¿ç”¨æ•°æ®åˆ†å¸ƒæ¥å†³å®šåŒºé—´çš„èŒƒå›´ã€‚</p><p>åŸºäºåˆ†ä½æ•°çš„åˆ†åŒºé—´æ–¹æ³•æ˜¯è‡ªé€‚åº”åˆ†ç®±æ–¹æ³•ä¸­ä¸€ä¸ªå¾ˆå¥½çš„æŠ€å·§ã€‚é‡åŒ–å¯¹äºç‰¹å®šå€¼æˆ–åˆ‡ç‚¹æœ‰åŠ©äºå°†ç‰¹å®šæ•°å€¼åŸŸçš„è¿ç»­å€¼åˆ†å¸ƒåˆ’åˆ†ä¸ºç¦»æ•£çš„äº’ç›¸æŒ¨ç€çš„åŒºé—´ã€‚å› æ­¤ q åˆ†ä½æ•°æœ‰åŠ©äºå°†æ•°å€¼å±æ€§åˆ’åˆ†ä¸º q ä¸ªç›¸ç­‰çš„éƒ¨åˆ†ã€‚å…³äºé‡åŒ–æ¯”è¾ƒæµè¡Œçš„ä¾‹å­åŒ…æ‹¬ 2 åˆ†ä½æ•°ï¼Œä¹Ÿå«ä¸­å€¼ï¼Œå°†æ•°æ®åˆ†å¸ƒåˆ’åˆ†ä¸º2ä¸ªç›¸ç­‰çš„åŒºé—´ï¼›4 åˆ†ä½æ•°ï¼Œä¹Ÿç®€ç§°åˆ†ä½æ•°ï¼Œå®ƒå°†æ•°æ®åˆ’åˆ†ä¸º 4 ä¸ªç›¸ç­‰çš„åŒºé—´ï¼›ä»¥åŠ 10 åˆ†ä½æ•°ï¼Œä¹Ÿå«ååˆ†ä½æ•°ï¼Œåˆ›å»º 10 ä¸ªç›¸ç­‰å®½åº¦çš„åŒºé—´ï¼Œç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹å¼€å‘è€…æ•°æ®é›†çš„ Income å­—æ®µçš„æ•°æ®åˆ†å¸ƒã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots()</span><br><span class="line"></span><br><span class="line">fcc_survey_df[<span class="string">'Income'</span>].hist(bins=<span class="number">30</span>, color=<span class="string">'#A9C5D3'</span>,edgecolor=<span class="string">'black'</span>,grid=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">ax.set_title(<span class="string">'Developer Income Histogram'</span>,fontsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line">ax.set_xlabel(<span class="string">'Developer Income'</span>, fontsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line">ax.set_ylabel(<span class="string">'Frequency'</span>, fontsize=<span class="number">12</span>)</span><br></pre></td></tr></table></figure><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5f583631eff.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸Šç¯‡ - è¿ç»­æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><p><strong>æè¿°å¼€å‘è€…æ”¶å…¥åˆ†å¸ƒçš„ç›´æ–¹å›¾</strong></p><p>ä¸Šè¿°çš„åˆ†å¸ƒæè¿°äº†ä¸€ä¸ªåœ¨æ”¶å…¥ä¸Šå³æ­ªæ–œçš„åˆ†å¸ƒï¼Œå°‘æ•°äººèµšæ›´å¤šçš„é’±ï¼Œå¤šæ•°äººèµšæ›´å°‘çš„é’±ã€‚è®©æˆ‘ä»¬åŸºäºè‡ªé€‚åº”åˆ†ç®±æ–¹å¼åšä¸€ä¸ª 4-åˆ†ä½æ•°æˆ–åˆ†ä½æ•°ã€‚æˆ‘ä»¬å¯ä»¥å¾ˆå®¹æ˜“åœ°å¾—åˆ°å¦‚ä¸‹çš„åˆ†ä½æ•°ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">quantile_list = [<span class="number">0</span>, <span class="number">.25</span>, <span class="number">.5</span>, <span class="number">.75</span>, <span class="number">1.</span>]</span><br><span class="line"></span><br><span class="line">quantiles =</span><br><span class="line"></span><br><span class="line">fcc_survey_df[<span class="string">'Income'</span>].quantile(quantile_list)</span><br><span class="line"></span><br><span class="line">quantiles</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">**Output**</span><br><span class="line"></span><br><span class="line">**------**</span><br><span class="line"></span><br><span class="line"><span class="number">0.00</span> <span class="number">6000.0</span></span><br><span class="line"></span><br><span class="line"><span class="number">0.25</span> <span class="number">20000.0</span></span><br><span class="line"></span><br><span class="line"><span class="number">0.50</span> <span class="number">37000.0</span></span><br><span class="line"></span><br><span class="line"><span class="number">0.75</span> <span class="number">60000.0</span></span><br><span class="line"></span><br><span class="line"><span class="number">1.00</span> <span class="number">200000.0</span></span><br><span class="line"></span><br><span class="line">Name: Income, dtype: float64</span><br></pre></td></tr></table></figure><p>ç°åœ¨è®©æˆ‘ä»¬åœ¨åŸå§‹çš„åˆ†å¸ƒç›´æ–¹å›¾ä¸­å¯è§†åŒ–ä¸‹è¿™äº›åˆ†ä½æ•°ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots()</span><br><span class="line"></span><br><span class="line">fcc_survey_df[<span class="string">'Income'</span>].hist(bins=<span class="number">30</span>, color=<span class="string">'#A9C5D3'</span>,edgecolor=<span class="string">'black'</span>,grid=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> quantile <span class="keyword">in</span> quantiles:</span><br><span class="line"></span><br><span class="line">qvl = plt.axvline(quantile, color=<span class="string">'r'</span>)</span><br><span class="line"></span><br><span class="line">ax.legend([qvl], [<span class="string">'Quantiles'</span>], fontsize=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">ax.set_title(<span class="string">'Developer Income Histogram with Quantiles'</span>,fontsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line">ax.set_xlabel(<span class="string">'Developer Income'</span>, fontsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line">ax.set_ylabel(<span class="string">'Frequency'</span>, fontsize=<span class="number">12</span>)</span><br></pre></td></tr></table></figure><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5f5853f1a2c.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸Šç¯‡ - è¿ç»­æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><h5 id="å¸¦åˆ†ä½æ•°å½¢å¼æè¿°å¼€å‘è€…æ”¶å…¥åˆ†å¸ƒçš„ç›´æ–¹å›¾"><a href="#å¸¦åˆ†ä½æ•°å½¢å¼æè¿°å¼€å‘è€…æ”¶å…¥åˆ†å¸ƒçš„ç›´æ–¹å›¾" class="headerlink" title="å¸¦åˆ†ä½æ•°å½¢å¼æè¿°å¼€å‘è€…æ”¶å…¥åˆ†å¸ƒçš„ç›´æ–¹å›¾"></a>å¸¦åˆ†ä½æ•°å½¢å¼æè¿°å¼€å‘è€…æ”¶å…¥åˆ†å¸ƒçš„ç›´æ–¹å›¾</h5><p>ä¸Šé¢æè¿°çš„åˆ†å¸ƒä¸­çº¢è‰²çº¿ä»£è¡¨äº†åˆ†ä½æ•°å€¼å’Œæˆ‘ä»¬æ½œåœ¨çš„åŒºé—´ã€‚è®©æˆ‘ä»¬åˆ©ç”¨è¿™äº›çŸ¥è¯†æ¥æ„å»ºæˆ‘ä»¬åŸºäºåˆ†åŒºé—´ç­–ç•¥çš„åˆ†ä½æ•°ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">quantile_labels = [<span class="string">'0-25Q'</span>, <span class="string">'25-50Q'</span>, <span class="string">'50-75Q'</span>, <span class="string">'75-100Q'</span>]</span><br><span class="line"></span><br><span class="line">fcc_survey_df[<span class="string">'Income_quantile_range'</span>] = pd.qcut(</span><br><span class="line"></span><br><span class="line">fcc_survey_df[<span class="string">'Income'</span>],q=quantile_list)</span><br><span class="line"></span><br><span class="line">fcc_survey_df[<span class="string">'Income_quantile_label'</span>] = pd.qcut(</span><br><span class="line"></span><br><span class="line">fcc_survey_df[<span class="string">'Income'</span>],q=quantile_list,labels=quantile_labels)</span><br><span class="line"></span><br><span class="line">fcc_survey_df[[<span class="string">'ID.x'</span>, <span class="string">'Age'</span>, <span class="string">'Income'</span>,<span class="string">'Income_quantile_range'</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">'Income_quantile_label'</span>]].iloc[<span class="number">4</span>:<span class="number">9</span>]</span><br></pre></td></tr></table></figure><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5f586dbd8f4.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸Šç¯‡ - è¿ç»­æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><h5 id="åŸºäºåˆ†ä½æ•°çš„å¼€å‘è€…æ”¶å…¥çš„åŒºé—´èŒƒå›´å’Œæ ‡ç­¾"><a href="#åŸºäºåˆ†ä½æ•°çš„å¼€å‘è€…æ”¶å…¥çš„åŒºé—´èŒƒå›´å’Œæ ‡ç­¾" class="headerlink" title="åŸºäºåˆ†ä½æ•°çš„å¼€å‘è€…æ”¶å…¥çš„åŒºé—´èŒƒå›´å’Œæ ‡ç­¾"></a>åŸºäºåˆ†ä½æ•°çš„å¼€å‘è€…æ”¶å…¥çš„åŒºé—´èŒƒå›´å’Œæ ‡ç­¾</h5><p>é€šè¿‡è¿™ä¸ªä¾‹å­ï¼Œä½ åº”è¯¥å¯¹å¦‚ä½•åšåŸºäºåˆ†ä½æ•°çš„è‡ªé€‚åº”åˆ†åŒºé—´æ³•æœ‰äº†ä¸€ä¸ªå¾ˆå¥½çš„è®¤è¯†ã€‚ä¸€ä¸ªéœ€è¦é‡ç‚¹è®°ä½çš„æ˜¯ï¼Œåˆ†åŒºé—´çš„ç»“æœæ˜¯ç¦»æ•£å€¼ç±»å‹çš„åˆ†ç±»ç‰¹å¾ï¼Œå½“ä½ åœ¨æ¨¡å‹ä¸­ä½¿ç”¨åˆ†ç±»æ•°æ®ä¹‹å‰ï¼Œå¯èƒ½éœ€è¦é¢å¤–çš„ç‰¹å¾å·¥ç¨‹ç›¸å…³æ­¥éª¤ã€‚æˆ‘ä»¬å°†åœ¨æ¥ä¸‹æ¥çš„éƒ¨åˆ†ç®€è¦åœ°è®²è¿°åˆ†ç±»æ•°æ®çš„ç‰¹å¾å·¥ç¨‹æŠ€å·§ã€‚</p><h4 id="ç»Ÿè®¡å˜æ¢"><a href="#ç»Ÿè®¡å˜æ¢" class="headerlink" title="ç»Ÿè®¡å˜æ¢"></a>ç»Ÿè®¡å˜æ¢</h4><p>æˆ‘ä»¬è®¨è®ºä¸‹å…ˆå‰ç®€å•æåˆ°è¿‡çš„æ•°æ®åˆ†å¸ƒå€¾æ–œçš„è´Ÿé¢å½±å“ã€‚ç°åœ¨æˆ‘ä»¬å¯ä»¥è€ƒè™‘å¦ä¸€ä¸ªç‰¹å¾å·¥ç¨‹æŠ€å·§ï¼Œå³åˆ©ç”¨ç»Ÿè®¡æˆ–æ•°å­¦å˜æ¢ã€‚æˆ‘ä»¬è¯•è¯•çœ‹ Log å˜æ¢å’Œ Box-Cox å˜æ¢ã€‚è¿™ä¸¤ç§å˜æ¢å‡½æ•°éƒ½å±äºå¹‚å˜æ¢å‡½æ•°ç°‡ï¼Œé€šå¸¸ç”¨æ¥åˆ›å»ºå•è°ƒçš„æ•°æ®å˜æ¢ã€‚å®ƒä»¬çš„ä¸»è¦ä½œç”¨åœ¨äºå®ƒèƒ½å¸®åŠ©ç¨³å®šæ–¹å·®ï¼Œå§‹ç»ˆä¿æŒåˆ†å¸ƒæ¥è¿‘äºæ­£æ€åˆ†å¸ƒå¹¶ä½¿å¾—æ•°æ®ä¸åˆ†å¸ƒçš„å¹³å‡å€¼æ— å…³ã€‚</p><h4 id="Logå˜æ¢"><a href="#Logå˜æ¢" class="headerlink" title="Logå˜æ¢"></a>Logå˜æ¢</h4><p>log å˜æ¢å±äºå¹‚å˜æ¢å‡½æ•°ç°‡ã€‚è¯¥å‡½æ•°ç”¨æ•°å­¦è¡¨è¾¾å¼è¡¨ç¤ºä¸º</p><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5f588a0f6a5.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸Šç¯‡ - è¿ç»­æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><p>è¯»ä¸ºä»¥ b ä¸ºåº• x çš„å¯¹æ•°ç­‰äº yã€‚è¿™å¯ä»¥å˜æ¢ä¸º</p><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5f589e77242.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸Šç¯‡ - è¿ç»­æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><p>è¡¨ç¤ºä»¥bä¸ºåº•æŒ‡æ•°å¿…é¡»è¾¾åˆ°å¤šå°‘æ‰ç­‰äºxã€‚è‡ªç„¶å¯¹æ•°ä½¿ç”¨ b=eï¼Œe=2.71828ï¼Œé€šå¸¸å«ä½œæ¬§æ‹‰å¸¸æ•°ã€‚ä½ å¯ä»¥ä½¿ç”¨é€šå¸¸åœ¨åè¿›åˆ¶ç³»ç»Ÿä¸­ä½¿ç”¨çš„ b=10 ä½œä¸ºåº•æ•°ã€‚</p><p><strong>å½“åº”ç”¨äºå€¾æ–œåˆ†å¸ƒæ—¶ Log å˜æ¢æ˜¯å¾ˆæœ‰ç”¨çš„ï¼Œå› ä¸ºä»–ä»¬å€¾å‘äºæ‹‰ä¼¸é‚£äº›è½åœ¨è¾ƒä½çš„å¹…åº¦èŒƒå›´å†…è‡ªå˜é‡å€¼çš„èŒƒå›´ï¼Œå€¾å‘äºå‹ç¼©æˆ–å‡å°‘æ›´é«˜å¹…åº¦èŒƒå›´å†…çš„è‡ªå˜é‡å€¼çš„èŒƒå›´</strong>ã€‚ä»è€Œä½¿å¾—å€¾æ–œåˆ†å¸ƒå°½å¯èƒ½çš„æ¥è¿‘æ­£æ€åˆ†å¸ƒã€‚è®©æˆ‘ä»¬å¯¹å…ˆå‰ä½¿ç”¨çš„å¼€å‘è€…æ•°æ®é›†çš„ Income ç‰¹å¾ä¸Šä½¿ç”¨logå˜æ¢ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fcc_survey_df[<span class="string">'Income_log'</span>] = np.log((<span class="number">1</span>+fcc_survey_df[<span class="string">'Income'</span>]))</span><br><span class="line"></span><br><span class="line">fcc_survey_df[[<span class="string">'ID.x'</span>, <span class="string">'Age'</span>, <span class="string">'Income'</span>,<span class="string">'Income_log'</span>]].iloc[<span class="number">4</span>:<span class="number">9</span>]</span><br></pre></td></tr></table></figure><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5f58b3ed249.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸Šç¯‡ - è¿ç»­æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><h5 id="å¼€å‘è€…æ”¶å…¥logå˜æ¢åç»“æ„"><a href="#å¼€å‘è€…æ”¶å…¥logå˜æ¢åç»“æ„" class="headerlink" title="å¼€å‘è€…æ”¶å…¥logå˜æ¢åç»“æ„"></a>å¼€å‘è€…æ”¶å…¥logå˜æ¢åç»“æ„</h5><p>Income_log å­—æ®µæè¿°äº†ç»è¿‡ log å˜æ¢åçš„ç‰¹å¾ã€‚ç°åœ¨è®©æˆ‘ä»¬æ¥çœ‹çœ‹å­—æ®µå˜æ¢åæ•°æ®çš„åˆ†å¸ƒã€‚</p><p>åŸºäºä¸Šé¢çš„å›¾ï¼Œæˆ‘ä»¬å¯ä»¥æ¸…æ¥šåœ°çœ‹åˆ°ä¸å…ˆå‰å€¾æ–œåˆ†å¸ƒç›¸æ¯”ï¼Œè¯¥åˆ†å¸ƒæ›´åŠ åƒæ­£æ€åˆ†å¸ƒæˆ–é«˜æ–¯åˆ†å¸ƒã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">income_log_mean =np.round(np.mean(fcc_survey_df[<span class="string">'Income_log'</span>]), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line"></span><br><span class="line">fcc_survey_df[<span class="string">'Income_log'</span>].hist(bins=<span class="number">30</span>,color=<span class="string">'#A9C5D3'</span>,edgecolor=<span class="string">'black'</span>,grid=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">plt.axvline(income_log_mean, color=<span class="string">'r'</span>)</span><br><span class="line"></span><br><span class="line">ax.set_title(<span class="string">'Developer Income Histogram after Log Transform'</span>,fontsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line">ax.set_xlabel(<span class="string">'Developer Income (log scale)'</span>,fontsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line">ax.set_ylabel(<span class="string">'Frequency'</span>, fontsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line">ax.text(<span class="number">11.5</span>, <span class="number">450</span>, <span class="string">r'$\mu$='</span>+str(income_log_mean),fontsize=<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5f58cdaf02a.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸Šç¯‡ - è¿ç»­æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><p><strong>ç»è¿‡logå˜æ¢åæè¿°å¼€å‘è€…æ”¶å…¥åˆ†å¸ƒçš„ç›´æ–¹å›¾</strong></p><h4 id="Box-Coxå˜æ¢"><a href="#Box-Coxå˜æ¢" class="headerlink" title="Box-Coxå˜æ¢"></a>Box-Coxå˜æ¢</h4><p>Box-Cox å˜æ¢æ˜¯å¦ä¸€ä¸ªæµè¡Œçš„å¹‚å˜æ¢å‡½æ•°ç°‡ä¸­çš„ä¸€ä¸ªå‡½æ•°ã€‚è¯¥å‡½æ•°æœ‰ä¸€ä¸ªå‰ææ¡ä»¶ï¼Œå³æ•°å€¼å‹å€¼å¿…é¡»å…ˆå˜æ¢ä¸ºæ­£æ•°ï¼ˆä¸ log å˜æ¢æ‰€è¦æ±‚çš„ä¸€æ ·ï¼‰ã€‚ä¸‡ä¸€å‡ºç°æ•°å€¼æ˜¯è´Ÿçš„ï¼Œä½¿ç”¨ä¸€ä¸ªå¸¸æ•°å¯¹æ•°å€¼è¿›è¡Œåç§»æ˜¯æœ‰å¸®åŠ©çš„ã€‚æ•°å­¦ä¸Šï¼ŒBox-Cox å˜æ¢å‡½æ•°å¯ä»¥è¡¨ç¤ºå¦‚ä¸‹ã€‚</p><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5f58e556c08.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸Šç¯‡ - è¿ç»­æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><p>ç”Ÿæˆçš„å˜æ¢åçš„è¾“å‡ºyæ˜¯è¾“å…¥ x å’Œå˜æ¢å‚æ•°çš„å‡½æ•°ï¼›å½“ Î»=0 æ—¶ï¼Œè¯¥å˜æ¢å°±æ˜¯è‡ªç„¶å¯¹æ•° log å˜æ¢ï¼Œå‰é¢æˆ‘ä»¬å·²ç»æåˆ°è¿‡äº†ã€‚Î» çš„æœ€ä½³å–å€¼é€šå¸¸ç”±æœ€å¤§ä¼¼ç„¶æˆ–æœ€å¤§å¯¹æ•°ä¼¼ç„¶ç¡®å®šã€‚ç°åœ¨è®©æˆ‘ä»¬åœ¨å¼€å‘è€…æ•°æ®é›†çš„æ”¶å…¥ç‰¹å¾ä¸Šåº”ç”¨ Box-Cox å˜æ¢ã€‚é¦–å…ˆæˆ‘ä»¬ä»æ•°æ®åˆ†å¸ƒä¸­ç§»é™¤éé›¶å€¼å¾—åˆ°æœ€ä½³çš„å€¼ï¼Œç»“æœå¦‚ä¸‹ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">income = np.array(fcc_survey_df[<span class="string">'Income'</span>])</span><br><span class="line"></span><br><span class="line">income_clean = income[~np.isnan(income)]</span><br><span class="line"></span><br><span class="line">l, opt_lambda = spstats.boxcox(income_clean)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Optimal lambda value:'</span>, opt_lambda)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">**Output**</span><br><span class="line"></span><br><span class="line">**------**</span><br><span class="line"></span><br><span class="line">Optimal <span class="keyword">lambda</span> value: <span class="number">0.117991239456</span></span><br></pre></td></tr></table></figure><p>ç°åœ¨æˆ‘ä»¬å¾—åˆ°äº†æœ€ä½³çš„å€¼ï¼Œè®©æˆ‘ä»¬åœ¨å–å€¼ä¸º 0 å’Œ Î»ï¼ˆæœ€ä½³å–å€¼ Î» ï¼‰æ—¶ä½¿ç”¨ Box-Cox å˜æ¢å¯¹å¼€å‘è€…æ”¶å…¥ç‰¹å¾è¿›è¡Œå˜æ¢ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fcc_survey_df[<span class="string">'Income_boxcox_lambda_0'</span>] = spstats.boxcox((<span class="number">1</span>+fcc_survey_df[<span class="string">'Income'</span>]),lmbda=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">fcc_survey_df[<span class="string">'Income_boxcox_lambda_opt'</span>] = spstats.boxcox(fcc_survey_df[<span class="string">'Income'</span>],lmbda=opt_lambda)</span><br><span class="line"></span><br><span class="line">fcc_survey_df[[<span class="string">'ID.x'</span>, <span class="string">'Age'</span>, <span class="string">'Income'</span>, <span class="string">'Income_log'</span>,<span class="string">'Income_boxcox_lambda_0'</span>,<span class="string">'Income_boxcox_lambda_opt'</span>]].iloc[<span class="number">4</span>:<span class="number">9</span>]</span><br></pre></td></tr></table></figure><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5f58fd7fd5e.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸Šç¯‡ - è¿ç»­æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><h5 id="ç»è¿‡-Box-Cox-å˜æ¢åå¼€å‘è€…çš„æ”¶å…¥åˆ†å¸ƒ"><a href="#ç»è¿‡-Box-Cox-å˜æ¢åå¼€å‘è€…çš„æ”¶å…¥åˆ†å¸ƒ" class="headerlink" title="ç»è¿‡ Box-Cox å˜æ¢åå¼€å‘è€…çš„æ”¶å…¥åˆ†å¸ƒ"></a>ç»è¿‡ Box-Cox å˜æ¢åå¼€å‘è€…çš„æ”¶å…¥åˆ†å¸ƒ</h5><p>å˜æ¢åçš„ç‰¹å¾åœ¨ä¸Šè¿°æ•°æ®æ¡†ä¸­æè¿°äº†ã€‚å°±åƒæˆ‘ä»¬æœŸæœ›çš„é‚£æ ·ï¼ŒIncome_log å’Œ Income_boxcox_lamba_0å…·æœ‰ç›¸åŒçš„å–å€¼ã€‚è®©æˆ‘ä»¬çœ‹çœ‹ç»è¿‡æœ€ä½³Î»å˜æ¢å Income ç‰¹å¾çš„åˆ†å¸ƒã€‚</p><blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&gt;income_boxcox_mean = np.round(np.mean(fcc_survey_df[<span class="string">'Income_boxcox_lambda_opt'</span>]),<span class="number">2</span>)</span><br><span class="line">&gt; </span><br><span class="line">&gt;fig, ax = plt.subplots()</span><br><span class="line">&gt; </span><br><span class="line">&gt;fcc_survey_df[<span class="string">'Income_boxcox_lambda_opt'</span>].hist(bins=<span class="number">30</span>,  color=<span class="string">'#A9C5D3'</span>,edgecolor=<span class="string">'black'</span>, grid=<span class="literal">False</span>)</span><br><span class="line">&gt;    plt.axvline(income_boxcox_mean, color=<span class="string">'r'</span>)</span><br><span class="line">&gt;</span><br><span class="line">&gt; ax.set_title(<span class="string">'Developer Income Histogram after Boxâ€“Cox Transform'</span>,fontsize=<span class="number">12</span>)</span><br><span class="line">&gt;</span><br><span class="line">&gt; ax.set_xlabel(<span class="string">'Developer Income (Boxâ€“Cox transform)'</span>,fontsize=<span class="number">12</span>)</span><br><span class="line">&gt;</span><br><span class="line">&gt; ax.set_ylabel(<span class="string">'Frequency'</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">&gt;</span><br><span class="line">&gt; ax.text(<span class="number">24</span>, <span class="number">450</span>, <span class="string">r'$\mu$='</span>+str(income_boxcox_mean),fontsize=<span class="number">10</span>)       </span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5f591679bfb.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸Šç¯‡ - è¿ç»­æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><p><strong>ç»è¿‡Box-Coxå˜æ¢åæè¿°å¼€å‘è€…æ”¶å…¥åˆ†å¸ƒçš„ç›´æ–¹å›¾</strong></p><p> åˆ†å¸ƒçœ‹èµ·æ¥æ›´åƒæ˜¯æ­£æ€åˆ†å¸ƒï¼Œä¸æˆ‘ä»¬ç»è¿‡ log å˜æ¢åçš„åˆ†å¸ƒç›¸ä¼¼ã€‚</p><h3 id="ç±»åˆ«å‹æ•°æ®ä¸Šçš„ç‰¹å¾å·¥ç¨‹"><a href="#ç±»åˆ«å‹æ•°æ®ä¸Šçš„ç‰¹å¾å·¥ç¨‹" class="headerlink" title="ç±»åˆ«å‹æ•°æ®ä¸Šçš„ç‰¹å¾å·¥ç¨‹"></a>ç±»åˆ«å‹æ•°æ®ä¸Šçš„ç‰¹å¾å·¥ç¨‹</h3><p>åœ¨æ·±å…¥ç ”ç©¶ç‰¹å¾å·¥ç¨‹ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å…ˆäº†è§£ä¸€ä¸‹åˆ†ç±»æ•°æ®ã€‚é€šå¸¸ï¼Œåœ¨<strong>è‡ªç„¶ç•Œä¸­å¯åˆ†ç±»çš„ä»»æ„æ•°æ®å±æ€§éƒ½æ˜¯ç¦»æ•£å€¼ï¼Œè¿™æ„å‘³ç€å®ƒä»¬å±äºæŸä¸€ç‰¹å®šçš„æœ‰é™ç±»åˆ«</strong>ã€‚åœ¨æ¨¡å‹é¢„æµ‹çš„å±æ€§æˆ–è€…å˜é‡ï¼ˆé€šå¸¸è¢«ç§°ä¸º<strong>å“åº”å˜é‡ response variables</strong>ï¼‰ä¸­ï¼Œè¿™äº›ä¹Ÿç»å¸¸è¢«ç§°ä¸ºç±»åˆ«æˆ–è€…æ ‡ç­¾ã€‚è¿™äº›ç¦»æ•£å€¼åœ¨è‡ªç„¶ç•Œä¸­å¯ä»¥æ˜¯æ–‡æœ¬æˆ–è€…æ•°å­—ï¼ˆç”šè‡³æ˜¯è¯¸å¦‚å›¾åƒè¿™æ ·çš„éç»“æ„åŒ–æ•°æ®ï¼‰ã€‚åˆ†ç±»æ•°æ®æœ‰ä¸¤å¤§ç±»â€”â€”<strong>å®šç±»ï¼ˆNominalï¼‰å’Œå®šåºï¼ˆOrdinalï¼‰</strong>ã€‚</p><p>åœ¨ä»»æ„å®šç±»åˆ†ç±»æ•°æ®å±æ€§ä¸­ï¼Œè¿™äº›å±æ€§å€¼ä¹‹é—´<strong>æ²¡æœ‰é¡ºåºçš„æ¦‚å¿µ</strong>ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œä¸¾ä¸ªç®€å•çš„ä¾‹å­ï¼Œå¤©æ°”åˆ†ç±»ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œåœ¨è¿™ä¸ªç‰¹å®šçš„åœºæ™¯ä¸­ï¼Œä¸»è¦æœ‰å…­ä¸ªå¤§ç±»ï¼Œè€Œè¿™äº›ç±»ä¹‹é—´æ²¡æœ‰ä»»ä½•é¡ºåºä¸Šçš„å…³ç³»ï¼ˆåˆ®é£å¤©å¹¶ä¸æ€»æ˜¯å‘ç”Ÿåœ¨æ™´å¤©ä¹‹å‰ï¼Œå¹¶ä¸”ä¹Ÿä¸èƒ½è¯´æ¯”æ™´å¤©æ¥çš„æ›´å°æˆ–è€…æ›´å¤§ï¼‰</p><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5af6bc87b4e.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸‹ç¯‡ - ç¦»æ•£æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><p>å°†å¤©æ°”ä½œä¸ºåˆ†ç±»å±æ€§</p><p>ä¸å¤©æ°”ç›¸ç±»ä¼¼çš„å±æ€§è¿˜æœ‰å¾ˆå¤šï¼Œæ¯”å¦‚ç”µå½±ã€éŸ³ä¹ã€ç”µå­æ¸¸æˆã€å›½å®¶ã€é£Ÿç‰©å’Œç¾é£Ÿç±»å‹ç­‰ç­‰ï¼Œè¿™äº›éƒ½å±äºå®šç±»åˆ†ç±»å±æ€§ã€‚</p><p>å®šåºåˆ†ç±»çš„å±æ€§å€¼åˆ™å­˜åœ¨ç€ä¸€å®šçš„é¡ºåºæ„ä¹‰æˆ–æ¦‚å¿µã€‚ä¾‹å¦‚ï¼Œä¸‹å›¾ä¸­çš„å­—æ¯æ ‡è¯†äº†è¡¬è¡«çš„å¤§å°ã€‚æ˜¾è€Œæ˜“è§çš„æ˜¯ï¼Œå½“æˆ‘ä»¬è€ƒè™‘è¡¬è¡«çš„æ—¶å€™ï¼Œå®ƒçš„â€œå¤§å°â€å±æ€§æ˜¯å¾ˆé‡è¦çš„ï¼ˆS ç æ¯” M ç æ¥çš„å°ï¼Œè€Œ M ç åˆå°äº L ç ç­‰ç­‰ï¼‰ã€‚</p><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5af6d3b83ac.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸‹ç¯‡ - ç¦»æ•£æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><p>è¡¬è¡«å¤§å°ä½œä¸ºå®šåºåˆ†ç±»å±æ€§</p><p>é‹å·ã€å—æ•™è‚²æ°´å¹³å’Œå…¬å¸èŒä½åˆ™æ˜¯å®šåºåˆ†ç±»å±æ€§çš„ä¸€äº›å…¶å®ƒä¾‹å­ã€‚æ—¢ç„¶å·²ç»å¯¹åˆ†ç±»æ•°æ®æœ‰äº†ä¸€ä¸ªå¤§è‡´çš„ç†è§£ä¹‹åï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬æ¥çœ‹çœ‹ä¸€äº›ç‰¹å¾å·¥ç¨‹çš„ç­–ç•¥ã€‚</p><p>åœ¨æ¥å—åƒæ–‡æœ¬æ ‡ç­¾è¿™æ ·å¤æ‚çš„åˆ†ç±»æ•°æ®ç±»å‹é—®é¢˜ä¸Šï¼Œå„ç§æœºå™¨å­¦ä¹ æ¡†æ¶å‡å·²å–å¾—äº†è®¸å¤šçš„è¿›æ­¥ã€‚é€šå¸¸ï¼Œç‰¹å¾å·¥ç¨‹ä¸­çš„ä»»æ„æ ‡å‡†å·¥ä½œæµéƒ½æ¶‰åŠå°†è¿™äº›åˆ†ç±»å€¼è½¬æ¢ä¸ºæ•°å€¼æ ‡ç­¾çš„æŸç§å½¢å¼ï¼Œç„¶åå¯¹è¿™äº›å€¼åº”ç”¨ä¸€äº›<strong>ç¼–ç æ–¹æ¡ˆ</strong>ã€‚æˆ‘ä»¬å°†åœ¨å¼€å§‹ä¹‹å‰å¯¼å…¥å¿…è¦çš„å·¥å…·åŒ…ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><h4 id="å®šç±»å±æ€§è½¬æ¢-LabelEncoding"><a href="#å®šç±»å±æ€§è½¬æ¢-LabelEncoding" class="headerlink" title="å®šç±»å±æ€§è½¬æ¢(LabelEncoding)"></a>å®šç±»å±æ€§è½¬æ¢(LabelEncoding)</h4><p><strong>å®šç±»å±æ€§ç”±ç¦»æ•£çš„åˆ†ç±»å€¼ç»„æˆï¼Œå®ƒä»¬æ²¡æœ‰å…ˆåé¡ºåºæ¦‚å¿µ</strong>ã€‚è¿™é‡Œçš„æ€æƒ³æ˜¯å°†è¿™äº›å±æ€§è½¬æ¢æˆæ›´å…·ä»£è¡¨æ€§çš„æ•°å€¼æ ¼å¼ï¼Œè¿™æ ·å¯ä»¥å¾ˆå®¹æ˜“è¢«ä¸‹æ¸¸çš„ä»£ç å’Œæµæ°´çº¿æ‰€ç†è§£ã€‚æˆ‘ä»¬æ¥çœ‹ä¸€ä¸ªå…³äºè§†é¢‘æ¸¸æˆé”€å”®çš„æ–°æ•°æ®é›†ã€‚è¿™ä¸ªæ•°æ®é›†ä¹Ÿå¯ä»¥åœ¨ <a href="https://www.kaggle.com/gregorut/videogamesales" target="_blank" rel="noopener">Kaggle</a> å’Œæˆ‘çš„ <a href="https://github.com/dipanjanS/practical-machine-learning-with-python/tree/master/notebooks/Ch04_Feature_Engineering_and_Selection" target="_blank" rel="noopener">GitHub</a> ä»“åº“ä¸­æ‰¾åˆ°ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vg_df = pd.read_csv(<span class="string">'datasets/vgsales.csv'</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line">vg_df[[<span class="string">'Name'</span>, <span class="string">'Platform'</span>, <span class="string">'Year'</span>, <span class="string">'Genre'</span>, <span class="string">'Publisher'</span>]].iloc[<span class="number">1</span>:<span class="number">7</span>]</span><br></pre></td></tr></table></figure><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5af756b687d.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸‹ç¯‡ - ç¦»æ•£æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><p>æ¸¸æˆé”€å”®æ•°æ®</p><p>è®©æˆ‘ä»¬é¦–å…ˆä¸“æ³¨äºä¸Šé¢æ•°æ®æ¡†ä¸­â€œè§†é¢‘æ¸¸æˆé£æ ¼ï¼ˆGenreï¼‰â€å±æ€§ã€‚æ˜¾è€Œæ˜“è§çš„æ˜¯ï¼Œè¿™æ˜¯ä¸€ä¸ªç±»ä¼¼äºâ€œå‘è¡Œå•†ï¼ˆPublisherï¼‰â€å’Œâ€œå¹³å°ï¼ˆPlatformï¼‰â€å±æ€§ä¸€æ ·çš„å®šç±»åˆ†ç±»å±æ€§ã€‚æˆ‘ä»¬å¯ä»¥å¾ˆå®¹æ˜“å¾—åˆ°ä¸€ä¸ªç‹¬ç‰¹çš„è§†é¢‘æ¸¸æˆé£æ ¼åˆ—è¡¨ï¼Œå¦‚ä¸‹ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">genres = np.unique(vg_df[<span class="string">'Genre'</span>])</span><br><span class="line"></span><br><span class="line">genres</span><br><span class="line"></span><br><span class="line">Output</span><br><span class="line"></span><br><span class="line">\------</span><br><span class="line"></span><br><span class="line">array([<span class="string">'Action'</span>, <span class="string">'Adventure'</span>, <span class="string">'Fighting'</span>, <span class="string">'Misc'</span>, <span class="string">'Platform'</span>, <span class="string">'Puzzle'</span>, <span class="string">'Racing'</span>, <span class="string">'Role-Playing'</span>, <span class="string">'Shooter'</span>, <span class="string">'Simulation'</span>, <span class="string">'Sports'</span>, <span class="string">'Strategy'</span>], dtype=object)</span><br></pre></td></tr></table></figure><p>è¾“å‡ºç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬æœ‰ 12 ç§ä¸åŒçš„è§†é¢‘æ¸¸æˆé£æ ¼ã€‚æˆ‘ä»¬ç°åœ¨å¯ä»¥ç”Ÿæˆä¸€ä¸ªæ ‡ç­¾ç¼–ç æ–¹æ³•ï¼Œå³åˆ©ç”¨ scikit-learn å°†æ¯ä¸ªç±»åˆ«æ˜ å°„åˆ°ä¸€ä¸ªæ•°å€¼ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"></span><br><span class="line">gle = LabelEncoder()</span><br><span class="line"></span><br><span class="line">genre_labels = gle.fit_transform(vg_df[<span class="string">'Genre'</span>])</span><br><span class="line"></span><br><span class="line">genre_mappings = &#123;index: label <span class="keyword">for</span> index, label <span class="keyword">in</span> enumerate(gle.classes_)&#125;</span><br><span class="line"></span><br><span class="line">genre_mappings</span><br><span class="line"></span><br><span class="line">Output</span><br><span class="line"></span><br><span class="line">\------</span><br><span class="line"></span><br><span class="line">&#123;<span class="number">0</span>: <span class="string">'Action'</span>, <span class="number">1</span>: <span class="string">'Adventure'</span>, <span class="number">2</span>: <span class="string">'Fighting'</span>, <span class="number">3</span>: <span class="string">'Misc'</span>, <span class="number">4</span>: <span class="string">'Platform'</span>, <span class="number">5</span>: <span class="string">'Puzzle'</span>, <span class="number">6</span>: <span class="string">'Racing'</span>, <span class="number">7</span>: <span class="string">'Role-Playing'</span>, <span class="number">8</span>: <span class="string">'Shooter'</span>, <span class="number">9</span>: <span class="string">'Simulation'</span>, <span class="number">10</span>: <span class="string">'Sports'</span>, <span class="number">11</span>: <span class="string">'Strategy'</span>&#125;</span><br></pre></td></tr></table></figure><p>å› æ­¤ï¼Œåœ¨ <em>LabelEncoder</em> ç±»çš„å®ä¾‹å¯¹è±¡ <em>gle</em> çš„å¸®åŠ©ä¸‹ç”Ÿæˆäº†ä¸€ä¸ªæ˜ å°„æ–¹æ¡ˆï¼ŒæˆåŠŸåœ°å°†æ¯ä¸ªé£æ ¼å±æ€§æ˜ å°„åˆ°ä¸€ä¸ªæ•°å€¼ã€‚è½¬æ¢åçš„æ ‡ç­¾å­˜å‚¨åœ¨ <em>genre_labels</em> ä¸­ï¼Œè¯¥å˜é‡å…è®¸æˆ‘ä»¬å°†å…¶å†™å›æ•°æ®è¡¨ä¸­ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vg_df[<span class="string">'GenreLabel'</span>] = genre_labels</span><br><span class="line"></span><br><span class="line">vg_df[[<span class="string">'Name'</span>, <span class="string">'Platform'</span>, <span class="string">'Year'</span>, <span class="string">'Genre'</span>, <span class="string">'GenreLabel'</span>]].iloc[<span class="number">1</span>:<span class="number">7</span>]</span><br></pre></td></tr></table></figure><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5af8164e6db.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸‹ç¯‡ - ç¦»æ•£æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><p>è§†é¢‘æ¸¸æˆé£æ ¼åŠå…¶ç¼–ç æ ‡ç­¾</p><p>å¦‚æœä½ æ‰“ç®—å°†å®ƒä»¬ç”¨ä½œé¢„æµ‹çš„å“åº”å˜é‡ï¼Œé‚£ä¹ˆè¿™äº›æ ‡ç­¾é€šå¸¸å¯ä»¥ç›´æ¥ç”¨äºè¯¸å¦‚ sikit-learn è¿™æ ·çš„æ¡†æ¶ã€‚ä½†æ˜¯å¦‚å‰æ‰€è¿°ï¼Œæˆ‘ä»¬è¿˜éœ€è¦é¢å¤–çš„ç¼–ç æ­¥éª¤æ‰èƒ½å°†å®ƒä»¬ç”¨ä½œç‰¹å¾ã€‚</p><h4 id="å®šåºå±æ€§ç¼–ç "><a href="#å®šåºå±æ€§ç¼–ç " class="headerlink" title="å®šåºå±æ€§ç¼–ç "></a>å®šåºå±æ€§ç¼–ç </h4><p><strong>å®šåºå±æ€§æ˜¯ä¸€ç§å¸¦æœ‰å…ˆåé¡ºåºæ¦‚å¿µçš„åˆ†ç±»å±æ€§</strong>ã€‚è¿™é‡Œæˆ‘å°†ä»¥æœ¬ç³»åˆ—æ–‡ç« ç¬¬ä¸€éƒ¨åˆ†æ‰€ä½¿ç”¨çš„<a href="https://www.kaggle.com/abcsds/pokemon/data" target="_blank" rel="noopener">ç¥å¥‡å®è´æ•°æ®é›†</a>è¿›è¡Œè¯´æ˜ã€‚è®©æˆ‘ä»¬å…ˆä¸“æ³¨äº ã€Œä¸–ä»£ï¼ˆGenerationï¼‰ã€ å±æ€§ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&gt; poke_df = pd.read_csv(<span class="string">'datasets/Pokemon.csv'</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">&gt;</span><br><span class="line">&gt; poke_df = poke_df.sample(random_state=<span class="number">1</span>, frac=<span class="number">1</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">&gt;</span><br><span class="line">&gt; np.unique(poke_df[<span class="string">'Generation'</span>])</span><br><span class="line">&gt;</span><br><span class="line">&gt; Output</span><br><span class="line">&gt;</span><br><span class="line">&gt; \------</span><br><span class="line">&gt;</span><br><span class="line">&gt; array([<span class="string">'Gen 1'</span>, <span class="string">'Gen 2'</span>, <span class="string">'Gen 3'</span>, <span class="string">'Gen 4'</span>, <span class="string">'Gen 5'</span>, <span class="string">'Gen 6'</span>], dtype=object)</span><br></pre></td></tr></table></figure><p>æ ¹æ®ä¸Šé¢çš„è¾“å‡ºï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸€å…±æœ‰ 6 ä»£ï¼Œå¹¶ä¸”æ¯ä¸ªç¥å¥‡å®è´é€šå¸¸å±äºè§†é¢‘æ¸¸æˆçš„ç‰¹å®šä¸–ä»£ï¼ˆä¾æ®å‘å¸ƒé¡ºåºï¼‰ï¼Œè€Œä¸”ç”µè§†ç³»åˆ—ä¹Ÿéµå¾ªäº†ç›¸ä¼¼çš„æ—¶é—´çº¿ã€‚è¿™ä¸ªå±æ€§é€šå¸¸æ˜¯å®šåºçš„ï¼ˆéœ€è¦ç›¸å…³çš„é¢†åŸŸçŸ¥è¯†æ‰èƒ½ç†è§£ï¼‰ï¼Œå› ä¸ºå±äºç¬¬ä¸€ä»£çš„å¤§å¤šæ•°ç¥å¥‡å®è´åœ¨ç¬¬äºŒä»£çš„è§†é¢‘æ¸¸æˆæˆ–è€…ç”µè§†èŠ‚ç›®ä¸­ä¹Ÿä¼šè¢«æ›´æ—©åœ°å¼•å…¥ã€‚ç¥å¥‡å®è´çš„ç²‰ä¸ä»¬å¯ä»¥çœ‹ä¸‹ä¸‹å›¾ï¼Œç„¶åè®°ä½æ¯ä¸€ä»£ä¸­ä¸€äº›æ¯”è¾ƒå—æ¬¢è¿çš„ç¥å¥‡å®è´ï¼ˆä¸åŒçš„ç²‰ä¸å¯èƒ½æœ‰ä¸åŒçš„çœ‹æ³•ï¼‰ã€‚</p><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5af8f58f535.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸‹ç¯‡ - ç¦»æ•£æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><p>åŸºäºä¸åŒç±»å‹å’Œä¸–ä»£é€‰å‡ºçš„ä¸€äº›å—æ¬¢è¿çš„ç¥å¥‡å®è´</p><p>å› æ­¤ï¼Œå®ƒä»¬ä¹‹é—´å­˜åœ¨ç€å…ˆåé¡ºåºã€‚ä¸€èˆ¬æ¥è¯´ï¼Œæ²¡æœ‰é€šç”¨çš„æ¨¡å—æˆ–è€…å‡½æ•°å¯ä»¥æ ¹æ®è¿™äº›é¡ºåºè‡ªåŠ¨å°†è¿™äº›ç‰¹å¾è½¬æ¢å’Œæ˜ å°„åˆ°æ•°å€¼è¡¨ç¤ºã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è‡ªå®šä¹‰çš„ç¼–ç \æ˜ å°„æ–¹æ¡ˆã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">gen_ord_map = &#123;<span class="string">'Gen 1'</span>: <span class="number">1</span>, <span class="string">'Gen 2'</span>: <span class="number">2</span>, <span class="string">'Gen 3'</span>: <span class="number">3</span>, <span class="string">'Gen 4'</span>: <span class="number">4</span>, <span class="string">'Gen 5'</span>: <span class="number">5</span>, <span class="string">'Gen 6'</span>: <span class="number">6</span>&#125; </span><br><span class="line"></span><br><span class="line">poke_df[<span class="string">'GenerationLabel'</span>] = poke_df[<span class="string">'Generation'</span>].map(gen_ord_map)</span><br><span class="line"></span><br><span class="line">poke_df[[<span class="string">'Name'</span>, <span class="string">'Generation'</span>, <span class="string">'GenerationLabel'</span>]].iloc[<span class="number">4</span>:<span class="number">10</span>]</span><br></pre></td></tr></table></figure><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5af95f94dc8.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸‹ç¯‡ - ç¦»æ•£æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><p>ç¥å¥‡å®è´ä¸–ä»£ç¼–ç </p><p>ä»ä¸Šé¢çš„ä»£ç ä¸­å¯ä»¥çœ‹å‡ºï¼Œæ¥è‡ª <em>pandas</em> åº“çš„ <em>map(â€¦)</em> å‡½æ•°åœ¨è½¬æ¢è¿™ç§å®šåºç‰¹å¾çš„æ—¶å€™éå¸¸æœ‰ç”¨ã€‚</p><h4 id="ç¼–ç åˆ†ç±»å±æ€§â€“ç‹¬çƒ­ç¼–ç æ–¹æ¡ˆï¼ˆOne-hot-Encoding-Schemeï¼‰"><a href="#ç¼–ç åˆ†ç±»å±æ€§â€“ç‹¬çƒ­ç¼–ç æ–¹æ¡ˆï¼ˆOne-hot-Encoding-Schemeï¼‰" class="headerlink" title="ç¼–ç åˆ†ç±»å±æ€§â€“ç‹¬çƒ­ç¼–ç æ–¹æ¡ˆï¼ˆOne-hot Encoding Schemeï¼‰"></a>ç¼–ç åˆ†ç±»å±æ€§â€“ç‹¬çƒ­ç¼–ç æ–¹æ¡ˆï¼ˆOne-hot Encoding Schemeï¼‰</h4><p>å¦‚æœä½ è¿˜è®°å¾—æˆ‘ä»¬ä¹‹å‰æåˆ°è¿‡çš„å†…å®¹ï¼Œé€šå¸¸å¯¹åˆ†ç±»æ•°æ®è¿›è¡Œç‰¹å¾å·¥ç¨‹å°±æ¶‰åŠåˆ°ä¸€ä¸ªè½¬æ¢è¿‡ç¨‹ï¼Œæˆ‘ä»¬åœ¨å‰ä¸€éƒ¨åˆ†æè¿°äº†ä¸€ä¸ªè½¬æ¢è¿‡ç¨‹ï¼Œè¿˜æœ‰ä¸€ä¸ªå¼ºåˆ¶ç¼–ç è¿‡ç¨‹ï¼Œæˆ‘ä»¬åº”ç”¨ç‰¹å®šçš„ç¼–ç æ–¹æ¡ˆä¸ºç‰¹å®šçš„æ¯ä¸ªç±»åˆ«åˆ›å»ºè™šæ‹Ÿå˜é‡æˆ–ç‰¹å¾åˆ†ç±»å±æ€§ã€‚</p><p>ä½ å¯èƒ½æƒ³çŸ¥é“ï¼Œæˆ‘ä»¬åˆšåˆšåœ¨ä¸Šä¸€èŠ‚è¯´åˆ°å°†ç±»åˆ«è½¬æ¢ä¸ºæ•°å­—æ ‡ç­¾ï¼Œä¸ºä»€ä¹ˆç°åœ¨æˆ‘ä»¬åˆéœ€è¦è¿™ä¸ªï¼ŸåŸå› å¾ˆç®€å•ã€‚è€ƒè™‘åˆ°è§†é¢‘æ¸¸æˆé£æ ¼ï¼Œå¦‚æœæˆ‘ä»¬ç›´æ¥å°† <em>GenereLabel</em> ä½œä¸ºå±æ€§ç‰¹å¾æä¾›ç»™æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œåˆ™æ¨¡å‹ä¼šè®¤ä¸ºå®ƒæ˜¯ä¸€ä¸ªè¿ç»­çš„æ•°å€¼ç‰¹å¾ï¼Œä»è€Œè®¤ä¸ºå€¼ 10 ï¼ˆä½“è‚²ï¼‰è¦å¤§äºå€¼ 6 ï¼ˆèµ›è½¦ï¼‰ï¼Œç„¶è€Œäº‹å®ä¸Šè¿™ç§ä¿¡æ¯æ˜¯æ¯«æ— æ„ä¹‰çš„ï¼Œå› ä¸º<em>ä½“è‚²ç±»å‹</em>æ˜¾ç„¶å¹¶ä¸å¤§äºæˆ–è€…å°äº<em>èµ›è½¦ç±»å‹</em>ï¼Œè¿™äº›ä¸åŒå€¼æˆ–è€…ç±»åˆ«æ— æ³•ç›´æ¥è¿›è¡Œæ¯”è¾ƒã€‚å› æ­¤æˆ‘ä»¬éœ€è¦å¦ä¸€å¥—ç¼–ç æ–¹æ¡ˆå±‚ï¼Œå®ƒè¦èƒ½ä¸ºæ¯ä¸ªå±æ€§çš„æ‰€æœ‰ä¸åŒç±»åˆ«ä¸­çš„æ¯ä¸ªå”¯ä¸€å€¼æˆ–ç±»åˆ«åˆ›å»ºè™šæ‹Ÿç‰¹å¾ã€‚</p><p>è€ƒè™‘åˆ°ä»»æ„å…·æœ‰ m ä¸ªæ ‡ç­¾çš„åˆ†ç±»å±æ€§ï¼ˆå˜æ¢ä¹‹åï¼‰çš„æ•°å­—è¡¨ç¤ºï¼Œç‹¬çƒ­ç¼–ç æ–¹æ¡ˆå°†è¯¥å±æ€§ç¼–ç æˆ–å˜æ¢æˆ m ä¸ªäºŒè¿›åˆ¶ç‰¹å¾å‘é‡ï¼ˆå‘é‡ä¸­çš„æ¯ä¸€ç»´çš„å€¼åªèƒ½ä¸º 0 æˆ– 1ï¼‰ã€‚é‚£ä¹ˆåœ¨è¿™ä¸ªåˆ†ç±»ç‰¹å¾ä¸­æ¯ä¸ªå±æ€§å€¼éƒ½è¢«è½¬æ¢æˆä¸€ä¸ª m ç»´çš„å‘é‡ï¼Œå…¶ä¸­åªæœ‰æŸä¸€ç»´çš„å€¼ä¸º 1ã€‚è®©æˆ‘ä»¬æ¥çœ‹çœ‹ç¥å¥‡å®è´æ•°æ®é›†çš„ä¸€ä¸ªå­é›†ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">poke_df[[<span class="string">'Name'</span>, <span class="string">'Generation'</span>, <span class="string">'Legendary'</span>]].iloc[<span class="number">4</span>:<span class="number">10</span>]</span><br></pre></td></tr></table></figure><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5af9b37bf97.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸‹ç¯‡ - ç¦»æ•£æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><p>ç¥å¥‡å®è´æ•°æ®é›†å­é›†</p><p>è¿™é‡Œå…³æ³¨çš„å±æ€§æ˜¯ç¥å¥‡å®è´çš„ã€Œä¸–ä»£ï¼ˆGenerationï¼‰ã€å’Œã€Œä¼ å¥‡ï¼ˆLegendaryï¼‰ã€çŠ¶æ€ã€‚ç¬¬ä¸€æ­¥æ˜¯æ ¹æ®ä¹‹å‰å­¦åˆ°çš„å°†è¿™äº›å±æ€§è½¬æ¢ä¸ºæ•°å€¼è¡¨ç¤ºã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder, LabelEncoder</span><br><span class="line"></span><br><span class="line">\<span class="comment"># transform and map pokemon generations</span></span><br><span class="line"></span><br><span class="line">gen_le = LabelEncoder()</span><br><span class="line"></span><br><span class="line">gen_labels = gen_le.fit_transform(poke_df[<span class="string">'Generation'</span>])</span><br><span class="line"></span><br><span class="line">poke_df[<span class="string">'Gen_Label'</span>] = gen_labels</span><br><span class="line"></span><br><span class="line">\<span class="comment"># transform and map pokemon legendary status</span></span><br><span class="line"></span><br><span class="line">leg_le = LabelEncoder()</span><br><span class="line"></span><br><span class="line">leg_labels = leg_le.fit_transform(poke_df[<span class="string">'Legendary'</span>])</span><br><span class="line"></span><br><span class="line">poke_df[<span class="string">'Lgnd_Label'</span>] = leg_labels</span><br><span class="line"></span><br><span class="line">poke_df_sub = poke_df[[<span class="string">'Name'</span>, <span class="string">'Generation'</span>, <span class="string">'Gen_Label'</span>, <span class="string">'Legendary'</span>, <span class="string">'Lgnd_Label'</span>]]</span><br><span class="line"></span><br><span class="line">poke_df_sub.iloc[<span class="number">4</span>:<span class="number">10</span>]</span><br></pre></td></tr></table></figure><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5afa18d27fc.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸‹ç¯‡ - ç¦»æ•£æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><p>è½¬æ¢åçš„æ ‡ç­¾å±æ€§</p><p><em>Gen_Label</em> å’Œ <em>Lgnd_Label</em> ç‰¹å¾æè¿°äº†æˆ‘ä»¬åˆ†ç±»ç‰¹å¾çš„æ•°å€¼è¡¨ç¤ºã€‚ç°åœ¨è®©æˆ‘ä»¬åœ¨è¿™äº›ç‰¹å¾ä¸Šåº”ç”¨ç‹¬çƒ­ç¼–ç æ–¹æ¡ˆã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># encode generation labels using one-hot encoding scheme</span></span><br><span class="line"></span><br><span class="line">gen_ohe = OneHotEncoder()</span><br><span class="line"></span><br><span class="line">gen_feature_arr = gen_ohe.fit_transform(poke_df[[<span class="string">'Gen_Label'</span>]]).toarray()</span><br><span class="line"></span><br><span class="line">gen_feature_labels = list(gen_le.classes_)</span><br><span class="line"></span><br><span class="line">gen_features = pd.DataFrame(gen_feature_arr, columns=gen_feature_labels)</span><br><span class="line"></span><br><span class="line">\<span class="comment"># encode legendary status labels using one-hot encoding scheme</span></span><br><span class="line"></span><br><span class="line">leg_ohe = OneHotEncoder()</span><br><span class="line"></span><br><span class="line">leg_feature_arr = leg_ohe.fit_transform(poke_df[[<span class="string">'Lgnd_Label'</span>]]).toarray()</span><br><span class="line"></span><br><span class="line">leg_feature_labels = [<span class="string">'Legendary_'</span>+str(cls_label) <span class="keyword">for</span> cls_label <span class="keyword">in</span> leg_le.classes_]</span><br><span class="line"></span><br><span class="line">leg_features = pd.DataFrame(leg_feature_arr, columns=leg_feature_labels)</span><br></pre></td></tr></table></figure><p>é€šå¸¸æ¥è¯´ï¼Œä½ å¯ä»¥ä½¿ç”¨ <em>fit_transform</em> å‡½æ•°å°†ä¸¤ä¸ªç‰¹å¾ä¸€èµ·ç¼–ç ï¼ˆé€šè¿‡å°†ä¸¤ä¸ªç‰¹å¾çš„äºŒç»´æ•°ç»„ä¸€èµ·ä¼ é€’ç»™å‡½æ•°ï¼Œè¯¦æƒ…<a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html" target="_blank" rel="noopener">æŸ¥çœ‹æ–‡æ¡£</a>ï¼‰ã€‚ä½†æ˜¯æˆ‘ä»¬åˆ†å¼€ç¼–ç æ¯ä¸ªç‰¹å¾ï¼Œè¿™æ ·å¯ä»¥æ›´æ˜“äºç†è§£ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥åˆ›å»ºå•ç‹¬çš„æ•°æ®è¡¨å¹¶ç›¸åº”åœ°æ ‡è®°å®ƒä»¬ã€‚ç°åœ¨è®©æˆ‘ä»¬é“¾æ¥è¿™äº›ç‰¹å¾è¡¨ï¼ˆFeature framesï¼‰ç„¶åçœ‹çœ‹æœ€ç»ˆçš„ç»“æœã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">poke_df_ohe = pd.concat([poke_df_sub, gen_features, leg_features], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">columns = sum([[<span class="string">'Name'</span>, <span class="string">'Generation'</span>, <span class="string">'Gen_Label'</span>], gen_feature_labels, [<span class="string">'Legendary'</span>, <span class="string">'Lgnd_Label'</span>], leg_feature_labels], [])</span><br><span class="line"></span><br><span class="line">poke_df_ohe[columns].iloc[<span class="number">4</span>:<span class="number">10</span>]</span><br></pre></td></tr></table></figure><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5afab9940ae.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸‹ç¯‡ - ç¦»æ•£æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><p>ç¥å¥‡å®è´ä¸–ä»£å’Œä¼ å¥‡çŠ¶æ€çš„ç‹¬çƒ­ç¼–ç ç‰¹å¾</p><p>æ­¤æ—¶å¯ä»¥çœ‹åˆ°å·²ç»ä¸ºã€Œä¸–ä»£ï¼ˆGenerationï¼‰ã€ç”Ÿæˆ 6 ä¸ªè™šæ‹Ÿå˜é‡æˆ–è€…äºŒè¿›åˆ¶ç‰¹å¾ï¼Œå¹¶ä¸ºã€Œä¼ å¥‡ï¼ˆLegendaryï¼‰ã€ç”Ÿæˆäº† 2 ä¸ªç‰¹å¾ã€‚è¿™äº›ç‰¹å¾æ•°é‡æ˜¯è¿™äº›å±æ€§ä¸­ä¸åŒç±»åˆ«çš„æ€»æ•°ã€‚<strong>æŸä¸€ç±»åˆ«çš„æ¿€æ´»çŠ¶æ€é€šè¿‡å°†å¯¹åº”çš„è™šæ‹Ÿå˜é‡ç½® 1 æ¥è¡¨ç¤º</strong>ï¼Œè¿™ä»ä¸Šé¢çš„æ•°æ®è¡¨ä¸­å¯ä»¥éå¸¸æ˜æ˜¾åœ°ä½“ç°å‡ºæ¥ã€‚</p><p>è€ƒè™‘ä½ åœ¨è®­ç»ƒæ•°æ®ä¸Šå»ºç«‹äº†è¿™ä¸ªç¼–ç æ–¹æ¡ˆï¼Œå¹¶å»ºç«‹äº†ä¸€äº›æ¨¡å‹ï¼Œç°åœ¨ä½ æœ‰äº†ä¸€äº›æ–°çš„æ•°æ®ï¼Œè¿™äº›æ•°æ®å¿…é¡»åœ¨é¢„æµ‹ä¹‹å‰è¿›è¡Œå¦‚ä¸‹è®¾è®¡ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">new_poke_df = pd.DataFrame([[<span class="string">'PikaZoom'</span>, <span class="string">'Gen 3'</span>, <span class="literal">True</span>], [<span class="string">'CharMyToast'</span>, <span class="string">'Gen 4'</span>, <span class="literal">False</span>]], columns=[<span class="string">'Name'</span>, <span class="string">'Generation'</span>, <span class="string">'Legendary'</span>])</span><br><span class="line"></span><br><span class="line">new_poke_df</span><br></pre></td></tr></table></figure><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5afaf0cb42e.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸‹ç¯‡ - ç¦»æ•£æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><p>æ–°æ•°æ®</p><p>ä½ å¯ä»¥é€šè¿‡è°ƒç”¨ä¹‹å‰æ„å»ºçš„ <em>LabelEncoder</em> å’Œ <em>OneHotEncoder</em> å¯¹è±¡çš„ <em>transform()</em> æ–¹æ³•æ¥å¤„ç†æ–°æ•°æ®ã€‚è¯·è®°å¾—æˆ‘ä»¬çš„å·¥ä½œæµç¨‹ï¼Œé¦–å…ˆæˆ‘ä»¬è¦åšè½¬æ¢ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">new_gen_labels = gen_le.transform(new_poke_df[<span class="string">'Generation'</span>])</span><br><span class="line"></span><br><span class="line">new_poke_df[<span class="string">'Gen_Label'</span>] = new_gen_labels</span><br><span class="line"></span><br><span class="line">new_leg_labels = leg_le.transform(new_poke_df[<span class="string">'Legendary'</span>])</span><br><span class="line"></span><br><span class="line">new_poke_df[<span class="string">'Lgnd_Label'</span>] = new_leg_labels</span><br><span class="line"></span><br><span class="line">new_poke_df[[<span class="string">'Name'</span>, <span class="string">'Generation'</span>, <span class="string">'Gen_Label'</span>, <span class="string">'Legendary'</span>, <span class="string">'Lgnd_Label'</span>]]</span><br></pre></td></tr></table></figure><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5afb428f0dc.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸‹ç¯‡ - ç¦»æ•£æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><p>è½¬æ¢ä¹‹åçš„åˆ†ç±»å±æ€§</p><p>åœ¨å¾—åˆ°äº†æ•°å€¼æ ‡ç­¾ä¹‹åï¼Œæ¥ä¸‹æ¥è®©æˆ‘ä»¬åº”ç”¨ç¼–ç æ–¹æ¡ˆå§ï¼</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">new_gen_feature_arr = gen_ohe.transform(new_poke_df[[<span class="string">'Gen_Label'</span>]]).toarray()</span><br><span class="line"></span><br><span class="line">new_gen_features = pd.DataFrame(new_gen_feature_arr, columns=gen_feature_labels)</span><br><span class="line"></span><br><span class="line">new_leg_feature_arr = leg_ohe.transform(new_poke_df[[<span class="string">'Lgnd_Label'</span>]]).toarray()</span><br><span class="line"></span><br><span class="line">new_leg_features = pd.DataFrame(new_leg_feature_arr, columns=leg_feature_labels)</span><br><span class="line"></span><br><span class="line">new_poke_ohe = pd.concat([new_poke_df, new_gen_features, new_leg_features], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">columns = sum([[<span class="string">'Name'</span>, <span class="string">'Generation'</span>, <span class="string">'Gen_Label'</span>], gen_feature_labels, [<span class="string">'Legendary'</span>, <span class="string">'Lgnd_Label'</span>], leg_feature_labels], [])</span><br><span class="line"></span><br><span class="line">new_poke_ohe[columns]</span><br></pre></td></tr></table></figure><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5afb91bb3be.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸‹ç¯‡ - ç¦»æ•£æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><p>ç‹¬çƒ­ç¼–ç ä¹‹åçš„åˆ†ç±»å±æ€§</p><p>å› æ­¤ï¼Œé€šè¿‡åˆ©ç”¨ scikit-learn å¼ºå¤§çš„ APIï¼Œæˆ‘ä»¬å¯ä»¥å¾ˆå®¹æ˜“å°†ç¼–ç æ–¹æ¡ˆåº”ç”¨äºæ–°æ•°æ®ã€‚</p><p>ä½ ä¹Ÿå¯ä»¥é€šè¿‡åˆ©ç”¨æ¥è‡ª pandas çš„ <em>to_dummies()</em> å‡½æ•°è½»æ¾åº”ç”¨ç‹¬çƒ­ç¼–ç æ–¹æ¡ˆã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gen_onehot_features = pd.get_dummies(poke_df[<span class="string">'Generation'</span>])</span><br><span class="line"></span><br><span class="line">pd.concat([poke_df[[<span class="string">'Name'</span>, <span class="string">'Generation'</span>]], gen_onehot_features], axis=<span class="number">1</span>).iloc[<span class="number">4</span>:<span class="number">10</span>]</span><br></pre></td></tr></table></figure><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5afbcc0ff2b.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸‹ç¯‡ - ç¦»æ•£æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><p>ä½¿ç”¨ pandas å®ç°çš„ç‹¬çƒ­ç¼–ç ç‰¹å¾</p><p>ä¸Šé¢çš„æ•°æ®è¡¨æè¿°äº†åº”ç”¨åœ¨ã€Œä¸–ä»£ï¼ˆGenerationï¼‰ã€å±æ€§ä¸Šçš„ç‹¬çƒ­ç¼–ç æ–¹æ¡ˆï¼Œç»“æœä¸ä¹‹å‰çš„ä¸€è‡´ã€‚</p><h4 id="åŒºé—´è®¡æ•°æ–¹æ¡ˆï¼ˆBin-counting-Schemeï¼‰"><a href="#åŒºé—´è®¡æ•°æ–¹æ¡ˆï¼ˆBin-counting-Schemeï¼‰" class="headerlink" title="åŒºé—´è®¡æ•°æ–¹æ¡ˆï¼ˆBin-counting Schemeï¼‰"></a>åŒºé—´è®¡æ•°æ–¹æ¡ˆï¼ˆBin-counting Schemeï¼‰</h4><p>åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬æ‰€è®¨è®ºçš„ç¼–ç æ–¹æ¡ˆåœ¨åˆ†ç±»æ•°æ®æ–¹é¢æ•ˆæœè¿˜ä¸é”™ï¼Œä½†æ˜¯å½“ä»»æ„ç‰¹å¾çš„ä¸åŒç±»åˆ«æ•°é‡å˜å¾—å¾ˆå¤§çš„æ—¶å€™ï¼Œé—®é¢˜å¼€å§‹å‡ºç°ã€‚å¯¹äºå…·æœ‰ m ä¸ªä¸åŒæ ‡ç­¾çš„ä»»æ„åˆ†ç±»ç‰¹å¾è¿™ç‚¹éå¸¸é‡è¦ï¼Œä½ å°†å¾—åˆ° m ä¸ªç‹¬ç«‹çš„ç‰¹å¾ã€‚è¿™ä¼šå¾ˆå®¹æ˜“åœ°å¢åŠ ç‰¹å¾é›†çš„å¤§å°ï¼Œä»è€Œå¯¼è‡´åœ¨æ—¶é—´ã€ç©ºé—´å’Œå†…å­˜æ–¹é¢å‡ºç°å­˜å‚¨é—®é¢˜æˆ–è€…æ¨¡å‹è®­ç»ƒé—®é¢˜ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜å¿…é¡»å¤„ç†â€œ<a href="https://en.wikipedia.org/wiki/Curse_of_dimensionality" target="_blank" rel="noopener">ç»´åº¦è¯…å’’</a>â€é—®é¢˜ï¼Œé€šå¸¸æŒ‡çš„æ˜¯æ‹¥æœ‰å¤§é‡çš„ç‰¹å¾ï¼Œå´ç¼ºä¹è¶³å¤Ÿçš„ä»£è¡¨æ€§æ ·æœ¬ï¼Œç„¶åæ¨¡å‹çš„æ€§èƒ½å¼€å§‹å—åˆ°å½±å“å¹¶å¯¼è‡´è¿‡æ‹Ÿåˆã€‚</p><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5afd0459749.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸‹ç¯‡ - ç¦»æ•£æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><p>å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦é’ˆå¯¹é‚£äº›å¯èƒ½å…·æœ‰éå¸¸å¤šç§ç±»åˆ«çš„ç‰¹å¾ï¼ˆå¦‚ IP åœ°å€ï¼‰ï¼Œç ”ç©¶å…¶å®ƒåˆ†ç±»æ•°æ®ç‰¹å¾å·¥ç¨‹æ–¹æ¡ˆã€‚åŒºé—´è®¡æ•°æ–¹æ¡ˆæ˜¯å¤„ç†å…·æœ‰å¤šä¸ªç±»åˆ«çš„åˆ†ç±»å˜é‡çš„æœ‰æ•ˆæ–¹æ¡ˆã€‚åœ¨è¿™ä¸ªæ–¹æ¡ˆä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨<strong>åŸºäºæ¦‚ç‡çš„ç»Ÿè®¡ä¿¡æ¯å’Œåœ¨å»ºæ¨¡è¿‡ç¨‹ä¸­æ‰€è¦é¢„æµ‹çš„å®é™…ç›®æ ‡æˆ–è€…å“åº”å€¼</strong>ï¼Œè€Œä¸æ˜¯ä½¿ç”¨å®é™…çš„æ ‡ç­¾å€¼è¿›è¡Œç¼–ç ã€‚ä¸€ä¸ªç®€å•çš„ä¾‹å­æ˜¯ï¼ŒåŸºäºè¿‡å»çš„ IP åœ°å€å†å²æ•°æ®å’Œ DDOS æ”»å‡»ä¸­æ‰€ä½¿ç”¨çš„å†å²æ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥ä¸ºä»»ä¸€ IP åœ°å€ä¼šè¢« DDOS æ”»å‡»çš„å¯èƒ½æ€§å»ºç«‹æ¦‚ç‡æ¨¡å‹ã€‚ä½¿ç”¨è¿™äº›ä¿¡æ¯ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹è¾“å…¥ç‰¹å¾è¿›è¡Œç¼–ç ï¼Œè¯¥è¾“å…¥ç‰¹å¾æè¿°äº†å¦‚æœå°†æ¥å‡ºç°ç›¸åŒçš„ IP åœ°å€ï¼Œåˆ™å¼•èµ· DDOS æ”»å‡»çš„æ¦‚ç‡å€¼æ˜¯å¤šå°‘ã€‚<strong>è¿™ä¸ªæ–¹æ¡ˆéœ€è¦å†å²æ•°æ®ä½œä¸ºå…ˆå†³æ¡ä»¶ï¼Œå¹¶ä¸”è¦æ±‚æ•°æ®éå¸¸è¯¦å°½ã€‚</strong></p><h4 id="ç‰¹å¾å“ˆå¸Œæ–¹æ¡ˆ"><a href="#ç‰¹å¾å“ˆå¸Œæ–¹æ¡ˆ" class="headerlink" title="ç‰¹å¾å“ˆå¸Œæ–¹æ¡ˆ"></a>ç‰¹å¾å“ˆå¸Œæ–¹æ¡ˆ</h4><p>ç‰¹å¾å“ˆå¸Œæ–¹æ¡ˆï¼ˆFeature Hashing Schemeï¼‰æ˜¯å¤„ç†å¤§è§„æ¨¡åˆ†ç±»ç‰¹å¾çš„å¦ä¸€ä¸ªæœ‰ç”¨çš„ç‰¹å¾å·¥ç¨‹æ–¹æ¡ˆã€‚åœ¨è¯¥æ–¹æ¡ˆä¸­ï¼Œå“ˆå¸Œå‡½æ•°é€šå¸¸ä¸é¢„è®¾çš„ç¼–ç ç‰¹å¾çš„æ•°é‡ï¼ˆä½œä¸ºé¢„å®šä¹‰é•¿åº¦å‘é‡ï¼‰ä¸€èµ·ä½¿ç”¨ï¼Œä½¿å¾—ç‰¹å¾çš„å“ˆå¸Œå€¼è¢«ç”¨ä½œè¿™ä¸ªé¢„å®šä¹‰å‘é‡ä¸­çš„ç´¢å¼•ï¼Œå¹¶ä¸”å€¼ä¹Ÿè¦åšç›¸åº”çš„æ›´æ–°ã€‚ç”±äºå“ˆå¸Œå‡½æ•°å°†å¤§é‡çš„å€¼æ˜ å°„åˆ°ä¸€ä¸ªå°çš„æœ‰é™é›†åˆä¸­ï¼Œå› æ­¤<strong>å¤šä¸ªä¸åŒå€¼å¯èƒ½ä¼šåˆ›å»ºç›¸åŒçš„å“ˆå¸Œ</strong>ï¼Œè¿™ä¸€ç°è±¡ç§°ä¸º<strong>å†²çª</strong>ã€‚å…¸å‹åœ°ï¼Œä½¿ç”¨å¸¦ç¬¦å·çš„å“ˆå¸Œå‡½æ•°ï¼Œä½¿å¾—ä»å“ˆå¸Œè·å¾—çš„å€¼çš„ç¬¦å·è¢«ç”¨ä½œé‚£äº›åœ¨é€‚å½“çš„ç´¢å¼•å¤„å­˜å‚¨åœ¨æœ€ç»ˆç‰¹å¾å‘é‡ä¸­çš„å€¼çš„ç¬¦å·ã€‚è¿™æ ·èƒ½å¤Ÿç¡®ä¿å®ç°è¾ƒå°‘çš„å†²çªå’Œç”±äºå†²çªå¯¼è‡´çš„è¯¯å·®ç´¯ç§¯ã€‚</p><p>å“ˆå¸Œæ–¹æ¡ˆé€‚ç”¨äºå­—ç¬¦ä¸²ã€æ•°å­—å’Œå…¶å®ƒç»“æ„ï¼ˆå¦‚å‘é‡ï¼‰ã€‚ä½ å¯ä»¥å°†å“ˆå¸Œè¾“å‡ºçœ‹ä½œä¸€ä¸ªæœ‰é™çš„ <em>b bins</em> é›†åˆï¼Œä»¥ä¾¿äºå½“å°†å“ˆå¸Œå‡½æ•°åº”ç”¨äºç›¸åŒçš„å€¼\ç±»åˆ«æ—¶ï¼Œå“ˆå¸Œå‡½æ•°èƒ½æ ¹æ®å“ˆå¸Œå€¼å°†å…¶åˆ†é…åˆ° <em>b bins</em> ä¸­çš„åŒä¸€ä¸ª binï¼ˆæˆ–è€… bins çš„å­é›†ï¼‰ã€‚æˆ‘ä»¬å¯ä»¥é¢„å…ˆå®šä¹‰ <em>b</em> çš„å€¼ï¼Œå®ƒæˆä¸ºæˆ‘ä»¬ä½¿ç”¨ç‰¹å¾å“ˆå¸Œæ–¹æ¡ˆç¼–ç çš„æ¯ä¸ªåˆ†ç±»å±æ€§çš„ç¼–ç ç‰¹å¾å‘é‡çš„æœ€ç»ˆå°ºå¯¸ã€‚</p><p>å› æ­¤ï¼Œå³ä½¿æˆ‘ä»¬æœ‰ä¸€ä¸ªç‰¹å¾æ‹¥æœ‰è¶…è¿‡ <strong>1000</strong> ä¸ªä¸åŒçš„ç±»åˆ«ï¼Œæˆ‘ä»¬è®¾ç½® <strong>b = 10</strong> ä½œä¸ºæœ€ç»ˆçš„ç‰¹å¾å‘é‡é•¿åº¦ï¼Œé‚£ä¹ˆæœ€ç»ˆè¾“å‡ºçš„ç‰¹å¾å°†åªæœ‰ 10 ä¸ªç‰¹å¾ã€‚è€Œé‡‡ç”¨ç‹¬çƒ­ç¼–ç æ–¹æ¡ˆåˆ™æœ‰ 1000 ä¸ªäºŒè¿›åˆ¶ç‰¹å¾ã€‚æˆ‘ä»¬æ¥è€ƒè™‘ä¸‹è§†é¢‘æ¸¸æˆæ•°æ®é›†ä¸­çš„ã€Œé£æ ¼ï¼ˆGenreï¼‰ã€å±æ€§ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">unique_genres = np.unique(vg_df[[<span class="string">'Genre'</span>]])</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Total game genres:"</span>, len(unique_genres))</span><br><span class="line"></span><br><span class="line">print(unique_genres)</span><br><span class="line"></span><br><span class="line">Output</span><br><span class="line"></span><br><span class="line">\------</span><br><span class="line"></span><br><span class="line">Total game genres: <span class="number">12</span></span><br><span class="line"></span><br><span class="line">[<span class="string">'Action'</span> <span class="string">'Adventure'</span> <span class="string">'Fighting'</span> <span class="string">'Misc'</span> <span class="string">'Platform'</span> <span class="string">'Puzzle'</span> <span class="string">'Racing'</span> <span class="string">'Role-Playing'</span> <span class="string">'Shooter'</span> <span class="string">'Simulation'</span> <span class="string">'Sports'</span> <span class="string">'Strategy'</span>]</span><br></pre></td></tr></table></figure><p>æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæ€»å…±æœ‰ 12 ä¸­é£æ ¼çš„æ¸¸æˆã€‚å¦‚æœæˆ‘ä»¬åœ¨â€œé£æ ¼â€ç‰¹å¾ä¸­é‡‡ç”¨ç‹¬çƒ­ç¼–ç æ–¹æ¡ˆï¼Œåˆ™å°†å¾—åˆ° 12 ä¸ªäºŒè¿›åˆ¶ç‰¹å¾ã€‚è€Œè¿™æ¬¡ï¼Œæˆ‘ä»¬å°†é€šè¿‡ scikit-learn çš„ <em>FeatureHasher</em> ç±»æ¥ä½¿ç”¨ç‰¹å¾å“ˆå¸Œæ–¹æ¡ˆï¼Œè¯¥ç±»ä½¿ç”¨äº†ä¸€ä¸ªæœ‰ç¬¦å·çš„ 32 ä½ç‰ˆæœ¬çš„ <em>Murmurhash3</em> å“ˆå¸Œå‡½æ•°ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°†é¢„å…ˆå®šä¹‰æœ€ç»ˆçš„ç‰¹å¾å‘é‡å¤§å°ä¸º 6ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction <span class="keyword">import</span> FeatureHasher</span><br><span class="line"></span><br><span class="line">fh = FeatureHasher(n_features=<span class="number">6</span>, input_type=<span class="string">'string'</span>)</span><br><span class="line"></span><br><span class="line">hashed_features = fh.fit_transform(vg_df[<span class="string">'Genre'</span>])</span><br><span class="line"></span><br><span class="line">hashed_features = hashed_features.toarray()pd.concat([vg_df[[<span class="string">'Name'</span>, <span class="string">'Genre'</span>]], pd.DataFrame(hashed_features)], axis=<span class="number">1</span>).iloc[<span class="number">1</span>:<span class="number">7</span>]</span><br></pre></td></tr></table></figure><p><img src="https://static.leiphone.com/uploads/new/article/740_740/201801/5a5afd62f2a51.png?imageMogr2/format/jpg/quality/90" alt="ä¸ä¼šåšç‰¹å¾å·¥ç¨‹çš„ AI ç ”ç©¶å‘˜ä¸æ˜¯å¥½æ•°æ®ç§‘å­¦å®¶ï¼ä¸‹ç¯‡ - ç¦»æ•£æ•°æ®çš„å¤„ç†æ–¹æ³•"></p><p>é£æ ¼å±æ€§çš„ç‰¹å¾å“ˆå¸Œ</p><p>åŸºäºä¸Šè¿°è¾“å‡ºï¼Œã€Œé£æ ¼ï¼ˆGenreï¼‰ã€å±æ€§å·²ç»ä½¿ç”¨å“ˆå¸Œæ–¹æ¡ˆç¼–ç æˆ 6 ä¸ªç‰¹å¾è€Œä¸æ˜¯ 12 ä¸ªã€‚æˆ‘ä»¬è¿˜å¯ä»¥çœ‹åˆ°ï¼Œç¬¬ 1 è¡Œå’Œç¬¬ 6 è¡Œè¡¨ç¤ºç›¸åŒé£æ ¼çš„æ¸¸æˆã€Œå¹³å°ï¼ˆPlatformï¼‰ã€ï¼Œè€Œå®ƒä»¬ä¹Ÿè¢«æ­£ç¡®ç¼–ç æˆäº†ç›¸åŒçš„ç‰¹å¾å‘é‡ã€‚</p><h3 id="æ—¶é—´å‹"><a href="#æ—¶é—´å‹" class="headerlink" title="æ—¶é—´å‹"></a>æ—¶é—´å‹</h3><p><img src="https://s1.ax1x.com/2020/04/24/JBQ8OS.jpg" alt="avatar"><br><img src="https://s1.ax1x.com/2020/04/24/JBQrOU.jpg" alt="avatar"><br><img src="https://s1.ax1x.com/2020/04/24/JBQcTJ.jpg" alt="avatar"></p><h3 id="æ–‡æœ¬å‹"><a href="#æ–‡æœ¬å‹" class="headerlink" title="æ–‡æœ¬å‹"></a>æ–‡æœ¬å‹</h3><p><img src="https://s1.ax1x.com/2020/04/24/JBQhSx.jpg" alt="avatar"><br><img src="https://s1.ax1x.com/2020/04/24/JBQIOO.jpg" alt="avatar"><br><img src="https://s1.ax1x.com/2020/04/24/JBQzX8.jpg" alt="avatar"><br><img src="https://s1.ax1x.com/2020/04/24/JBlC7Q.jpg" alt="avatar"></p>]]></content>
      
      
      <categories>
          
          <category> ç‰¹å¾å·¥ç¨‹ </category>
          
          <category> æ¨¡å‹è°ƒä¼˜ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ¨¡å‹è°ƒä¼˜ </tag>
            
            <tag> python </tag>
            
            <tag> ç‰¹å¾å·¥ç¨‹ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>è¯­è¨€æ¨¡å‹</title>
      <link href="/2020/04/18/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"/>
      <url>/2020/04/18/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="è¯­è¨€æ¨¡å‹"><a href="#è¯­è¨€æ¨¡å‹" class="headerlink" title="è¯­è¨€æ¨¡å‹"></a>è¯­è¨€æ¨¡å‹</h1><p>å­¦ä¹ ç›®æ ‡</p><ul><li>å­¦ä¹ è¯­è¨€æ¨¡å‹ï¼Œä»¥åŠå¦‚ä½•è®­ç»ƒä¸€ä¸ªè¯­è¨€æ¨¡å‹</li><li>å­¦ä¹ torchtextçš„åŸºæœ¬ä½¿ç”¨æ–¹æ³•<ul><li>æ„å»º vocabulary</li><li>word to inde å’Œ index to word</li></ul></li><li>å­¦ä¹ torch.nnçš„ä¸€äº›åŸºæœ¬æ¨¡å‹<ul><li>Linear</li><li>RNN</li><li>LSTM</li><li>GRU</li></ul></li><li>RNNçš„è®­ç»ƒæŠ€å·§<ul><li>Gradient Clipping</li></ul></li><li>å¦‚ä½•ä¿å­˜å’Œè¯»å–æ¨¡å‹</li></ul><p>æˆ‘ä»¬ä¼šä½¿ç”¨ <a href="https://github.com/pytorch/text" target="_blank" rel="noopener">torchtext</a> æ¥åˆ›å»ºvocabulary, ç„¶åæŠŠæ•°æ®è¯»æˆbatchçš„æ ¼å¼ã€‚è¯·å¤§å®¶è‡ªè¡Œé˜…è¯»READMEæ¥å­¦ä¹ torchtextã€‚</p><p><strong>å…ˆäº†è§£ä¸‹torchtextåº“ï¼š<a href="https://blog.csdn.net/u012436149/article/details/79310176" target="_blank" rel="noopener">torchtextä»‹ç»å’Œä½¿ç”¨æ•™ç¨‹</a></strong></p><p>In [1]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchtext</span><br><span class="line"><span class="keyword">from</span> torchtext.vocab <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">USE_CUDA = torch.cuda.is_available()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ä¸ºäº†ä¿è¯å®éªŒç»“æœå¯ä»¥å¤ç°ï¼Œæˆ‘ä»¬ç»å¸¸ä¼šæŠŠå„ç§random seedå›ºå®šåœ¨æŸä¸€ä¸ªå€¼</span></span><br><span class="line">random.seed(<span class="number">53113</span>)</span><br><span class="line">np.random.seed(<span class="number">53113</span>)</span><br><span class="line">torch.manual_seed(<span class="number">53113</span>)</span><br><span class="line"><span class="keyword">if</span> USE_CUDA:</span><br><span class="line">    torch.cuda.manual_seed(<span class="number">53113</span>)</span><br><span class="line"></span><br><span class="line">BATCH_SIZE = <span class="number">32</span> <span class="comment">#ä¸€ä¸ªbatchå¤šå°‘ä¸ªå¥å­</span></span><br><span class="line">EMBEDDING_SIZE = <span class="number">650</span>  <span class="comment">#æ¯ä¸ªå•è¯å¤šå°‘ç»´</span></span><br><span class="line">MAX_VOCAB_SIZE = <span class="number">50000</span>  <span class="comment">#å•è¯æ€»æ•°</span></span><br></pre></td></tr></table></figure><ul><li>æˆ‘ä»¬ä¼šç»§ç»­ä½¿ç”¨ä¸Šæ¬¡çš„text8ä½œä¸ºæˆ‘ä»¬çš„è®­ç»ƒï¼ŒéªŒè¯å’Œæµ‹è¯•æ•°æ®</li><li>torchtextæä¾›äº†LanguageModelingDatasetè¿™ä¸ªclassæ¥å¸®åŠ©æˆ‘ä»¬å¤„ç†è¯­è¨€æ¨¡å‹æ•°æ®é›†</li><li>BPTTIteratorå¯ä»¥è¿ç»­åœ°å¾—åˆ°è¿è´¯çš„å¥å­</li></ul><p>In [2]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">TEXT = torchtext.data.Field(lower=<span class="literal">True</span>) </span><br><span class="line"><span class="comment"># .Fieldè¿™ä¸ªå¯¹è±¡åŒ…å«äº†æˆ‘ä»¬æ‰“ç®—å¦‚ä½•é¢„å¤„ç†æ–‡æœ¬æ•°æ®çš„ä¿¡æ¯ï¼Œè¿™é‡Œå®šä¹‰å•è¯å…¨éƒ¨å°å†™</span></span><br><span class="line"></span><br><span class="line">train, val, test = \</span><br><span class="line">torchtext.datasets.LanguageModelingDataset.splits(</span><br><span class="line">    path=<span class="string">"."</span>, </span><br><span class="line">    train=<span class="string">"text8.train.txt"</span>, </span><br><span class="line">    validation=<span class="string">"text8.dev.txt"</span>, </span><br><span class="line">    test=<span class="string">"text8.test.txt"</span>, </span><br><span class="line">    text_field=TEXT)</span><br><span class="line"><span class="comment"># torchtextæä¾›äº†LanguageModelingDatasetè¿™ä¸ªclassæ¥å¸®åŠ©æˆ‘ä»¬å¤„ç†è¯­è¨€æ¨¡å‹æ•°æ®é›†</span></span><br><span class="line"></span><br><span class="line">TEXT.build_vocab(train, max_size=MAX_VOCAB_SIZE)</span><br><span class="line"><span class="comment"># build_vocabå¯ä»¥æ ¹æ®æˆ‘ä»¬æä¾›çš„è®­ç»ƒæ•°æ®é›†æ¥åˆ›å»ºæœ€é«˜é¢‘å•è¯çš„å•è¯è¡¨ï¼Œmax_sizeå¸®åŠ©æˆ‘ä»¬é™å®šå•è¯æ€»é‡ã€‚</span></span><br><span class="line">print(<span class="string">"vocabulary size: &#123;&#125;"</span>.format(len(TEXT.vocab)))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vocabulary size: 50002</span><br></pre></td></tr></table></figure><p>In [4]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test</span><br></pre></td></tr></table></figure><p>Out[4]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;torchtext.data.example.Example at 0x121738b00&gt;</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>In [9]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(TEXT.vocab.itos[<span class="number">0</span>:<span class="number">50</span>]) </span><br><span class="line"><span class="comment"># è¿™é‡Œè¶Šé å‰è¶Šå¸¸è§ï¼Œå¢åŠ äº†ä¸¤ä¸ªç‰¹æ®Šçš„tokenï¼Œ&lt;unk&gt;è¡¨ç¤ºæœªçŸ¥çš„å•è¯ï¼Œ&lt;pad&gt;è¡¨ç¤ºpaddingã€‚</span></span><br><span class="line">print(<span class="string">"------"</span>*<span class="number">10</span>)</span><br><span class="line">print(list(TEXT.vocab.stoi.items())[<span class="number">0</span>:<span class="number">50</span>])</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[&apos;&lt;unk&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;the&apos;, &apos;of&apos;, &apos;and&apos;, &apos;one&apos;, &apos;in&apos;, &apos;a&apos;, &apos;to&apos;, &apos;zero&apos;, &apos;nine&apos;, &apos;two&apos;, &apos;is&apos;, &apos;as&apos;, &apos;eight&apos;, &apos;for&apos;, &apos;s&apos;, &apos;five&apos;, &apos;three&apos;, &apos;was&apos;, &apos;by&apos;, &apos;that&apos;, &apos;four&apos;, &apos;six&apos;, &apos;seven&apos;, &apos;with&apos;, &apos;on&apos;, &apos;are&apos;, &apos;it&apos;, &apos;from&apos;, &apos;or&apos;, &apos;his&apos;, &apos;an&apos;, &apos;be&apos;, &apos;this&apos;, &apos;he&apos;, &apos;at&apos;, &apos;which&apos;, &apos;not&apos;, &apos;also&apos;, &apos;have&apos;, &apos;were&apos;, &apos;has&apos;, &apos;but&apos;, &apos;other&apos;, &apos;their&apos;, &apos;its&apos;, &apos;first&apos;, &apos;they&apos;, &apos;had&apos;]</span><br><span class="line">------------------------------------------------------------</span><br><span class="line">[(&apos;&lt;unk&gt;&apos;, 0), (&apos;&lt;pad&gt;&apos;, 1), (&apos;the&apos;, 2), (&apos;of&apos;, 3), (&apos;and&apos;, 4), (&apos;one&apos;, 5), (&apos;in&apos;, 6), (&apos;a&apos;, 7), (&apos;to&apos;, 8), (&apos;zero&apos;, 9), (&apos;nine&apos;, 10), (&apos;two&apos;, 11), (&apos;is&apos;, 12), (&apos;as&apos;, 13), (&apos;eight&apos;, 14), (&apos;for&apos;, 15), (&apos;s&apos;, 16), (&apos;five&apos;, 17), (&apos;three&apos;, 18), (&apos;was&apos;, 19), (&apos;by&apos;, 20), (&apos;that&apos;, 21), (&apos;four&apos;, 22), (&apos;six&apos;, 23), (&apos;seven&apos;, 24), (&apos;with&apos;, 25), (&apos;on&apos;, 26), (&apos;are&apos;, 27), (&apos;it&apos;, 28), (&apos;from&apos;, 29), (&apos;or&apos;, 30), (&apos;his&apos;, 31), (&apos;an&apos;, 32), (&apos;be&apos;, 33), (&apos;this&apos;, 34), (&apos;he&apos;, 35), (&apos;at&apos;, 36), (&apos;which&apos;, 37), (&apos;not&apos;, 38), (&apos;also&apos;, 39), (&apos;have&apos;, 40), (&apos;were&apos;, 41), (&apos;has&apos;, 42), (&apos;but&apos;, 43), (&apos;other&apos;, 44), (&apos;their&apos;, 45), (&apos;its&apos;, 46), (&apos;first&apos;, 47), (&apos;they&apos;, 48), (&apos;had&apos;, 49)]</span><br></pre></td></tr></table></figure><p>In [10]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">VOCAB_SIZE = len(TEXT.vocab) <span class="comment"># 50002</span></span><br><span class="line">train_iter, val_iter, test_iter = \</span><br><span class="line">torchtext.data.BPTTIterator.splits(</span><br><span class="line">    (train, val, test), </span><br><span class="line">    batch_size=BATCH_SIZE, </span><br><span class="line">    device=<span class="number">-1</span>, </span><br><span class="line">    bptt_len=<span class="number">50</span>, <span class="comment"># åå‘ä¼ æ’­å¾€å›ä¼ çš„é•¿åº¦ï¼Œè¿™é‡Œæˆ‘æš‚æ—¶ç†è§£ä¸ºä¸€ä¸ªæ ·æœ¬æœ‰å¤šå°‘ä¸ªå•è¯ä¼ å…¥æ¨¡å‹</span></span><br><span class="line">    repeat=<span class="literal">False</span>, </span><br><span class="line">    shuffle=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># BPTTIteratorå¯ä»¥è¿ç»­åœ°å¾—åˆ°è¿è´¯çš„å¥å­ï¼ŒBPTTçš„å…¨ç§°æ˜¯back propagation through timeã€‚</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Iteratorï¼šæ ‡å‡†è¿­ä»£å™¨</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">BucketIeratorï¼šç›¸æ¯”äºæ ‡å‡†è¿­ä»£å™¨ï¼Œä¼šå°†ç±»ä¼¼é•¿åº¦çš„æ ·æœ¬å½“åšä¸€æ‰¹æ¥å¤„ç†ï¼Œ</span></span><br><span class="line"><span class="string">å› ä¸ºåœ¨æ–‡æœ¬å¤„ç†ä¸­ç»å¸¸ä¼šéœ€è¦å°†æ¯ä¸€æ‰¹æ ·æœ¬é•¿åº¦è¡¥é½ä¸ºå½“å‰æ‰¹ä¸­æœ€é•¿åºåˆ—çš„é•¿åº¦ï¼Œ</span></span><br><span class="line"><span class="string">å› æ­¤å½“æ ·æœ¬é•¿åº¦å·®åˆ«è¾ƒå¤§æ—¶ï¼Œä½¿ç”¨BucketIeratorå¯ä»¥å¸¦æ¥å¡«å……æ•ˆç‡çš„æé«˜ã€‚</span></span><br><span class="line"><span class="string">é™¤æ­¤ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥åœ¨Fieldä¸­é€šè¿‡fix_lengthå‚æ•°æ¥å¯¹æ ·æœ¬è¿›è¡Œæˆªæ–­è¡¥é½æ“ä½œã€‚</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">BPTTIterator: åŸºäºBPTT(åŸºäºæ—¶é—´çš„åå‘ä¼ æ’­ç®—æ³•)çš„è¿­ä»£å™¨ï¼Œä¸€èˆ¬ç”¨äºè¯­è¨€æ¨¡å‹ä¸­ã€‚</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.</span><br><span class="line">The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.</span><br><span class="line">The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.</span><br></pre></td></tr></table></figure><p>Out[10]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&apos;\nIteratorï¼šæ ‡å‡†è¿­ä»£å™¨\n\nBucketIeratorï¼šç›¸æ¯”äºæ ‡å‡†è¿­ä»£å™¨ï¼Œä¼šå°†ç±»ä¼¼é•¿åº¦çš„æ ·æœ¬å½“åšä¸€æ‰¹æ¥å¤„ç†ï¼Œ\nå› ä¸ºåœ¨æ–‡æœ¬å¤„ç†ä¸­ç»å¸¸ä¼šéœ€è¦å°†æ¯ä¸€æ‰¹æ ·æœ¬é•¿åº¦è¡¥é½ä¸ºå½“å‰æ‰¹ä¸­æœ€é•¿åºåˆ—çš„é•¿åº¦ï¼Œ\nå› æ­¤å½“æ ·æœ¬é•¿åº¦å·®åˆ«è¾ƒå¤§æ—¶ï¼Œä½¿ç”¨BucketIeratorå¯ä»¥å¸¦æ¥å¡«å……æ•ˆç‡çš„æé«˜ã€‚\né™¤æ­¤ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥åœ¨Fieldä¸­é€šè¿‡fix_lengthå‚æ•°æ¥å¯¹æ ·æœ¬è¿›è¡Œæˆªæ–­è¡¥é½æ“ä½œã€‚\n\nBPTTIterator: åŸºäºBPTT(åŸºäºæ—¶é—´çš„åå‘ä¼ æ’­ç®—æ³•)çš„è¿­ä»£å™¨ï¼Œä¸€èˆ¬ç”¨äºè¯­è¨€æ¨¡å‹ä¸­ã€‚\n&apos;</span><br></pre></td></tr></table></figure><p>In [11]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(next(iter(train_iter))) <span class="comment"># ä¸€ä¸ªbatchè®­ç»ƒé›†ç»´åº¦</span></span><br><span class="line">print(next(iter(val_iter))) <span class="comment"># ä¸€ä¸ªbatchéªŒè¯é›†ç»´åº¦</span></span><br><span class="line">print(next(iter(test_iter))) <span class="comment"># ä¸€ä¸ªbatchæµ‹è¯•é›†ç»´åº¦</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[torchtext.data.batch.Batch of size <span class="number">32</span>]</span><br><span class="line">[.text]:[torch.LongTensor of size <span class="number">50</span>x32]</span><br><span class="line">[.target]:[torch.LongTensor of size <span class="number">50</span>x32]</span><br><span class="line"></span><br><span class="line">[torchtext.data.batch.Batch of size <span class="number">32</span>]</span><br><span class="line">[.text]:[torch.LongTensor of size <span class="number">50</span>x32]</span><br><span class="line">[.target]:[torch.LongTensor of size <span class="number">50</span>x32]</span><br><span class="line"></span><br><span class="line">[torchtext.data.batch.Batch of size <span class="number">32</span>]</span><br><span class="line">[.text]:[torch.LongTensor of size <span class="number">50</span>x32]</span><br><span class="line">[.target]:[torch.LongTensor of size <span class="number">50</span>x32]</span><br></pre></td></tr></table></figure><p>æ¨¡å‹çš„è¾“å…¥æ˜¯ä¸€ä¸²æ–‡å­—ï¼Œæ¨¡å‹çš„è¾“å‡ºä¹Ÿæ˜¯ä¸€ä¸²æ–‡å­—ï¼Œä»–ä»¬ä¹‹é—´ç›¸å·®ä¸€ä¸ªä½ç½®ï¼Œå› ä¸ºè¯­è¨€æ¨¡å‹çš„ç›®æ ‡æ˜¯æ ¹æ®ä¹‹å‰çš„å•è¯é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ã€‚</p><p>In [12]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">it = iter(train_iter)</span><br><span class="line">batch = next(it)</span><br><span class="line">print(<span class="string">" "</span>.join([TEXT.vocab.itos[i] <span class="keyword">for</span> i <span class="keyword">in</span> batch.text[:,<span class="number">1</span>].data])) <span class="comment"># æ‰“å°ä¸€ä¸ªè¾“å…¥çš„å¥å­</span></span><br><span class="line">print(<span class="string">" "</span>.join([TEXT.vocab.itos[i] <span class="keyword">for</span> i <span class="keyword">in</span> batch.target[:,<span class="number">1</span>].data])) <span class="comment"># æ‰“å°ä¸€ä¸ªè¾“å‡ºçš„å¥å­</span></span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">combine in pairs and then group into trios of pairs which are the smallest visible units of matter this parallels with the structure of modern atomic theory in which pairs or triplets of supposedly fundamental quarks combine to create most typical forms of matter they had also suggested the possibility</span><br><span class="line">in pairs and then group into trios of pairs which are the smallest visible units of matter this parallels with the structure of modern atomic theory in which pairs or triplets of supposedly fundamental quarks combine to create most typical forms of matter they had also suggested the possibility of</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>In [13]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">5</span>): <span class="comment"># è¿™ç§å–æ³•æ˜¯åœ¨ä¸€ä¸ªå›ºå®šçš„batché‡Œå–æ•°æ®ï¼Œå‘ç°ä¸€ä¸ªbatché‡Œçš„æ•°æ®æ˜¯è¿ä¸èµ·æ¥çš„ã€‚</span></span><br><span class="line">    print(j)</span><br><span class="line">    print(<span class="string">" "</span>.join([TEXT.vocab.itos[i] <span class="keyword">for</span> i <span class="keyword">in</span> batch.text[:,j].data]))</span><br><span class="line">    print(j)</span><br><span class="line">    print(<span class="string">" "</span>.join([TEXT.vocab.itos[i] <span class="keyword">for</span> i <span class="keyword">in</span> batch.target[:,j].data]))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">0</span><br><span class="line">anarchism originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans &lt;unk&gt; of the french revolution whilst the term is still used in a pejorative way to describe any act that used violent means to destroy the</span><br><span class="line">0</span><br><span class="line">originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans &lt;unk&gt; of the french revolution whilst the term is still used in a pejorative way to describe any act that used violent means to destroy the organization</span><br><span class="line">1</span><br><span class="line">combine in pairs and then group into trios of pairs which are the smallest visible units of matter this parallels with the structure of modern atomic theory in which pairs or triplets of supposedly fundamental quarks combine to create most typical forms of matter they had also suggested the possibility</span><br><span class="line">1</span><br><span class="line">in pairs and then group into trios of pairs which are the smallest visible units of matter this parallels with the structure of modern atomic theory in which pairs or triplets of supposedly fundamental quarks combine to create most typical forms of matter they had also suggested the possibility of</span><br><span class="line">2</span><br><span class="line">culture few living ainu settlements exist many authentic ainu villages advertised in hokkaido are simply tourist attractions language the ainu language is significantly different from japanese in its syntax phonology morphology and vocabulary although there have been attempts to show that they are related the vast majority of modern scholars</span><br><span class="line">2</span><br><span class="line">few living ainu settlements exist many authentic ainu villages advertised in hokkaido are simply tourist attractions language the ainu language is significantly different from japanese in its syntax phonology morphology and vocabulary although there have been attempts to show that they are related the vast majority of modern scholars reject</span><br><span class="line">3</span><br><span class="line">zero the apple iie card an expansion card for the lc line of macintosh computers was released essentially a miniaturized apple iie computer on a card utilizing the mega ii chip from the apple iigs it allowed the macintosh to run eight bit apple iie software through hardware emulation although</span><br><span class="line">3</span><br><span class="line">the apple iie card an expansion card for the lc line of macintosh computers was released essentially a miniaturized apple iie computer on a card utilizing the mega ii chip from the apple iigs it allowed the macintosh to run eight bit apple iie software through hardware emulation although video</span><br><span class="line">4</span><br><span class="line">in papers have been written arguing that the anthropic principle would explain the physical constants such as the fine structure constant the number of dimensions in the universe and the cosmological constant the three primary versions of the principle as stated by john d barrow and frank j &lt;unk&gt; one</span><br><span class="line">4</span><br><span class="line">papers have been written arguing that the anthropic principle would explain the physical constants such as the fine structure constant the number of dimensions in the universe and the cosmological constant the three primary versions of the principle as stated by john d barrow and frank j &lt;unk&gt; one nine</span><br></pre></td></tr></table></figure><p>In [14]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>): <span class="comment"># è¿™ç§å–æ³•æ˜¯åœ¨æ¯ä¸ªbatché‡Œå–æŸä¸€ä¸ªç›¸åŒä½ç½®æ•°æ®ï¼Œå‘ç°ä¸åŒbatché—´ç›¸åŒä½ç½®çš„æ•°æ®æ˜¯å¯ä»¥è¿èµ·æ¥çš„ã€‚è¿™é‡Œæœ‰ç‚¹å°ç–‘é—®ã€‚</span></span><br><span class="line">    batch = next(it)</span><br><span class="line">    print(i)</span><br><span class="line">    print(<span class="string">" "</span>.join([TEXT.vocab.itos[i] <span class="keyword">for</span> i <span class="keyword">in</span> batch.text[:,<span class="number">2</span>].data]))</span><br><span class="line">    print(i)</span><br><span class="line">    print(<span class="string">" "</span>.join([TEXT.vocab.itos[i] <span class="keyword">for</span> i <span class="keyword">in</span> batch.target[:,<span class="number">2</span>].data]))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">0</span><br><span class="line">reject that the relationship goes beyond contact i e mutual borrowing of words between japanese and ainu in fact no attempt to show a relationship with ainu to any other language has gained wide acceptance and ainu is currently considered to be a language isolate culture traditional ainu culture is</span><br><span class="line">0</span><br><span class="line">that the relationship goes beyond contact i e mutual borrowing of words between japanese and ainu in fact no attempt to show a relationship with ainu to any other language has gained wide acceptance and ainu is currently considered to be a language isolate culture traditional ainu culture is quite</span><br><span class="line">1</span><br><span class="line">quite different from japanese culture never shaving after a certain age the men had full beards and &lt;unk&gt; men and women alike cut their hair level with the shoulders at the sides of the head but trimmed it &lt;unk&gt; behind the women tattooed their mouths arms &lt;unk&gt; and sometimes their</span><br><span class="line">1</span><br><span class="line">different from japanese culture never shaving after a certain age the men had full beards and &lt;unk&gt; men and women alike cut their hair level with the shoulders at the sides of the head but trimmed it &lt;unk&gt; behind the women tattooed their mouths arms &lt;unk&gt; and sometimes their &lt;unk&gt;</span><br><span class="line">2</span><br><span class="line">&lt;unk&gt; starting at the onset of puberty the soot deposited on a pot hung over a fire of birch bark was used for colour their traditional dress is a robe spun from the bark of the elm tree it has long sleeves reaches nearly to the feet is folded round</span><br><span class="line">2</span><br><span class="line">starting at the onset of puberty the soot deposited on a pot hung over a fire of birch bark was used for colour their traditional dress is a robe spun from the bark of the elm tree it has long sleeves reaches nearly to the feet is folded round the</span><br><span class="line">3</span><br><span class="line">the body and is tied with a girdle of the same material women also wear an &lt;unk&gt; of japanese cloth in winter the skins of animals were worn with &lt;unk&gt; of &lt;unk&gt; and boots made from the skin of dogs or salmon both sexes are fond of earrings which are</span><br><span class="line">3</span><br><span class="line">body and is tied with a girdle of the same material women also wear an &lt;unk&gt; of japanese cloth in winter the skins of animals were worn with &lt;unk&gt; of &lt;unk&gt; and boots made from the skin of dogs or salmon both sexes are fond of earrings which are said</span><br><span class="line">4</span><br><span class="line">said to have been made of grapevine in former times as also are bead necklaces called &lt;unk&gt; which the women prized highly their traditional cuisine consists of the flesh of bear fox wolf badger ox or horse as well as fish fowl millet vegetables herbs and roots they never ate</span><br><span class="line">4</span><br><span class="line">to have been made of grapevine in former times as also are bead necklaces called &lt;unk&gt; which the women prized highly their traditional cuisine consists of the flesh of bear fox wolf badger ox or horse as well as fish fowl millet vegetables herbs and roots they never ate raw</span><br></pre></td></tr></table></figure><h3 id="å®šä¹‰æ¨¡å‹"><a href="#å®šä¹‰æ¨¡å‹" class="headerlink" title="å®šä¹‰æ¨¡å‹"></a>å®šä¹‰æ¨¡å‹</h3><ul><li>ç»§æ‰¿nn.Module</li><li>åˆå§‹åŒ–å‡½æ•°</li><li>forwardå‡½æ•°</li><li>å…¶ä½™å¯ä»¥æ ¹æ®æ¨¡å‹éœ€è¦å®šä¹‰ç›¸å…³çš„å‡½æ•°</li></ul><p>In [15]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RNNModel</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">""" ä¸€ä¸ªç®€å•çš„å¾ªç¯ç¥ç»ç½‘ç»œ"""</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, rnn_type, ntoken, ninp, nhid, nlayers, dropout=<span class="number">0.5</span>)</span>:</span></span><br><span class="line">        <span class="comment"># rnn_typeï¼›æœ‰ä¸¤ä¸ªå±‚ä¾›é€‰æ‹©'LSTM', 'GRU'</span></span><br><span class="line">        <span class="comment"># ntokenï¼šVOCAB_SIZE=50002</span></span><br><span class="line">        <span class="comment"># ninpï¼šEMBEDDING_SIZE = 650ï¼Œè¾“å…¥å±‚ç»´åº¦</span></span><br><span class="line">        <span class="comment"># nhidï¼šEMBEDDING_SIZE = 1000ï¼Œéšè—å±‚ç»´åº¦ï¼Œè¿™é‡Œæ˜¯æˆ‘è‡ªå·±è®¾ç½®çš„ï¼Œç”¨äºåŒºåˆ†ninpå±‚ã€‚</span></span><br><span class="line">        <span class="comment"># nlayersï¼šçºµå‘æœ‰å¤šå°‘å±‚ç¥ç»ç½‘ç»œ</span></span><br><span class="line"></span><br><span class="line">        <span class="string">''' è¯¥æ¨¡å‹åŒ…å«ä»¥ä¸‹å‡ å±‚:</span></span><br><span class="line"><span class="string">            - è¯åµŒå…¥å±‚</span></span><br><span class="line"><span class="string">            - ä¸€ä¸ªå¾ªç¯ç¥ç»ç½‘ç»œå±‚(RNN, LSTM, GRU)</span></span><br><span class="line"><span class="string">            - ä¸€ä¸ªçº¿æ€§å±‚ï¼Œä»hidden stateåˆ°è¾“å‡ºå•è¯è¡¨</span></span><br><span class="line"><span class="string">            - ä¸€ä¸ªdropoutå±‚ï¼Œç”¨æ¥åšregularization</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        super(RNNModel, self).__init__()</span><br><span class="line">        self.drop = nn.Dropout(dropout)</span><br><span class="line">        self.encoder = nn.Embedding(ntoken, ninp)</span><br><span class="line">        <span class="comment"># å®šä¹‰è¾“å…¥çš„Embeddingå±‚ï¼Œç”¨æ¥æŠŠæ¯ä¸ªå•è¯è½¬åŒ–ä¸ºè¯å‘é‡</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> rnn_type <span class="keyword">in</span> [<span class="string">'LSTM'</span>, <span class="string">'GRU'</span>]: <span class="comment"># ä¸‹é¢ä»£ç ä»¥LSTMä¸¾ä¾‹</span></span><br><span class="line">            </span><br><span class="line">            self.rnn = getattr(nn, rnn_type)(ninp, nhid, nlayers, dropout=dropout)</span><br><span class="line">            <span class="comment"># getattr(nn, rnn_type) ç›¸å½“äº nn.rnn_type</span></span><br><span class="line">            <span class="comment"># nlayersä»£è¡¨çºµå‘æœ‰å¤šå°‘å±‚ã€‚è¿˜æœ‰ä¸ªå‚æ•°æ˜¯bidirectional: æ˜¯å¦æ˜¯åŒå‘LSTMï¼Œé»˜è®¤false</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                nonlinearity = &#123;<span class="string">'RNN_TANH'</span>: <span class="string">'tanh'</span>, <span class="string">'RNN_RELU'</span>: <span class="string">'relu'</span>&#125;[rnn_type]</span><br><span class="line">            <span class="keyword">except</span> KeyError:</span><br><span class="line">                <span class="keyword">raise</span> ValueError( <span class="string">"""An invalid option for `--model` was supplied,</span></span><br><span class="line"><span class="string">                                 options are ['LSTM', 'GRU', 'RNN_TANH' or 'RNN_RELU']"""</span>)</span><br><span class="line">            self.rnn = nn.RNN(ninp, nhid, nlayers, nonlinearity=nonlinearity, dropout=dropout)</span><br><span class="line">        self.decoder = nn.Linear(nhid, ntoken)</span><br><span class="line">        <span class="comment"># æœ€åçº¿æ€§å…¨è¿æ¥éšè—å±‚çš„ç»´åº¦(1000,50002)</span></span><br><span class="line">      </span><br><span class="line"></span><br><span class="line">        self.init_weights()</span><br><span class="line"></span><br><span class="line">        self.rnn_type = rnn_type</span><br><span class="line">        self.nhid = nhid</span><br><span class="line">        self.nlayers = nlayers</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_weights</span><span class="params">(self)</span>:</span></span><br><span class="line">        initrange = <span class="number">0.1</span></span><br><span class="line">        self.encoder.weight.data.uniform_(-initrange, initrange)</span><br><span class="line">        self.decoder.bias.data.zero_()</span><br><span class="line">        self.decoder.weight.data.uniform_(-initrange, initrange)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, input, hidden)</span>:</span> </span><br><span class="line">        </span><br><span class="line">        <span class="string">''' Forward pass:</span></span><br><span class="line"><span class="string">            - word embedding</span></span><br><span class="line"><span class="string">            - è¾“å…¥å¾ªç¯ç¥ç»ç½‘ç»œ</span></span><br><span class="line"><span class="string">            - ä¸€ä¸ªçº¿æ€§å±‚ä»hidden stateè½¬åŒ–ä¸ºè¾“å‡ºå•è¯è¡¨</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># input.shape = seg_length * batch = torch.Size([50, 32])</span></span><br><span class="line">        <span class="comment"># å¦‚æœè§‰å¾—æƒ³å˜æˆ32*50æ ¼å¼ï¼Œå¯ä»¥åœ¨LSTMé‡Œå®šä¹‰batch_first = True</span></span><br><span class="line">        <span class="comment"># hidden = (nlayers * 32 * hidden_size, nlayers * 32 * hidden_size)</span></span><br><span class="line">        <span class="comment"># hiddenæ˜¯ä¸ªå…ƒç»„ï¼Œè¾“å…¥æœ‰ä¸¤ä¸ªå‚æ•°ï¼Œä¸€ä¸ªæ˜¯åˆšå¼€å§‹çš„éšè—å±‚hçš„ç»´åº¦ï¼Œä¸€ä¸ªæ˜¯åˆšå¼€å§‹çš„ç”¨äºè®°å¿†çš„cçš„ç»´åº¦ï¼Œ</span></span><br><span class="line">        <span class="comment"># è¿™ä¸¤ä¸ªå±‚çš„ç»´åº¦ä¸€æ ·ï¼Œå¹¶ä¸”éœ€è¦å…ˆåˆå§‹åŒ–ï¼Œhidden_sizeçš„ç»´åº¦å’Œä¸Šé¢nhidçš„ç»´åº¦ä¸€æ · =1000ï¼Œæˆ‘ç†è§£è¿™ä¸¤ä¸ªæ˜¯åŒä¸€ä¸ªä¸œè¥¿ã€‚</span></span><br><span class="line">        emb = self.drop(self.encoder(input)) <span class="comment"># </span></span><br><span class="line">        <span class="comment"># emb.shape=torch.Size([50, 32, 650]) # è¾“å…¥æ•°æ®çš„ç»´åº¦</span></span><br><span class="line">        <span class="comment"># è¿™é‡Œè¿›è¡Œäº†è¿ç®—ï¼ˆ50ï¼Œ50002ï¼Œ650ï¼‰*(50, 32ï¼Œ50002)</span></span><br><span class="line">        output, hidden = self.rnn(emb, hidden)</span><br><span class="line">        <span class="comment"># output.shape = 50 * 32 * hidden_size # æœ€ç»ˆè¾“å‡ºæ•°æ®çš„ç»´åº¦ï¼Œ</span></span><br><span class="line">        <span class="comment"># hiddenæ˜¯ä¸ªå…ƒç»„ï¼Œè¾“å‡ºæœ‰ä¸¤ä¸ªå‚æ•°ï¼Œä¸€ä¸ªæ˜¯æœ€åçš„éšè—å±‚hçš„ç»´åº¦ï¼Œä¸€ä¸ªæ˜¯æœ€åçš„ç”¨äºè®°å¿†çš„cçš„ç»´åº¦ï¼Œè¿™ä¸¤ä¸ªå±‚ç»´åº¦ç›¸åŒ </span></span><br><span class="line">        <span class="comment"># hidden = (hå±‚ç»´åº¦ï¼šnlayers * 32 * hidden_size, cå±‚ç»´åº¦ï¼šnlayers * 32 * hidden_size)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        output = self.drop(output)</span><br><span class="line">        decoded = self.decoder(output.view(output.size(<span class="number">0</span>)*output.size(<span class="number">1</span>), output.size(<span class="number">2</span>)))</span><br><span class="line">        <span class="comment"># outputæœ€åçš„è¾“å‡ºå±‚ä¸€å®šè¦æ˜¯äºŒç»´çš„ï¼Œåªæ˜¯ä¸ºäº†èƒ½è¿›è¡Œå…¨è¿æ¥å±‚çš„è¿ç®—ï¼Œæ‰€ä»¥æŠŠå‰ä¸¤ä¸ªç»´åº¦æ‹¼åˆ°ä¸€èµ·ï¼Œï¼ˆ50*32,hidden_size)</span></span><br><span class="line">        <span class="comment"># decoded.shape=ï¼ˆ50*32,hidden_size)*(hidden_size,50002)=torch.Size([1600, 50002])</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> decoded.view(output.size(<span class="number">0</span>), output.size(<span class="number">1</span>), decoded.size(<span class="number">1</span>)), hidden</span><br><span class="line">               <span class="comment"># æˆ‘ä»¬è¦çŸ¥é“æ¯ä¸€ä¸ªä½ç½®é¢„æµ‹çš„æ˜¯å“ªä¸ªå•è¯ï¼Œæ‰€ä»¥æœ€ç»ˆè¾“å‡ºè¦æ¢å¤ç»´åº¦ = (50,32,50002)</span></span><br><span class="line">               <span class="comment"># hidden = (hå±‚ç»´åº¦ï¼š2 * 32 * 1000, cå±‚ç»´åº¦ï¼š2 * 32 * 1000)</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_hidden</span><span class="params">(self, bsz, requires_grad=True)</span>:</span></span><br><span class="line">        <span class="comment"># è¿™æ­¥æˆ‘ä»¬åˆå§‹åŒ–ä¸‹éšè—å±‚å‚æ•°</span></span><br><span class="line">        weight = next(self.parameters())</span><br><span class="line">        <span class="comment"># weight = torch.Size([50002, 650])æ˜¯æ‰€æœ‰å‚æ•°çš„ç¬¬ä¸€ä¸ªå‚æ•°</span></span><br><span class="line">        <span class="comment"># æ‰€æœ‰å‚æ•°self.parameters()ï¼Œæ˜¯ä¸ªç”Ÿæˆå™¨ï¼ŒLSTMæ‰€æœ‰å‚æ•°ç»´åº¦ç§ç±»å¦‚ä¸‹ï¼š</span></span><br><span class="line">        <span class="comment"># print(list(iter(self.parameters())))</span></span><br><span class="line">        <span class="comment"># torch.Size([50002, 650])</span></span><br><span class="line">        <span class="comment"># torch.Size([4000, 650])</span></span><br><span class="line">        <span class="comment"># torch.Size([4000, 1000])</span></span><br><span class="line">        <span class="comment"># torch.Size([4000]) # åç½®é¡¹</span></span><br><span class="line">        <span class="comment"># torch.Size([4000])</span></span><br><span class="line">        <span class="comment"># torch.Size([4000, 1000])</span></span><br><span class="line">        <span class="comment"># torch.Size([4000, 1000])</span></span><br><span class="line">        <span class="comment"># torch.Size([4000])</span></span><br><span class="line">        <span class="comment"># torch.Size([4000])</span></span><br><span class="line">        <span class="comment"># torch.Size([50002, 1000])</span></span><br><span class="line">        <span class="comment"># torch.Size([50002])</span></span><br><span class="line">        <span class="keyword">if</span> self.rnn_type == <span class="string">'LSTM'</span>:</span><br><span class="line">            <span class="keyword">return</span> (weight.new_zeros((self.nlayers, bsz, self.nhid), requires_grad=requires_grad),</span><br><span class="line">                    weight.new_zeros((self.nlayers, bsz, self.nhid), requires_grad=requires_grad))</span><br><span class="line">                   <span class="comment"># return = (2 * 32 * 1000, 2 * 32 * 1000)</span></span><br><span class="line">                   <span class="comment"># è¿™é‡Œä¸æ˜ç™½ä¸ºä»€ä¹ˆéœ€è¦weight.new_zerosï¼Œæˆ‘ä¼°è®¡æ˜¯æƒ³æ•´ä¸ªè®¡ç®—å›¾èƒ½é“¾æ¥èµ·æ¥</span></span><br><span class="line">                   <span class="comment"># è¿™é‡Œç‰¹åˆ«æ³¨æ„hiddençš„è¾“å…¥ä¸æ˜¯modelçš„å‚æ•°ï¼Œä¸å‚ä¸æ›´æ–°ï¼Œå°±è·Ÿè¾“å…¥æ•°æ®xä¸€æ ·</span></span><br><span class="line">                   </span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> weight.new_zeros((self.nlayers, bsz, self.nhid), requires_grad=requires_grad)</span><br><span class="line">            <span class="comment"># GRUç¥ç»ç½‘ç»œæŠŠhå±‚å’Œcå±‚åˆå¹¶äº†ï¼Œæ‰€ä»¥è¿™é‡Œåªæœ‰ä¸€å±‚ã€‚</span></span><br></pre></td></tr></table></figure><p>åˆå§‹åŒ–ä¸€ä¸ªæ¨¡å‹</p><p>In [16]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nhid = <span class="number">1000</span> <span class="comment"># æˆ‘è‡ªå·±è®¾ç½®çš„ç»´åº¦ï¼Œç”¨äºåŒºåˆ†embeding_size=650</span></span><br><span class="line">model = RNNModel(<span class="string">"LSTM"</span>, VOCAB_SIZE, EMBEDDING_SIZE, nhid, <span class="number">2</span>, dropout=<span class="number">0.5</span>)</span><br><span class="line"><span class="keyword">if</span> USE_CUDA:</span><br><span class="line">    model = model.cuda()</span><br></pre></td></tr></table></figure><p>In [17]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model</span><br></pre></td></tr></table></figure><p>Out[17]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">RNNModel(</span><br><span class="line">  (drop): Dropout(p=<span class="number">0.5</span>)</span><br><span class="line">  (encoder): Embedding(<span class="number">50002</span>, <span class="number">650</span>)</span><br><span class="line">  (rnn): LSTM(<span class="number">650</span>, <span class="number">1000</span>, num_layers=<span class="number">2</span>, dropout=<span class="number">0.5</span>)</span><br><span class="line">  (decoder): Linear(in_features=<span class="number">1000</span>, out_features=<span class="number">50002</span>, bias=<span class="literal">True</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>In [23]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">list(model.parameters())[0].shape</span><br></pre></td></tr></table></figure><p>Out[23]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([50002, 650])</span><br></pre></td></tr></table></figure><ul><li>æˆ‘ä»¬é¦–å…ˆå®šä¹‰è¯„ä¼°æ¨¡å‹çš„ä»£ç ã€‚</li><li>æ¨¡å‹çš„è¯„ä¼°å’Œæ¨¡å‹çš„è®­ç»ƒé€»è¾‘åŸºæœ¬ç›¸åŒï¼Œå”¯ä¸€çš„åŒºåˆ«æ˜¯æˆ‘ä»¬åªéœ€è¦forward passï¼Œä¸éœ€è¦backward pass</li></ul><p>In [68]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å…ˆä»ä¸‹é¢è®­ç»ƒæ¨¡å¼çœ‹èµ·ï¼Œåœ¨çœ‹evaluate</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">(model, data)</span>:</span></span><br><span class="line">    model.eval() <span class="comment"># é¢„æµ‹æ¨¡å¼</span></span><br><span class="line">    total_loss = <span class="number">0.</span></span><br><span class="line">    it = iter(data)</span><br><span class="line">    total_count = <span class="number">0.</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        hidden = model.init_hidden(BATCH_SIZE, requires_grad=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># è¿™é‡Œä¸ç®¡æ˜¯è®­ç»ƒæ¨¡å¼è¿˜æ˜¯é¢„æµ‹æ¨¡å¼ï¼Œhå±‚çš„è¾“å…¥éƒ½æ˜¯åˆå§‹åŒ–ä¸º0ï¼Œhiddençš„è¾“å…¥ä¸æ˜¯modelçš„å‚æ•°</span></span><br><span class="line"><span class="comment"># è¿™é‡Œmodelé‡Œçš„model.parameters()å·²ç»æ˜¯è®­ç»ƒè¿‡çš„å‚æ•°ã€‚</span></span><br><span class="line">        <span class="keyword">for</span> i, batch <span class="keyword">in</span> enumerate(it):</span><br><span class="line">            data, target = batch.text, batch.target</span><br><span class="line">            <span class="comment"># # å–å‡ºéªŒè¯é›†çš„è¾“å…¥çš„æ•°æ®å’Œè¾“å‡ºçš„æ•°æ®ï¼Œç›¸å½“äºç‰¹å¾å’Œæ ‡ç­¾</span></span><br><span class="line">            <span class="keyword">if</span> USE_CUDA:</span><br><span class="line">                data, target = data.cuda(), target.cuda()</span><br><span class="line">            hidden = repackage_hidden(hidden) <span class="comment"># æˆªæ–­è®¡ç®—å›¾</span></span><br><span class="line">            <span class="keyword">with</span> torch.no_grad(): <span class="comment"># éªŒè¯é˜¶æ®µä¸éœ€è¦æ›´æ–°æ¢¯åº¦</span></span><br><span class="line">                output, hidden = model(data, hidden)</span><br><span class="line">                <span class="comment">#è°ƒç”¨modelçš„forwardæ–¹æ³•è¿›è¡Œä¸€æ¬¡å‰å‘ä¼ æ’­ï¼Œå¾—åˆ°returnè¾“å‡ºå€¼</span></span><br><span class="line">            loss = loss_fn(output.view(<span class="number">-1</span>, VOCAB_SIZE), target.view(<span class="number">-1</span>))</span><br><span class="line">            <span class="comment"># è®¡ç®—äº¤å‰ç†µæŸå¤±</span></span><br><span class="line">            </span><br><span class="line">            total_count += np.multiply(*data.size()) </span><br><span class="line"><span class="comment"># ä¸Šé¢è®¡ç®—äº¤å‰ç†µçš„æŸå¤±æ˜¯å¹³å‡è¿‡çš„ï¼Œè¿™é‡Œéœ€è¦è®¡ç®—ä¸‹æ€»çš„æŸå¤±</span></span><br><span class="line"><span class="comment"># total_countå…ˆè®¡ç®—éªŒè¯é›†æ ·æœ¬çš„å•è¯æ€»æ•°ï¼Œä¸€ä¸ªæ ·æœ¬æœ‰50ä¸ªå•è¯ï¼Œä¸€ä¸ªbatch32ä¸ªæ ·æœ¬</span></span><br><span class="line"><span class="comment"># np.multiply(*data.size()) =50*32=1600</span></span><br><span class="line">            total_loss += loss.item()*np.multiply(*data.size())</span><br><span class="line"><span class="comment"># æ¯æ¬¡batchå¹³å‡åçš„æŸå¤±ä¹˜ä»¥æ¯æ¬¡batchçš„æ ·æœ¬çš„æ€»çš„å•è¯æ•° = ä¸€æ¬¡batchæ€»çš„æŸå¤±</span></span><br><span class="line">            </span><br><span class="line">    loss = total_loss / total_count <span class="comment"># æ•´ä¸ªéªŒè¯é›†æ€»çš„æŸå¤±é™¤ä»¥æ€»çš„å•è¯æ•°</span></span><br><span class="line">    model.train() <span class="comment"># è®­ç»ƒæ¨¡å¼</span></span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure><p>In [9]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = torch.ones((<span class="number">5</span>,<span class="number">3</span>))</span><br><span class="line">print(a.size())</span><br><span class="line">np.multiply(*a.size())</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([5, 3])</span><br></pre></td></tr></table></figure><p>Out[9]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">15</span><br></pre></td></tr></table></figure><p>æˆ‘ä»¬éœ€è¦å®šä¹‰ä¸‹é¢çš„ä¸€ä¸ªfunctionï¼Œå¸®åŠ©æˆ‘ä»¬æŠŠä¸€ä¸ªhidden stateå’Œè®¡ç®—å›¾ä¹‹å‰çš„å†å²åˆ†ç¦»ã€‚</p><p>In [69]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Remove this part</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">repackage_hidden</span><span class="params">(h)</span>:</span></span><br><span class="line">    <span class="string">"""Wraps hidden states in new Tensors, to detach them from their history."""</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(h, torch.Tensor): </span><br><span class="line">        <span class="comment"># è¿™ä¸ªæ˜¯GRUçš„æˆªæ–­ï¼Œå› ä¸ºåªæœ‰ä¸€ä¸ªéšè—å±‚</span></span><br><span class="line">        <span class="comment"># åˆ¤æ–­hæ˜¯ä¸æ˜¯torch.Tensor</span></span><br><span class="line">        <span class="keyword">return</span> h.detach() <span class="comment"># æˆªæ–­è®¡ç®—å›¾ï¼Œhæ˜¯å…¨çš„è®¡ç®—å›¾çš„å¼€å§‹ï¼Œåªæ˜¯ä¿ç•™äº†hçš„å€¼</span></span><br><span class="line">    <span class="keyword">else</span>: <span class="comment"># è¿™ä¸ªæ˜¯LSTMçš„æˆªæ–­ï¼Œæœ‰ä¸¤ä¸ªéšè—å±‚ï¼Œæ ¼å¼æ˜¯å…ƒç»„</span></span><br><span class="line">        <span class="keyword">return</span> tuple(repackage_hidden(v) <span class="keyword">for</span> v <span class="keyword">in</span> h)</span><br></pre></td></tr></table></figure><p>å®šä¹‰loss functionå’Œoptimizer</p><p>In [70]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">loss_fn = nn.CrossEntropyLoss() <span class="comment"># äº¤å‰ç†µæŸå¤±</span></span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)</span><br><span class="line">scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, <span class="number">0.5</span>)</span><br><span class="line"><span class="comment"># æ¯è°ƒç”¨ä¸€æ¬¡è¿™ä¸ªå‡½æ•°ï¼Œlenrning_rateå°±é™ä¸€åŠï¼Œ0.5å°±æ˜¯ä¸€åŠçš„æ„æ€</span></span><br></pre></td></tr></table></figure><p>è®­ç»ƒæ¨¡å‹ï¼š</p><ul><li>æ¨¡å‹ä¸€èˆ¬éœ€è¦è®­ç»ƒè‹¥å¹²ä¸ªepoch</li><li>æ¯ä¸ªepochæˆ‘ä»¬éƒ½æŠŠæ‰€æœ‰çš„æ•°æ®åˆ†æˆè‹¥å¹²ä¸ªbatch</li><li>æŠŠæ¯ä¸ªbatchçš„è¾“å…¥å’Œè¾“å‡ºéƒ½åŒ…è£…æˆcuda tensor</li><li>forward passï¼Œé€šè¿‡è¾“å…¥çš„å¥å­é¢„æµ‹æ¯ä¸ªå•è¯çš„ä¸‹ä¸€ä¸ªå•è¯</li><li>ç”¨æ¨¡å‹çš„é¢„æµ‹å’Œæ­£ç¡®çš„ä¸‹ä¸€ä¸ªå•è¯è®¡ç®—cross entropy loss</li><li>æ¸…ç©ºæ¨¡å‹å½“å‰gradient</li><li>backward pass</li><li>gradient clippingï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸</li><li>æ›´æ–°æ¨¡å‹å‚æ•°</li><li>æ¯éš”ä¸€å®šçš„iterationè¾“å‡ºæ¨¡å‹åœ¨å½“å‰iterationçš„lossï¼Œä»¥åŠåœ¨éªŒè¯é›†ä¸Šåšæ¨¡å‹çš„è¯„ä¼°</li></ul><p>In [13]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> copy</span><br><span class="line">GRAD_CLIP = <span class="number">1.</span></span><br><span class="line">NUM_EPOCHS = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">val_losses = []</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(NUM_EPOCHS):</span><br><span class="line">    model.train() <span class="comment"># è®­ç»ƒæ¨¡å¼</span></span><br><span class="line">    it = iter(train_iter) </span><br><span class="line">    <span class="comment"># iter,ç”Ÿæˆè¿­ä»£å™¨,è¿™é‡Œtrain_iterä¹Ÿæ˜¯è¿­ä»£å™¨ï¼Œä¸ç”¨iterä¹Ÿå¯ä»¥</span></span><br><span class="line">    hidden = model.init_hidden(BATCH_SIZE) </span><br><span class="line">    <span class="comment"># å¾—åˆ°hiddenåˆå§‹åŒ–åçš„ç»´åº¦</span></span><br><span class="line">    <span class="keyword">for</span> i, batch <span class="keyword">in</span> enumerate(it):</span><br><span class="line">        data, target = batch.text, batch.target</span><br><span class="line">        <span class="comment"># å–å‡ºè®­ç»ƒé›†çš„è¾“å…¥çš„æ•°æ®å’Œè¾“å‡ºçš„æ•°æ®ï¼Œç›¸å½“äºç‰¹å¾å’Œæ ‡ç­¾</span></span><br><span class="line">        <span class="keyword">if</span> USE_CUDA:</span><br><span class="line">            data, target = data.cuda(), target.cuda()</span><br><span class="line">        hidden = repackage_hidden(hidden)</span><br><span class="line"><span class="comment"># è¯­è¨€æ¨¡å‹æ¯ä¸ªbatchçš„éšè—å±‚çš„è¾“å‡ºå€¼æ˜¯è¦ç»§ç»­ä½œä¸ºä¸‹ä¸€ä¸ªbatchçš„éšè—å±‚çš„è¾“å…¥çš„</span></span><br><span class="line"><span class="comment"># å› ä¸ºbatchæ•°é‡å¾ˆå¤šï¼Œå¦‚æœä¸€ç›´å¾€åä¼ ï¼Œä¼šé€ æˆæ•´ä¸ªè®¡ç®—å›¾å¾ˆåºå¤§ï¼Œåå‘ä¼ æ’­ä¼šå†…å­˜å´©æºƒã€‚</span></span><br><span class="line"><span class="comment"># æ‰€æœ‰æ¯æ¬¡ä¸€ä¸ªbatchçš„è®¡ç®—å›¾è¿­ä»£å®Œæˆåï¼Œéœ€è¦æŠŠè®¡ç®—å›¾æˆªæ–­ï¼Œåªä¿ç•™éšè—å±‚çš„è¾“å‡ºå€¼ã€‚</span></span><br><span class="line"><span class="comment"># ä¸è¿‡åªæœ‰è¯­è¨€æ¨¡å‹æ‰è¿™ä¹ˆå¹²ï¼Œå…¶ä»–æ¯”å¦‚ç¿»è¯‘æ¨¡å‹ä¸éœ€è¦è¿™ä¹ˆåšã€‚</span></span><br><span class="line"><span class="comment"># repackage_hiddenè‡ªå®šä¹‰å‡½æ•°ç”¨æ¥æˆªæ–­è®¡ç®—å›¾çš„ã€‚</span></span><br><span class="line">        model.zero_grad() <span class="comment"># æ¢¯åº¦å½’é›¶ï¼Œä¸ç„¶æ¯æ¬¡è¿­ä»£æ¢¯åº¦ä¼šç´¯åŠ </span></span><br><span class="line">        output, hidden = model(data, hidden)</span><br><span class="line">        <span class="comment"># output = (50,32,50002)</span></span><br><span class="line">        loss = loss_fn(output.view(<span class="number">-1</span>, VOCAB_SIZE), target.view(<span class="number">-1</span>))</span><br><span class="line"><span class="comment"># output.view(-1, VOCAB_SIZE) = (1600,50002)</span></span><br><span class="line"><span class="comment"># target.view(-1) =(1600),å…³äºpytorchä¸­äº¤å‰ç†µçš„è®¡ç®—å…¬å¼è¯·çœ‹ä¸‹é¢é“¾æ¥ã€‚</span></span><br><span class="line"><span class="comment"># https://blog.csdn.net/geter_CS/article/details/84857220</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)</span><br><span class="line">        <span class="comment"># é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼Œè®¾å®šé˜ˆå€¼ï¼Œå½“æ¢¯åº¦å¤§äºé˜ˆå€¼æ—¶ï¼Œæ›´æ–°çš„æ¢¯åº¦ä¸ºé˜ˆå€¼</span></span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"epoch"</span>, epoch, <span class="string">"iter"</span>, i, <span class="string">"loss"</span>, loss.item())</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">10000</span> == <span class="number">0</span>:</span><br><span class="line">            val_loss = evaluate(model, val_iter)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> len(val_losses) == <span class="number">0</span> <span class="keyword">or</span> val_loss &lt; min(val_losses):</span><br><span class="line">                <span class="comment"># å¦‚æœæ¯”ä¹‹å‰çš„lossè¦å°ï¼Œå°±ä¿å­˜æ¨¡å‹</span></span><br><span class="line">                print(<span class="string">"best model, val loss: "</span>, val_loss)</span><br><span class="line">                torch.save(model.state_dict(), <span class="string">"lm-best.th"</span>)</span><br><span class="line">            <span class="keyword">else</span>: <span class="comment"># å¦åˆ™lossæ²¡æœ‰é™ä¸‹æ¥ï¼Œéœ€è¦ä¼˜åŒ–</span></span><br><span class="line">                scheduler.step() <span class="comment"># è‡ªåŠ¨è°ƒæ•´å­¦ä¹ ç‡</span></span><br><span class="line">                optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)</span><br><span class="line">                <span class="comment"># å­¦ä¹ ç‡è°ƒæ•´åéœ€è¦æ›´æ–°optimizerï¼Œä¸‹æ¬¡è®­ç»ƒå°±ç”¨æ›´æ–°åçš„</span></span><br><span class="line">            val_losses.append(val_loss) <span class="comment"># ä¿å­˜æ¯10000æ¬¡è¿­ä»£åçš„éªŒè¯é›†æŸå¤±æŸå¤±</span></span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">epoch 0 iter 0 loss 10.821578979492188</span><br><span class="line">best model, val loss:  10.782116411285918</span><br><span class="line">epoch 0 iter 1000 loss 6.5122528076171875</span><br><span class="line">epoch 0 iter 2000 loss 6.3599748611450195</span><br><span class="line">epoch 0 iter 3000 loss 6.13856315612793</span><br><span class="line">epoch 0 iter 4000 loss 5.473214626312256</span><br><span class="line">epoch 0 iter 5000 loss 5.901871204376221</span><br><span class="line">epoch 0 iter 6000 loss 5.85321569442749</span><br><span class="line">epoch 0 iter 7000 loss 5.636535167694092</span><br><span class="line">epoch 0 iter 8000 loss 5.7489800453186035</span><br><span class="line">epoch 0 iter 9000 loss 5.464158058166504</span><br><span class="line">epoch 0 iter 10000 loss 5.554863452911377</span><br><span class="line">best model, val loss:  5.264891533569864</span><br><span class="line">epoch 0 iter 11000 loss 5.703625202178955</span><br><span class="line">epoch 0 iter 12000 loss 5.6448974609375</span><br><span class="line">epoch 0 iter 13000 loss 5.372857570648193</span><br><span class="line">epoch 0 iter 14000 loss 5.2639479637146</span><br><span class="line">epoch 1 iter 0 loss 5.696778297424316</span><br><span class="line">best model, val loss:  5.124550380139679</span><br><span class="line">epoch 1 iter 1000 loss 5.534722805023193</span><br><span class="line">epoch 1 iter 2000 loss 5.599489212036133</span><br><span class="line">epoch 1 iter 3000 loss 5.459986686706543</span><br><span class="line">epoch 1 iter 4000 loss 4.927192211151123</span><br><span class="line">epoch 1 iter 5000 loss 5.435710906982422</span><br><span class="line">epoch 1 iter 6000 loss 5.4059576988220215</span><br><span class="line">epoch 1 iter 7000 loss 5.308575630187988</span><br><span class="line">epoch 1 iter 8000 loss 5.405811786651611</span><br><span class="line">epoch 1 iter 9000 loss 5.1389055252075195</span><br><span class="line">epoch 1 iter 10000 loss 5.226413726806641</span><br><span class="line">best model, val loss:  4.946829228873176</span><br><span class="line">epoch 1 iter 11000 loss 5.379891395568848</span><br><span class="line">epoch 1 iter 12000 loss 5.360724925994873</span><br><span class="line">epoch 1 iter 13000 loss 5.176026344299316</span><br><span class="line">epoch 1 iter 14000 loss 5.110936641693115</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åŠ è½½ä¿å­˜å¥½çš„æ¨¡å‹å‚æ•°</span></span><br><span class="line">best_model = RNNModel(<span class="string">"LSTM"</span>, VOCAB_SIZE, EMBEDDING_SIZE, nhid, <span class="number">2</span>, dropout=<span class="number">0.5</span>)</span><br><span class="line"><span class="keyword">if</span> USE_CUDA:</span><br><span class="line">    best_model = best_model.cuda()</span><br><span class="line">best_model.load_state_dict(torch.load(<span class="string">"lm-best.th"</span>))</span><br><span class="line"><span class="comment"># æŠŠæ¨¡å‹å‚æ•°loadåˆ°best_modelé‡Œ</span></span><br></pre></td></tr></table></figure><h3 id="ä½¿ç”¨æœ€å¥½çš„æ¨¡å‹åœ¨validæ•°æ®ä¸Šè®¡ç®—perplexity"><a href="#ä½¿ç”¨æœ€å¥½çš„æ¨¡å‹åœ¨validæ•°æ®ä¸Šè®¡ç®—perplexity" class="headerlink" title="ä½¿ç”¨æœ€å¥½çš„æ¨¡å‹åœ¨validæ•°æ®ä¸Šè®¡ç®—perplexity"></a>ä½¿ç”¨æœ€å¥½çš„æ¨¡å‹åœ¨validæ•°æ®ä¸Šè®¡ç®—perplexity</h3><p>In [15]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">val_loss = evaluate(best_model, val_iter)</span><br><span class="line">print(<span class="string">"perplexity: "</span>, np.exp(val_loss))</span><br><span class="line"><span class="comment"># è¿™é‡Œä¸æ¸…æ¥šè¯­è¨€æ¨¡å‹çš„è¯„ä¼°æŒ‡æ ‡perplexity = np.exp(val_loss)</span></span><br><span class="line"><span class="comment"># æ¸…æ¥šçš„æœ‹å‹æ¬¢è¿äº¤æµä¸‹</span></span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">perplexity:  140.72803934425724</span><br></pre></td></tr></table></figure><h3 id="ä½¿ç”¨æœ€å¥½çš„æ¨¡å‹åœ¨æµ‹è¯•æ•°æ®ä¸Šè®¡ç®—perplexity"><a href="#ä½¿ç”¨æœ€å¥½çš„æ¨¡å‹åœ¨æµ‹è¯•æ•°æ®ä¸Šè®¡ç®—perplexity" class="headerlink" title="ä½¿ç”¨æœ€å¥½çš„æ¨¡å‹åœ¨æµ‹è¯•æ•°æ®ä¸Šè®¡ç®—perplexity"></a>ä½¿ç”¨æœ€å¥½çš„æ¨¡å‹åœ¨æµ‹è¯•æ•°æ®ä¸Šè®¡ç®—perplexity</h3><p>In [16]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test_loss = evaluate(best_model, test_iter)</span><br><span class="line">print(<span class="string">"perplexity: "</span>, np.exp(test_loss))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">perplexity:  178.54742013696125</span><br></pre></td></tr></table></figure><p>ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ç”Ÿæˆä¸€äº›å¥å­ã€‚</p><p>In [18]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">hidden = best_model.init_hidden(<span class="number">1</span>) <span class="comment"># batch_size = 1</span></span><br><span class="line">device = torch.device(<span class="string">"cuda"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line">input = torch.randint(VOCAB_SIZE, (<span class="number">1</span>, <span class="number">1</span>), dtype=torch.long).to(device)</span><br><span class="line"><span class="comment"># (1,1)è¡¨ç¤ºè¾“å‡ºæ ¼å¼æ˜¯1è¡Œ1åˆ—çš„2ç»´tensorï¼ŒVOCAB_SIZEè¡¨ç¤ºéšæœºå–çš„å€¼å°äºVOCAB_SIZE=50002</span></span><br><span class="line"><span class="comment"># æˆ‘ä»¬inputç›¸å½“äºå–çš„æ˜¯ä¸€ä¸ªå•è¯</span></span><br><span class="line">words = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    output, hidden = best_model(input, hidden)</span><br><span class="line">    <span class="comment"># output.shape = 1 * 1 * 50002</span></span><br><span class="line">    <span class="comment"># hidden = (2 * 1 * 1000, 2 * 1 * 1000)</span></span><br><span class="line">    word_weights = output.squeeze().exp().cpu()</span><br><span class="line">    <span class="comment"># .exp()çš„ä¸¤ä¸ªä½œç”¨ï¼šä¸€æ˜¯æŠŠæ¦‚ç‡æ›´å¤§çš„å˜å¾—æ›´å¤§ï¼ŒäºŒæ˜¯æŠŠè´Ÿæ•°ç»è¿‡eåå˜æˆæ­£æ•°ï¼Œä¸‹é¢.multinomialå‚æ•°éœ€è¦æ­£æ•°</span></span><br><span class="line">    word_idx = torch.multinomial(word_weights, <span class="number">1</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># æŒ‰ç…§word_weightsé‡Œé¢çš„æ¦‚ç‡éšæœºçš„å–å€¼ï¼Œæ¦‚ç‡å¤§çš„å–åˆ°çš„æœºä¼šå¤§ã€‚</span></span><br><span class="line">    <span class="comment"># torch.multinomialçœ‹è¿™ä¸ªåšå®¢ç†è§£ï¼šhttps://blog.csdn.net/monchin/article/details/79787621</span></span><br><span class="line">    <span class="comment"># è¿™é‡Œå¦‚æœé€‰æ‹©æ¦‚ç‡æœ€å¤§çš„ï¼Œä¼šæ¯æ¬¡ç”Ÿæˆé‡å¤çš„å¥å­ã€‚</span></span><br><span class="line">    input.fill_(word_idx) <span class="comment"># é¢„æµ‹çš„å•è¯indexæ˜¯word_idxï¼Œç„¶åæŠŠword_idxä½œä¸ºä¸‹ä¸€ä¸ªå¾ªç¯é¢„æµ‹çš„inputè¾“å…¥</span></span><br><span class="line">    word = TEXT.vocab.itos[word_idx] <span class="comment"># æ ¹æ®word_idxå–å‡ºå¯¹åº”çš„å•è¯</span></span><br><span class="line">    words.append(word) </span><br><span class="line">print(<span class="string">" "</span>.join(words))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">s influence clinton decision de gaulle is himself sappho s iv one family banquet was made published by paul &lt;unk&gt; and by a persuaded to prevent arcane of animate poverty based at copernicus bachelor in search services and in a cruise corps references eds the robin series july four one nine zero eight summer gutenberg one nine six four births one nine two eight deaths timeline of this method by the fourth amendment the german ioc known for his &lt;unk&gt; from &lt;unk&gt; one eight nine eight one seven eight nine management was established in one nine seven zero they had</span><br></pre></td></tr></table></figure><p>In [42]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.randint(50002, (1, 1))</span><br></pre></td></tr></table></figure><p>Out[42]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([[11293]])</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RNN </tag>
            
            <tag> Linear </tag>
            
            <tag> Gradient Clipping </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SQuAD-BiDAF</title>
      <link href="/2020/04/17/SQuAD-BiDAF/"/>
      <url>/2020/04/17/SQuAD-BiDAF/</url>
      
        <content type="html"><![CDATA[<p>ä»£ç æ˜¯åœ¨github<a href="https://github.com/galsang/BiDAF-pytorch" target="_blank" rel="noopener">BiDAF-pytorch</a>ä¸Šä¸‹è½½çš„ï¼Œæˆ‘æŠŠä»£ç å¼„æˆäº†ä¸‹é¢jupyter notebookæ ¼å¼ï¼Œä»£ç æ˜¯åœ¨kaggle GPUè·‘çš„ï¼Œ</p><p>æ•°æ®é›†å¦‚æœä¸èƒ½ä¸‹è½½çš„å¯ä»¥åˆ°æˆ‘çš„ç½‘ç›˜ä¸‹è½½ï¼ŒåŒ…æ‹¬æ•°æ®é›†å’Œè®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œæ¯”è¾ƒå¤§ï¼š<a href="https://pan.baidu.com/s/1XCEUG6E2biCdqFyaxIGtBw" target="_blank" rel="noopener">ç™¾åº¦ç½‘ç›˜ä¸‹è½½åœ°å€</a></p><p>æ•´ä¸ªä»£ç è·‘ä¸‹æ¥ï¼Œè®­ç»ƒé›†å¯ä»¥è·‘é€šï¼Œæµ‹è¯•é›†å½“æ—¶è·‘çš„æ—¶å€™kaggleå†…å­˜ä¸å¤Ÿäº†ï¼ŒæŠ¥é”™äº†ï¼Œæœ‰å…´è¶£å¯ä»¥è¯•ä¸‹æœ€ç»ˆçš„æ•ˆæœã€‚</p><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This Python 3 environment comes with many helpful analytics libraries installed</span></span><br><span class="line"><span class="comment"># It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python</span></span><br><span class="line"><span class="comment"># For example, here's several helpful packages to load in </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># linear algebra</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment"># data processing, CSV file I/O (e.g. pd.read_csv)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Input data files are available in the "../input/" directory.</span></span><br><span class="line"><span class="comment"># For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">print(os.listdir(<span class="string">"../input"</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Any results you write to the current directory are saved as output.</span></span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!cp -r /kaggle/input/bidaf-pytorch-master/BiDAF-pytorch-master /kaggle/working</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">os.chdir(&quot;BiDAF-pytorch-master&quot;)</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">os.chdir(&quot;..&quot;)</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">!ls</span><br><span class="line">!pwd</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> copy, json, os</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> gmtime, strftime</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> torchtext <span class="keyword">import</span> data</span><br><span class="line"><span class="keyword">import</span> torchtext</span><br><span class="line"><span class="keyword">from</span> torchtext <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torchtext.vocab <span class="keyword">import</span> GloVe</span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> tensorboardX <span class="keyword">import</span> SummaryWriter</span><br></pre></td></tr></table></figure><h1 id="ä¸€ã€å®šä¹‰åˆå§‹å˜é‡å‚æ•°"><a href="#ä¸€ã€å®šä¹‰åˆå§‹å˜é‡å‚æ•°" class="headerlink" title="ä¸€ã€å®šä¹‰åˆå§‹å˜é‡å‚æ•°"></a>ä¸€ã€å®šä¹‰åˆå§‹å˜é‡å‚æ•°</h1><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æœ‰å…³argparseçš„å®˜æ–¹æ–‡æ¡£æ“ä½œè¯·æŸ¥çœ‹ï¼šhttps://docs.python.org/3/library/argparse.html#module-argparseï¼Œ</span></span><br><span class="line"><span class="comment"># ä¸‹é¢çš„å‚æ•°ä»£ç æ³¨é‡Šï¼Œæˆ‘ä¹Ÿä¸æ˜¯ç‰¹åˆ«æ‡‚ï¼Œä»…ä¾›å‚è€ƒ</span></span><br><span class="line"><span class="comment"># å…³äºparser.add_argument(ï¼‰çš„è¯¦è§£è¯·æŸ¥çœ‹ï¼šhttps://blog.csdn.net/u013177568/article/details/62432761/</span></span><br><span class="line"><span class="comment"># å¯¹äºä¸‹é¢å‡½æ•°add_argument()ç¬¬ä¸€ä¸ªæ˜¯é€‰é¡¹æ˜¯å¿…é¡»å†™çš„å‚æ•°ï¼Œè¯¥å‚æ•°æ¥å—é€‰é¡¹å‚æ•°æˆ–è€…æ˜¯ä½ç½®å‚æ•°ï¼ˆä¸€ä¸²æ–‡ä»¶åï¼‰</span></span><br><span class="line"><span class="comment"># ç¬¬äºŒä¸ªæ˜¯defaulté»˜è®¤å€¼ï¼Œå¦‚æœç¬¬ä¸€ä¸ªé€‰é¡¹å‚æ•°æ²¡æœ‰å•ç‹¬æŒ‡å®šï¼Œé‚£é€‰é¡¹å‚æ•°çš„å€¼å°±æ˜¯é»˜è®¤å€¼</span></span><br><span class="line"><span class="comment"># ç¬¬ä¸‰ä¸ªæ˜¯å‚æ•°æ•°æ®ç±»å‹ï¼Œä»£è¡¨ä½ çš„é€‰é¡¹å‚æ•°å¿…é¡»æ˜¯æ˜¯intè¿˜æ˜¯floatå­—ç¬¦å‹æ•°æ®ã€‚</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_args</span><span class="params">()</span>:</span></span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">'--char-dim'</span>, default=<span class="number">8</span>, type=int)</span><br><span class="line">    <span class="comment"># char-dim é»˜è®¤å€¼æ˜¯8</span></span><br><span class="line">    parser.add_argument(<span class="string">'--char-channel-width'</span>, default=<span class="number">5</span>, type=int)</span><br><span class="line">    <span class="comment"># char-channel-width é»˜è®¤å€¼æ˜¯5 ä»¥ä¸‹ç±»ä¼¼</span></span><br><span class="line">    parser.add_argument(<span class="string">'--char-channel-size'</span>, default=<span class="number">100</span>, type=int)</span><br><span class="line">    parser.add_argument(<span class="string">'--context-threshold'</span>, default=<span class="number">400</span>, type=int)</span><br><span class="line">    parser.add_argument(<span class="string">'--dev-batch-size'</span>, default=<span class="number">100</span>, type=int)</span><br><span class="line">    parser.add_argument(<span class="string">'--dev-file'</span>, default=<span class="string">'dev-v1.1.json'</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'--dropout'</span>, default=<span class="number">0.2</span>, type=float)</span><br><span class="line">    parser.add_argument(<span class="string">'--epoch'</span>, default=<span class="number">12</span>, type=int)</span><br><span class="line">    parser.add_argument(<span class="string">'--exp-decay-rate'</span>, default=<span class="number">0.999</span>, type=float)</span><br><span class="line">    parser.add_argument(<span class="string">'--gpu'</span>, default=<span class="number">0</span>, type=int)</span><br><span class="line">    parser.add_argument(<span class="string">'--hidden-size'</span>, default=<span class="number">100</span>, type=int)</span><br><span class="line">    parser.add_argument(<span class="string">'--learning-rate'</span>, default=<span class="number">0.5</span>, type=float)</span><br><span class="line">    parser.add_argument(<span class="string">'--print-freq'</span>, default=<span class="number">250</span>, type=int)</span><br><span class="line">    parser.add_argument(<span class="string">'--train-batch-size'</span>, default=<span class="number">60</span>, type=int)</span><br><span class="line">    parser.add_argument(<span class="string">'--train-file'</span>, default=<span class="string">'train-v1.1.json'</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'--word-dim'</span>, default=<span class="number">100</span>, type=int)</span><br><span class="line">    args = parser.parse_args(args=[]) </span><br><span class="line"><span class="comment"># .parse_args()æ˜¯å°†ä¹‹å‰æ‰€æœ‰add_argumentå®šä¹‰çš„å‚æ•°åœ¨æ‹¬å·é‡Œè¿›è¡Œèµ‹å€¼ï¼Œæ²¡æœ‰èµ‹å€¼(args=[])ï¼Œå°±è¿”å›å‚æ•°å„è‡ªdefaultçš„é»˜è®¤å€¼ã€‚</span></span><br><span class="line"><span class="comment"># è¿”å›å€¼argsç›¸å½“äºæ˜¯ä¸ªå‚æ•°å‘½åç©ºé—´çš„é›†åˆï¼Œå¯ä»¥è°ƒç”¨ä¸Šé¢ç¬¬ä¸€é¡¹é€‰é¡¹å‚æ•°çš„åå­—ï¼Œå°±å¯ä»¥å¾—åˆ°defaultå€¼äº†ã€‚</span></span><br><span class="line"><span class="comment"># æ¯”å¦‚è°ƒç”¨ä¸Šé¢å‚æ•°æ–¹å¼ï¼šargs.char_dim,args.char_channel_width....é»˜è®¤æƒ…å†µä¸‹ï¼Œä¸­åˆ’çº¿ä¼šè½¬æ¢ä¸ºä¸‹åˆ’çº¿.</span></span><br><span class="line">    <span class="keyword">return</span> args</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">args = parse_args()</span><br></pre></td></tr></table></figure><h1 id="äºŒã€SQuADé—®ç­”æ•°æ®é¢„å¤„ç†"><a href="#äºŒã€SQuADé—®ç­”æ•°æ®é¢„å¤„ç†" class="headerlink" title="äºŒã€SQuADé—®ç­”æ•°æ®é¢„å¤„ç†"></a>äºŒã€SQuADé—®ç­”æ•°æ®é¢„å¤„ç†</h1><h2 id="1ã€æŸ¥çœ‹æ•°æ®é›†ç»“æ„"><a href="#1ã€æŸ¥çœ‹æ•°æ®é›†ç»“æ„" class="headerlink" title="1ã€æŸ¥çœ‹æ•°æ®é›†ç»“æ„"></a>1ã€æŸ¥çœ‹æ•°æ®é›†ç»“æ„</h2><p>SQuADé—®ç­”æ•°æ®ä»‹ç»ï¼š<a href="https://rajpurkar.github.io/SQuAD-explorer/" target="_blank" rel="noopener">https://rajpurkar.github.io/SQuAD-explorer/</a> è¿™ä¸ªæ•°æ®é›†æœ‰ä¸¤ä¸ªæ–‡ä»¶ï¼ŒéªŒè¯é›†å’Œæµ‹è¯•é›†ï¼štrain-v1.1.jsonï¼Œdev-v1.1.json</p><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">'data/squad/dev-v1.1.json'</span>, <span class="string">'r'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">                line = f.readline() <span class="comment"># è¯¥æ–¹æ³•æ¯æ¬¡è¯»å‡ºä¸€è¡Œå†…å®¹</span></span><br><span class="line">                <span class="keyword">if</span> line:</span><br><span class="line">                    print(<span class="string">"type(line)"</span>,type(line)) <span class="comment"># ç›´æ¥æ‰“å°å°±æ˜¯å­—ç¬¦ä¸²æ ¼å¼</span></span><br><span class="line">                    r = json.loads(line)</span><br><span class="line">                    print(<span class="string">"type(r)"</span>,type(r)) <span class="comment"># ä½¿ç”¨json.loadså°†å­—ç¬¦ä¸²è½¬åŒ–ä¸ºå­—å…¸</span></span><br><span class="line">                    print(r)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            f.close()</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æ•°æ®æ¶æ„å¦‚ä¸‹</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"data"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">"title"</span>: <span class="string">"Super_Bowl_50"</span>, <span class="comment"># ç¬¬ä¸€ä¸ªä¸»é¢˜</span></span><br><span class="line">            <span class="string">"paragraphs"</span>: [</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="string">"context"</span>: <span class="string">" numerals 50......."</span>, <span class="comment"># æ¯ä¸ªä¸»é¢˜ä¼šæœ‰å¾ˆå¤šcontextçŸ­æ–‡,è¿™é‡Œåªåˆ—å‡ºä¸€ä¸ª</span></span><br><span class="line">                    <span class="string">"qas"</span>: [  <span class="comment"># è¿™ä¸ªåˆ—è¡¨é‡Œæ”¾é—®é¢˜å’Œç­”æ¡ˆçš„ä½ç½®ï¼Œæ¯ç¯‡contextä¼šæœ‰å¾ˆæœ‰å¾ˆå¤šanswerå’Œquestionï¼Œè¿™é‡Œåªåˆ—å‡ºä¸€ä¸ª</span></span><br><span class="line">                        &#123;</span><br><span class="line">                            <span class="string">"answers"</span>: [  <span class="comment"># ä¸€ä¸ªé—®é¢˜ä¼šæœ‰ä¸‰ä¸ªç­”æ¡ˆï¼Œä¸‰ä¸ªç­”æ¡ˆéƒ½æ˜¯å¯¹çš„ï¼Œåªæ˜¯åœ¨contextä¸åŒæˆ–ç›¸åŒä½ç½®</span></span><br><span class="line">                                &#123;         <span class="comment"># ä¸‹é¢ä¸‰ä¸ªç­”æ¡ˆéƒ½åœ¨ç›¸åŒçš„ä½ç½®</span></span><br><span class="line">                                    <span class="string">"answer_start"</span>: <span class="number">177</span>,  <span class="comment"># ç­”æ¡ˆåœ¨æ–‡ä¸­çš„èµ·å§‹ä½ç½®æ˜¯ç¬¬177çš„å­—ç¬¦ã€‚</span></span><br><span class="line">                                    <span class="string">"text"</span>: <span class="string">"Denver Broncos"</span></span><br><span class="line">                                &#125;,</span><br><span class="line">                                &#123;</span><br><span class="line">                                    <span class="string">"answer_start"</span>: <span class="number">177</span>,</span><br><span class="line">                                    <span class="string">"text"</span>: <span class="string">"Denver Broncos"</span></span><br><span class="line">                                &#125;,</span><br><span class="line">                                &#123;</span><br><span class="line">                                    <span class="string">"answer_start"</span>: <span class="number">177</span>,</span><br><span class="line">                                    <span class="string">"text"</span>: <span class="string">"Denver Broncos"</span></span><br><span class="line">                                &#125;</span><br><span class="line">                            ],</span><br><span class="line">                            <span class="string">"question"</span>: <span class="string">"Which NFL team represented the AFC at Super Bowl 50?"</span>,</span><br><span class="line">                            <span class="string">"id"</span>: <span class="string">"56be4db0acb8001400a502ec"</span></span><br><span class="line">                        &#125;</span><br><span class="line"></span><br><span class="line">                    ]</span><br><span class="line">                &#125;</span><br><span class="line">                </span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        </span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">"title"</span>: <span class="string">"Warsaw"</span>, <span class="comment"># ç¬¬äºŒä¸ªä¸»é¢˜</span></span><br><span class="line">            <span class="string">"paragraphs"</span>:   </span><br><span class="line">        &#125;,</span><br><span class="line">        </span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">"title"</span>: <span class="string">"Normans"</span>, <span class="comment"># ç¬¬ä¸‰ä¸ªä¸»é¢˜</span></span><br><span class="line">            <span class="string">"paragraphs"</span>: </span><br><span class="line">        &#125;,</span><br><span class="line">        </span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">"title"</span>: <span class="string">"Nikola_Tesla"</span>, <span class="comment"># ç¬¬å››ä¸ªä¸»é¢˜</span></span><br><span class="line">            <span class="string">"paragraphs"</span>: </span><br><span class="line">        &#125;,</span><br><span class="line">        ........... <span class="comment"># è¿˜æœ‰å¾ˆå¤š</span></span><br><span class="line">        </span><br><span class="line">    ],</span><br><span class="line">    <span class="string">"version"</span>: <span class="string">"1.1"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2ã€å®šä¹‰åˆ†è¯æ–¹æ³•"><a href="#2ã€å®šä¹‰åˆ†è¯æ–¹æ³•" class="headerlink" title="2ã€å®šä¹‰åˆ†è¯æ–¹æ³•"></a>2ã€å®šä¹‰åˆ†è¯æ–¹æ³•</h2><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">word_tokenize</span><span class="params">(tokens)</span>:</span></span><br><span class="line">    tokens = [token.replace(<span class="string">"''"</span>, <span class="string">'"'</span>).replace(<span class="string">"``"</span>, <span class="string">'"'</span>) <span class="keyword">for</span> token <span class="keyword">in</span> nltk.word_tokenize(tokens)]</span><br><span class="line">    <span class="comment"># nltk.word_tokenize(tokens)åˆ†è¯ï¼Œreplaceè§„èŒƒåŒ–å¼•å·ï¼Œæ–¹ä¾¿åé¢å¤„ç†</span></span><br><span class="line">    <span class="keyword">return</span> tokens</span><br></pre></td></tr></table></figure><h2 id="3ã€æ¸…æ´—æ•°æ®ï¼Œå¹¶ç”Ÿæˆæ•°æ®è¿­ä»£å™¨"><a href="#3ã€æ¸…æ´—æ•°æ®ï¼Œå¹¶ç”Ÿæˆæ•°æ®è¿­ä»£å™¨" class="headerlink" title="3ã€æ¸…æ´—æ•°æ®ï¼Œå¹¶ç”Ÿæˆæ•°æ®è¿­ä»£å™¨"></a>3ã€æ¸…æ´—æ•°æ®ï¼Œå¹¶ç”Ÿæˆæ•°æ®è¿­ä»£å™¨</h2><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQuAD</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, args)</span>:</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># ä»¥ä¸‹å®šå¥½ä¸­é—´è¾“å‡ºç¼“å­˜æ–‡ä»¶çš„è·¯å¾„</span></span><br><span class="line">        path = <span class="string">'data/squad'</span> </span><br><span class="line">        dataset_path = path + <span class="string">'/torch_text/'</span> </span><br><span class="line">        train_examples_path = dataset_path + <span class="string">'train_examples.pt'</span></span><br><span class="line">        dev_examples_path = dataset_path + <span class="string">'dev_examples.pt'</span></span><br><span class="line"></span><br><span class="line">        print(<span class="string">"preprocessing data files..."</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">f'<span class="subst">&#123;path&#125;</span>/<span class="subst">&#123;args.train_file&#125;</span>l'</span>):</span><br><span class="line">            <span class="comment"># å­—ç¬¦ä¸²å‰ä»¥få¼€å¤´è¡¨ç¤ºåœ¨å­—ç¬¦ä¸²å†…æ”¯æŒå¤§æ‹¬å·å†…çš„ python è¡¨è¾¾å¼</span></span><br><span class="line">            <span class="comment"># args.train_file = 'train-v1.1.json'</span></span><br><span class="line">            print(<span class="string">f'<span class="subst">&#123;path&#125;</span>/<span class="subst">&#123;args.train_file&#125;</span>'</span>)</span><br><span class="line">            self.preprocess_file(<span class="string">f'<span class="subst">&#123;path&#125;</span>/<span class="subst">&#123;args.train_file&#125;</span>'</span>)  </span><br><span class="line">            <span class="comment"># preprocess_fileä¸‹é¢å‡½æ•°æœ‰å®šä¹‰ï¼Œå®Œæˆæ–‡ä»¶çš„é¢„å¤„ç†</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">f'<span class="subst">&#123;path&#125;</span>/<span class="subst">&#123;args.dev_file&#125;</span>l'</span>):</span><br><span class="line">            <span class="comment"># args.dev_file = 'dev-v1.1.json'</span></span><br><span class="line">            self.preprocess_file(<span class="string">f'<span class="subst">&#123;path&#125;</span>/<span class="subst">&#123;args.dev_file&#125;</span>'</span>)</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># ä¸‹é¢æ˜¯ç”¨torchtextå¤„ç†æ•°æ®çš„æ­¥éª¤çœ‹ä¸æ‡‚äº†ï¼Œæœ‰çŸ¥é“çš„å¯ä»¥äº¤æµä¸‹   </span></span><br><span class="line">        self.RAW = data.RawField()<span class="comment"># è¿™ä¸ªæ˜¯å®Œå…¨ç©ºç™½çš„fieldï¼Œæ„å‘³ç€ä¸ç»è¿‡ä»»ä½•å¤„ç†</span></span><br><span class="line">        <span class="comment"># explicit declaration for torchtext compatibility</span></span><br><span class="line">        self.RAW.is_target = <span class="literal">False</span></span><br><span class="line">        self.CHAR_NESTING = data.Field(batch_first=<span class="literal">True</span>, tokenize=list, lower=<span class="literal">True</span>)</span><br><span class="line">        self.CHAR = data.NestedField(self.CHAR_NESTING, tokenize=word_tokenize)</span><br><span class="line">        self.WORD = data.Field(batch_first=<span class="literal">True</span>, tokenize=word_tokenize, lower=<span class="literal">True</span>, include_lengths=<span class="literal">True</span>)</span><br><span class="line">        self.LABEL = data.Field(sequential=<span class="literal">False</span>, unk_token=<span class="literal">None</span>, use_vocab=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        dict_fields = &#123;<span class="string">'id'</span>: (<span class="string">'id'</span>, self.RAW),</span><br><span class="line">                       <span class="string">'s_idx'</span>: (<span class="string">'s_idx'</span>, self.LABEL),</span><br><span class="line">                       <span class="string">'e_idx'</span>: (<span class="string">'e_idx'</span>, self.LABEL),</span><br><span class="line">                       <span class="string">'context'</span>: [(<span class="string">'c_word'</span>, self.WORD), (<span class="string">'c_char'</span>, self.CHAR)],</span><br><span class="line">                       <span class="string">'question'</span>: [(<span class="string">'q_word'</span>, self.WORD), (<span class="string">'q_char'</span>, self.CHAR)]&#125;</span><br><span class="line"></span><br><span class="line">        list_fields = [(<span class="string">'id'</span>, self.RAW), (<span class="string">'s_idx'</span>, self.LABEL), (<span class="string">'e_idx'</span>, self.LABEL),</span><br><span class="line">                       (<span class="string">'c_word'</span>, self.WORD), (<span class="string">'c_char'</span>, self.CHAR),</span><br><span class="line">                       (<span class="string">'q_word'</span>, self.WORD), (<span class="string">'q_char'</span>, self.CHAR)]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> os.path.exists(dataset_path):</span><br><span class="line">            print(<span class="string">"loading splits..."</span>)</span><br><span class="line">            train_examples = torch.load(train_examples_path)</span><br><span class="line">            dev_examples = torch.load(dev_examples_path)</span><br><span class="line"></span><br><span class="line">            self.train = data.Dataset(examples=train_examples, fields=list_fields)</span><br><span class="line">            self.dev = data.Dataset(examples=dev_examples, fields=list_fields)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">"building splits..."</span>)</span><br><span class="line">             <span class="comment"># åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†</span></span><br><span class="line">            self.train, self.dev = data.TabularDataset.splits(</span><br><span class="line">                path=path,</span><br><span class="line">                train=<span class="string">f'<span class="subst">&#123;args.train_file&#125;</span>l'</span>,</span><br><span class="line">                validation=<span class="string">f'<span class="subst">&#123;args.dev_file&#125;</span>l'</span>,</span><br><span class="line">                format=<span class="string">'json'</span>,</span><br><span class="line">                fields=dict_fields)</span><br><span class="line"></span><br><span class="line">            os.makedirs(dataset_path)</span><br><span class="line">            torch.save(self.train.examples, train_examples_path)</span><br><span class="line">            torch.save(self.dev.examples, dev_examples_path)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#cut too long context in the training set for efficiency.</span></span><br><span class="line">        <span class="keyword">if</span> args.context_threshold &gt; <span class="number">0</span>:</span><br><span class="line">            self.train.examples = [e <span class="keyword">for</span> e <span class="keyword">in</span> self.train.examples <span class="keyword">if</span> len(e.c_word) &lt;= args.context_threshold]</span><br><span class="line"></span><br><span class="line">        print(<span class="string">"building vocab..."</span>)</span><br><span class="line">        self.CHAR.build_vocab(self.train, self.dev) <span class="comment"># å­—ç¬¦å‘é‡æ²¡æœ‰è®¾ç½®vector</span></span><br><span class="line">        self.WORD.build_vocab(self.train, self.dev, vectors=GloVe(name=<span class="string">'6B'</span>, dim=args.word_dim))</span><br><span class="line">        <span class="comment"># åŠ è½½Gloveå‘é‡ï¼Œargs.word_dim = 100</span></span><br><span class="line"></span><br><span class="line">        print(<span class="string">"building iterators..."</span>)</span><br><span class="line">        device = torch.device(<span class="string">f"cuda:<span class="subst">&#123;args.gpu&#125;</span>"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line">        <span class="comment"># ç”Ÿæˆè¿­ä»£å™¨</span></span><br><span class="line">        self.train_iter, self.dev_iter = \</span><br><span class="line">            data.BucketIterator.splits((self.train, self.dev),</span><br><span class="line">                                       batch_sizes=[args.train_batch_size, args.dev_batch_size],</span><br><span class="line">                                       device=device,</span><br><span class="line">                                       sort_key=<span class="keyword">lambda</span> x: len(x.c_word))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">preprocess_file</span><span class="params">(self,path)</span>:</span></span><br><span class="line">        dump = []</span><br><span class="line">        abnormals = [<span class="string">' '</span>, <span class="string">'\n'</span>, <span class="string">'\u3000'</span>, <span class="string">'\u202f'</span>, <span class="string">'\u2009'</span>]</span><br><span class="line">        <span class="comment"># ç©ºç™½æ— æ•ˆå­—ç¬¦åˆ—è¡¨</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> open(path, <span class="string">'r'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            data = json.load(f) <span class="comment"># ç›´æ¥æ–‡ä»¶å¥æŸ„è½¬åŒ–ä¸ºå­—å…¸</span></span><br><span class="line">            data = data[<span class="string">'data'</span>] <span class="comment"># è¿”å›å€¼dataæ˜¯ä¸ªåˆ—è¡¨ï¼Œå­—å…¸æ˜¯åˆ—è¡¨çš„å…ƒç´ </span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> article <span class="keyword">in</span> data:</span><br><span class="line">                <span class="comment"># æ¯ä¸ªarticleæ˜¯ä¸€ä¸ªå­—å…¸ï¼Œä¸€ä¸ªå­—å…¸åŒ…å«ä¸€ä¸ªtitleçš„ä¿¡æ¯</span></span><br><span class="line">                <span class="keyword">for</span> paragraph <span class="keyword">in</span> article[<span class="string">'paragraphs'</span>]:</span><br><span class="line">                    <span class="comment"># æ¯ä¸ªparagraphæ˜¯ä¸€ä¸ªå­—å…¸ï¼Œä¸€ä¸ªå­—å…¸é‡Œæœ‰ä¸€ä¸ªcontextå’Œqasçš„ä¿¡æ¯ï¼Œqasæ˜¯é—®é¢˜å’Œç­”æ¡ˆã€‚</span></span><br><span class="line">                    context = paragraph[<span class="string">'context'</span>]</span><br><span class="line">                    <span class="comment"># contextçš„å†…å®¹ï¼Œæ˜¯å­—ç¬¦ä¸²ï¼Œå¦‚ï¼š" numerals 50............."</span></span><br><span class="line">                    tokens = word_tokenize(context) <span class="comment"># å¯¹contextè¿›è¡Œåˆ†è¯</span></span><br><span class="line">                    <span class="keyword">for</span> qa <span class="keyword">in</span> paragraph[<span class="string">'qas'</span>]:</span><br><span class="line">                        <span class="comment"># æ¯ä¸ªqaæ˜¯ä¸€ä¸ªå­—å…¸ï¼Œä¸€ä¸ªå­—å…¸åŒ…å«ä¸€å¯¹answerså’Œquestionçš„ä¿¡æ¯</span></span><br><span class="line">                        id = qa[<span class="string">'id'</span>]</span><br><span class="line">                        <span class="comment"># å–å‡ºè¿™å¯¹answerså’Œquestionçš„idä¿¡æ¯ï¼Œå¦‚ï¼š"56be4db0acb8001400a502ec"</span></span><br><span class="line">                        question = qa[<span class="string">'question'</span>]</span><br><span class="line">                        <span class="comment"># å–å‡ºquestionï¼Œå¦‚ï¼š"Which NFL team represented the AFC at Super Bowl 50?"</span></span><br><span class="line">                        <span class="keyword">for</span> ans <span class="keyword">in</span> qa[<span class="string">'answers'</span>]:</span><br><span class="line">                            <span class="comment"># ansä¸ºæ¯ä¸ªç­”æ¡ˆï¼Œå…±æœ‰ä¸‰ä¸ªæ ‡å‡†ç­”æ¡ˆï¼Œå¯ä»¥ç›¸åŒï¼Œå¯ä»¥ä¸åŒï¼Œç»Ÿä¸€ä¸º3ä¸ªã€‚</span></span><br><span class="line">                            answer = ans[<span class="string">'text'</span>]</span><br><span class="line">                            <span class="comment"># é—®é¢˜çš„æ¯ä¸ªå›ç­”ï¼Œå¦‚ï¼š"Denver Broncos"</span></span><br><span class="line">                            s_idx = ans[<span class="string">'answer_start'</span>]</span><br><span class="line">                            <span class="comment"># æ¯ä¸ªå›ç­”çš„startä½ç½®ï¼Œæ•°å€¼ä»£è¡¨contextä¸­ç¬¬å‡ ä¸ªå­—ç¬¦ï¼Œå¦‚ï¼š177</span></span><br><span class="line">                            e_idx = s_idx + len(answer)</span><br><span class="line">                            <span class="comment"># æ¯ä¸ªå›ç­”çš„endä½ç½®</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                            <span class="comment"># ä¸‹é¢é‡æ–°æ›´æ–°å­—ç¬¦çš„èµ·å§‹ä½ç½®ï¼Œä½¿ç”¨å­—ç¬¦è®¡ç®—ä½ç½®æ”¹ä¸ºä½¿ç”¨å•è¯è®¡ç®—ä½ç½®</span></span><br><span class="line">                            <span class="comment"># è¯·çœ‹ä¸‹é¢å•å…ƒæ ¼çš„ç¤ºä¾‹è¾“å‡ºæœ‰åŠ©ç†è§£ã€‚</span></span><br><span class="line">                            l = <span class="number">0</span></span><br><span class="line">                            s_found = <span class="literal">False</span></span><br><span class="line">                            <span class="keyword">for</span> i, t <span class="keyword">in</span> enumerate(tokens):</span><br><span class="line">                                <span class="comment"># å¾ªç¯tæ¬¡ï¼Œtä¸ºåˆ†è¯åçš„å•è¯æ•°é‡</span></span><br><span class="line">                                <span class="keyword">while</span> l &lt; len(context):</span><br><span class="line">                                    <span class="keyword">if</span> context[l] <span class="keyword">in</span> abnormals:</span><br><span class="line">                                        <span class="comment"># contextä¸­æœ‰ç©ºç™½æ— æ•ˆå­—ç¬¦ï¼Œå°±è®¡æ•°</span></span><br><span class="line">                                        l += <span class="number">1</span></span><br><span class="line">                                    <span class="keyword">else</span>:    <span class="comment"># ä¸€ç¢°åˆ°ä¸æ˜¯ç©ºç™½å­—ç¬¦çš„å°±break</span></span><br><span class="line">                                        <span class="keyword">break</span></span><br><span class="line">                                <span class="comment"># exceptional cases</span></span><br><span class="line">                                <span class="keyword">if</span> t[<span class="number">0</span>] == <span class="string">'"'</span> <span class="keyword">and</span> context[l:l + <span class="number">2</span>] == <span class="string">'\'\''</span>:</span><br><span class="line">                                    <span class="comment"># ä¸“é—¨è®¡ç®—context=''an è¿™ç§é•¿åº¦ï¼Œè¿™ä¸ªé•¿åº¦ä¸º4</span></span><br><span class="line">                                    t = <span class="string">'\'\''</span> + t[<span class="number">1</span>:] </span><br><span class="line">                                <span class="keyword">elif</span> t == <span class="string">'"'</span> <span class="keyword">and</span> context[l:l + <span class="number">2</span>] == <span class="string">'\'\''</span>:</span><br><span class="line">                                    <span class="comment"># ä¸“é—¨è®¡ç®—context='' è¿™ç§é•¿åº¦</span></span><br><span class="line">                                    <span class="comment"># ä¸Šé¢t[0] == '"'è¡¨è¾¾å¼åŒ…å«äº†è¿™ç§ï¼Œæ‰€ä»¥æˆ‘è®¤ä¸ºè¿™ä¸ªè¡¨è¾¾å¼æ²¡ç”¨ä¸Š</span></span><br><span class="line">                                    t = <span class="string">'\'\''</span></span><br><span class="line"></span><br><span class="line">                                l += len(t)</span><br><span class="line">                                <span class="keyword">if</span> l &gt; s_idx <span class="keyword">and</span> s_found == <span class="literal">False</span>:</span><br><span class="line">                                    <span class="comment"># åªè¦è®¡æ•°è¶…è¿‡èµ·å§‹ä½ç½®å€¼ï¼Œè¿™ä¸ªå•è¯å°±æ˜¯startçš„å•è¯</span></span><br><span class="line">                                    s_idx = i</span><br><span class="line">                                    s_found = <span class="literal">True</span></span><br><span class="line">                                <span class="keyword">if</span> l &gt;= e_idx:</span><br><span class="line">                                    <span class="comment"># è¿™é‡Œä¸å‡ºé”™çš„è¯ï¼Œç­‰äºe_idxå°±æ˜¯endçš„å•è¯</span></span><br><span class="line">                                    e_idx = i</span><br><span class="line">                                    <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">                            <span class="comment"># è¿™é‡ŒæŠŠä¸‰ä¸ªansweråˆ†å¼€ï¼Œæ¯ä¸ªansweréƒ½æ”¾è¿›å­—å…¸ä¸­,å¹¶ä½œä¸ºä¸€ä¸ªæ ·æœ¬</span></span><br><span class="line">                            dump.append(dict([(<span class="string">'id'</span>, id),</span><br><span class="line">                                              (<span class="string">'context'</span>, context),</span><br><span class="line">                                              (<span class="string">'question'</span>, question),</span><br><span class="line">                                              (<span class="string">'answer'</span>, answer),</span><br><span class="line">                                              (<span class="string">'s_idx'</span>, s_idx),</span><br><span class="line">                                              (<span class="string">'e_idx'</span>, e_idx)]))</span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">f'<span class="subst">&#123;path&#125;</span>l'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> dump:</span><br><span class="line">                <span class="comment"># lineä¸ºå­—å…¸ï¼Œä¸€ä¸ªæ ·æœ¬å­˜å‚¨</span></span><br><span class="line">                json.dump(line, f)</span><br><span class="line">                <span class="comment">#dumpï¼šå°†dictç±»å‹è½¬æ¢ä¸ºjsonå­—ç¬¦ä¸²æ ¼å¼ï¼Œå†™å…¥åˆ°æ–‡ä»¶</span></span><br><span class="line">                print(<span class="string">''</span>, file=f) <span class="comment"># è¿™é‡Œprintçš„ä½œç”¨å°±æ˜¯æ¢è¡Œç”¨çš„ã€‚</span></span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data = SQuAD(args)</span><br></pre></td></tr></table></figure><h3 id="ä¸Šé¢ä¸å¤ªæ˜ç™½çš„ä¸¾ä¾‹å­"><a href="#ä¸Šé¢ä¸å¤ªæ˜ç™½çš„ä¸¾ä¾‹å­" class="headerlink" title="ä¸Šé¢ä¸å¤ªæ˜ç™½çš„ä¸¾ä¾‹å­"></a>ä¸Šé¢ä¸å¤ªæ˜ç™½çš„ä¸¾ä¾‹å­</h3><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ä¸¾ä¾‹å­</span></span><br><span class="line">a = <span class="string">" \u2009\n\u3000Super Bowl 50 was ''an'' American football     \u3000game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24\u201310 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50."</span></span><br><span class="line">tokens = word_tokenize(a)</span><br><span class="line">print(nltk.word_tokenize(a)) <span class="comment"># æ‰€æœ‰çš„â€œ\u2009â€ï¼Œâ€œ\nâ€ï¼Œâ€œ\u3000â€ç­‰ç©ºç™½å­—ç¬¦éƒ½å»æ‰äº†</span></span><br><span class="line">print(<span class="string">"----"</span>*<span class="number">20</span>)</span><br><span class="line">print(tokens)</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># </span></span><br><span class="line">print(a[<span class="number">0</span>]) <span class="comment"># ç©ºç™½å­—ç¬¦æ‰“å°ä¸å‡ºæ¥</span></span><br><span class="line">print(a[<span class="number">1</span>]) <span class="comment"># ç©ºç™½å­—ç¬¦æ‰“å°ä¸å‡ºæ¥</span></span><br><span class="line">print(a[<span class="number">2</span>]) <span class="comment"># ç©ºç™½å­—ç¬¦æ‰“å°ä¸å‡ºæ¥</span></span><br><span class="line">print(a[<span class="number">3</span>]) <span class="comment"># ç©ºç™½å­—ç¬¦æ‰“å°ä¸å‡ºæ¥</span></span><br><span class="line">print(a[<span class="number">4</span>]) </span><br><span class="line">print(a[<span class="number">5</span>])</span><br><span class="line">a[<span class="number">1</span>]</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ä¸‹é¢ç‰¹åˆ«æ³¨æ„</span></span><br><span class="line">print(tokens[<span class="number">4</span>][<span class="number">0</span>]== <span class="string">'"'</span>) <span class="comment"># è™½ç„¶åˆ‡åˆ†åçœ‹èµ·æ¥æ˜¯"''"ï¼Œä½†å®é™…ä¸Šæ˜¯'"'</span></span><br><span class="line">print(tokens[<span class="number">4</span>][<span class="number">0</span>]== <span class="string">"''"</span>) </span><br><span class="line">print(tokens[<span class="number">5</span>]== <span class="string">'"'</span>)</span><br><span class="line">print(len(<span class="string">'"'</span>)) <span class="comment"># è¿™ç§é•¿åº¦ä¸º1</span></span><br><span class="line">print(len(<span class="string">"''"</span>)) <span class="comment"># è¿™ç§é•¿åº¦ä¸º2</span></span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æŸ¥çœ‹è¾“å‡ºç†è§£</span></span><br><span class="line">s_idx = <span class="number">177</span></span><br><span class="line">e_idx = s_idx + len(<span class="string">"Denver Broncos"</span>)</span><br><span class="line">l=<span class="number">0</span></span><br><span class="line">context = <span class="string">" \u2009\n\u3000Super Bowl 50 was ''an'' American football     \u3000game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24\u201310 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50."</span></span><br><span class="line">tokens = word_tokenize(context)</span><br><span class="line">abnormals = [<span class="string">' '</span>, <span class="string">'\n'</span>, <span class="string">'\u3000'</span>, <span class="string">'\u202f'</span>, <span class="string">'\u2009'</span>]</span><br><span class="line">s_found = <span class="literal">False</span></span><br><span class="line"><span class="keyword">for</span> i, t <span class="keyword">in</span> enumerate(tokens):</span><br><span class="line">    print(<span class="string">"t="</span>,t)</span><br><span class="line">    <span class="keyword">while</span> l &lt; len(context):</span><br><span class="line">        <span class="keyword">if</span> context[l] <span class="keyword">in</span> abnormals:</span><br><span class="line">            l += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    print(<span class="string">"l"</span>,l)</span><br><span class="line">    <span class="comment"># exceptional cases</span></span><br><span class="line">    <span class="keyword">if</span> t[<span class="number">0</span>] == <span class="string">'"'</span> <span class="keyword">and</span> context[l:l + <span class="number">2</span>] == <span class="string">'\'\''</span>:</span><br><span class="line">        print(<span class="string">"1111111111111111111"</span>)</span><br><span class="line">        print(t)</span><br><span class="line">        print(t[<span class="number">1</span>:])</span><br><span class="line">        t = <span class="string">'\'\''</span> + t[<span class="number">1</span>:]</span><br><span class="line">        print(t)</span><br><span class="line">    <span class="keyword">elif</span> t == <span class="string">'"'</span> <span class="keyword">and</span> context[l:l + <span class="number">2</span>] == <span class="string">'\'\''</span>:</span><br><span class="line">        <span class="comment"># çœ‹è¾“å‡ºç»“æœï¼Œè¿™ä¸ªè¡¨è¾¾å¼æ²¡æœ‰ç”¨åˆ°</span></span><br><span class="line">        print(<span class="string">"22222222222222222222"</span>)</span><br><span class="line">        print(t)</span><br><span class="line">        t = <span class="string">'\'\''</span></span><br><span class="line">    print(<span class="string">"len(t)"</span>,len(t))</span><br><span class="line">    l += len(t)</span><br><span class="line">    print(<span class="string">"l"</span>,l)</span><br><span class="line">    <span class="keyword">if</span> l &gt; s_idx <span class="keyword">and</span> s_found == <span class="literal">False</span>:</span><br><span class="line">        s_idx = i</span><br><span class="line">        print(<span class="string">"s_idx"</span>,s_idx)</span><br><span class="line">        s_found = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">if</span> l &gt;= e_idx:</span><br><span class="line">        e_idx = i</span><br><span class="line">        print(<span class="string">"e_idx"</span>,e_idx)</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">batch = next(iter(data.train_iter)) <span class="comment">#ä¸€ä¸ªbatchçš„ä¿¡æ¯</span></span><br><span class="line">print(batch)</span><br><span class="line"><span class="comment"># è®­ç»ƒé›†çš„batch_sizes=60</span></span><br><span class="line"><span class="comment"># batch.c_word = 60x293ï¼Œ293æ˜¯60ä¸ªæ ·æœ¬ä¸­æœ€é•¿æ ·æœ¬tokençš„å•è¯æ•°</span></span><br><span class="line"><span class="comment"># batch.c_char = 60x293x25ï¼Œ25æ˜¯æŸä¸ªå•è¯å­—ç¬¦çš„æœ€å¤§çš„æ•°é‡</span></span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(batch.q_word)</span><br><span class="line">print(batch.q_char[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ä¸‹é¢ä¸ºargsæ–°å¢å‚æ•°ï¼Œå¹¶èµ‹å€¼</span></span><br><span class="line"><span class="comment"># hasattr() getattr() setattr() å‡½æ•°ä½¿ç”¨æ–¹æ³•è¯¦è§£https://www.cnblogs.com/cenyu/p/5713686.html</span></span><br><span class="line">setattr(args, <span class="string">'char_vocab_size'</span>, len(data.CHAR.vocab)) <span class="comment"># è®¾ç½®å±æ€§args.char_vocab_sizeçš„å€¼ = len(data.CHAR.vocab)</span></span><br><span class="line">setattr(args, <span class="string">'word_vocab_size'</span>, len(data.WORD.vocab))</span><br><span class="line">setattr(args, <span class="string">'dataset_file'</span>, <span class="string">f'data/squad/<span class="subst">&#123;args.dev_file&#125;</span>'</span>)</span><br><span class="line">setattr(args, <span class="string">'prediction_file'</span>, <span class="string">f'prediction<span class="subst">&#123;args.gpu&#125;</span>.out'</span>)</span><br><span class="line">setattr(args, <span class="string">'model_time'</span>, strftime(<span class="string">'%H:%M:%S'</span>, gmtime())) <span class="comment"># æ—¶é—´</span></span><br><span class="line">print(<span class="string">'data loading complete!'</span>)</span><br></pre></td></tr></table></figure><h2 id="BIDAF"><a href="#BIDAF" class="headerlink" title="BIDAF"></a>BIDAF</h2><p><img src="https://s1.ax1x.com/2020/06/09/t4C2yd.jpg" alt="avatar"></p><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LSTM</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_size, hidden_size, batch_first=False, num_layers=<span class="number">1</span>, bidirectional=False, dropout=<span class="number">0.2</span>)</span>:</span></span><br><span class="line">        <span class="comment"># input_size=args.hidden_size * 2 = 200,</span></span><br><span class="line">        <span class="comment"># hidden_size=args.hidden_size = 100,</span></span><br><span class="line">        <span class="comment"># bidirectional=True,</span></span><br><span class="line">        <span class="comment"># batch_first=True, </span></span><br><span class="line">        <span class="comment"># dropout=args.dropout = 0.2</span></span><br><span class="line">        super(LSTM, self).__init__()</span><br><span class="line">        self.rnn = nn.LSTM(input_size=input_size,</span><br><span class="line">                           hidden_size=hidden_size,</span><br><span class="line">                           num_layers=num_layers,</span><br><span class="line">                           bidirectional=bidirectional,</span><br><span class="line">                           batch_first=batch_first)</span><br><span class="line">        self.reset_params() <span class="comment"># é‡ç½®å‚æ•°</span></span><br><span class="line">        self.dropout = nn.Dropout(p=dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reset_params</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.rnn.num_layers):</span><br><span class="line">            nn.init.orthogonal_(getattr(self.rnn, <span class="string">f'weight_hh_l<span class="subst">&#123;i&#125;</span>'</span>)) <span class="comment"># hidden-hidden weights</span></span><br><span class="line">            <span class="comment"># weight_hh_l&#123;i&#125;ã€weight_ih_l&#123;i&#125;ã€bias_hh_l&#123;i&#125;ã€bias_ih_l&#123;i&#125; éƒ½æ˜¯nn.LSTMæºç é‡Œçš„å‚æ•°</span></span><br><span class="line">            <span class="comment"># getattrå–å‡ºæºç é‡Œå‚æ•°çš„å€¼ï¼Œç”¨nn.init.orthogonal_æ­£äº¤è¿›è¡Œé‡æ–°åˆå§‹åŒ–</span></span><br><span class="line">            <span class="comment"># nn.initåˆå§‹åŒ–æ–¹æ³•çœ‹è¿™ä¸ªé“¾æ¥ï¼šhttps://www.aiuai.cn/aifarm613.html</span></span><br><span class="line">            nn.init.kaiming_normal_(getattr(self.rnn, <span class="string">f'weight_ih_l<span class="subst">&#123;i&#125;</span>'</span>)) <span class="comment"># input-hidden weights</span></span><br><span class="line">            nn.init.constant_(getattr(self.rnn, <span class="string">f'bias_hh_l<span class="subst">&#123;i&#125;</span>'</span>), val=<span class="number">0</span>) <span class="comment"># hidden-hidden bias</span></span><br><span class="line">            nn.init.constant_(getattr(self.rnn, <span class="string">f'bias_ih_l<span class="subst">&#123;i&#125;</span>'</span>), val=<span class="number">0</span>) <span class="comment"># input-hidden bias</span></span><br><span class="line">            getattr(self.rnn, <span class="string">f'bias_hh_l<span class="subst">&#123;i&#125;</span>'</span>).chunk(<span class="number">4</span>)[<span class="number">1</span>].fill_(<span class="number">1</span>)</span><br><span class="line">            <span class="comment"># .chunkçœ‹ä¸‹è¿™ä¸ªé“¾æ¥ï¼šhttps://blog.csdn.net/XuM222222/article/details/92380538</span></span><br><span class="line">            <span class="comment"># .fill_(1),ä¸‹åˆ’çº¿ä»£è¡¨ç›´æ¥æ›¿æ¢ï¼Œçœ‹é“¾æ¥ï¼šhttps://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.fill.html</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> self.rnn.bidirectional: <span class="comment"># åŒå‘ï¼Œéœ€è¦åˆå§‹åŒ–åå‘çš„å‚æ•°</span></span><br><span class="line">                nn.init.orthogonal_(getattr(self.rnn, <span class="string">f'weight_hh_l<span class="subst">&#123;i&#125;</span>_reverse'</span>))</span><br><span class="line">                nn.init.kaiming_normal_(getattr(self.rnn, <span class="string">f'weight_ih_l<span class="subst">&#123;i&#125;</span>_reverse'</span>))</span><br><span class="line">                nn.init.constant_(getattr(self.rnn, <span class="string">f'bias_hh_l<span class="subst">&#123;i&#125;</span>_reverse'</span>), val=<span class="number">0</span>)</span><br><span class="line">                nn.init.constant_(getattr(self.rnn, <span class="string">f'bias_ih_l<span class="subst">&#123;i&#125;</span>_reverse'</span>), val=<span class="number">0</span>)</span><br><span class="line">                getattr(self.rnn, <span class="string">f'bias_hh_l<span class="subst">&#123;i&#125;</span>_reverse'</span>).chunk(<span class="number">4</span>)[<span class="number">1</span>].fill_(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="comment"># xæ˜¯ä¸€ä¸ªå…ƒç»„(c, c_lens)</span></span><br><span class="line">        x, x_len = x</span><br><span class="line">        <span class="comment"># x = (batch, seq_len, hidden_size * 2)</span></span><br><span class="line">        <span class="comment"># x_len = (batch) ä¸€ä¸ªbatchä¸­æ‰€æœ‰contextæˆ–questionçš„æ ·æœ¬é•¿åº¦</span></span><br><span class="line">        x = self.dropout(x)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># ä¸‹é¢ä¸€é¡¿æ“ä½œå’Œç¬¬ä¸ƒè¯¾æœºå™¨ç¿»è¯‘çš„ä¸€æ ·ï¼Œ</span></span><br><span class="line">        <span class="comment"># çœ‹ä¸‹è¿™ç¯‡åšå®¢ç†è§£ï¼šhttps://www.cnblogs.com/sbj123456789/p/9834018.html</span></span><br><span class="line">        x_len_sorted, x_idx = torch.sort(x_len, descending=<span class="literal">True</span>)</span><br><span class="line">        x_sorted = x.index_select(dim=<span class="number">0</span>, index=x_idx)</span><br><span class="line">        _, x_ori_idx = torch.sort(x_idx)</span><br><span class="line"></span><br><span class="line">        x_packed = nn.utils.rnn.pack_padded_sequence(x_sorted, x_len_sorted, batch_first=<span class="literal">True</span>)</span><br><span class="line">        x_packed, (h, c) = self.rnn(x_packed)</span><br><span class="line"></span><br><span class="line">        x = nn.utils.rnn.pad_packed_sequence(x_packed, batch_first=<span class="literal">True</span>)[<span class="number">0</span>]</span><br><span class="line">        x = x.index_select(dim=<span class="number">0</span>, index=x_ori_idx)</span><br><span class="line">        h = h.permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>).contiguous().view(<span class="number">-1</span>, h.size(<span class="number">0</span>) * h.size(<span class="number">2</span>)).squeeze()</span><br><span class="line">        h = h.index_select(dim=<span class="number">0</span>, index=x_ori_idx)</span><br><span class="line">        <span class="comment"># x = (batch, seq_len, hidden_size * 2)</span></span><br><span class="line">        <span class="comment"># h = (1, batch, hidden_size * 2) è¿™ä¸ªç»´åº¦ä¸ç”¨ç®¡</span></span><br><span class="line">        <span class="keyword">return</span> x, h</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Linear</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_features, out_features, dropout=<span class="number">0.0</span>)</span>:</span></span><br><span class="line">        super(Linear, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.linear = nn.Linear(in_features=in_features, out_features=out_features)</span><br><span class="line">        <span class="comment"># in_features = hidden_size * 2</span></span><br><span class="line">        <span class="comment"># out_features = hidden_size * 2</span></span><br><span class="line">        <span class="keyword">if</span> dropout &gt; <span class="number">0</span>:</span><br><span class="line">            self.dropout = nn.Dropout(p=dropout)</span><br><span class="line">        self.reset_params()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reset_params</span><span class="params">(self)</span>:</span></span><br><span class="line">        nn.init.kaiming_normal_(self.linear.weight)</span><br><span class="line">        nn.init.constant_(self.linear.bias, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> hasattr(self, <span class="string">'dropout'</span>): <span class="comment"># åˆ¤æ–­selfæœ‰æ²¡æœ‰'dropout'è¿™ä¸ªå‚æ•°ï¼Œè¿”å›boolå€¼</span></span><br><span class="line">            x = self.dropout(x)</span><br><span class="line">        x = self.linear(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">args.char_dim</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># çœ‹è‹±æ–‡è®ºæ–‡æˆ–è¿™ç¯‡åšå®¢ç†è§£æ¨¡å‹ï¼šhttps://blog.csdn.net/u014665013/article/details/79793395</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BiDAF</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, args, pretrained)</span>:</span></span><br><span class="line">        <span class="comment"># pretrained = data.WORD.vocab.vectors = (108777, 100)</span></span><br><span class="line">        super(BiDAF, self).__init__()</span><br><span class="line">        self.args = args</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 1. Character Embedding Layer æ˜¯æ¨¡å‹ç¤ºæ„å›¾å·¦è¾¹çš„å±‚çš„åå­—ï¼Œä»ä¸‹å¾€ä¸Š</span></span><br><span class="line">        <span class="comment"># å­—ç¬¦ç¼–ç å±‚</span></span><br><span class="line">        self.char_emb = nn.Embedding(args.char_vocab_size, args.char_dim, padding_idx=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># args.char_vocab_size = 1307ï¼Œargs.char_dim = 8</span></span><br><span class="line">        nn.init.uniform_(self.char_emb.weight, <span class="number">-0.001</span>, <span class="number">0.001</span>)</span><br><span class="line">        <span class="comment"># åˆå§‹åŒ–æƒé‡</span></span><br><span class="line"></span><br><span class="line">        self.char_conv = nn.Conv2d(<span class="number">1</span>, args.char_channel_size, (args.char_dim, args.char_channel_width))</span><br><span class="line">        <span class="comment"># args.char_channel_size = 100 å·ç§¯æ ¸æ•°é‡ </span></span><br><span class="line">        <span class="comment"># (args.char_dim, args.char_channel_width) = (8,5) è¿‡æ»¤å™¨å¤§å°</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2. Word Embedding Layer</span></span><br><span class="line">        <span class="comment"># å•è¯ç¼–ç å±‚</span></span><br><span class="line">        <span class="comment"># initialize word embedding with GloVe</span></span><br><span class="line">        self.word_emb = nn.Embedding.from_pretrained(pretrained, freeze=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># åˆå§‹åŒ–è¯å‘é‡æƒé‡ï¼Œç”¨çš„Gloveå‘é‡</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># highway network</span></span><br><span class="line">        <span class="keyword">assert</span> self.args.hidden_size * <span class="number">2</span> == (self.args.char_channel_size + self.args.word_dim)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">            setattr(self, <span class="string">f'highway_linear<span class="subst">&#123;i&#125;</span>'</span>,</span><br><span class="line">                    nn.Sequential(Linear(args.hidden_size * <span class="number">2</span>, args.hidden_size * <span class="number">2</span>),</span><br><span class="line">                                  nn.ReLU()))</span><br><span class="line">            <span class="comment"># è®¾ç½®highway_linear0 = nn.Sequential(Linear(args.hidden_size * 2, args.hidden_size * 2)</span></span><br><span class="line">            <span class="comment"># è®¾ç½®highway_linear1 = nn.Sequential(Linear(args.hidden_size * 2, args.hidden_size * 2)</span></span><br><span class="line">            <span class="comment"># args.hidden_size = 100</span></span><br><span class="line">                                </span><br><span class="line">            setattr(self, <span class="string">f'highway_gate<span class="subst">&#123;i&#125;</span>'</span>,</span><br><span class="line">                    nn.Sequential(Linear(args.hidden_size * <span class="number">2</span>, args.hidden_size * <span class="number">2</span>),</span><br><span class="line">                                  nn.Sigmoid()))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3. Contextual Embedding Layer</span></span><br><span class="line">        <span class="comment"># ä¸Šä¸‹æ–‡ï¼Œå’Œç­”æ¡ˆåµŒå…¥å±‚ï¼Œç”¨çš„LSTM</span></span><br><span class="line">        <span class="comment"># ä¸‹é¢LSTMå®šä½åˆ°äº†è‡ªå®šä¹‰çš„class LSTM(nn.Module)ã€‚</span></span><br><span class="line">        self.context_LSTM = LSTM(input_size=args.hidden_size * <span class="number">2</span>,</span><br><span class="line">                                 hidden_size=args.hidden_size,</span><br><span class="line">                                 bidirectional=<span class="literal">True</span>,</span><br><span class="line">                                 batch_first=<span class="literal">True</span>,</span><br><span class="line">                                 dropout=args.dropout) </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 4. Attention Flow Layer</span></span><br><span class="line">        <span class="comment"># æ³¨æ„åŠ›å±‚</span></span><br><span class="line">        self.att_weight_c = Linear(args.hidden_size * <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">        self.att_weight_q = Linear(args.hidden_size * <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">        self.att_weight_cq = Linear(args.hidden_size * <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 5. Modeling Layer</span></span><br><span class="line">        self.modeling_LSTM1 = LSTM(input_size=args.hidden_size * <span class="number">8</span>,</span><br><span class="line">                                   hidden_size=args.hidden_size,</span><br><span class="line">                                   bidirectional=<span class="literal">True</span>,</span><br><span class="line">                                   batch_first=<span class="literal">True</span>,</span><br><span class="line">                                   dropout=args.dropout)</span><br><span class="line"></span><br><span class="line">        self.modeling_LSTM2 = LSTM(input_size=args.hidden_size * <span class="number">2</span>,</span><br><span class="line">                                   hidden_size=args.hidden_size,</span><br><span class="line">                                   bidirectional=<span class="literal">True</span>,</span><br><span class="line">                                   batch_first=<span class="literal">True</span>,</span><br><span class="line">                                   dropout=args.dropout)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 6. Output Layer</span></span><br><span class="line">        self.p1_weight_g = Linear(args.hidden_size * <span class="number">8</span>, <span class="number">1</span>, dropout=args.dropout)</span><br><span class="line">        self.p1_weight_m = Linear(args.hidden_size * <span class="number">2</span>, <span class="number">1</span>, dropout=args.dropout)</span><br><span class="line">        self.p2_weight_g = Linear(args.hidden_size * <span class="number">8</span>, <span class="number">1</span>, dropout=args.dropout)</span><br><span class="line">        self.p2_weight_m = Linear(args.hidden_size * <span class="number">2</span>, <span class="number">1</span>, dropout=args.dropout)</span><br><span class="line"></span><br><span class="line">        self.output_LSTM = LSTM(input_size=args.hidden_size * <span class="number">2</span>,</span><br><span class="line">                                hidden_size=args.hidden_size,</span><br><span class="line">                                bidirectional=<span class="literal">True</span>,</span><br><span class="line">                                batch_first=<span class="literal">True</span>,</span><br><span class="line">                                dropout=args.dropout)</span><br><span class="line"></span><br><span class="line">        self.dropout = nn.Dropout(p=args.dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, batch)</span>:</span></span><br><span class="line">        <span class="comment"># batché‡Œé¢æœ‰'id','s_idx','e_idx', 'c_word','c_char','q_word', 'q_char'æ•°æ®</span></span><br><span class="line">        <span class="comment"># <span class="doctag">TODO:</span> More memory-efficient architecture</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">char_emb_layer</span><span class="params">(x)</span>:</span></span><br><span class="line">            <span class="string">"""</span></span><br><span class="line"><span class="string">            :param x: (batch, seq_len, word_len)</span></span><br><span class="line"><span class="string">            :return: (batch, seq_len, char_channel_size)</span></span><br><span class="line"><span class="string">            """</span></span><br><span class="line">            <span class="comment"># x = (batch_sizes,seq_len,word_len)</span></span><br><span class="line">            batch_size = x.size(<span class="number">0</span>)</span><br><span class="line">            x = self.dropout(self.char_emb(x))</span><br><span class="line">            <span class="comment"># (batch, seq_len, word_len, char_dim)</span></span><br><span class="line">            x = x.view(<span class="number">-1</span>, self.args.char_dim, x.size(<span class="number">2</span>)).unsqueeze(<span class="number">1</span>)</span><br><span class="line">            <span class="comment"># (batch * seq_len, 1, char_dim, word_len) 1æ˜¯è¾“å…¥çš„channelçš„ç»´åº¦</span></span><br><span class="line">            x = self.char_conv(x).squeeze()</span><br><span class="line">            <span class="comment"># (batch * seq_len, char_channel_size, 1, conv_len) -&gt; </span></span><br><span class="line">            <span class="comment"># (batch * seq_len, char_channel_size, conv_len) conv_lenä¸ç”¨ç®¡ï¼Œä¸‹ä¸€æ­¥éƒ½ä¼špoolæ‰</span></span><br><span class="line">            x = F.max_pool1d(x, x.size(<span class="number">2</span>)).squeeze()</span><br><span class="line">            <span class="comment"># (batch * seq_len, char_channel_size, 1) -&gt; (batch * seq_len, char_channel_size)</span></span><br><span class="line">            x = x.view(batch_size, <span class="number">-1</span>, self.args.char_channel_size)</span><br><span class="line">            <span class="comment"># (batch, seq_len, char_channel_size)</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">highway_network</span><span class="params">(x1, x2)</span>:</span></span><br><span class="line">            <span class="string">"""</span></span><br><span class="line"><span class="string">            :param x1: (batch, seq_len, char_channel_size)</span></span><br><span class="line"><span class="string">            :param x2: (batch, seq_len, word_dim)</span></span><br><span class="line"><span class="string">            :return: (batch, seq_len, hidden_size * 2)</span></span><br><span class="line"><span class="string">            """</span></span><br><span class="line">            </span><br><span class="line">            x = torch.cat([x1, x2], dim=<span class="number">-1</span>)</span><br><span class="line">            <span class="comment"># x = (batch, seq_len, char_channel_size + word_dim)</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">                h = getattr(self, <span class="string">f'highway_linear<span class="subst">&#123;i&#125;</span>'</span>)(x) <span class="comment"># è°ƒç”¨Linearçš„forwardæ–¹æ³•</span></span><br><span class="line">                <span class="comment"># h = (batch, seq_len, hidden_size * 2)</span></span><br><span class="line">                g = getattr(self, <span class="string">f'highway_gate<span class="subst">&#123;i&#125;</span>'</span>)(x)</span><br><span class="line">                <span class="comment"># g = (batch, seq_len, hidden_size * 2)</span></span><br><span class="line">                x = g * h + (<span class="number">1</span> - g) * x</span><br><span class="line">            <span class="comment"># (batch, seq_len, hidden_size * 2)</span></span><br><span class="line">            <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">att_flow_layer</span><span class="params">(c, q)</span>:</span></span><br><span class="line">            <span class="string">"""</span></span><br><span class="line"><span class="string">            :param c: (batch, c_len, hidden_size * 2)</span></span><br><span class="line"><span class="string">            :param q: (batch, q_len, hidden_size * 2)</span></span><br><span class="line"><span class="string">            :return: (batch, c_len, q_len)</span></span><br><span class="line"><span class="string">            """</span></span><br><span class="line">            c_len = c.size(<span class="number">1</span>)</span><br><span class="line">            q_len = q.size(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># (batch, c_len, q_len, hidden_size * 2)</span></span><br><span class="line">            <span class="comment">#c_tiled = c.unsqueeze(2).expand(-1, -1, q_len, -1)</span></span><br><span class="line">            <span class="comment"># (batch, c_len, q_len, hidden_size * 2)</span></span><br><span class="line">            <span class="comment">#q_tiled = q.unsqueeze(1).expand(-1, c_len, -1, -1)</span></span><br><span class="line">            <span class="comment"># (batch, c_len, q_len, hidden_size * 2)</span></span><br><span class="line">            <span class="comment">#cq_tiled = c_tiled * q_tiled</span></span><br><span class="line">            <span class="comment">#cq_tiled = c.unsqueeze(2).expand(-1, -1, q_len, -1) * q.unsqueeze(1).expand(-1, c_len, -1, -1)</span></span><br><span class="line"><span class="comment">#        # 4. Attention Flow Layer</span></span><br><span class="line"><span class="comment">#         # æ³¨æ„åŠ›å±‚</span></span><br><span class="line"><span class="comment">#         self.att_weight_c = Linear(args.hidden_size * 2, 1)</span></span><br><span class="line"><span class="comment">#         self.att_weight_q = Linear(args.hidden_size * 2, 1)</span></span><br><span class="line"><span class="comment">#         self.att_weight_cq = Linear(args.hidden_size * 2, 1)</span></span><br><span class="line">            cq = []</span><br><span class="line">            <span class="comment"># 1ã€ç›¸ä¼¼åº¦è®¡ç®—æ–¹å¼ï¼Œçœ‹ä¸‹è¿™ç¯‡åšå®¢ç†è§£ï¼šhttps://blog.csdn.net/u014665013/article/details/79793395</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(q_len):</span><br><span class="line">                qi = q.select(<span class="number">1</span>, i).unsqueeze(<span class="number">1</span>)</span><br><span class="line">                <span class="comment"># (batch, 1, hidden_size * 2)</span></span><br><span class="line">                <span class="comment"># .selectçœ‹è¿™ä¸ªï¼šhttps://blog.csdn.net/hungryof/article/details/51802829</span></span><br><span class="line">                ci = self.att_weight_cq(c * qi).squeeze()</span><br><span class="line">                <span class="comment"># (batch, c_len, 1)</span></span><br><span class="line">                cq.append(ci)</span><br><span class="line">            cq = torch.stack(cq, dim=<span class="number">-1</span>) </span><br><span class="line">            <span class="comment"># (batch, c_len, q_len) cpæ˜¯å…±äº«ç›¸ä¼¼åº¦çŸ©é˜µ</span></span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 2ã€è®¡ç®—å¯¹æ¯ä¸€ä¸ª context word è€Œè¨€å“ªäº› query words å’Œå®ƒæœ€ç›¸å…³ã€‚</span></span><br><span class="line">            <span class="comment"># context-to-query attention(C2Q):</span></span><br><span class="line">            s = self.att_weight_c(c).expand(<span class="number">-1</span>, <span class="number">-1</span>, q_len) + \</span><br><span class="line">                self.att_weight_q(q).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>).expand(<span class="number">-1</span>, c_len, <span class="number">-1</span>) + cq</span><br><span class="line">            <span class="comment"># (batch, c_len, q_len) </span></span><br><span class="line">            a = F.softmax(s, dim=<span class="number">2</span>) </span><br><span class="line">            <span class="comment"># (batch, c_len, q_len)</span></span><br><span class="line">            c2q_att = torch.bmm(a, q) </span><br><span class="line">            <span class="comment"># (batch, c_len, q_len) * (batch, q_len, hidden_size * 2) -&gt; (batch, c_len, hidden_size * 2)</span></span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 3ã€è®¡ç®—å¯¹æ¯ä¸€ä¸ª query word è€Œè¨€å“ªäº› context words å’Œå®ƒæœ€ç›¸å…³</span></span><br><span class="line">            <span class="comment"># query-to-context attention(Q2C):</span></span><br><span class="line">            b = F.softmax(torch.max(s, dim=<span class="number">2</span>)[<span class="number">0</span>], dim=<span class="number">1</span>).unsqueeze(<span class="number">1</span>)</span><br><span class="line">            <span class="comment"># (batch, 1, c_len)</span></span><br><span class="line">            q2c_att = torch.bmm(b, c).squeeze()</span><br><span class="line">            <span class="comment"># (batch, 1, c_len) * (batch, c_len, hidden_size * 2) -&gt; (batch, hidden_size * 2)</span></span><br><span class="line">            q2c_att = q2c_att.unsqueeze(<span class="number">1</span>).expand(<span class="number">-1</span>, c_len, <span class="number">-1</span>)</span><br><span class="line">            <span class="comment"># (batch, c_len, hidden_size * 2) (tiled)</span></span><br><span class="line">            <span class="comment"># q2c_att = torch.stack([q2c_att] * c_len, dim=1)</span></span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 4ã€æœ€åå°†context embeddingå’ŒC2Qã€Q2Cçš„ç»“æœï¼ˆä¸‰ä¸ªçŸ©é˜µï¼‰æ‹¼æ¥èµ·æ¥</span></span><br><span class="line">            x = torch.cat([c, c2q_att, c * c2q_att, c * q2c_att], dim=<span class="number">-1</span>)</span><br><span class="line">            <span class="comment"># (batch, c_len, hidden_size * 8)</span></span><br><span class="line">            <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">output_layer</span><span class="params">(g, m, l)</span>:</span></span><br><span class="line">            <span class="string">"""</span></span><br><span class="line"><span class="string">            :param g: (batch, c_len, hidden_size * 8)</span></span><br><span class="line"><span class="string">            :param m: (batch, c_len ,hidden_size * 2)</span></span><br><span class="line"><span class="string">             #  l = c_lens</span></span><br><span class="line"><span class="string">            :return: p1: (batch, c_len), p2: (batch, c_len)</span></span><br><span class="line"><span class="string">            """</span></span><br><span class="line">            p1 = (self.p1_weight_g(g) + self.p1_weight_m(m)).squeeze()</span><br><span class="line">            <span class="comment"># (batch, c_len)</span></span><br><span class="line">            m2 = self.output_LSTM((m, l))[<span class="number">0</span>]</span><br><span class="line">            <span class="comment"># (batch, c_len, hidden_size * 2)</span></span><br><span class="line">            p2 = (self.p2_weight_g(g) + self.p2_weight_m(m2)).squeeze()</span><br><span class="line">            <span class="comment"># (batch, c_len)</span></span><br><span class="line">            <span class="keyword">return</span> p1, p2</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 1. Character Embedding Layer</span></span><br><span class="line">        <span class="comment"># ä»¤:ä¸€ä¸ªbatchä¸­å•è¯æ•°é‡æœ€å¤šçš„æ ·æœ¬é•¿åº¦ä¸ºseq_len</span></span><br><span class="line">        <span class="comment"># ä»¤:ä¸€ä¸ªbatchä¸­æŸä¸ªå•è¯é•¿åº¦æœ€é•¿çš„å•è¯é•¿åº¦ä¸ºword_len</span></span><br><span class="line">        </span><br><span class="line">        c_char = char_emb_layer(batch.c_char) </span><br><span class="line">        <span class="comment"># batch.c_char = (batch,seq_len,word_len) åä¸¤ä¸ªç»´åº¦å¯¹åº”context</span></span><br><span class="line">        <span class="comment"># c_char = (batch, seq_len, char_channel_size)</span></span><br><span class="line"></span><br><span class="line">        q_char = char_emb_layer(batch.q_char)</span><br><span class="line">        <span class="comment"># batch.c_char = (batch,seq_len,word_len) åä¸¤ä¸ªç»´åº¦å¯¹åº”question</span></span><br><span class="line">        <span class="comment"># c_char = (batch, seq_len, char_channel_size)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 2. Word Embedding Layer</span></span><br><span class="line">        c_word = self.word_emb(batch.c_word[<span class="number">0</span>])</span><br><span class="line">        <span class="comment"># batch.c_word[0] = (batch,seq_len) åä¸€ä¸ªç»´åº¦å¯¹åº”context</span></span><br><span class="line">        <span class="comment"># c_word = (batch, seq_len, word_dim) word_dimæ˜¯Gloveè¯å‘é‡ç»´åº¦</span></span><br><span class="line">        q_word = self.word_emb(batch.q_word[<span class="number">0</span>]) </span><br><span class="line">        <span class="comment"># batch.q_word[0] = (batch,seq_len) åä¸€ä¸ªç»´åº¦å¯¹åº”question</span></span><br><span class="line">        <span class="comment"># q_word = (batch, seq_len, word_dim)</span></span><br><span class="line">        c_lens = batch.c_word[<span class="number">1</span>]</span><br><span class="line">        <span class="comment"># c_lensï¼šä¸€ä¸ªbatchä¸­æ‰€æœ‰contextçš„æ ·æœ¬é•¿åº¦</span></span><br><span class="line">        q_lens = batch.q_word[<span class="number">1</span>]</span><br><span class="line">        <span class="comment"># q_lensï¼šä¸€ä¸ªbatchä¸­æ‰€æœ‰questionçš„æ ·æœ¬é•¿åº¦</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Highway network</span></span><br><span class="line">        c = highway_network(c_char, c_word)</span><br><span class="line">        <span class="comment"># c = (batch, seq_len, hidden_size * 2)</span></span><br><span class="line">        q = highway_network(q_char, q_word)</span><br><span class="line">        <span class="comment"># q = (batch, seq_len, hidden_size * 2)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 3. Contextual Embedding Layer</span></span><br><span class="line">        c = self.context_LSTM((c, c_lens))[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># c = (batch, seq_len, hidden_size * 2)</span></span><br><span class="line">        q = self.context_LSTM((q, q_lens))[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># q = (batch, seq_len, hidden_size * 2)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 4. Attention Flow Layer</span></span><br><span class="line">        g = att_flow_layer(c, q)</span><br><span class="line">        <span class="comment"># (batch, c_len, hidden_size * 8)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 5. Modeling Layer</span></span><br><span class="line">        m = self.modeling_LSTM2((self.modeling_LSTM1((g, c_lens))[<span class="number">0</span>], c_lens))[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># self.modeling_LSTM1((g, c_lens))[0] = (batch, c_len, hidden_size * 2) # 2å› ä¸ºæ˜¯åŒå‘</span></span><br><span class="line">        <span class="comment"># m = (batch, c_len, hidden_size * 2) 2å› ä¸ºæ˜¯åŒå‘</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 6. Output Layer</span></span><br><span class="line">        p1, p2 = output_layer(g, m, c_lens) <span class="comment"># é¢„æµ‹å¼€å§‹ä½ç½®å’Œç»“æŸä½ç½®</span></span><br><span class="line">        <span class="comment"># (batch, c_len), (batch, c_len)</span></span><br><span class="line">        <span class="keyword">return</span> p1, p2</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = torch.rand((<span class="number">2</span>,<span class="number">5</span>,<span class="number">6</span>))</span><br><span class="line">print(x)</span><br><span class="line">y = x.select(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">print(y)</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">print(len(data.WORD.vocab)) <span class="comment"># 108777ä¸ªå•è¯</span></span><br><span class="line">print(data.WORD.vocab.vectors.shape) <span class="comment"># è¯å‘é‡ç»´åº¦</span></span><br><span class="line"></span><br><span class="line">print(data.WORD.vocab.itos[:<span class="number">50</span>]) <span class="comment"># å‰50ä¸ªè¯é¢‘æœ€é«˜çš„å•è¯</span></span><br><span class="line">print(<span class="string">"------"</span>*<span class="number">10</span>)</span><br><span class="line">print(list(data.WORD.vocab.stoi.items())[<span class="number">0</span>:<span class="number">50</span>]) <span class="comment"># å¯¹åº”çš„ç´¢å¼•</span></span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(len(data.CHAR.vocab)) <span class="comment"># 1307ä¸ªå•è¯</span></span><br><span class="line">print(data.CHAR.vocab.itos[:<span class="number">50</span>]) <span class="comment"># 108777ä¸ªå•è¯</span></span><br><span class="line">print(<span class="string">"------"</span>*<span class="number">10</span>)</span><br><span class="line">print(list(data.CHAR.vocab.stoi.items())[<span class="number">0</span>:<span class="number">50</span>]) <span class="comment"># å¯¹åº”çš„ç´¢å¼•</span></span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">f"cuda:<span class="subst">&#123;args.gpu&#125;</span>"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line">model = BiDAF(args, data.WORD.vocab.vectors).to(device)</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EMA</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, mu)</span>:</span></span><br><span class="line">        <span class="comment"># mu = args.exp_decay_rate = 0.999</span></span><br><span class="line">        self.mu = mu</span><br><span class="line">        self.shadow = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">register</span><span class="params">(self, name, val)</span>:</span></span><br><span class="line">        <span class="comment"># name:å„ä¸ªå‚æ•°å±‚çš„åå­—, param.dataï¼›å‚æ•°å±‚çš„æ•°æ®</span></span><br><span class="line">        self.shadow[name] = val.clone() <span class="comment"># å»ºç«‹å­—å…¸</span></span><br><span class="line">        <span class="comment"># clone()å¾—åˆ°çš„Tensorä¸ä»…æ‹·è´äº†åŸå§‹çš„valueï¼Œè€Œä¸”ä¼šè®¡ç®—æ¢¯åº¦ä¼ æ’­ä¿¡æ¯ï¼Œcopy_()åªæ‹·è´æ•°å€¼</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get</span><span class="params">(self, name)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.shadow[name]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update</span><span class="params">(self, name, x)</span>:</span></span><br><span class="line">        <span class="keyword">assert</span> name <span class="keyword">in</span> self.shadow</span><br><span class="line">        new_average = (<span class="number">1.0</span> - self.mu) * x + self.mu * self.shadow[name]</span><br><span class="line">        self.shadow[name] = new_average.clone()</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(model, ema, args, data)</span>:</span></span><br><span class="line">    device = torch.device(<span class="string">f"cuda:<span class="subst">&#123;args.gpu&#125;</span>"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line">    criterion = nn.CrossEntropyLoss()</span><br><span class="line">    loss = <span class="number">0</span></span><br><span class="line">    answers = dict()</span><br><span class="line">    model.eval()</span><br><span class="line"></span><br><span class="line">    backup_params = EMA(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">        <span class="keyword">if</span> param.requires_grad:</span><br><span class="line">            backup_params.register(name, param.data) <span class="comment"># é‡æ–°å»ºç«‹å­—å…¸</span></span><br><span class="line">            param.data.copy_(ema.get(name))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.set_grad_enabled(<span class="literal">False</span>):</span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> iter(data.dev_iter):</span><br><span class="line">            p1, p2 = model(batch)</span><br><span class="line">            print(p1.shape,p2.shape)</span><br><span class="line">            print(batch.s_idx,batch.e_idx)</span><br><span class="line">            batch_loss = criterion(p1, batch.s_idx<span class="number">-1</span>) + criterion(p2, batch.e_idx<span class="number">-1</span>)</span><br><span class="line">            print(<span class="string">"batch_loss"</span>,batch_loss)</span><br><span class="line">            print(<span class="string">"----"</span>*<span class="number">40</span>)</span><br><span class="line">            loss += batch_loss.item()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># (batch, c_len, c_len)</span></span><br><span class="line">            batch_size, c_len = p1.size()</span><br><span class="line">            ls = nn.LogSoftmax(dim=<span class="number">1</span>)</span><br><span class="line">            mask = (torch.ones(c_len, c_len) * float(<span class="string">'-inf'</span>)).to(device).tril(<span class="number">-1</span>).unsqueeze(<span class="number">0</span>).expand(batch_size, <span class="number">-1</span>, <span class="number">-1</span>)</span><br><span class="line">            score = (ls(p1).unsqueeze(<span class="number">2</span>) + ls(p2).unsqueeze(<span class="number">1</span>)) + mask</span><br><span class="line">            score, s_idx = score.max(dim=<span class="number">1</span>)</span><br><span class="line">            score, e_idx = score.max(dim=<span class="number">1</span>)</span><br><span class="line">            s_idx = torch.gather(s_idx, <span class="number">1</span>, e_idx.view(<span class="number">-1</span>, <span class="number">1</span>)).squeeze()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(batch_size):</span><br><span class="line">                id = batch.id[i]</span><br><span class="line">                answer = batch.c_word[<span class="number">0</span>][i][s_idx[i]:e_idx[i]+<span class="number">1</span>]</span><br><span class="line">                answer = <span class="string">' '</span>.join([data.WORD.vocab.itos[idx] <span class="keyword">for</span> idx <span class="keyword">in</span> answer])</span><br><span class="line">                answers[id] = answer</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">            <span class="keyword">if</span> param.requires_grad:</span><br><span class="line">                param.data.copy_(backup_params.get(name))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> open(args.prediction_file, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        print(json.dumps(answers), file=f)</span><br><span class="line"></span><br><span class="line">    results = evaluate.main(args)</span><br><span class="line">    <span class="keyword">return</span> loss, results[<span class="string">'exact_match'</span>], results[<span class="string">'f1'</span>]</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">    print(name)</span><br><span class="line">    print(param.requires_grad)</span><br><span class="line">    print(param.data.shape)</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">strftime(&apos;%H:%M:%S&apos;, gmtime())</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">iterator = data.train_iter</span><br><span class="line">n= <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">    print(<span class="string">"j="</span>,j)</span><br><span class="line">    <span class="keyword">for</span> i, batch <span class="keyword">in</span> enumerate(iterator):</span><br><span class="line">        print(<span class="string">"å½“å‰epoch"</span>,int(iterator.epoch))</span><br><span class="line">        print(<span class="string">"-----"</span>*<span class="number">10</span>)</span><br><span class="line">        print(i)</span><br><span class="line">        print(batch)</span><br><span class="line">        n+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> n&gt;<span class="number">3</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(args, data)</span>:</span></span><br><span class="line">    device = torch.device(<span class="string">f"cuda:<span class="subst">&#123;args.gpu&#125;</span>"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line">    model = BiDAF(args, data.WORD.vocab.vectors).to(device) <span class="comment"># å®šä¹‰ä¸»æ¨¡å‹ç±»å®ä¾‹</span></span><br><span class="line"></span><br><span class="line">    ema = EMA(args.exp_decay_rate) <span class="comment"># args.exp_decay_rate = 0.999</span></span><br><span class="line">    <span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters(): </span><br><span class="line">        <span class="keyword">if</span> param.requires_grad:</span><br><span class="line">            ema.register(name, param.data) <span class="comment"># å‚æ•°åå­—å’Œå¯¹åº”çš„å‚æ•°æ•°æ®å½¢æˆå­—å…¸</span></span><br><span class="line">    parameters = filter(<span class="keyword">lambda</span> p: p.requires_grad, model.parameters())</span><br><span class="line">    <span class="comment"># p.requires_grad = True or False ä¿ç•™æœ‰æ¢¯åº¦çš„å‚æ•°</span></span><br><span class="line">    optimizer = optim.Adadelta(parameters, lr=args.learning_rate)</span><br><span class="line">    <span class="comment"># args.learning_rate = 0.5,ä¼˜åŒ–å™¨é€‰ç”¨Adadelta</span></span><br><span class="line">    criterion = nn.CrossEntropyLoss()</span><br><span class="line">    <span class="comment"># äº¤å‰ç†µæŸå¤±</span></span><br><span class="line"></span><br><span class="line">    writer = SummaryWriter(log_dir=<span class="string">'runs/'</span> + args.model_time)</span><br><span class="line">    <span class="comment"># args.model_time = strftime('%H:%M:%S', gmtime()) æ–‡ä»¶å¤¹å‘½åä¸ºå†™å…¥æ–‡ä»¶çš„å½“åœ°æ—¶é—´</span></span><br><span class="line"></span><br><span class="line">    model.train()</span><br><span class="line">    loss, last_epoch = <span class="number">0</span>, <span class="number">-1</span></span><br><span class="line">    max_dev_exact, max_dev_f1 = <span class="number">-1</span>, <span class="number">-1</span></span><br><span class="line"></span><br><span class="line">    iterator = data.train_iter</span><br><span class="line">    <span class="keyword">for</span> i, batch <span class="keyword">in</span> enumerate(iterator):</span><br><span class="line">        present_epoch = int(iterator.epoch) </span><br><span class="line">        <span class="comment">#print("å½“å‰epoch",present_epoch)# è¿™ä¸ªæˆ‘æ‰“å°äº†ä¸‹ï¼Œä¸€ç›´æ˜¯0ï¼Œè§‰å¾—æœ‰é—®é¢˜</span></span><br><span class="line">        <span class="keyword">if</span> present_epoch == args.epoch:</span><br><span class="line">            <span class="comment"># args.epoch=12</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">if</span> present_epoch &gt; last_epoch:</span><br><span class="line">            print(<span class="string">'epoch:'</span>, present_epoch + <span class="number">1</span>)</span><br><span class="line">        last_epoch = present_epoch</span><br><span class="line"></span><br><span class="line">        p1, p2 = model(batch)</span><br><span class="line">        <span class="comment"># (batch, c_len), (batch, c_len)</span></span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        </span><br><span class="line">        batch_loss = criterion(p1, batch.s_idx) + criterion(p2, batch.e_idx)</span><br><span class="line">        <span class="comment"># æœ€åçš„ç›®æ ‡å‡½æ•°ï¼šbatch.s_idxæ˜¯ç­”æ¡ˆå¼€å§‹çš„ä½ç½®ï¼Œbatch.e_idxæ˜¯ç­”æ¡ˆç»“æŸçš„ä½ç½®</span></span><br><span class="line">        loss += batch_loss.item()</span><br><span class="line">        batch_loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">            <span class="keyword">if</span> param.requires_grad:</span><br><span class="line">                ema.update(name, param.data) <span class="comment"># æ›´æ–°è®­ç»ƒå®Œåçš„çš„å‚æ•°æ•°æ®</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (i + <span class="number">1</span>) % args.print_freq == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"i"</span>,i)</span><br><span class="line">            dev_loss, dev_exact, dev_f1 = test(model, ema, args, data)</span><br><span class="line">            c = (i + <span class="number">1</span>) // args.print_freq</span><br><span class="line"></span><br><span class="line">            writer.add_scalar(<span class="string">'loss/train'</span>, loss, c)</span><br><span class="line">            writer.add_scalar(<span class="string">'loss/dev'</span>, dev_loss, c)</span><br><span class="line">            writer.add_scalar(<span class="string">'exact_match/dev'</span>, dev_exact, c)</span><br><span class="line">            writer.add_scalar(<span class="string">'f1/dev'</span>, dev_f1, c)</span><br><span class="line">            print(<span class="string">f'train loss: <span class="subst">&#123;loss:<span class="number">.3</span>f&#125;</span> / dev loss: <span class="subst">&#123;dev_loss:<span class="number">.3</span>f&#125;</span>'</span></span><br><span class="line">                  <span class="string">f' / dev EM: <span class="subst">&#123;dev_exact:<span class="number">.3</span>f&#125;</span> / dev F1: <span class="subst">&#123;dev_f1:<span class="number">.3</span>f&#125;</span>'</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> dev_f1 &gt; max_dev_f1:</span><br><span class="line">                max_dev_f1 = dev_f1</span><br><span class="line">                max_dev_exact = dev_exact</span><br><span class="line">                best_model = copy.deepcopy(model)</span><br><span class="line"></span><br><span class="line">            loss = <span class="number">0</span></span><br><span class="line">            model.train()</span><br><span class="line"></span><br><span class="line">    writer.close()</span><br><span class="line"><span class="comment">#     print(f'max dev EM: &#123;max_dev_exact:.3f&#125; / max dev F1: &#123;max_dev_f1:.3f&#125;')</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> best_model</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(&apos;training start!&apos;)</span><br><span class="line">best_model = train(args, data)</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/pytorch/pytorch/issues/4144</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SQuAD-BiDAF </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NLPä¸­çš„ConvNet</title>
      <link href="/2020/04/15/NLP%E4%B8%AD%E7%9A%84ConvNet/"/>
      <url>/2020/04/15/NLP%E4%B8%AD%E7%9A%84ConvNet/</url>
      
        <content type="html"><![CDATA[<p>â€‹        NLP/AIæ˜¯è¿‘å‡ å¹´æ¥é£é€Ÿå‘å±•çš„é¢†åŸŸï¼Œå¾ˆå¤šçš„æ¨¡å‹å’Œç®—æ³•åªèƒ½åœ¨è®ºæ–‡ã€è®²ä¹‰å’Œåšå®¢ä¸­æ‰¾åˆ°ï¼Œè€Œä¸ä¼šå‡ºç°åœ¨ä»»ä½•çš„æ•™ç§‘ä¹¦ä¸­ã€‚å‡¡æ˜¯è¯¾ç¨‹ä¸­æåˆ°çš„è®ºæ–‡ï¼Œå¤§å®¶éƒ½èƒ½å¤Ÿé˜…è¯»ä¸€éã€‚å¯¹äºé‡è¦çš„è®ºæ–‡ï¼ˆæˆ‘ä¼šç‰¹åˆ«æ ‡æ˜æˆ–è€…åœ¨è¯¾ä¸Šå¼ºè°ƒï¼Œä¾‹å¦‚BERT, transformerç­‰ï¼‰ï¼Œå»ºè®®è®¤çœŸé˜…è¯»ï¼Œææ¸…æ¥šæ¨¡å‹çš„ç»†èŠ‚ã€‚å…¶ä½™çš„è®ºæ–‡ï¼Œå»ºè®®è‡³å°‘èƒ½å¤Ÿé˜…è¯»ï¼Œäº†è§£è®ºæ–‡çš„åˆ›æ–°ç‚¹å’Œä¸­å¿ƒæ€æƒ³ã€‚</p><h3 id="å¦‚ä½•è¯»è®ºæ–‡ï¼Ÿ"><a href="#å¦‚ä½•è¯»è®ºæ–‡ï¼Ÿ" class="headerlink" title="å¦‚ä½•è¯»è®ºæ–‡ï¼Ÿ"></a>å¦‚ä½•è¯»è®ºæ–‡ï¼Ÿ</h3><p>å¯¹äºå¦‚ä½•è¯»è®ºæ–‡ï¼Œæ¯ä¸ªäººæœ‰è‡ªå·±ä¸åŒçš„æ–¹æ³•ã€‚æˆ‘çš„å»ºè®®æ˜¯ï¼š</p><ul><li><p>æœ€å¿«è¯»è®ºæ–‡çš„æ–¹æ³•ï¼šä¸Šå„å¤§ä¸­æ–‡ç½‘ç«™ï¼ˆçŸ¥ä¹ï¼ŒCSDNï¼Œå¾®ä¿¡å…¬ä¼—å·ç­‰ï¼‰å¯»æ‰¾è¯¥è®ºæ–‡çš„ä¸­æ–‡è§£è¯»ï¼Œå¤§éƒ¨åˆ†æœ‰åçš„è®ºæ–‡éƒ½ä¼šæœ‰å¾ˆå¤šçš„è§£è¯»æ–‡ç« ã€‚</p></li><li><p>è¯»è®ºæ–‡æ—¶å€™çš„é‡ç‚¹ç« èŠ‚ï¼šå¤§éƒ¨åˆ†NLPçš„è®ºæ–‡çš„ä¸»è¦ä¸¤ä¸ªç« èŠ‚æ˜¯ï¼ŒModel, Experimentsã€‚åŸºæœ¬ä¸Šçœ‹å®Œè¿™ä¸¤ä¸ªç« èŠ‚å°±äº†è§£äº†è®ºæ–‡çš„æ ¸å¿ƒæ€æƒ³ã€‚å¦å¤–æˆ‘ä¹Ÿä¼šç‰¹åˆ«å…³æ³¨è®ºæ–‡ä½¿ç”¨çš„<strong>æ•°æ®</strong>ï¼Œå› ä¸ºè¿™äº›æ•°æ®æˆ‘ä»¬å¯èƒ½å¯ä»¥æ‹¿æ¥ç”¨åœ¨è‡ªå·±çš„é¡¹ç›®ä¸Šã€‚</p></li><li><p>å¦‚æœæƒ³è¦æ›´åŠ æ·±å…¥åœ°å­¦ä¹ è¯¥è®ºæ–‡çš„å†…å®¹ï¼Œå¯ä»¥ä¸Šç½‘å»å¯»æ‰¾ä¸è¯¥è®ºæ–‡ç›¸å…³çš„èµ„æ–™ï¼ŒåŒ…æ‹¬ä½œè€…çš„ä¸ªäººä¸»é¡µï¼Œä»–/å¥¹å‘å¸ƒçš„è®ºæ–‡slidesï¼Œè®ºæ–‡ä»£ç ç­‰ç­‰ã€‚é¡ºä¾¿è¯´ä¸€ä¸‹ï¼Œå¦‚æœä½ æƒ³è¦å¤ç°è®ºæ–‡çš„ç»“æœï¼Œä½†æ˜¯åœ¨ç½‘ä¸Šæ‰¾ä¸åˆ°ä»£ç ï¼Œä¸è¦æ€¥äºè‡ªå·±å®ç°ï¼Œå¯ä»¥å†™é‚®ä»¶ç»™è®ºæ–‡çš„ç¬¬ä¸€ä½œè€…ä¸é€šè®¯ä½œè€…ï¼ˆæœ€åä¸€ä½ï¼‰ï¼Œç¤¼è²Œåœ°è¯¢é—®å¯¹æ–¹æ˜¯å¦å¯ä»¥å°†æºç å’Œæ•°æ®æä¾›ç»™ä½ ï¼Œç†è®ºä¸Šè®ºæ–‡ä½œè€…æœ‰ä¹‰åŠ¡å…¬å¼€è‡ªå·±çš„ä»£ç å’Œæ•°æ®ã€‚å¦‚æœæ²¡æœ‰ä»£ç å¯ä»¥å…¬å¼€ï¼Œè¦ä¸ç„¶å¯èƒ½æ˜¯è®ºæ–‡å¤ªæ–°ï¼Œè¿˜æ²¡æœ‰å…¬å¼€ä»£ç ï¼Œè¦ä¸ç„¶å¯èƒ½æ˜¯è®ºæ–‡ä¸­æŸäº›éƒ¨åˆ†çš„å®ç°æœ‰å›°éš¾ï¼Œä¸é‚£ä¹ˆå®¹æ˜“å¤ç°ã€‚</p></li><li><p>å¦å¤–å¦‚æœä½ æƒ³è¦æ›´æ·±å…¥åœ°å­¦ä¹ è¿™ä¸ªè®ºæ–‡ç›¸å…³çš„é¢†åŸŸï¼Œå¯ä»¥è¯»ä¸€ä¸‹Related Workä¸­æåˆ°çš„ä¸€äº›æ–‡ç« ã€‚</p></li></ul><h1 id="NLPä¸­çš„-ConvNet-ç²¾é€‰è®ºæ–‡"><a href="#NLPä¸­çš„-ConvNet-ç²¾é€‰è®ºæ–‡" class="headerlink" title="NLPä¸­çš„ ConvNet ç²¾é€‰è®ºæ–‡"></a>NLPä¸­çš„ ConvNet ç²¾é€‰è®ºæ–‡</h1><p>MNIST</p><p>convolutional kernel: local feature detector</p><p>å›¾åƒï¼š</p><ul><li><p>å¹³ç§»ä¸å˜æ€§</p></li><li><p>pixel features</p></li></ul><p>Hinton</p><ul><li><p>Capsule Network</p></li><li><p>ConvNetçš„ç¼ºé™·ï¼š</p></li><li><p>æ²¡æœ‰å¤„ç†æ—‹è½¬ä¸å˜æ€§</p></li><li><p>å›¾ç‰‡å¤§å°å‘ç”Ÿæ”¹å˜</p></li></ul><p>æ–‡æœ¬</p><ul><li><p>ngram</p></li><li><p>ngram ä¹‹é—´çš„è”ç³» n-n-gram</p></li></ul><p>æ›¾ç»æœ‰ä¸€æ®µæ—¶é—´ç”±äº<strong>Yann Lecun</strong>åŠ å…¥Facebook AI Researchæ‹…ä»»Directorçš„å…³ç³»ï¼ŒFBæŠ•å…¥äº†å¾ˆå¤šçš„ç²¾åŠ›ç ”å‘æŠŠConvNetç”¨åœ¨Texté—®é¢˜ä¸Šã€‚ConvNetä¸»æ‰“çš„ä¸€ä¸ªå¼ºé¡¹å°±æ˜¯é€Ÿåº¦æ¯”RNNå¿«ï¼ŒEncoderå¯ä»¥å¹¶è¡Œã€‚åæ¥å¯èƒ½æ˜¯ç”±äºGoogleçš„Transformerå¼€å§‹ç»Ÿæ²»è¿™ä¸ªé¢†åŸŸï¼Œå¯¼è‡´å¤§å®¶æ…¢æ…¢åœ¨ConvNetä¸Šçš„å…³æ³¨åº¦è¶Šæ¥è¶Šå°ã€‚</p><p>transformer (BERT) å°±æ˜¯ filter size ä¸º 1 çš„ convolutional neural network ã€‚</p><p>ä¸è¿‡è¿™ä¸€ç³»åˆ—ä»¥ConvNetä¸ºæ ¸å¿ƒçš„NLPæ¨¡å‹ä¾ç„¶éå¸¸å€¼å¾—å­¦ä¹ ã€‚ConvNetçš„ä¸€ä¸ªé•¿å¤„åœ¨äºå®ƒå¯ä»¥å¾ˆè‡ªç„¶åœ°å¾—åˆ° <strong>ngram</strong> çš„è¡¨ç¤ºã€‚ç”±äºNLPæœ€è¿‘çš„è¿›å±•æ—¥æ–°æœˆå¼‚ï¼Œå¯èƒ½å‡ å¤©æˆ–è€…å‡ ä¸ªæœˆä¹‹ååˆæœ‰ä¸€ç³»åˆ—åŸºäºConvNetçš„æ¨¡å‹é‡ç™»SOTAï¼Œè°çŸ¥é“å‘¢ã€‚</p><p>å¯¹äºä¸äº†è§£ä»€ä¹ˆæ˜¯Convolutional Neural Networkçš„åŒå­¦ï¼Œå»ºè®®é˜…è¯»æ–¯å¦ç¦cs231çš„è¯¾ç¨‹èµ„æ–™ <a href="http://cs231n.github.io/convolutional-networks/" target="_blank" rel="noopener">http://cs231n.github.io/convolutional-networks/</a> ç½‘ä¸Šçš„ä¸­æ–‡ç¿»è¯‘å¾ˆå¤šï¼Œä¾‹å¦‚ï¼š<a href="https://zhuanlan.zhihu.com/p/22038289?refer=intelligentunit" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/22038289?refer=intelligentunit</a></p><h2 id="Yoon-Kim-Convolutional-Neural-Networks-for-Sentence-Classification"><a href="#Yoon-Kim-Convolutional-Neural-Networks-for-Sentence-Classification" class="headerlink" title="Yoon Kim Convolutional Neural Networks for Sentence Classification"></a>Yoon Kim <a href="https://aclweb.org/anthology/D14-1181" target="_blank" rel="noopener">Convolutional Neural Networks for Sentence Classification</a></h2><p><a href="https://aclweb.org/anthology/D14-1181" target="_blank" rel="noopener">https://aclweb.org/anthology/D14-1181</a></p><p>è¿™ç¯‡æ–‡ç« é¦–æ¬¡æå‡ºäº†åœ¨textä¸Šä½¿ç”¨convolutional networkï¼Œå¹¶ä¸”å–å¾—äº†ä¸é”™çš„æ•ˆæœã€‚åç»­å¾ˆå¤šæŠŠConvNetç”¨åœ¨NLPä»»åŠ¡ä¸Šéƒ½æ˜¯åŸºäºè¿™ç¯‡è®ºæ–‡çš„æ¨¡å‹æ”¹è¿›ã€‚</p><h3 id="æ¨¡å‹æ¶æ„å›¾"><a href="#æ¨¡å‹æ¶æ„å›¾" class="headerlink" title="æ¨¡å‹æ¶æ„å›¾"></a>æ¨¡å‹æ¶æ„å›¾</h3><p><img src="https://uploader.shimo.im/f/bAD5TU2kjCQipLid.png!thumbnail" alt="img"></p><h3 id="embeddingå±‚"><a href="#embeddingå±‚" class="headerlink" title="embeddingå±‚"></a>embeddingå±‚</h3><p><img src="https://uploader.shimo.im/f/pOmG3eS8ntYi0dSQ.png!thumbnail" alt="img"></p><h3 id="convolutionå±‚"><a href="#convolutionå±‚" class="headerlink" title="convolutionå±‚"></a>convolutionå±‚</h3><p><img src="https://uploader.shimo.im/f/MlEd8ePXgDs7gaLg.png!thumbnail" alt="img"></p><p><img src="https://uploader.shimo.im/f/T3pionftmyImwzPH.png!thumbnail" alt="img"></p><h3 id="Max-over-time-pooling"><a href="#Max-over-time-pooling" class="headerlink" title="Max over time pooling"></a>Max over time pooling</h3><p><img src="https://uploader.shimo.im/f/cM7DZvGSt3gNz8uL.png!thumbnail" alt="img"></p><h3 id="è¾“å‡ºå±‚"><a href="#è¾“å‡ºå±‚" class="headerlink" title="è¾“å‡ºå±‚"></a>è¾“å‡ºå±‚</h3><p>ä¸€ä¸ªaffine transformationåŠ ä¸Šdropout</p><p><img src="https://uploader.shimo.im/f/5ZrPtIuh6X4P9lQJ.png!thumbnail" alt="img"></p><h3 id="æ¨¡å‹çš„æ•ˆæœ"><a href="#æ¨¡å‹çš„æ•ˆæœ" class="headerlink" title="æ¨¡å‹çš„æ•ˆæœ"></a>æ¨¡å‹çš„æ•ˆæœ</h3><p>å¯ä»¥åª²ç¾å½“æ—¶çš„ä¼—å¤šä¼ ç»Ÿæ¨¡å‹ã€‚ä»ä»Šå¤©çš„çœ¼å…‰æ¥çœ‹è¿™ä¸ªæ¨¡å‹çš„æ€è·¯è¿˜æ˜¯æŒºç®€å•çš„ï¼Œä¸è¿‡å½“æ—¶å¤§å®¶å¼€å§‹æ¢ç´¢æŠŠCNNç”¨åˆ°texté—®é¢˜ä¸Šçš„æ—¶å€™ï¼Œè¿™ä¸€ç³»åˆ—æ¨¡å‹æ¶æ„çš„æƒ³æ³•è¿˜æ˜¯å¾ˆæ–°é¢–çš„ã€‚</p><p><img src="https://uploader.shimo.im/f/BxnIovJf5Pwv8RHZ.png!thumbnail" alt="img"></p><h3 id="æˆ‘ä»¬çš„ä»£ç å®ç°"><a href="#æˆ‘ä»¬çš„ä»£ç å®ç°" class="headerlink" title="æˆ‘ä»¬çš„ä»£ç å®ç°"></a>æˆ‘ä»¬çš„ä»£ç å®ç°</h3><p>ç”¨ConvNetåšæ–‡æœ¬åˆ†ç±»çš„éƒ¨åˆ†ä»£ç ã€‚æœ‰äº›éƒ¨åˆ†å¯èƒ½çš„å®ç°å¯èƒ½å’Œæ¨¡å‹æœ‰ä¸€å®šå‡ºå…¥ï¼Œä¸è¿‡æˆ‘çš„æ¨¡å‹å®ç°æ•ˆæœä¹Ÿå¾ˆä¸é”™ï¼Œä»…ä¾›å‚è€ƒã€‚</p><p><a href="https://github.com/ZeweiChu/PyTorch-Course/blob/master/notebooks/4.sentiment_with_mask.ipynb" target="_blank" rel="noopener">https://github.com/ZeweiChu/PyTorch-Course/blob/master/notebooks/4.sentiment_with_mask.ipynb</a></p><p>æ„Ÿå…´è¶£çš„åŒå­¦å¯ä»¥å‚è€ƒæ›´å¤šYoon Kimçš„å·¥ä½œ</p><p><a href="http://www.people.fas.harvard.edu/~yoonkim/" target="_blank" rel="noopener">http://www.people.fas.harvard.edu/~yoonkim/</a></p><p>Yoon Kimçš„å¯¼å¸ˆAlex Rush</p><p><a href="http://nlp.seas.harvard.edu/rush.html" target="_blank" rel="noopener">http://nlp.seas.harvard.edu/rush.html</a></p><p>ä»–ä»¬çš„ä¸€é¡¹å·¥ä½œOpenNMT-py</p><p><a href="https://github.com/OpenNMT/OpenNMT-py" target="_blank" rel="noopener">https://github.com/OpenNMT/OpenNMT-py</a></p><p>Alex Rushçš„ä¸€äº›ä¼˜ç§€å­¦ç”Ÿ</p><p>Sam Wiseman <a href="https://swiseman.github.io/" target="_blank" rel="noopener">https://swiseman.github.io/</a> ä»–åšäº†å¾ˆå¤šVAEçš„å·¥ä½œ</p><h2 id="Zhang-et-al-Character-level-Convolutional-Networks-for-Text-Classification"><a href="#Zhang-et-al-Character-level-Convolutional-Networks-for-Text-Classification" class="headerlink" title="Zhang et. al., Character-level Convolutional Networks for Text Classification "></a>Zhang et. al., <a href="https://papers.nips.cc/paper/5782-character-level-convolutional-networks-for-text-classification.pdf" target="_blank" rel="noopener">Character-level Convolutional Networks for Text Classification </a></h2><p><a href="https://papers.nips.cc/paper/5782-character-level-convolutional-networks-for-text-classification.pdf" target="_blank" rel="noopener">https://papers.nips.cc/paper/5782-character-level-convolutional-networks-for-text-classification.pdf</a></p><p>è¿™ç¯‡æ–‡ç« åœ¨charå±‚é¢ä¸Šä½¿ç”¨ConvNetï¼Œå½“æ—¶åœ¨åˆ†ç±»ä»»åŠ¡ä¸Šå–å¾—äº†SOTAçš„æ•ˆæœã€‚åæ¥äººä»¬ç»å¸¸æŠŠè¿™å¥—æ–¹æ³•ç”¨æ¥åšå•è¯è¡¨ç¤ºçš„å­¦ä¹ ï¼Œä¾‹å¦‚ELMoå°±æ˜¯ç”¨CharCNNæ¥encodeå•è¯çš„ã€‚</p><h3 id="å…³é”®Modules"><a href="#å…³é”®Modules" class="headerlink" title="å…³é”®Modules"></a>å…³é”®Modules</h3><p>Convolutional Module</p><p><img src="https://uploader.shimo.im/f/24t3sOep2m8g4ls6.png!thumbnail" alt="img"></p><p>kæ˜¯kernel sizeã€‚</p><p>max pooling</p><p><img src="https://uploader.shimo.im/f/NzpvIEElx3UVKJyo.png!thumbnail" alt="img"></p><h3 id="æ¨¡å‹æ¶æ„å›¾-1"><a href="#æ¨¡å‹æ¶æ„å›¾-1" class="headerlink" title="æ¨¡å‹æ¶æ„å›¾"></a>æ¨¡å‹æ¶æ„å›¾</h3><h2 id><a href="#" class="headerlink" title></a><img src="https://uploader.shimo.im/f/WDfJgndz6HMQ5CTF.png!thumbnail" alt="img"></h2><p>åœ¨ELMoä¸Šçš„character embedding</p><p><img src="https://uploader.shimo.im/f/3aLnMpCpyUUQSGcQ.png!thumbnail" alt="img"></p><h3 id="æ¨¡å‹ä»£ç "><a href="#æ¨¡å‹ä»£ç " class="headerlink" title="æ¨¡å‹ä»£ç "></a>æ¨¡å‹ä»£ç </h3><p><a href="https://github.com/srviest/char-cnn-text-classification-pytorch/blob/master/model.py" target="_blank" rel="noopener">https://github.com/srviest/char-cnn-text-classification-pytorch/blob/master/model.py</a></p><h2 id="Gehring-et-al-Convolutional-Sequence-to-Sequence-Learning"><a href="#Gehring-et-al-Convolutional-Sequence-to-Sequence-Learning" class="headerlink" title="Gehring et. al., Convolutional Sequence to Sequence Learning"></a>Gehring et. al., <a href="https://arxiv.org/pdf/1705.03122.pdf" target="_blank" rel="noopener">Convolutional Sequence to Sequence Learning</a></h2><p><a href="https://arxiv.org/pdf/1705.03122.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1705.03122.pdf</a></p><p>å‚è€ƒåšå®¢èµ„æ–™</p><p><a href="https://ycts.github.io/weeklypapers/convSeq2seq/" target="_blank" rel="noopener">https://ycts.github.io/weeklypapers/convSeq2seq/</a></p><p>ç”¨ConvNetåšSeq2Seqæ¨¡å‹ï¼Œå…¶å®è¿™ç¯‡æ–‡ç« ä¸­æœ‰å¾ˆå¤šTransformerçš„å½±å­ï¼Œå¹¶ä¸”æ¨¡å‹æ•ˆæœä¹Ÿå¾ˆå¥½ã€‚å¯èƒ½ç”±äºåŒæ—¶æœŸçš„Transformerå…‰èŠ’è¿‡äºè€€çœ¼ï¼Œæ©ç›–äº†è¿™ä¸€ç¯‡åŒæ ·éå¸¸é‡é‡çº§çš„æ–‡ç« ã€‚</p><p>æˆ‘çš„å»ºè®®æ˜¯ï¼Œè¿™ç¯‡æ–‡ç« å¯ä»¥ç®€è¦é˜…è¯»ï¼Œäº†è§£ConvNetå¯ä»¥æ€ä¹ˆæ ·è¢«è¿ç”¨åˆ°Text Modelingé—®é¢˜ä¸Šã€‚ç”±äºç°åœ¨å­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œçš„ä¸»æµæ˜¯å„ç§Transformeræ¨¡å‹çš„å˜ç§ï¼Œä¸”Transformerçš„æ¨¡å‹ç›¸å¯¹æ›´ç®€æ´æ˜“æ‡‚ï¼Œæ‰€ä»¥å»ºè®®åŒå­¦ä»¬åœ¨åé¢èŠ±æ›´å¤šçš„æ—¶é—´åœ¨Transformerä¸Šã€‚æœ€è¿‘å¾ˆå¤šNLPçš„é¢è¯•éƒ½ä¼šé—®åˆ°ä¸€äº›ä¸Transformerå’ŒBERTç›¸å…³çš„é—®é¢˜ï¼Œå¯èƒ½å¾ˆå¤šäººä¸å¤ªäº†è§£è¿™ç¯‡Conv Seq2Seqçš„è®ºæ–‡ã€‚</p><h3 id="Positional-Embedddings"><a href="#Positional-Embedddings" class="headerlink" title="Positional Embedddings"></a>Positional Embedddings</h3><p><img src="https://uploader.shimo.im/f/3s1XVoEyWCA2091O.png!thumbnail" alt="img"></p><p>å¯¹æ¯ä¸ªå•è¯åˆ†åˆ«åšword embedding w_iå’Œpositional embedding p_iï¼Œç„¶åå•è¯çš„embeddingçš„w_i + p_iã€‚p_iæ˜¯æ¨¡å‹çš„å‚æ•°ï¼Œåœ¨è®­ç»ƒä¸­ä¼šè¢«æ›´æ–°ã€‚</p><p>å¦‚æœæ²¡æœ‰positional embeddingï¼ŒCNNæ˜¯æ— æ³•çŸ¥æ™“å•è¯çš„ä½ç½®ä¿¡æ¯çš„ã€‚å› ä¸ºä¸åŒäºLSTMï¼Œå¦‚æœæ²¡æœ‰postional embeddingï¼Œåœ¨CNN encoderä¸­çš„å•è¯ä½ç½®å…¶å®æ²¡æœ‰åŒºåˆ«ã€‚</p><h3 id="Convolutional-Block-Structure"><a href="#Convolutional-Block-Structure" class="headerlink" title="Convolutional Block Structure"></a>Convolutional Block Structure</h3><p>Encoderå’ŒDecoderç¬¬lå±‚çš„è¾“å…¥</p><p><img src="https://uploader.shimo.im/f/8RwAjCP390sIoG1A.png!thumbnail" alt="img"></p><p>æ¯ä¸€å±‚éƒ½åŒ…å«ä¸€ä¸ªä¸€ç»´Convolutionï¼Œä»¥åŠä¸€ä¸ªnon-linearityå•å…ƒï¼Œå…¶ä¸­conv block/layerçš„kernelå®½åº¦ä¸ºkï¼Œå…¶outputåŒ…å«kä¸ªè¾“å…¥å…ƒç´ çš„ä¿¡æ¯ã€‚å‚æ•°ä¸º</p><p><img src="https://uploader.shimo.im/f/8tCfiuW0gHgwBKAi.png!thumbnail" alt="img"></p><p>è¾“å‡ºä¸º</p><p><img src="https://uploader.shimo.im/f/kDZ1ulm65h8m0dOX.png!thumbnail" alt="img"></p><p>ç„¶åä½¿ç”¨ä¸€ä¸ªGated Linear Unitsä½œä¸ºnon-linearityã€‚</p><p><img src="https://uploader.shimo.im/f/MuogKhR9b48cABpI.png!thumbnail" alt="img"></p><p>encoderå’Œdecoderéƒ½æœ‰å¥½å¤šå±‚ï¼Œæ¯ä¸€å±‚éƒ½åŠ ä¸Šäº†residual connectionã€‚</p><p><img src="https://uploader.shimo.im/f/EdLJ369IWcQgqx0x.png!thumbnail" alt="img"></p><p>æˆ‘ä»¬åœ¨encoderæ¯ä¸€å±‚çš„å·¦å³ä¸¤è¾¹éƒ½æ·»åŠ paddingï¼Œè¿™æ ·å¯ä»¥ä¿è¯æ¯ä¸€å±‚ç»è¿‡convolutionä¹‹åè¾“å‡ºçš„é•¿åº¦å’ŒåŸæ¥ä¸€æ ·ã€‚decoderå’Œencoderç¨æœ‰ä¸åŒï¼Œå› ä¸ºæˆ‘ä»¬å¿…é¡»ä¿è¯æˆ‘ä»¬åœ¨decoderä¸€ä¸ªä½ç½®çš„å•è¯çš„æ—¶å€™æ²¡æœ‰çœ‹åˆ°è¿™ä¸ªä½ç½®åé¢çš„å•è¯ã€‚æ‰€ä»¥æˆ‘ä»¬çš„åšæ³•æ˜¯ï¼Œåœ¨decoderæ¯ä¸€å±‚å·¦å³ä¸¤è¾¹éƒ½åŠ ä¸Šk-1ä¸ªpaddingï¼Œåšå®Œconvä¹‹åæŠŠå³è¾¹çš„kä¸ªå•ä½ç§»é™¤ã€‚</p><p>æœ€åçš„ä¸€ä¸ªæ ‡å‡†å¥—è·¯æ˜¯æŠŠhidden stateåšä¸ªaffine transformationï¼Œç„¶åSoftmaxå˜æˆå•è¯è¡¨ä¸Šçš„ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒã€‚</p><p><img src="https://uploader.shimo.im/f/yFXfmhqvzzcU8D7D.png!thumbnail" alt="img"></p><h3 id="Multi-step-Attention"><a href="#Multi-step-Attention" class="headerlink" title="Multi-step Attention"></a>Multi-step Attention</h3><p>Decoderçš„æ¯ä¸€å±‚éƒ½æœ‰å•ç‹¬çš„Attentionã€‚</p><p><img src="https://uploader.shimo.im/f/uQLvQ1erpmAJfLlP.png!thumbnail" alt="img"></p><p>g_iæ˜¯å½“å‰å•è¯çš„embeddingï¼Œ</p><p><img src="https://uploader.shimo.im/f/eHzdNjYIZBM93TQN.png!thumbnail" alt="img"></p><p>ç„¶åæˆ‘ä»¬ç”¨è¿™ä¸ªæ–°é€ çš„ d_i^l å¯¹ encoder çš„æ¯ä¸ªä½ç½®åšattentionã€‚</p><p><img src="https://uploader.shimo.im/f/er1A7CMeiukGczjw.png!thumbnail" alt="img"></p><p>ç„¶åéå¸¸å¸¸è§„çš„ï¼Œç”¨attention scoreå¯¹encoder hidden statesåšåŠ æƒå¹³å‡ã€‚å”¯ä¸€ä¸åŒçš„æ˜¯ï¼Œè¿™é‡Œè¿˜ç›´æ¥åŠ ä¸Šäº†è¾“å…¥çš„embeddingã€‚</p><p><img src="https://uploader.shimo.im/f/BJXPoQQi9Xg4fJJa.png!thumbnail" alt="img"></p><p>ä½œè€…è¯´ä»–ä»¬å‘ç°ç›´æ¥åŠ ä¸Šè¿™ä¸ªè¯å‘é‡çš„embeddingè¿˜æ˜¯å¾ˆæœ‰ç”¨çš„ã€‚</p><h3 id="æ¨¡å‹æ¶æ„å›¾-2"><a href="#æ¨¡å‹æ¶æ„å›¾-2" class="headerlink" title="æ¨¡å‹æ¶æ„å›¾"></a>æ¨¡å‹æ¶æ„å›¾</h3><p><img src="https://uploader.shimo.im/f/r5pAK5SQWzQDyDFL.png!thumbnail" alt="img"></p><h3 id="Normalizationç­–ç•¥"><a href="#Normalizationç­–ç•¥" class="headerlink" title="Normalizationç­–ç•¥"></a>Normalizationç­–ç•¥</h3><p>ä¸ºäº†ä¿æŒæ¨¡å‹è®­ç»ƒçš„ç¨³å®šæ€§ï¼Œæˆ‘ä»¬å¸Œæœ›æ¨¡å‹ä¸­é—´çš„å‘é‡çš„varianceä¸è¦å¤ªå¤§ã€‚</p><ul><li>è¾“å‡º+residualä¹‹åä¹˜ä»¥\sqrt{5}ï¼Œè¿™æ ·å¯ä»¥è®©è¿™äº›vectoræ¯ä¸ªç»´åº¦çš„varianceå‡åŠã€‚å…¶å®å¾ˆå¤šæ—¶å€™è¿™äº›ç¡®ä¿æ¨¡å‹ç¨³å®šåº¦çš„ç»†èŠ‚æŒºå…³é”®çš„ï¼Œå¤§å®¶å¯èƒ½ä¹ŸçŸ¥é“transformerä¸­ä¹Ÿå¢åŠ äº†ä¸€äº›å‡å°‘varianceçš„æ–¹æ³•ã€‚å¦‚æœä¸æ˜¯è°ƒæ¨¡å‹ä¸“å®¶å°±ä¼šå¿½è§†è¿™äº›ç»†èŠ‚ï¼Œç„¶åæ¨¡å‹å°±è®­ç»ƒä¸å¥½äº†ã€‚</li></ul><p><img src="https://uploader.shimo.im/f/IMLzC3rtvxkqLmuo.png!thumbnail" alt="img"></p><p>è¿˜æœ‰æ›´å¤šçš„æ¨¡å‹å‚æ•°åˆå§‹åŒ–ç»†èŠ‚ï¼Œæ„Ÿå…´è¶£çš„åŒå­¦å¯ä»¥è‡ªå·±å»è®¤çœŸé˜…è¯»paperã€‚</p><h3 id="å®éªŒç»“æœ"><a href="#å®éªŒç»“æœ" class="headerlink" title="å®éªŒç»“æœ"></a>å®éªŒç»“æœ</h3><p><img src="https://uploader.shimo.im/f/aNGZg3EjGyw1aWu7.png!thumbnail" alt="img"></p><p>åœ¨ç¿»è¯‘ä»»åŠ¡ä¸Šè¶…è¶Šäº†GNMT (Google Neural Machine Translation)ï¼Œå…¶å®è¿™ä¸ªæ¯”è¾ƒèƒ½è¯´æ˜é—®é¢˜ï¼Œå› ä¸ºå½“æ—¶çš„GNMTæ˜¯State of the Artã€‚</p><p><img src="https://uploader.shimo.im/f/VMfU3If3biw5286r.png!thumbnail" alt="img"></p><p>ç„¶åä»–ä»¬è¿˜å±•ç¤ºäº†ConvS2Sçš„é€Ÿåº¦æ¯”GNMTæ›´å¿«ã€‚</p><p>æ€»ç»“æ¥è¯´ï¼ŒConvS2Så…¶å®æ˜¯ä¸€ç¯‡å¾ˆæœ‰ä»·å€¼çš„æ–‡ç« ï¼ŒDecoderçš„è®¾è®¡æ¯”è¾ƒç²¾è‡´ï¼Œ ä¸çŸ¥é“è¿™ç¯‡æ–‡ç« å¯¹åæ¥çš„Transformeräº§ç”Ÿäº†å¤šå°‘çš„å½±å“ï¼Œå½“ç„¶ä»–ä»¬å¯ä»¥è¯´æ˜¯åŒæ—¶æœŸçš„ä½œå“ã€‚</p><h3 id="ä»£ç "><a href="#ä»£ç " class="headerlink" title="ä»£ç "></a>ä»£ç </h3><p>ä¸»è¦ä»£ç åœ¨Fairseqçš„ä¸‹é¢è¿™ä¸ªæ–‡ä»¶ä¸­</p><p><a href="https://github.com/ZeweiChu/fairseq/blob/master/fairseq/models/fconv.py" target="_blank" rel="noopener">https://github.com/ZeweiChu/fairseq/blob/master/fairseq/models/fconv.py</a></p><p>Fairseqæ˜¯ä¸€ä¸ªå€¼å¾—å…³æ³¨ä¸€æ³¢çš„å·¥å…·åŒ…ï¼Œç”±Facebookå¼€å‘ï¼Œä¸»è¦å¼€å‘è€…æœ‰ </p><ul><li>Myle Ott <a href="https://myleott.com/" target="_blank" rel="noopener">https://myleott.com/</a></li></ul><h1 id="å…³äºæ–‡æœ¬åˆ†ç±»çš„æ›´å¤šå‚è€ƒèµ„æ–™"><a href="#å…³äºæ–‡æœ¬åˆ†ç±»çš„æ›´å¤šå‚è€ƒèµ„æ–™" class="headerlink" title="å…³äºæ–‡æœ¬åˆ†ç±»çš„æ›´å¤šå‚è€ƒèµ„æ–™"></a>å…³äºæ–‡æœ¬åˆ†ç±»çš„æ›´å¤šå‚è€ƒèµ„æ–™</h1><p>åŸºäºæ·±åº¦å­¦ä¹ çš„æ–‡æœ¬åˆ†ç±»</p><p><a href="https://zhuanlan.zhihu.com/p/34212945" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/34212945</a></p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ConvNet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>seq2seq</title>
      <link href="/2020/04/13/seq2seq/"/>
      <url>/2020/04/13/seq2seq/</url>
      
        <content type="html"><![CDATA[<h1 id="Seq2Seq-Attention"><a href="#Seq2Seq-Attention" class="headerlink" title="Seq2Seq, Attention"></a>Seq2Seq, Attention</h1><p>åœ¨è¿™ä»½notebookå½“ä¸­ï¼Œæˆ‘ä»¬ä¼š(å°½å¯èƒ½)å¤ç°Luongçš„attentionæ¨¡å‹</p><p>ç”±äºæˆ‘ä»¬çš„æ•°æ®é›†éå¸¸å°ï¼Œåªæœ‰ä¸€ä¸‡å¤šä¸ªå¥å­çš„è®­ç»ƒæ•°æ®ï¼Œæ‰€ä»¥è®­ç»ƒå‡ºæ¥çš„æ¨¡å‹æ•ˆæœå¹¶ä¸å¥½ã€‚å¦‚æœå¤§å®¶æƒ³è®­ç»ƒä¸€ä¸ªå¥½ä¸€ç‚¹çš„æ¨¡å‹ï¼Œå¯ä»¥å‚è€ƒä¸‹é¢çš„èµ„æ–™ã€‚</p><h2 id="æ›´å¤šé˜…è¯»"><a href="#æ›´å¤šé˜…è¯»" class="headerlink" title="æ›´å¤šé˜…è¯»"></a>æ›´å¤šé˜…è¯»</h2><h4 id="è¯¾ä»¶"><a href="#è¯¾ä»¶" class="headerlink" title="è¯¾ä»¶"></a>è¯¾ä»¶</h4><ul><li><a href="http://cs224d.stanford.edu/lectures/CS224d-Lecture15.pdf" target="_blank" rel="noopener">cs224d</a></li></ul><h4 id="è®ºæ–‡"><a href="#è®ºæ–‡" class="headerlink" title="è®ºæ–‡"></a>è®ºæ–‡</h4><ul><li><a href="https://arxiv.org/abs/1406.1078" target="_blank" rel="noopener">Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation</a></li><li><a href="https://arxiv.org/abs/1508.04025?context=cs" target="_blank" rel="noopener">Effective Approaches to Attention-based Neural Machine Translation</a></li><li><a href="https://arxiv.org/abs/1406.1078" target="_blank" rel="noopener">Neural Machine Translation by Jointly Learning to Align and Translate</a></li></ul><h4 id="PyTorchä»£ç "><a href="#PyTorchä»£ç " class="headerlink" title="PyTorchä»£ç "></a>PyTorchä»£ç </h4><ul><li><a href="https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation.ipynb" target="_blank" rel="noopener">seq2seq-tutorial</a></li><li><a href="https://github.com/bentrevett/pytorch-seq2seq" target="_blank" rel="noopener">Tutorial from Ben Trevett</a></li><li><a href="https://github.com/IBM/pytorch-seq2seq" target="_blank" rel="noopener">IBM seq2seq</a></li><li><a href="https://github.com/OpenNMT/OpenNMT-py" target="_blank" rel="noopener">OpenNMT-py</a></li></ul><h4 id="æ›´å¤šå…³äºMachine-Translation"><a href="#æ›´å¤šå…³äºMachine-Translation" class="headerlink" title="æ›´å¤šå…³äºMachine Translation"></a>æ›´å¤šå…³äºMachine Translation</h4><ul><li><a href="https://www.coursera.org/lecture/nlp-sequence-models/beam-search-4EtHZ" target="_blank" rel="noopener">Beam Search</a></li><li>Pointer network æ–‡æœ¬æ‘˜è¦</li><li>Copy Mechanism æ–‡æœ¬æ‘˜è¦</li><li>Converage Loss </li><li>ConvSeq2Seq</li><li>Transformer</li><li>Tensor2Tensor</li></ul><h4 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h4><ul><li>å»ºè®®åŒå­¦å°è¯•å¯¹ä¸­æ–‡è¿›è¡Œåˆ†è¯</li></ul><h4 id="NER"><a href="#NER" class="headerlink" title="NER"></a>NER</h4><ul><li><a href="https://github.com/allenai/allennlp/tree/master/allennlp" target="_blank" rel="noopener">https://github.com/allenai/allennlp/tree/master/allennlp</a></li></ul><p>In [137]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter <span class="comment">#è®¡æ•°å™¨</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> nltk</span><br></pre></td></tr></table></figure><p>è¯»å…¥ä¸­è‹±æ–‡æ•°æ®</p><ul><li>è‹±æ–‡æˆ‘ä»¬ä½¿ç”¨nltkçš„word tokenizeræ¥åˆ†è¯ï¼Œå¹¶ä¸”ä½¿ç”¨å°å†™å­—æ¯</li><li>ä¸­æ–‡æˆ‘ä»¬ç›´æ¥ä½¿ç”¨å•ä¸ªæ±‰å­—ä½œä¸ºåŸºæœ¬å•å…ƒ</li></ul><p>In [138]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span><span class="params">(in_file)</span>:</span></span><br><span class="line">    cn = []</span><br><span class="line">    en = []</span><br><span class="line">    num_examples = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> open(in_file, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">            <span class="comment">#print(line) #Anyone can do that.ä»»ä½•äººéƒ½å¯ä»¥åšåˆ°ã€‚</span></span><br><span class="line">            line = line.strip().split(<span class="string">"\t"</span>) <span class="comment">#åˆ†è¯åç”¨é€—å·éš”å¼€</span></span><br><span class="line">            <span class="comment">#print(line) #['Anyone can do that.', 'ä»»ä½•äººéƒ½å¯ä»¥åšåˆ°ã€‚']</span></span><br><span class="line">            en.append([<span class="string">"BOS"</span>] + nltk.word_tokenize(line[<span class="number">0</span>].lower()) + [<span class="string">"EOS"</span>])</span><br><span class="line">            <span class="comment">#BOS:beginning of sequence EOS:end of</span></span><br><span class="line">            <span class="comment"># split chinese sentence into characters</span></span><br><span class="line">            cn.append([<span class="string">"BOS"</span>] + [c <span class="keyword">for</span> c <span class="keyword">in</span> line[<span class="number">1</span>]] + [<span class="string">"EOS"</span>])</span><br><span class="line">            <span class="comment">#ä¸­æ–‡ä¸€ä¸ªä¸€ä¸ªå­—åˆ†è¯ï¼Œå¯ä»¥å°è¯•ç”¨åˆ†è¯å™¨åˆ†è¯</span></span><br><span class="line">    <span class="keyword">return</span> en, cn</span><br><span class="line"></span><br><span class="line">train_file = <span class="string">"nmt/en-cn/train.txt"</span></span><br><span class="line">dev_file = <span class="string">"nmt/en-cn/dev.txt"</span></span><br><span class="line">train_en, train_cn = load_data(train_file)</span><br><span class="line">dev_en, dev_cn = load_data(dev_file)</span><br></pre></td></tr></table></figure><p>In [0]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(train_en[:10])</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[&apos;BOS&apos;, &apos;anyone&apos;, &apos;can&apos;, &apos;do&apos;, &apos;that&apos;, &apos;.&apos;, &apos;EOS&apos;], [&apos;BOS&apos;, &apos;how&apos;, &apos;about&apos;, &apos;another&apos;, &apos;piece&apos;, &apos;of&apos;, &apos;cake&apos;, &apos;?&apos;, &apos;EOS&apos;], [&apos;BOS&apos;, &apos;she&apos;, &apos;married&apos;, &apos;him&apos;, &apos;.&apos;, &apos;EOS&apos;], [&apos;BOS&apos;, &apos;i&apos;, &apos;do&apos;, &quot;n&apos;t&quot;, &apos;like&apos;, &apos;learning&apos;, &apos;irregular&apos;, &apos;verbs&apos;, &apos;.&apos;, &apos;EOS&apos;], [&apos;BOS&apos;, &apos;it&apos;, &quot;&apos;s&quot;, &apos;a&apos;, &apos;whole&apos;, &apos;new&apos;, &apos;ball&apos;, &apos;game&apos;, &apos;for&apos;, &apos;me&apos;, &apos;.&apos;, &apos;EOS&apos;], [&apos;BOS&apos;, &apos;he&apos;, &quot;&apos;s&quot;, &apos;sleeping&apos;, &apos;like&apos;, &apos;a&apos;, &apos;baby&apos;, &apos;.&apos;, &apos;EOS&apos;], [&apos;BOS&apos;, &apos;he&apos;, &apos;can&apos;, &apos;play&apos;, &apos;both&apos;, &apos;tennis&apos;, &apos;and&apos;, &apos;baseball&apos;, &apos;.&apos;, &apos;EOS&apos;], [&apos;BOS&apos;, &apos;we&apos;, &apos;should&apos;, &apos;cancel&apos;, &apos;the&apos;, &apos;hike&apos;, &apos;.&apos;, &apos;EOS&apos;], [&apos;BOS&apos;, &apos;he&apos;, &apos;is&apos;, &apos;good&apos;, &apos;at&apos;, &apos;dealing&apos;, &apos;with&apos;, &apos;children&apos;, &apos;.&apos;, &apos;EOS&apos;], [&apos;BOS&apos;, &apos;she&apos;, &apos;will&apos;, &apos;do&apos;, &apos;her&apos;, &apos;best&apos;, &apos;to&apos;, &apos;be&apos;, &apos;here&apos;, &apos;on&apos;, &apos;time&apos;, &apos;.&apos;, &apos;EOS&apos;]]</span><br></pre></td></tr></table></figure><p>In [0]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(train_cn[:10])</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[&apos;BOS&apos;, &apos;ä»»&apos;, &apos;ä½•&apos;, &apos;äºº&apos;, &apos;éƒ½&apos;, &apos;å¯&apos;, &apos;ä»¥&apos;, &apos;åš&apos;, &apos;åˆ°&apos;, &apos;ã€‚&apos;, &apos;EOS&apos;], [&apos;BOS&apos;, &apos;è¦&apos;, &apos;ä¸&apos;, &apos;è¦&apos;, &apos;å†&apos;, &apos;ä¾†&apos;, &apos;ä¸€&apos;, &apos;å¡Š&apos;, &apos;è›‹&apos;, &apos;ç³•&apos;, &apos;ï¼Ÿ&apos;, &apos;EOS&apos;], [&apos;BOS&apos;, &apos;å¥¹&apos;, &apos;å«&apos;, &apos;ç»™&apos;, &apos;äº†&apos;, &apos;ä»–&apos;, &apos;ã€‚&apos;, &apos;EOS&apos;], [&apos;BOS&apos;, &apos;æˆ‘&apos;, &apos;ä¸&apos;, &apos;å–œ&apos;, &apos;æ¬¢&apos;, &apos;å­¦&apos;, &apos;ä¹ &apos;, &apos;ä¸&apos;, &apos;è§„&apos;, &apos;åˆ™&apos;, &apos;åŠ¨&apos;, &apos;è¯&apos;, &apos;ã€‚&apos;, &apos;EOS&apos;], [&apos;BOS&apos;, &apos;é€™&apos;, &apos;å°&apos;, &apos;æˆ‘&apos;, &apos;ä¾†&apos;, &apos;èªª&apos;, &apos;æ˜¯&apos;, &apos;å€‹&apos;, &apos;å…¨&apos;, &apos;æ–°&apos;, &apos;çš„&apos;, &apos;çƒ&apos;, &apos;é¡&apos;, &apos;éŠ&apos;, &apos;æˆ²&apos;, &apos;ã€‚&apos;, &apos;EOS&apos;], [&apos;BOS&apos;, &apos;ä»–&apos;, &apos;æ­£&apos;, &apos;ç¡&apos;, &apos;ç€&apos;, &apos;ï¼Œ&apos;, &apos;åƒ&apos;, &apos;ä¸ª&apos;, &apos;å©´&apos;, &apos;å„¿&apos;, &apos;ä¸€&apos;, &apos;æ ·&apos;, &apos;ã€‚&apos;, &apos;EOS&apos;], [&apos;BOS&apos;, &apos;ä»–&apos;, &apos;æ—¢&apos;, &apos;ä¼š&apos;, &apos;æ‰“&apos;, &apos;ç½‘&apos;, &apos;çƒ&apos;, &apos;ï¼Œ&apos;, &apos;åˆ&apos;, &apos;ä¼š&apos;, &apos;æ‰“&apos;, &apos;æ£’&apos;, &apos;çƒ&apos;, &apos;ã€‚&apos;, &apos;EOS&apos;], [&apos;BOS&apos;, &apos;æˆ‘&apos;, &apos;å€‘&apos;, &apos;æ‡‰&apos;, &apos;è©²&apos;, &apos;å–&apos;, &apos;æ¶ˆ&apos;, &apos;é€™&apos;, &apos;æ¬¡&apos;, &apos;é &apos;, &apos;è¶³&apos;, &apos;ã€‚&apos;, &apos;EOS&apos;], [&apos;BOS&apos;, &apos;ä»–&apos;, &apos;æ“…&apos;, &apos;é•·&apos;, &apos;æ‡‰&apos;, &apos;ä»˜&apos;, &apos;å°&apos;, &apos;å­©&apos;, &apos;å­&apos;, &apos;ã€‚&apos;, &apos;EOS&apos;], [&apos;BOS&apos;, &apos;å¥¹&apos;, &apos;ä¼š&apos;, &apos;å°½&apos;, &apos;é‡&apos;, &apos;æŒ‰&apos;, &apos;æ—¶&apos;, &apos;èµ¶&apos;, &apos;æ¥&apos;, &apos;çš„&apos;, &apos;ã€‚&apos;, &apos;EOS&apos;]]</span><br></pre></td></tr></table></figure><p>In [0]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>æ„å»ºå•è¯è¡¨</p><p>In [139]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">UNK_IDX = <span class="number">0</span></span><br><span class="line">PAD_IDX = <span class="number">1</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_dict</span><span class="params">(sentences, max_words=<span class="number">50000</span>)</span>:</span></span><br><span class="line">    word_count = Counter()</span><br><span class="line">    <span class="keyword">for</span> sentence <span class="keyword">in</span> sentences:</span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> sentence:</span><br><span class="line">            word_count[s] += <span class="number">1</span>  <span class="comment">#word_countè¿™é‡Œåº”è¯¥æ˜¯ä¸ªå­—å…¸</span></span><br><span class="line">    ls = word_count.most_common(max_words) </span><br><span class="line">    <span class="comment">#æŒ‰æ¯ä¸ªå•è¯æ•°é‡æ’åºå‰50000ä¸ª,è¿™ä¸ªæ•°å­—è‡ªå·±å®šçš„ï¼Œä¸é‡å¤å•è¯æ•°æ²¡æœ‰50000</span></span><br><span class="line">    print(len(ls)) <span class="comment">#train_enï¼š5491</span></span><br><span class="line">    total_words = len(ls) + <span class="number">2</span></span><br><span class="line">    <span class="comment">#åŠ çš„2æ˜¯ç•™ç»™"unk"å’Œ"pad"</span></span><br><span class="line">    <span class="comment">#ls = [('BOS', 14533), ('EOS', 14533), ('.', 12521), ('i', 4045), .......</span></span><br><span class="line">    word_dict = &#123;w[<span class="number">0</span>]: index+<span class="number">2</span> <span class="keyword">for</span> index, w <span class="keyword">in</span> enumerate(ls)&#125;</span><br><span class="line">    <span class="comment">#åŠ çš„2æ˜¯ç•™ç»™"unk"å’Œ"pad",è½¬æ¢æˆå­—å…¸æ ¼å¼ã€‚</span></span><br><span class="line">    word_dict[<span class="string">"UNK"</span>] = UNK_IDX</span><br><span class="line">    word_dict[<span class="string">"PAD"</span>] = PAD_IDX</span><br><span class="line">    <span class="keyword">return</span> word_dict, total_words</span><br><span class="line"></span><br><span class="line">en_dict, en_total_words = build_dict(train_en)</span><br><span class="line">cn_dict, cn_total_words = build_dict(train_cn)</span><br><span class="line">inv_en_dict = &#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> en_dict.items()&#125;</span><br><span class="line"><span class="comment">#en_dict.items()æŠŠå­—å…¸è½¬æ¢æˆå¯è¿­ä»£å¯¹è±¡ï¼Œå–å‡ºé”®å€¼ï¼Œå¹¶è°ƒæ¢é”®å€¼çš„ä½ç½®ã€‚</span></span><br><span class="line">inv_cn_dict = &#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> cn_dict.items()&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">5491</span><br><span class="line">3193</span><br></pre></td></tr></table></figure><p>In [1]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># print(en_dict)</span><br><span class="line"># print(en_total_words)</span><br></pre></td></tr></table></figure><p>In [3]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(cn_dict)</span><br><span class="line">print(cn_total_words)</span><br></pre></td></tr></table></figure><p>In [4]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(inv_en_dict)</span><br></pre></td></tr></table></figure><p>In [5]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(inv_cn_dict)</span><br></pre></td></tr></table></figure><p>æŠŠå•è¯å…¨éƒ¨è½¬å˜æˆæ•°å­—</p><p>In [140]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">encode</span><span class="params">(en_sentences, cn_sentences, en_dict, cn_dict, sort_by_len=True)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">        Encode the sequences. </span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    length = len(en_sentences)</span><br><span class="line">    <span class="comment">#en_sentences=[['BOS', 'anyone', 'can', 'do', 'that', '.', 'EOS'],....</span></span><br><span class="line">    </span><br><span class="line">    out_en_sentences = [[en_dict.get(w, <span class="number">0</span>) <span class="keyword">for</span> w <span class="keyword">in</span> sent] <span class="keyword">for</span> sent <span class="keyword">in</span> en_sentences]</span><br><span class="line">    <span class="comment">#out_en_sentences=[[2, 328, 43, 14, 28, 4, 3], ....</span></span><br><span class="line">    <span class="comment">#.get(w, 0)ï¼Œè¿”å›wå¯¹åº”çš„å€¼ï¼Œæ²¡æœ‰å°±ä¸º0.å› é¢˜åº“æ¯”è¾ƒå°ï¼Œè¿™é‡Œæ‰€æœ‰çš„å•è¯å‘é‡éƒ½æœ‰éé›¶ç´¢å¼•ã€‚</span></span><br><span class="line">    </span><br><span class="line"> </span><br><span class="line">    out_cn_sentences = [[cn_dict.get(w, <span class="number">0</span>) <span class="keyword">for</span> w <span class="keyword">in</span> sent] <span class="keyword">for</span> sent <span class="keyword">in</span> cn_sentences]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># sort sentences by english lengths</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">len_argsort</span><span class="params">(seq)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> sorted(range(len(seq)), key=<span class="keyword">lambda</span> x: len(seq[x]))</span><br><span class="line">      <span class="comment">#sorted()æ’åº,keyå‚æ•°å¯ä»¥è‡ªå®šä¹‰è§„åˆ™ï¼ŒæŒ‰seq[x]çš„é•¿åº¦æ’åºï¼Œseq[0]ä¸ºç¬¬ä¸€å¥è¯é•¿åº¦</span></span><br><span class="line">       </span><br><span class="line">    <span class="comment"># æŠŠä¸­æ–‡å’Œè‹±æ–‡æŒ‰ç…§åŒæ ·çš„é¡ºåºæ’åº</span></span><br><span class="line">    <span class="keyword">if</span> sort_by_len:</span><br><span class="line">        sorted_index = len_argsort(out_en_sentences)</span><br><span class="line">    <span class="comment">#print(sorted_index)</span></span><br><span class="line">    <span class="comment">#sorted_index=[63, 1544, 1917, 2650, 3998, 6240, 6294, 6703, ....</span></span><br><span class="line">     <span class="comment">#å‰é¢çš„ç´¢å¼•éƒ½æ˜¯æœ€çŸ­å¥å­çš„ç´¢å¼•</span></span><br><span class="line">      </span><br><span class="line">        out_en_sentences = [out_en_sentences[i] <span class="keyword">for</span> i <span class="keyword">in</span> sorted_index]</span><br><span class="line">     <span class="comment">#print(out_en_sentences)</span></span><br><span class="line">     <span class="comment">#out_en_sentences=[[2, 475, 4, 3], [2, 1318, 126, 3], [2, 1707, 126, 3], ......</span></span><br><span class="line">     </span><br><span class="line">        out_cn_sentences = [out_cn_sentences[i] <span class="keyword">for</span> i <span class="keyword">in</span> sorted_index]</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> out_en_sentences, out_cn_sentences</span><br><span class="line"></span><br><span class="line">train_en, train_cn = encode(train_en, train_cn, en_dict, cn_dict)</span><br><span class="line">dev_en, dev_cn = encode(dev_en, dev_cn, en_dict, cn_dict)</span><br></pre></td></tr></table></figure><p>In [6]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">k=10000</span><br><span class="line">print(&quot; &quot;.join([inv_cn_dict[i] for i in train_cn[k]])) #é€šè¿‡invå­—å…¸è·å–å•è¯</span><br><span class="line">print(&quot; &quot;.join([inv_en_dict[i] for i in train_en[k]]))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">BOS ä»– æ¥ è¿™ é‡Œ çš„ ç›® çš„ æ˜¯ ä»€ ä¹ˆ ï¼Ÿ EOS</span><br><span class="line">BOS for what purpose did he come here ? EOS</span><br></pre></td></tr></table></figure><p>æŠŠå…¨éƒ¨å¥å­åˆ†æˆbatch</p><p>In [0]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(np.arange(0, 100, 15))</span><br><span class="line">print(np.arange(0, 15))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[ 0 15 30 45 60 75 90]</span><br><span class="line">[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]</span><br></pre></td></tr></table></figure><p>In [141]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_minibatches</span><span class="params">(n, minibatch_size, shuffle=True)</span>:</span></span><br><span class="line">    idx_list = np.arange(<span class="number">0</span>, n, minibatch_size) <span class="comment"># [0, 1, ..., n-1]</span></span><br><span class="line">    <span class="keyword">if</span> shuffle:</span><br><span class="line">        np.random.shuffle(idx_list) <span class="comment">#æ‰“ä¹±æ•°æ®</span></span><br><span class="line">    minibatches = []</span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> idx_list:</span><br><span class="line">        minibatches.append(np.arange(idx, min(idx + minibatch_size, n)))</span><br><span class="line">        <span class="comment">#æ‰€æœ‰batchæ”¾åœ¨ä¸€ä¸ªå¤§åˆ—è¡¨é‡Œ</span></span><br><span class="line">    <span class="keyword">return</span> minibatches</span><br></pre></td></tr></table></figure><p>In [10]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">get_minibatches(<span class="number">100</span>,<span class="number">15</span>) <span class="comment">#éšæœºæ‰“ä¹±çš„</span></span><br></pre></td></tr></table></figure><p>Out[10]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[array([75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89]),</span><br><span class="line"> array([45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]),</span><br><span class="line"> array([30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44]),</span><br><span class="line"> array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),</span><br><span class="line"> array([15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),</span><br><span class="line"> array([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]),</span><br><span class="line"> array([90, 91, 92, 93, 94, 95, 96, 97, 98, 99])]</span><br></pre></td></tr></table></figure><p>In [142]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">prepare_data</span><span class="params">(seqs)</span>:</span></span><br><span class="line"><span class="comment">#seqs=[[2, 12, 167, 23, 114, 5, 27, 1755, 4, 3], ........</span></span><br><span class="line">    lengths = [len(seq) <span class="keyword">for</span> seq <span class="keyword">in</span> seqs]<span class="comment">#æ¯ä¸ªbatché‡Œè¯­å¥çš„é•¿åº¦ç»Ÿè®¡å‡ºæ¥</span></span><br><span class="line">    n_samples = len(seqs) <span class="comment">#ä¸€ä¸ªbatchæœ‰å¤šå°‘è¯­å¥</span></span><br><span class="line">    max_len = np.max(lengths) <span class="comment">#å–å‡ºæœ€é•¿çš„çš„è¯­å¥é•¿åº¦ï¼Œåé¢ç”¨è¿™ä¸ªåšpaddingåŸºå‡†</span></span><br><span class="line">    x = np.zeros((n_samples, max_len)).astype(<span class="string">'int32'</span>)</span><br><span class="line">    <span class="comment">#å…ˆåˆå§‹åŒ–å…¨é›¶çŸ©é˜µï¼Œåé¢ä¾æ¬¡èµ‹å€¼</span></span><br><span class="line">    <span class="comment">#print(x.shape) #64*æœ€å¤§å¥å­é•¿åº¦</span></span><br><span class="line">    </span><br><span class="line">    x_lengths = np.array(lengths).astype(<span class="string">"int32"</span>)</span><br><span class="line">    <span class="comment">#print(x_lengths) </span></span><br><span class="line"><span class="comment">#è¿™é‡Œçœ‹ä¸‹é¢çš„è¾“å…¥è¯­å¥å‘ç°è‹±æ–‡å¥å­é•¿åº¦éƒ½ä¸€æ ·ï¼Œä¸­æ–‡å¥å­é•¿çŸ­ä¸ä¸€ã€‚</span></span><br><span class="line"><span class="comment">#è¯´æ˜è‹±æ–‡å¥å­æ˜¯ç‰¹å¾ï¼Œä¸­æ–‡å¥å­æ˜¯æ ‡ç­¾ã€‚</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> idx, seq <span class="keyword">in</span> enumerate(seqs):</span><br><span class="line">      <span class="comment">#å–å‡ºä¸€ä¸ªbatchçš„æ¯æ¡è¯­å¥å’Œå¯¹åº”çš„ç´¢å¼•</span></span><br><span class="line">        x[idx, :lengths[idx]] = seq</span><br><span class="line">        <span class="comment">#æ¯æ¡è¯­å¥æŒ‰è¡Œèµ‹å€¼ç»™xï¼Œxä¼šæœ‰ä¸€äº›é›¶å€¼æ²¡æœ‰è¢«èµ‹å€¼ã€‚</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> x, x_lengths <span class="comment">#x_mask</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen_examples</span><span class="params">(en_sentences, cn_sentences, batch_size)</span>:</span></span><br><span class="line">    minibatches = get_minibatches(len(en_sentences), batch_size)</span><br><span class="line">    all_ex = []</span><br><span class="line">    <span class="keyword">for</span> minibatch <span class="keyword">in</span> minibatches:</span><br><span class="line">        mb_en_sentences = [en_sentences[t] <span class="keyword">for</span> t <span class="keyword">in</span> minibatch]</span><br><span class="line"><span class="comment">#æŒ‰æ‰“ä¹±çš„batchåºå·åˆ†æ•°æ®ï¼Œæ‰“ä¹±åªæ˜¯batchæ‰“ä¹±ï¼Œä¸€ä¸ªbataché‡Œé¢çš„è¯­å¥è¿˜æ˜¯é¡ºåºçš„ã€‚</span></span><br><span class="line">        <span class="comment">#print(mb_en_sentences)</span></span><br><span class="line">        </span><br><span class="line">        mb_cn_sentences = [cn_sentences[t] <span class="keyword">for</span> t <span class="keyword">in</span> minibatch]</span><br><span class="line">        mb_x, mb_x_len = prepare_data(mb_en_sentences)</span><br><span class="line">        <span class="comment">#è¿”å›çš„ç»´åº¦ä¸ºï¼šmb_x=(64 * æœ€å¤§å¥å­é•¿åº¦ï¼‰,mb_x_len=æœ€å¤§å¥å­é•¿åº¦</span></span><br><span class="line">        mb_y, mb_y_len = prepare_data(mb_cn_sentences)</span><br><span class="line">        </span><br><span class="line">        all_ex.append((mb_x, mb_x_len, mb_y, mb_y_len))</span><br><span class="line">  <span class="comment">#è¿™é‡ŒæŠŠæ‰€æœ‰batchæ•°æ®é›†åˆåˆ°ä¸€èµ·ã€‚</span></span><br><span class="line">  <span class="comment">#ä¾æ¬¡ä¸ºè‹±æ–‡å¥å­ï¼Œè‹±æ–‡é•¿åº¦ï¼Œä¸­æ–‡å¥å­ç¿»è¯‘ï¼Œä¸­æ–‡å¥å­é•¿åº¦ï¼Œè¿™å››ä¸ªæ”¾åœ¨ä¸€ä¸ªåˆ—è¡¨ä¸­</span></span><br><span class="line">  <span class="comment">#ä¸€ä¸ªåˆ—è¡¨ä¸ºä¸€ä¸ªbatchçš„æ•°æ®ï¼Œæ‰€æœ‰batchç»„æˆä¸€ä¸ªå¤§åˆ—è¡¨æ•°æ®</span></span><br><span class="line">  </span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> all_ex</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">train_data = gen_examples(train_en, train_cn, batch_size)</span><br><span class="line">random.shuffle(train_data)</span><br><span class="line">dev_data = gen_examples(dev_en, dev_cn, batch_size)</span><br></pre></td></tr></table></figure><p>In [28]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data[0]</span><br></pre></td></tr></table></figure><p>Out[28]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">(array([[   2,   12,  707,   23,    7,  295,    4,    3],</span><br><span class="line">        [   2,   12,  120, 1207,  517,  604,    4,    3],</span><br><span class="line">        [   2,    8,   90,  433,   64, 1470,  126,    3],</span><br><span class="line">        [   2,   12,  144,   46,    9,   94,    4,    3],</span><br><span class="line">        [   2,   25,   10,    9,  535,  639,    4,    3],</span><br><span class="line">        [   2,   25,   10,   64,  377, 2512,    4,    3],</span><br><span class="line">        [   2,   12,   43,  309,    9,   96,    4,    3],</span><br><span class="line">        [   2,   43,  328, 1475,   25,  469,   11,    3],</span><br><span class="line">        [   2,   82, 1043,   34, 1991, 2514,    4,    3],</span><br><span class="line">        [   2,    5,   54,    7,  181, 1694,    4,    3],</span><br><span class="line">        [   2,   30,   51,  472,    6,  294,   11,    3],</span><br><span class="line">        [   2,    5,  241,   16,   65,  551,    4,    3],</span><br><span class="line">        [   2,   14,    8,   36, 2516,  680,   11,    3],</span><br><span class="line">        [   2,    8,   30,    9,   66,  333,    4,    3],</span><br><span class="line">        [   2,   12,   10,   34,   40,  777,    4,    3],</span><br><span class="line">        [   2,   29,   54,    9,  138, 1633,    4,    3],</span><br><span class="line">        [   2,   43,    8,  309,    9,   96,   11,    3],</span><br><span class="line">        [   2,   47,   12,   39,   59,  190,   11,    3],</span><br><span class="line">        [   2,   29,   85,   14,  150,  221,    4,    3],</span><br><span class="line">        [   2,   12,   70,   37,   36,  242,    4,    3],</span><br><span class="line">        [   2,    5,  239,   64, 2521, 1696,    4,    3],</span><br><span class="line">        [   2,    5,   14,   13,   36,  314,    4,    3],</span><br><span class="line">        [   2,    5,  234,    7,   45,   44,    4,    3],</span><br><span class="line">        [   2,    5,   76,  226,   17,  621,    4,    3],</span><br><span class="line">        [   2,   29,  180,    9,  269,  266,    4,    3],</span><br><span class="line">        [   2,   85,    5,   22,    6,  708,   11,    3],</span><br><span class="line">        [   2,    6,  788,   48,   37,  889,    4,    3],</span><br><span class="line">        [   2,    8,   63,  124,   45,   95,    4,    3],</span><br><span class="line">        [   2,  921,   10,   21,  640,  350,    4,    3],</span><br><span class="line">        [   2,   52,   10,    6,  296,   44,   11,    3],</span><br><span class="line">        [   2,  681,   10,  190,   24,  146,   11,    3],</span><br><span class="line">        [   2,   19, 1480,  838,    7,  596,    4,    3],</span><br><span class="line">        [   2,   29,   90,  472, 2036,  132,    4,    3],</span><br><span class="line">        [   2,    8,   90,    9,   66,  645,    4,    3],</span><br><span class="line">        [   2,    5,  192,  257,    7,  684,    4,    3],</span><br><span class="line">        [   2,    5,   68,   36,  384, 1686,    4,    3],</span><br><span class="line">        [   2,   12,   10,  120,   38,   23,    4,    3],</span><br><span class="line">        [   2,   18,   47,  965,  106,  112,    4,    3],</span><br><span class="line">        [   2,    8,   30,   37,    9,  250,    4,    3],</span><br><span class="line">        [   2,   31,   20,  129,   20,  900,   11,    3],</span><br><span class="line">        [   2,   29,  519,  118, 2044, 1313,    4,    3],</span><br><span class="line">        [   2,   29,   22,    6,  294,  229,    4,    3],</span><br><span class="line">        [   2,   25,  189, 1056,  335,  151,    4,    3],</span><br><span class="line">        [   2,    8,   67,   89,   57,  887,    4,    3],</span><br><span class="line">        [   2,   41,    8,   72,   59,  362,   11,    3],</span><br><span class="line">        [   2,   51,  923, 2534,   26,  364,    4,    3],</span><br><span class="line">        [   2,   22,    8, 1209,  914,  834,   11,    3],</span><br><span class="line">        [   2,   19,   48,    9, 1127,  847,    4,    3],</span><br><span class="line">        [   2,   25,  224,   70,   13,  425,    4,    3],</span><br><span class="line">        [   2,   19,  949,   62, 1112,  657,    4,    3],</span><br><span class="line">        [   2,   87,   10,    6,  751,  443,   11,    3],</span><br><span class="line">        [   2,   19,  144,   99,    9,  539,    4,    3],</span><br><span class="line">        [   2,   19,  599,  242,  117,  103,    4,    3],</span><br><span class="line">        [   2,   14,    8,   22,    9,  386,   11,    3],</span><br><span class="line">        [   2,   16,   20,   60,    7,   45,    4,    3],</span><br><span class="line">        [   2,   25,  145,  133,   10, 1974,    4,    3],</span><br><span class="line">        [   2,   25,   10,  426,   17,  343,    4,    3],</span><br><span class="line">        [   2,    5,   22,  239,    6,  461,    4,    3],</span><br><span class="line">        [   2,   14,   13,    8,  162,  242,   11,    3],</span><br><span class="line">        [   2,    8,   67,   13,  159,   59,    4,    3],</span><br><span class="line">        [   2,  140, 3452, 1220,   33,  601,    4,    3],</span><br><span class="line">        [   2,    5,   79, 1937,   35,  232,    4,    3],</span><br><span class="line">        [   2,   18, 1612,   35,  779,  926,    4,    3],</span><br><span class="line">        [   2,   12,  197,  599,    6,  632,    4,    3]], dtype=int32),</span><br><span class="line"> array([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,</span><br><span class="line">        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,</span><br><span class="line">        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8],</span><br><span class="line">       dtype=int32),</span><br><span class="line"> array([[  2,   9, 793, ...,   0,   0,   0],</span><br><span class="line">        [  2,   9, 504, ...,   0,   0,   0],</span><br><span class="line">        [  2,   8, 114, ...,   0,   0,   0],</span><br><span class="line">        ...,</span><br><span class="line">        [  2,   5, 154, ...,   0,   0,   0],</span><br><span class="line">        [  2, 214, 171, ..., 838,   4,   3],</span><br><span class="line">        [  2,   9,  74, ...,   0,   0,   0]], dtype=int32),</span><br><span class="line"> array([10, 12,  9, 10,  8, 10,  7, 13, 17,  8, 11, 10, 11,  9,  9, 12,  8,</span><br><span class="line">        12, 10,  9, 14,  9,  9,  6,  9, 10,  9, 10, 13, 11, 14, 13, 14,  8,</span><br><span class="line">         8, 10, 10,  9,  8,  7, 14, 12, 13, 13, 13, 12, 13,  8, 11, 11, 10,</span><br><span class="line">        12, 10,  9,  6, 10,  8, 11,  9, 11, 10, 12, 21,  9], dtype=int32))</span><br></pre></td></tr></table></figure><h3 id="æ²¡æœ‰Attentionçš„ç‰ˆæœ¬"><a href="#æ²¡æœ‰Attentionçš„ç‰ˆæœ¬" class="headerlink" title="æ²¡æœ‰Attentionçš„ç‰ˆæœ¬"></a>æ²¡æœ‰Attentionçš„ç‰ˆæœ¬</h3><p>ä¸‹é¢æ˜¯ä¸€ä¸ªæ›´ç®€å•çš„æ²¡æœ‰Attentionçš„encoder decoderæ¨¡å‹</p><p>In [143]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PlainEncoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, vocab_size, hidden_size, dropout=<span class="number">0.2</span>)</span>:</span></span><br><span class="line">        <span class="comment">#ä»¥è‹±æ–‡ä¸ºä¾‹ï¼Œvocab_size=5493, hidden_size=100, dropout=0.2</span></span><br><span class="line">        super(PlainEncoder, self).__init__()</span><br><span class="line">        self.embed = nn.Embedding(vocab_size, hidden_size)</span><br><span class="line">        <span class="comment">#è¿™é‡Œçš„hidden_sizeä¸ºembedding_dimï¼šä¸€ä¸ªå•è¯çš„ç»´åº¦ </span></span><br><span class="line">        <span class="comment">#torch.nn.Embedding(num_embeddings, embedding_dim, .....)</span></span><br><span class="line">        <span class="comment">#è¿™é‡Œçš„hidden_size = 100</span></span><br><span class="line">        </span><br><span class="line">        self.rnn = nn.GRU(hidden_size, hidden_size, batch_first=<span class="literal">True</span>)      </span><br><span class="line">        <span class="comment">#ç¬¬ä¸€ä¸ªå‚æ•°ä¸ºinput_size ï¼šè¾“å…¥ç‰¹å¾æ•°é‡</span></span><br><span class="line">        <span class="comment">#ç¬¬äºŒä¸ªå‚æ•°ä¸ºhidden_size ï¼šéšè—å±‚ç‰¹å¾æ•°é‡</span></span><br><span class="line"></span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, lengths)</span>:</span> </span><br><span class="line">        <span class="comment">#xæ˜¯è¾“å…¥çš„batchçš„æ‰€æœ‰å•è¯ï¼Œlengthsï¼šbatché‡Œæ¯ä¸ªå¥å­çš„é•¿åº¦</span></span><br><span class="line">        <span class="comment">#å› ä¸ºéœ€è¦æŠŠæœ€åä¸€ä¸ªhidden stateå–å‡ºæ¥ï¼Œéœ€è¦çŸ¥é“é•¿åº¦ï¼Œå› ä¸ºå¥å­é•¿åº¦ä¸ä¸€æ ·</span></span><br><span class="line">        <span class="comment">##print(x.shape,lengths),x.sahpe = torch.Size([64, 10])</span></span><br><span class="line">        <span class="comment"># lengths= =tensor([10, 10, 10, ..... 10, 10, 10])</span></span><br><span class="line">        </span><br><span class="line">        sorted_len, sorted_idx = lengths.sort(<span class="number">0</span>, descending=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment">#æŒ‰ç…§é•¿åº¦æ’åºï¼Œdescending=Trueé•¿çš„åœ¨å‰ã€‚</span></span><br><span class="line">        <span class="comment">#è¿”å›ä¸¤ä¸ªå‚æ•°ï¼Œå¥å­é•¿åº¦å’Œæœªæ’åºå‰çš„ç´¢å¼•</span></span><br><span class="line">        <span class="comment"># sorted_idx=tensor([41, 40, 46, 45,...... 19, 18, 63])</span></span><br><span class="line">        <span class="comment"># sorted_len=tensor([10, 10, 10, ..... 10, 10, 10])</span></span><br><span class="line">        </span><br><span class="line">        x_sorted = x[sorted_idx.long()] <span class="comment">#å¥å­ç”¨æ–°çš„idxï¼ŒæŒ‰é•¿åº¦æ’å¥½åºäº†</span></span><br><span class="line">        </span><br><span class="line">        embedded = self.dropout(self.embed(x_sorted))</span><br><span class="line">        <span class="comment">#print(embedded.shape)=torch.Size([64, 10, 100])</span></span><br><span class="line">        <span class="comment">#tensor([[[-0.6312, -0.9863, -0.3123,  ..., -0.7384,  0.9230, -0.4311],....</span></span><br><span class="line"></span><br><span class="line">        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, sorted_len.long().cpu().data.numpy(), batch_first=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment">#è¿™ä¸ªå‡½æ•°å°±æ˜¯ç”¨æ¥å¤„ç†ä¸åŒé•¿åº¦çš„å¥å­çš„ï¼Œhttps: // www.cnblogs.com / sbj123456789 / p / 9834018. html</span></span><br><span class="line"></span><br><span class="line">        packed_out, hid = self.rnn(packed_embedded)</span><br><span class="line">        <span class="comment">#hid.shape = torch.Size([1, 64, 100])</span></span><br><span class="line">        </span><br><span class="line">        out, _ = nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment">#out.shape = torch.Size([64, 10, 100]),</span></span><br><span class="line"></span><br><span class="line">        _, original_idx = sorted_idx.sort(<span class="number">0</span>, descending=<span class="literal">False</span>)</span><br><span class="line">        out = out[original_idx.long()].contiguous()</span><br><span class="line">        hid = hid[:, original_idx.long()].contiguous()</span><br><span class="line">        <span class="comment">#out.shape = torch.Size([64, 10, 100])</span></span><br><span class="line">        <span class="comment">#hid.shape = torch.Size([1, 64, 100])</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> out, hid[[<span class="number">-1</span>]] <span class="comment">#æœ‰æ—¶å€™num_layerså±‚æ•°å¤šï¼Œéœ€è¦å–å‡ºæœ€åä¸€å±‚</span></span><br></pre></td></tr></table></figure><p>In [124]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PlainDecoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, vocab_size, hidden_size, dropout=<span class="number">0.2</span>)</span>:</span></span><br><span class="line">        super(PlainDecoder, self).__init__()</span><br><span class="line">        self.embed = nn.Embedding(vocab_size, hidden_size)</span><br><span class="line">        self.rnn = nn.GRU(hidden_size, hidden_size, batch_first=<span class="literal">True</span>)</span><br><span class="line">        self.out = nn.Linear(hidden_size, vocab_size)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, y, y_lengths, hid)</span>:</span></span><br><span class="line">        <span class="comment">#print(y.shape)=torch.Size([64, 12])</span></span><br><span class="line">        <span class="comment">#print(hid.shape)=torch.Size([1, 64, 100])</span></span><br><span class="line">        <span class="comment">#ä¸­æ–‡çš„yå’Œy_lengths</span></span><br><span class="line">        sorted_len, sorted_idx = y_lengths.sort(<span class="number">0</span>, descending=<span class="literal">True</span>)</span><br><span class="line">        y_sorted = y[sorted_idx.long()]</span><br><span class="line">        hid = hid[:, sorted_idx.long()] <span class="comment">#éšè—å±‚ä¹Ÿè¦æ’åº</span></span><br><span class="line"></span><br><span class="line">        y_sorted = self.dropout(self.embed(y_sorted)) </span><br><span class="line">        <span class="comment"># batch_size, output_length, embed_size</span></span><br><span class="line"></span><br><span class="line">        packed_seq = nn.utils.rnn.pack_padded_sequence(y_sorted, sorted_len.long().cpu().data.numpy(), batch_first=<span class="literal">True</span>)</span><br><span class="line">        out, hid = self.rnn(packed_seq, hid) <span class="comment">#åŠ ä¸Šéšè—å±‚</span></span><br><span class="line">        <span class="comment">#print(hid.shape)=torch.Size([1, 64, 100])</span></span><br><span class="line">        unpacked, _ = nn.utils.rnn.pad_packed_sequence(out, batch_first=<span class="literal">True</span>)</span><br><span class="line">        _, original_idx = sorted_idx.sort(<span class="number">0</span>, descending=<span class="literal">False</span>)</span><br><span class="line">        output_seq = unpacked[original_idx.long()].contiguous()</span><br><span class="line">        <span class="comment">#print(output_seq.shape)=torch.Size([64, 12, 100])</span></span><br><span class="line">        hid = hid[:, original_idx.long()].contiguous()</span><br><span class="line">        <span class="comment">#print(hid.shape)=torch.Size([1, 64, 100])</span></span><br><span class="line">        output = F.log_softmax(self.out(output_seq), <span class="number">-1</span>)</span><br><span class="line">        <span class="comment">#print(output.shape)=torch.Size([64, 12, 3195])</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> output, hid</span><br></pre></td></tr></table></figure><p>In [144]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PlainSeq2Seq</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, encoder, decoder)</span>:</span></span><br><span class="line">        <span class="comment">#encoderæ˜¯ä¸Šé¢PlainEncoderçš„å®ä¾‹</span></span><br><span class="line">        <span class="comment">#decoderæ˜¯ä¸Šé¢PlainDecoderçš„å®ä¾‹</span></span><br><span class="line">        super(PlainSeq2Seq, self).__init__()</span><br><span class="line">        self.encoder = encoder</span><br><span class="line">        self.decoder = decoder</span><br><span class="line">       </span><br><span class="line">    <span class="comment">#æŠŠä¸¤ä¸ªæ¨¡å‹ä¸²èµ·æ¥ </span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, x_lengths, y, y_lengths)</span>:</span></span><br><span class="line">        encoder_out, hid = self.encoder(x, x_lengths)</span><br><span class="line">        <span class="comment">#self.encoder(x, x_lengths)è°ƒç”¨PlainEncoderé‡Œé¢forwardçš„æ–¹æ³•</span></span><br><span class="line">        <span class="comment">#è¿”å›forwardçš„outå’Œhid</span></span><br><span class="line">        </span><br><span class="line">        output, hid = self.decoder(y=y,y_lengths=y_lengths,hid=hid)</span><br><span class="line">        <span class="comment">#self.dencoder()è°ƒç”¨PlainDecoderé‡Œé¢forwardçš„æ–¹æ³•</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> output, <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">translate</span><span class="params">(self, x, x_lengths, y, max_length=<span class="number">10</span>)</span>:</span></span><br><span class="line">        <span class="comment">#xæ˜¯ä¸€ä¸ªå¥å­ï¼Œç”¨æ•°å€¼è¡¨ç¤º</span></span><br><span class="line">        <span class="comment">#yæ˜¯å¥å­çš„é•¿åº¦</span></span><br><span class="line">        <span class="comment">#yæ˜¯â€œbosâ€çš„æ•°å€¼ç´¢å¼•=2</span></span><br><span class="line">        </span><br><span class="line">        encoder_out, hid = self.encoder(x, x_lengths)</span><br><span class="line">        preds = []</span><br><span class="line">        batch_size = x.shape[<span class="number">0</span>]</span><br><span class="line">        attns = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(max_length):</span><br><span class="line">            output, hid = self.decoder(y=y,</span><br><span class="line">                    y_lengths=torch.ones(batch_size).long().to(y.device),</span><br><span class="line">                    hid=hid) </span><br><span class="line">            </span><br><span class="line"><span class="comment">#åˆšå¼€å§‹å¾ªç¯bosä½œä¸ºæ¨¡å‹çš„é¦–ä¸ªè¾“å…¥å•è¯ï¼Œåç»­æ›´æ–°yï¼Œä¸‹ä¸ªé¢„æµ‹å•è¯çš„è¾“å…¥æ˜¯ä¸Šä¸ªè¾“å‡ºå•è¯</span></span><br><span class="line">            y = output.max(<span class="number">2</span>)[<span class="number">1</span>].view(batch_size, <span class="number">1</span>)</span><br><span class="line">            preds.append(y)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> torch.cat(preds, <span class="number">1</span>), <span class="literal">None</span></span><br></pre></td></tr></table></figure><p>In [145]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">"cuda"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line">dropout = <span class="number">0.2</span></span><br><span class="line">hidden_size = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#ä¼ å…¥ä¸­æ–‡å’Œè‹±æ–‡å‚æ•°</span></span><br><span class="line">encoder = PlainEncoder(vocab_size=en_total_words,</span><br><span class="line">                      hidden_size=hidden_size,</span><br><span class="line">                      dropout=dropout)</span><br><span class="line">decoder = PlainDecoder(vocab_size=cn_total_words,</span><br><span class="line">                      hidden_size=hidden_size,</span><br><span class="line">                      dropout=dropout)</span><br><span class="line">model = PlainSeq2Seq(encoder, decoder)</span><br></pre></td></tr></table></figure><p>In [146]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># masked cross entropy loss</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LanguageModelCriterion</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(LanguageModelCriterion, self).__init__()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, input, target, mask)</span>:</span></span><br><span class="line">        <span class="comment">#target=tensor([[5,108,8,4,3,0,0,0,0,0,0,0],....</span></span><br><span class="line">        <span class="comment">#  mask=tensor([[1,1 ,1,1,1,0,0,0,0,0,0,0],.....</span></span><br><span class="line">        <span class="comment">#print(input.shape,target.shape,mask.shape)</span></span><br><span class="line">        <span class="comment">#torch.Size([64, 12, 3195]) torch.Size([64, 12]) torch.Size([64, 12])</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># input: (batch_size * seq_len) * vocab_size</span></span><br><span class="line">        input = input.contiguous().view(<span class="number">-1</span>, input.size(<span class="number">2</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># target: batch_size * 1=768*1</span></span><br><span class="line">        target = target.contiguous().view(<span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line">        mask = mask.contiguous().view(<span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="comment">#print(-input.gather(1, target))</span></span><br><span class="line">        output = -input.gather(<span class="number">1</span>, target) * mask</span><br><span class="line"><span class="comment">#è¿™é‡Œç®—å¾—å°±æ˜¯äº¤å‰ç†µæŸå¤±ï¼Œå‰é¢å·²ç»ç®—äº†F.log_softmax</span></span><br><span class="line"><span class="comment">#.gatherçš„ä½œç”¨https://blog.csdn.net/edogawachia/article/details/80515038</span></span><br><span class="line"><span class="comment">#output.shape=torch.Size([768, 1])</span></span><br><span class="line"><span class="comment">#maskä½œç”¨æ˜¯æŠŠpaddingä¸º0çš„åœ°æ–¹é‡ç½®ä¸ºé›¶ï¼Œå› ä¸ºinput.gatheræ—¶ï¼Œä¸º0çš„åœ°æ–¹ä¸æ˜¯é›¶äº†</span></span><br><span class="line">        </span><br><span class="line">        output = torch.sum(output) / torch.sum(mask)</span><br><span class="line">        <span class="comment">#å‡å€¼æŸå¤±</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure><p>In [147]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = model.to(device)</span><br><span class="line">loss_fn = LanguageModelCriterion().to(device)</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters())</span><br></pre></td></tr></table></figure><p>pythonIn [151]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(model, data, num_epochs=<span class="number">2</span>)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">        model.train()</span><br><span class="line">        total_num_words = total_loss = <span class="number">0.</span></span><br><span class="line">        <span class="keyword">for</span> it, (mb_x, mb_x_len, mb_y, mb_y_len) <span class="keyword">in</span> enumerate(data):</span><br><span class="line">            <span class="comment">#ï¼ˆè‹±æ–‡batchï¼Œè‹±æ–‡é•¿åº¦ï¼Œä¸­æ–‡batchï¼Œä¸­æ–‡é•¿åº¦ï¼‰</span></span><br><span class="line">            </span><br><span class="line">            mb_x = torch.from_numpy(mb_x).to(device).long()</span><br><span class="line">            mb_x_len = torch.from_numpy(mb_x_len).to(device).long()</span><br><span class="line">            </span><br><span class="line">            <span class="comment">#å‰n-1ä¸ªå•è¯ä½œä¸ºè¾“å…¥ï¼Œån-1ä¸ªå•è¯ä½œä¸ºè¾“å‡ºï¼Œå› ä¸ºè¾“å…¥çš„å‰ä¸€ä¸ªå•è¯è¦é¢„æµ‹åä¸€ä¸ªå•è¯</span></span><br><span class="line">            mb_input = torch.from_numpy(mb_y[:, :<span class="number">-1</span>]).to(device).long()</span><br><span class="line">            mb_output = torch.from_numpy(mb_y[:, <span class="number">1</span>:]).to(device).long()</span><br><span class="line">            <span class="comment">#</span></span><br><span class="line">            mb_y_len = torch.from_numpy(mb_y_len<span class="number">-1</span>).to(device).long()</span><br><span class="line">            <span class="comment">#è¾“å…¥è¾“å‡ºçš„é•¿åº¦éƒ½å‡ä¸€ã€‚</span></span><br><span class="line">            </span><br><span class="line">            mb_y_len[mb_y_len&lt;=<span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">            mb_pred, attn = model(mb_x, mb_x_len, mb_input, mb_y_len)</span><br><span class="line">            <span class="comment">#è¿”å›çš„æ˜¯ç±»PlainSeq2Seqé‡Œforwardå‡½æ•°çš„ä¸¤ä¸ªè¿”å›å€¼</span></span><br><span class="line">            </span><br><span class="line">            mb_out_mask = torch.arange(mb_y_len.max().item(), device=device)[<span class="literal">None</span>, :] &lt; mb_y_len[:, <span class="literal">None</span>]</span><br><span class="line"><span class="comment">#mb_out_mask=tensor([[1, 1, 1,  ..., 0, 0, 0],[1, 1, 1,  ..., 0, 0, 0],</span></span><br><span class="line"><span class="comment">#mb_out_mask.shape= (64*19),è¿™å¥ä»£ç å’±ä¸æ‡‚ï¼Œè¿™ä¸ªmaskå°±æ˜¯paddingçš„ä½ç½®è®¾ç½®ä¸º0ï¼Œå…¶ä»–è®¾ç½®ä¸º1</span></span><br><span class="line"><span class="comment">#mb_out_maskå°±æ˜¯LanguageModelCriterionçš„ä¼ å…¥å‚æ•°maskã€‚</span></span><br><span class="line"></span><br><span class="line">            mb_out_mask = mb_out_mask.float()</span><br><span class="line">            </span><br><span class="line">            loss = loss_fn(mb_pred, mb_output, mb_out_mask)</span><br><span class="line">            </span><br><span class="line">            num_words = torch.sum(mb_y_len).item()</span><br><span class="line">            <span class="comment">#ä¸€ä¸ªbatché‡Œå¤šå°‘ä¸ªå•è¯</span></span><br><span class="line">            </span><br><span class="line">            total_loss += loss.item() * num_words</span><br><span class="line">            <span class="comment">#æ€»æŸå¤±ï¼Œlossè®¡ç®—çš„æ˜¯å‡å€¼æŸå¤±ï¼Œæ¯ä¸ªå•è¯éƒ½æ˜¯éƒ½æœ‰æŸå¤±ï¼Œæ‰€ä»¥ä¹˜ä»¥å•è¯æ•°</span></span><br><span class="line">            </span><br><span class="line">            total_num_words += num_words</span><br><span class="line">            <span class="comment">#æ€»å•è¯æ•°</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># æ›´æ–°æ¨¡å‹</span></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            torch.nn.utils.clip_grad_norm_(model.parameters(), <span class="number">5.</span>)</span><br><span class="line">            <span class="comment">#ä¸ºäº†é˜²æ­¢æ¢¯åº¦è¿‡å¤§ï¼Œè®¾ç½®æ¢¯åº¦çš„é˜ˆå€¼</span></span><br><span class="line">            </span><br><span class="line">            optimizer.step()</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> it % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">                print(<span class="string">"Epoch"</span>, epoch, <span class="string">"iteration"</span>, it, <span class="string">"loss"</span>, loss.item())</span><br><span class="line"></span><br><span class="line">                </span><br><span class="line">        print(<span class="string">"Epoch"</span>, epoch, <span class="string">"Training loss"</span>, total_loss/total_num_words)</span><br><span class="line">        <span class="keyword">if</span> epoch % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">            evaluate(model, dev_data) <span class="comment">#è¯„ä¼°æ¨¡å‹</span></span><br><span class="line">train(model, train_data, num_epochs=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Epoch 0 iteration 0 loss 4.277793884277344</span><br><span class="line">Epoch 0 iteration 100 loss 3.5520756244659424</span><br><span class="line">Epoch 0 iteration 200 loss 3.483494997024536</span><br><span class="line">Epoch 0 Training loss 3.6435126089915557</span><br><span class="line">Evaluation loss 3.698509503997669</span><br><span class="line">Epoch 1 iteration 0 loss 4.158623218536377</span><br><span class="line">Epoch 1 iteration 100 loss 3.412541389465332</span><br><span class="line">Epoch 1 iteration 200 loss 3.3976175785064697</span><br><span class="line">Epoch 1 Training loss 3.5087569079050698</span><br></pre></td></tr></table></figure><p>In [135]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">(model, data)</span>:</span></span><br><span class="line">    model.eval()</span><br><span class="line">    total_num_words = total_loss = <span class="number">0.</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():<span class="comment">#ä¸éœ€è¦æ›´æ–°æ¨¡å‹ï¼Œä¸éœ€è¦æ¢¯åº¦</span></span><br><span class="line">        <span class="keyword">for</span> it, (mb_x, mb_x_len, mb_y, mb_y_len) <span class="keyword">in</span> enumerate(data):</span><br><span class="line">            mb_x = torch.from_numpy(mb_x).to(device).long()</span><br><span class="line">            mb_x_len = torch.from_numpy(mb_x_len).to(device).long()</span><br><span class="line">            mb_input = torch.from_numpy(mb_y[:, :<span class="number">-1</span>]).to(device).long()</span><br><span class="line">            mb_output = torch.from_numpy(mb_y[:, <span class="number">1</span>:]).to(device).long()</span><br><span class="line">            mb_y_len = torch.from_numpy(mb_y_len<span class="number">-1</span>).to(device).long()</span><br><span class="line">            mb_y_len[mb_y_len&lt;=<span class="number">0</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            mb_pred, attn = model(mb_x, mb_x_len, mb_input, mb_y_len)</span><br><span class="line"></span><br><span class="line">            mb_out_mask = torch.arange(mb_y_len.max().item(), device=device)[<span class="literal">None</span>, :] &lt; mb_y_len[:, <span class="literal">None</span>]</span><br><span class="line">            mb_out_mask = mb_out_mask.float()</span><br><span class="line"></span><br><span class="line">            loss = loss_fn(mb_pred, mb_output, mb_out_mask)</span><br><span class="line"></span><br><span class="line">            num_words = torch.sum(mb_y_len).item()</span><br><span class="line">            total_loss += loss.item() * num_words</span><br><span class="line">            total_num_words += num_words</span><br><span class="line">    print(<span class="string">"Evaluation loss"</span>, total_loss/total_num_words)</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#ç¿»è¯‘ä¸ªå¥å­çœ‹çœ‹ç»“æœå’‹æ ·</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">translate_dev</span><span class="params">(i)</span>:</span></span><br><span class="line">    <span class="comment">#éšä¾¿å–å‡ºå¥å­</span></span><br><span class="line">    en_sent = <span class="string">" "</span>.join([inv_en_dict[w] <span class="keyword">for</span> w <span class="keyword">in</span> dev_en[i]])</span><br><span class="line">    print(en_sent)</span><br><span class="line">    cn_sent = <span class="string">" "</span>.join([inv_cn_dict[w] <span class="keyword">for</span> w <span class="keyword">in</span> dev_cn[i]])</span><br><span class="line">    print(<span class="string">""</span>.join(cn_sent))</span><br><span class="line"></span><br><span class="line">    mb_x = torch.from_numpy(np.array(dev_en[i]).reshape(<span class="number">1</span>, <span class="number">-1</span>)).long().to(device)</span><br><span class="line">    <span class="comment">#æŠŠå¥å­å‡ç»´ï¼Œå¹¶è½¬æ¢æˆtensor</span></span><br><span class="line">    </span><br><span class="line">    mb_x_len = torch.from_numpy(np.array([len(dev_en[i])])).long().to(device)</span><br><span class="line">    <span class="comment">#å–å‡ºå¥å­é•¿åº¦ï¼Œå¹¶è½¬æ¢æˆtensor</span></span><br><span class="line">    </span><br><span class="line">    bos = torch.Tensor([[cn_dict[<span class="string">"BOS"</span>]]]).long().to(device)</span><br><span class="line">    <span class="comment">#bos=tensor([[2]])</span></span><br><span class="line"></span><br><span class="line">    translation, attn = model.translate(mb_x, mb_x_len, bos)</span><br><span class="line">    <span class="comment">#è¿™é‡Œä¼ å…¥bosä½œä¸ºé¦–ä¸ªå•è¯çš„è¾“å…¥</span></span><br><span class="line">    <span class="comment">#translation=tensor([[ 8,  6, 11, 25, 22, 57, 10,  5,  6,  4]])</span></span><br><span class="line">    </span><br><span class="line">    translation = [inv_cn_dict[i] <span class="keyword">for</span> i <span class="keyword">in</span> translation.data.cpu().numpy().reshape(<span class="number">-1</span>)]</span><br><span class="line">    trans = []</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> translation:</span><br><span class="line">        <span class="keyword">if</span> word != <span class="string">"EOS"</span>: <span class="comment"># æŠŠæ•°å€¼å˜æˆå•è¯å½¢å¼</span></span><br><span class="line">            trans.append(word) <span class="comment">#</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    print(<span class="string">""</span>.join(trans))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>,<span class="number">120</span>):</span><br><span class="line">    translate_dev(i)</span><br><span class="line">    print()</span><br></pre></td></tr></table></figure><p>æ•°æ®å…¨éƒ¨å¤„ç†å®Œæˆï¼Œç°åœ¨æˆ‘ä»¬å¼€å§‹æ„å»ºseq2seqæ¨¡å‹</p><h4 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h4><ul><li>Encoderæ¨¡å‹çš„ä»»åŠ¡æ˜¯æŠŠè¾“å…¥æ–‡å­—ä¼ å…¥embeddingå±‚å’ŒGRUå±‚ï¼Œè½¬æ¢æˆä¸€äº›hidden statesä½œä¸ºåç»­çš„context vectors</li></ul><h2 id="ä¸‹é¢çš„æ³¨é‡Šæˆ‘å…ˆæŠŠåŸç†æ‹æ¸…æ¥šå§"><a href="#ä¸‹é¢çš„æ³¨é‡Šæˆ‘å…ˆæŠŠåŸç†æ‹æ¸…æ¥šå§" class="headerlink" title="ä¸‹é¢çš„æ³¨é‡Šæˆ‘å…ˆæŠŠåŸç†æ‹æ¸…æ¥šå§"></a>ä¸‹é¢çš„æ³¨é‡Šæˆ‘å…ˆæŠŠåŸç†æ‹æ¸…æ¥šå§</h2><p>In [0]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Encoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, vocab_size, embed_size, enc_hidden_size, dec_hidden_size, dropout=<span class="number">0.2</span>)</span>:</span></span><br><span class="line">        super(Encoder, self).__init__()</span><br><span class="line">        self.embed = nn.Embedding(vocab_size, embed_size)</span><br><span class="line">        </span><br><span class="line">        self.rnn = nn.GRU(embed_size, enc_hidden_size, batch_first=<span class="literal">True</span>, bidirectional=<span class="literal">True</span>)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line">        self.fc = nn.Linear(enc_hidden_size * <span class="number">2</span>, dec_hidden_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, lengths)</span>:</span></span><br><span class="line">        sorted_len, sorted_idx = lengths.sort(<span class="number">0</span>, descending=<span class="literal">True</span>)</span><br><span class="line">        x_sorted = x[sorted_idx.long()]</span><br><span class="line">        embedded = self.dropout(self.embed(x_sorted))</span><br><span class="line">        </span><br><span class="line">        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, sorted_len.long().cpu().data.numpy(), batch_first=<span class="literal">True</span>)</span><br><span class="line">        packed_out, hid = self.rnn(packed_embedded)</span><br><span class="line">        out, _ = nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=<span class="literal">True</span>)</span><br><span class="line">        _, original_idx = sorted_idx.sort(<span class="number">0</span>, descending=<span class="literal">False</span>)</span><br><span class="line">        out = out[original_idx.long()].contiguous()</span><br><span class="line">        hid = hid[:, original_idx.long()].contiguous()</span><br><span class="line">        </span><br><span class="line">        hid = torch.cat([hid[<span class="number">-2</span>], hid[<span class="number">-1</span>]], dim=<span class="number">1</span>)</span><br><span class="line">        hid = torch.tanh(self.fc(hid)).unsqueeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out, hid</span><br></pre></td></tr></table></figure><h4 id="Luong-Attention"><a href="#Luong-Attention" class="headerlink" title="Luong Attention"></a>Luong Attention</h4><ul><li>æ ¹æ®context vectorså’Œå½“å‰çš„è¾“å‡ºhidden statesï¼Œè®¡ç®—è¾“å‡º</li></ul><p>In [0]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Attention</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, enc_hidden_size, dec_hidden_size)</span>:</span></span><br><span class="line">        super(Attention, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.enc_hidden_size = enc_hidden_size</span><br><span class="line">        self.dec_hidden_size = dec_hidden_size</span><br><span class="line"></span><br><span class="line">        self.linear_in = nn.Linear(enc_hidden_size*<span class="number">2</span>, dec_hidden_size, bias=<span class="literal">False</span>)</span><br><span class="line">        self.linear_out = nn.Linear(enc_hidden_size*<span class="number">2</span> + dec_hidden_size, dec_hidden_size)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, output, context, mask)</span>:</span></span><br><span class="line">        <span class="comment"># output: batch_size, output_len, dec_hidden_size</span></span><br><span class="line">        <span class="comment"># context: batch_size, context_len, 2*enc_hidden_size</span></span><br><span class="line">    </span><br><span class="line">        batch_size = output.size(<span class="number">0</span>)</span><br><span class="line">        output_len = output.size(<span class="number">1</span>)</span><br><span class="line">        input_len = context.size(<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        context_in = self.linear_in(context.view(batch_size*input_len, <span class="number">-1</span>)).view(                </span><br><span class="line">            batch_size, input_len, <span class="number">-1</span>) <span class="comment"># batch_size, context_len, dec_hidden_size</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># context_in.transpose(1,2): batch_size, dec_hidden_size, context_len </span></span><br><span class="line">        <span class="comment"># output: batch_size, output_len, dec_hidden_size</span></span><br><span class="line">        attn = torch.bmm(output, context_in.transpose(<span class="number">1</span>,<span class="number">2</span>)) </span><br><span class="line">        <span class="comment"># batch_size, output_len, context_len</span></span><br><span class="line"></span><br><span class="line">        attn.data.masked_fill(mask, <span class="number">-1e6</span>)</span><br><span class="line"></span><br><span class="line">        attn = F.softmax(attn, dim=<span class="number">2</span>) </span><br><span class="line">        <span class="comment"># batch_size, output_len, context_len</span></span><br><span class="line"></span><br><span class="line">        context = torch.bmm(attn, context) </span><br><span class="line">        <span class="comment"># batch_size, output_len, enc_hidden_size</span></span><br><span class="line">        </span><br><span class="line">        output = torch.cat((context, output), dim=<span class="number">2</span>) <span class="comment"># batch_size, output_len, hidden_size*2</span></span><br><span class="line"></span><br><span class="line">        output = output.view(batch_size*output_len, <span class="number">-1</span>)</span><br><span class="line">        output = torch.tanh(self.linear_out(output))</span><br><span class="line">        output = output.view(batch_size, output_len, <span class="number">-1</span>)</span><br><span class="line">        <span class="keyword">return</span> output, attn</span><br></pre></td></tr></table></figure><h4 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h4><ul><li>decoderä¼šæ ¹æ®å·²ç»ç¿»è¯‘çš„å¥å­å†…å®¹ï¼Œå’Œcontext vectorsï¼Œæ¥å†³å®šä¸‹ä¸€ä¸ªè¾“å‡ºçš„å•è¯</li></ul><p>In [0]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Decoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, vocab_size, embed_size, enc_hidden_size, dec_hidden_size, dropout=<span class="number">0.2</span>)</span>:</span></span><br><span class="line">        super(Decoder, self).__init__()</span><br><span class="line">        self.embed = nn.Embedding(vocab_size, embed_size)</span><br><span class="line">        self.attention = Attention(enc_hidden_size, dec_hidden_size)</span><br><span class="line">        self.rnn = nn.GRU(embed_size, hidden_size, batch_first=<span class="literal">True</span>)</span><br><span class="line">        self.out = nn.Linear(dec_hidden_size, vocab_size)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">create_mask</span><span class="params">(self, x_len, y_len)</span>:</span></span><br><span class="line">        <span class="comment"># a mask of shape x_len * y_len</span></span><br><span class="line">        device = x_len.device</span><br><span class="line">        max_x_len = x_len.max()</span><br><span class="line">        max_y_len = y_len.max()</span><br><span class="line">        x_mask = torch.arange(max_x_len, device=x_len.device)[<span class="literal">None</span>, :] &lt; x_len[:, <span class="literal">None</span>]</span><br><span class="line">        y_mask = torch.arange(max_y_len, device=x_len.device)[<span class="literal">None</span>, :] &lt; y_len[:, <span class="literal">None</span>]</span><br><span class="line">        mask = (<span class="number">1</span> - x_mask[:, :, <span class="literal">None</span>] * y_mask[:, <span class="literal">None</span>, :]).byte()</span><br><span class="line">        <span class="keyword">return</span> mask</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, ctx, ctx_lengths, y, y_lengths, hid)</span>:</span></span><br><span class="line">        sorted_len, sorted_idx = y_lengths.sort(<span class="number">0</span>, descending=<span class="literal">True</span>)</span><br><span class="line">        y_sorted = y[sorted_idx.long()]</span><br><span class="line">        hid = hid[:, sorted_idx.long()]</span><br><span class="line">        </span><br><span class="line">        y_sorted = self.dropout(self.embed(y_sorted)) <span class="comment"># batch_size, output_length, embed_size</span></span><br><span class="line"></span><br><span class="line">        packed_seq = nn.utils.rnn.pack_padded_sequence(y_sorted, sorted_len.long().cpu().data.numpy(), batch_first=<span class="literal">True</span>)</span><br><span class="line">        out, hid = self.rnn(packed_seq, hid)</span><br><span class="line">        unpacked, _ = nn.utils.rnn.pad_packed_sequence(out, batch_first=<span class="literal">True</span>)</span><br><span class="line">        _, original_idx = sorted_idx.sort(<span class="number">0</span>, descending=<span class="literal">False</span>)</span><br><span class="line">        output_seq = unpacked[original_idx.long()].contiguous()</span><br><span class="line">        hid = hid[:, original_idx.long()].contiguous()</span><br><span class="line"></span><br><span class="line">        mask = self.create_mask(y_lengths, ctx_lengths)</span><br><span class="line"></span><br><span class="line">        output, attn = self.attention(output_seq, ctx, mask)</span><br><span class="line">        output = F.log_softmax(self.out(output), <span class="number">-1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> output, hid, attn</span><br></pre></td></tr></table></figure><h4 id="Seq2Seq"><a href="#Seq2Seq" class="headerlink" title="Seq2Seq"></a>Seq2Seq</h4><ul><li>æœ€åæˆ‘ä»¬æ„å»ºSeq2Seqæ¨¡å‹æŠŠencoder, attention, decoderä¸²åˆ°ä¸€èµ·</li></ul><p>In [0]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Seq2Seq</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, encoder, decoder)</span>:</span></span><br><span class="line">        super(Seq2Seq, self).__init__()</span><br><span class="line">        self.encoder = encoder</span><br><span class="line">        self.decoder = decoder</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, x_lengths, y, y_lengths)</span>:</span></span><br><span class="line">        encoder_out, hid = self.encoder(x, x_lengths)</span><br><span class="line">        output, hid, attn = self.decoder(ctx=encoder_out, </span><br><span class="line">                    ctx_lengths=x_lengths,</span><br><span class="line">                    y=y,</span><br><span class="line">                    y_lengths=y_lengths,</span><br><span class="line">                    hid=hid)</span><br><span class="line">        <span class="keyword">return</span> output, attn</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">translate</span><span class="params">(self, x, x_lengths, y, max_length=<span class="number">100</span>)</span>:</span></span><br><span class="line">        encoder_out, hid = self.encoder(x, x_lengths)</span><br><span class="line">        preds = []</span><br><span class="line">        batch_size = x.shape[<span class="number">0</span>]</span><br><span class="line">        attns = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(max_length):</span><br><span class="line">            output, hid, attn = self.decoder(ctx=encoder_out, </span><br><span class="line">                    ctx_lengths=x_lengths,</span><br><span class="line">                    y=y,</span><br><span class="line">                    y_lengths=torch.ones(batch_size).long().to(y.device),</span><br><span class="line">                    hid=hid)</span><br><span class="line">            y = output.max(<span class="number">2</span>)[<span class="number">1</span>].view(batch_size, <span class="number">1</span>)</span><br><span class="line">            preds.append(y)</span><br><span class="line">            attns.append(attn)</span><br><span class="line">        <span class="keyword">return</span> torch.cat(preds, <span class="number">1</span>), torch.cat(attns, <span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>è®­ç»ƒ</p><p>In [0]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">dropout = <span class="number">0.2</span></span><br><span class="line">embed_size = hidden_size = <span class="number">100</span></span><br><span class="line">encoder = Encoder(vocab_size=en_total_words,</span><br><span class="line">                       embed_size=embed_size,</span><br><span class="line">                      enc_hidden_size=hidden_size,</span><br><span class="line">                       dec_hidden_size=hidden_size,</span><br><span class="line">                      dropout=dropout)</span><br><span class="line">decoder = Decoder(vocab_size=cn_total_words,</span><br><span class="line">                      embed_size=embed_size,</span><br><span class="line">                      enc_hidden_size=hidden_size,</span><br><span class="line">                       dec_hidden_size=hidden_size,</span><br><span class="line">                      dropout=dropout)</span><br><span class="line">model = Seq2Seq(encoder, decoder)</span><br><span class="line">model = model.to(device)</span><br><span class="line">loss_fn = LanguageModelCriterion().to(device)</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters())</span><br></pre></td></tr></table></figure><p>In [2]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train(model, train_data, num_epochs=30)</span><br></pre></td></tr></table></figure><p>In [0]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for i in range(100,120):</span><br><span class="line">    translate_dev(i)</span><br><span class="line">    print()</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">BOS you have nice skin . EOS</span><br><span class="line">BOS ä½  çš„ çš® è†š çœŸ å¥½ ã€‚ EOS</span><br><span class="line">ä½ å¥½å®³æ€•ã€‚</span><br><span class="line"></span><br><span class="line">BOS you &apos;re UNK correct . EOS</span><br><span class="line">BOS ä½  éƒ¨ åˆ† æ­£ ç¡® ã€‚ EOS</span><br><span class="line">ä½ æ˜¯å…¨å­çš„å£°éŸ³ã€‚</span><br><span class="line"></span><br><span class="line">BOS everyone admired his courage . EOS</span><br><span class="line">BOS æ¯ å€‹ äºº éƒ½ ä½© æœ ä»– çš„ å‹‡ æ°£ ã€‚ EOS</span><br><span class="line">ä»–çš„è¢‹å­æ˜¯ä»–çš„å‹‡æ°£ã€‚</span><br><span class="line"></span><br><span class="line">BOS what time is it ? EOS</span><br><span class="line">BOS å‡  ç‚¹ äº† ï¼Ÿ EOS</span><br><span class="line">å¤šå°‘æ—¶é—´æ˜¯ä»€ä¹ˆï¼Ÿ</span><br><span class="line"></span><br><span class="line">BOS i &apos;m free tonight . EOS</span><br><span class="line">BOS æˆ‘ ä»Š æ™š æœ‰ ç©º ã€‚ EOS</span><br><span class="line">æˆ‘ä»Šæ™šæœ‰ç©ºã€‚</span><br><span class="line"></span><br><span class="line">BOS here is your book . EOS</span><br><span class="line">BOS é€™ æ˜¯ ä½  çš„ æ›¸ ã€‚ EOS</span><br><span class="line">è¿™å„¿æ˜¯ä½ çš„ä¹¦ã€‚</span><br><span class="line"></span><br><span class="line">BOS they are at lunch . EOS</span><br><span class="line">BOS ä»– ä»¬ åœ¨ åƒ åˆ é¥­ ã€‚ EOS</span><br><span class="line">ä»–ä»¬åœ¨åˆé¤ã€‚</span><br><span class="line"></span><br><span class="line">BOS this chair is UNK . EOS</span><br><span class="line">BOS é€™ æŠŠ æ¤… å­ å¾ˆ UNK ã€‚ EOS</span><br><span class="line">é€™äº›èŠ±ä¸€ä¸‹æ˜¯æ­£åœ¨çš„ã€‚</span><br><span class="line"></span><br><span class="line">BOS it &apos;s pretty heavy . EOS</span><br><span class="line">BOS å®ƒ çœŸ é‡ ã€‚ EOS</span><br><span class="line">å®ƒå¾ˆç¾çš„è„šã€‚</span><br><span class="line"></span><br><span class="line">BOS many attended his funeral . EOS</span><br><span class="line">BOS å¾ˆ å¤š äºº éƒ½ å‚ åŠ  äº† ä»– çš„ è‘¬ ç¤¼ ã€‚ EOS</span><br><span class="line">å¤šå¤šè¡›å¹´è½»åœ°äº†ä»–ã€‚</span><br><span class="line"></span><br><span class="line">BOS training will be provided . EOS</span><br><span class="line">BOS ä¼š æœ‰ è®­ ç»ƒ ã€‚ EOS</span><br><span class="line">åˆ«å°†è¢«ä»˜éŒ¢ã€‚</span><br><span class="line"></span><br><span class="line">BOS someone is watching you . EOS</span><br><span class="line">BOS æœ‰ äºº åœ¨ çœ‹ è‘— ä½  ã€‚ EOS</span><br><span class="line">æœ‰äººçœ‹ä½ ã€‚</span><br><span class="line"></span><br><span class="line">BOS i slapped his face . EOS</span><br><span class="line">BOS æˆ‘ æ‘‘ äº† ä»– çš„ è‡‰ ã€‚ EOS</span><br><span class="line">æˆ‘æŠŠä»–çš„è‡‰æŠ±æ­‰ã€‚</span><br><span class="line"></span><br><span class="line">BOS i like UNK music . EOS</span><br><span class="line">BOS æˆ‘ å–œ æ­¡ æµ è¡Œ éŸ³ æ¨‚ ã€‚ EOS</span><br><span class="line">æˆ‘å–œæ­¡éŸ³æ¨‚ã€‚</span><br><span class="line"></span><br><span class="line">BOS tom had no children . EOS</span><br><span class="line">BOS T o m æ²’ æœ‰ å­© å­ ã€‚ EOS</span><br><span class="line">æ±¤å§†æ²¡æœ‰ç…§é¡§å­©å­ã€‚</span><br><span class="line"></span><br><span class="line">BOS please lock the door . EOS</span><br><span class="line">BOS è«‹ æŠŠ é–€ é– ä¸Š ã€‚ EOS</span><br><span class="line">è¯·æŠŠé–€é–‹é–€ã€‚</span><br><span class="line"></span><br><span class="line">BOS tom has calmed down . EOS</span><br><span class="line">BOS æ±¤ å§† å†· é™ ä¸‹ æ¥ äº† ã€‚ EOS</span><br><span class="line">æ±¤å§†åœ¨åšäº†ã€‚</span><br><span class="line"></span><br><span class="line">BOS please speak more loudly . EOS</span><br><span class="line">BOS è«‹ èªª å¤§ è² ä¸€ é» å…’ ã€‚ EOS</span><br><span class="line">è«‹èªªæ›´å¤šã€‚</span><br><span class="line"></span><br><span class="line">BOS keep next sunday free . EOS</span><br><span class="line">BOS æŠŠ ä¸‹ å‘¨ æ—¥ ç©º å‡º æ¥ ã€‚ EOS</span><br><span class="line">ç¹¼çºŒä¸‹é€±ä¸€ä¸‹ä¸€æ­¥ã€‚</span><br><span class="line"></span><br><span class="line">BOS i made a mistake . EOS</span><br><span class="line">BOS æˆ‘ çŠ¯ äº† ä¸€ å€‹ éŒ¯ ã€‚ EOS</span><br><span class="line">æˆ‘åšäº†ä¸€ä»¶äº‹ã€‚</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Seq2Seq </tag>
            
            <tag> Attention </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>æœºå™¨ç¿»è¯‘ä¸æ–‡æœ¬æ‘˜è¦</title>
      <link href="/2020/04/09/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E4%B8%8E%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81/"/>
      <url>/2020/04/09/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E4%B8%8E%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81/</url>
      
        <content type="html"><![CDATA[<h1 id="æœºå™¨ç¿»è¯‘"><a href="#æœºå™¨ç¿»è¯‘" class="headerlink" title="æœºå™¨ç¿»è¯‘"></a>æœºå™¨ç¿»è¯‘</h1><p><img src="https://uploader.shimo.im/f/brdWUlzu4FsL8Owh.png!thumbnail" alt="img"></p><p><img src="https://uploader.shimo.im/f/L7hZdGTE2Rw7LaK7.png!thumbnail" alt="img"></p><p><img src="https://uploader.shimo.im/f/khdZXF2WzdUjtnfh.png!thumbnail" alt="img"></p><h1 id><a href="#" class="headerlink" title></a><img src="https://uploader.shimo.im/f/OA9BcNUkI4USlE4s.png!thumbnail" alt="img"></h1><p>ç°åœ¨çš„<strong>æœºå™¨ç¿»è¯‘æ¨¡å‹éƒ½æ˜¯ç”±æ•°æ®é©±åŠ¨</strong>çš„ã€‚ä»€ä¹ˆæ•°æ®ï¼Ÿ</p><ul><li><p>æ–°é—»</p></li><li><p>å…¬å¸ç½‘é¡µ</p></li><li><p>æ³•å¾‹/ä¸“åˆ©æ–‡ä»¶ï¼Œè”åˆå›½documents</p></li><li><p>ç”µå½±/ç”µè§†å­—å¹•</p></li></ul><p>IBM fire a linguist, their machine translation system improves by 1%</p><p>Parallel Data</p><ul><li><p>æˆ‘ä»¬å¸Œæœ›ä½¿ç”¨åŒè¯­çš„ï¼Œæœ‰å¯¹åº”å…³ç³»çš„æ•°æ®</p></li><li><p>å¤§éƒ¨åˆ†æ•°æ®éƒ½æ˜¯ç”±æ–‡æ¡£çº§åˆ«çš„</p></li></ul><p>å¦‚ä½•<strong>è¯„ä¼°</strong>ç¿»è¯‘æ¨¡å‹ï¼Ÿ</p><ul><li><p><strong>äººå·¥è¯„ä¼°</strong>æœ€å¥½ï¼Œä½†æ˜¯éå¸¸<strong>è´¹æ—¶è´¹åŠ›</strong></p></li><li><p>è¿˜æœ‰å“ªäº›é—®é¢˜éœ€è¦äººç±»è¯„ä¼°ï¼Ÿ</p></li><li><p>éœ€è¦ä¸€äº›è‡ªåŠ¨è¯„ä¼°çš„æ‰‹æ®µ</p></li><li><p><strong>BLUE</strong> (Bilingual Evaluation Understudy), Papineni et al. (2002)</p></li><li><p>è®¡ç®—ç³»ç»Ÿç”Ÿæˆç¿»è¯‘ä¸äººç±»å‚è€ƒç¿»è¯‘ä¹‹é—´çš„n-gram overlap</p></li><li><p>BLEU scoreä¸<strong>äººç±»è¯„æµ‹çš„ç›¸å…³åº¦éå¸¸é«˜</strong></p></li><li><p><a href="https://www.aclweb.org/anthology/P02-1040.pdf" target="_blank" rel="noopener">https://www.aclweb.org/anthology/P02-1040.pdf</a></p></li><li><p>precision based metric</p></li><li><p>è‡ªåŠ¨è¯„ä¼°ä¾ç„¶æ˜¯ä¸€ä¸ª<strong>æœ‰ä»·å€¼çš„ç ”ç©¶é—®é¢˜</strong></p></li></ul><p>precision: åœ¨æˆ‘ç¿»è¯‘çš„å•è¯å½“ä¸­ï¼Œæœ‰å“ªäº›å•è¯æ˜¯æ­£ç¡®çš„ã€‚</p><p>unigram, bigram, trigram, 4-gram precision </p><p><strong>BLEU-4</strong>: average of the 4 kinds of grams</p><p><strong>BLEU-3</strong></p><p>ç»Ÿè®¡å­¦ç¿»è¯‘æ¨¡å‹</p><p><img src="https://uploader.shimo.im/f/phryZdcQGH8Z5i5V.png!thumbnail" alt="img"></p><p>Encoder-decoder æ¨¡å‹</p><p>xï¼šè‹±æ–‡</p><p><strong>yï¼šä¸­æ–‡</strong></p><p>P(y|x) x: noisy input</p><p><img src="https://uploader.shimo.im/f/1zBNjrukMK8ennr8.png!thumbnail" alt="img"></p><p>P(y|x) = P(x, y) / P(x) = P(x|y)P(y) / P(x)</p><p>argmax_y P(y|x) = <strong>argmax_y P(x|y)P(y)</strong></p><p><strong>P(x|y)</strong> </p><p><strong>P(y)</strong></p><h2 id="Encoder-Decoder-Model"><a href="#Encoder-Decoder-Model" class="headerlink" title="Encoder-Decoder Model"></a>Encoder-Decoder Model</h2><p><img src="https://uploader.shimo.im/f/fSgtSMHGwlsMwqR8.png!thumbnail" alt="img"></p><p><img src="https://uploader.shimo.im/f/NJXXeu6kA4QJzzj3.png!thumbnail" alt="img"></p><p>RNN(x) â€“&gt; c (<strong>cèƒ½å¤Ÿå®Œå…¨åŒ…å«æ•´ä¸ªå¥å­çš„ä¿¡æ¯?</strong>ï¼‰</p><p>RNN(c) â€“&gt; y (cä½œä¸ºè¾“å…¥è¿›å…¥æ¯ä¸€ä¸ªdecoding step)</p><p>è®­ç»ƒæ–¹å¼æ˜¯ä»€ä¹ˆï¼ŸæŸå¤±å‡½æ•°æ˜¯ä»€ä¹ˆï¼Ÿ</p><ul><li><p>cross entropy lossï¼Œ ä½œä¸šä¸€ä¸­çš„contextæ¨¡å‹</p></li><li><p>SGD, Adam</p></li></ul><p>GRU</p><p><a href="https://arxiv.org/pdf/1406.1078.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1406.1078.pdf</a></p><p><img src="https://uploader.shimo.im/f/UBhRdKWsAvEKpbz0.png!thumbnail" alt="img"></p><p><img src="https://uploader.shimo.im/f/eF9pRfBLFSQi5NHd.png!thumbnail" alt="img"></p><h2 id="Attentionæœºåˆ¶"><a href="#Attentionæœºåˆ¶" class="headerlink" title="Attentionæœºåˆ¶"></a>Attentionæœºåˆ¶</h2><p><img src="https://uploader.shimo.im/f/CkL5KNLrUQE2tzH4.png!thumbnail" alt="img"></p><p><img src="https://uploader.shimo.im/f/JQtrWTdEgiURNKTX.png!thumbnail" alt="img"></p><p>å›¾ç‰‡æ¥è‡ª Bahdanau et al., Neural Machine Translation by Jointly Learning to Align and Translate <a href="https://arxiv.org/pdf/1409.0473.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1409.0473.pdf</a></p><h2 id="-1"><a href="#-1" class="headerlink" title></a><img src="https://uploader.shimo.im/f/dWsWHO9MF20QJ2kI.png!thumbnail" alt="img"></h2><p><img src="https://uploader.shimo.im/f/KRbuH9pTLpoNLHN7.png!thumbnail" alt="img"></p><p>å›¾ç‰‡æ¥è‡ªLuong et al., Effective Approaches to Attention-based Neural Machine Translation</p><p><a href="https://arxiv.org/pdf/1508.04025.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1508.04025.pdf</a></p><p>Google Neural Machine Translation</p><p><a href="https://arxiv.org/pdf/1609.08144.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1609.08144.pdf</a></p><p><img src="https://uploader.shimo.im/f/en9dH9PnTeoPDMMv.png!thumbnail" alt="img"></p><p><img src="https://uploader.shimo.im/f/W8BSXh4U2Kc8ZKjL.png!thumbnail" alt="img"></p><p><img src="https://uploader.shimo.im/f/vpGOGoKHN5AQvKiB.png!thumbnail" alt="img"></p><h2 id="Zero-shot-NMT"><a href="#Zero-shot-NMT" class="headerlink" title="Zero-shot NMT"></a>Zero-shot NMT</h2><p><img src="https://uploader.shimo.im/f/I5SzyIfYl6sfFUoA.png!thumbnail" alt="img"></p><p><img src="https://uploader.shimo.im/f/v9nmM5q6jDoyq7ZR.png!thumbnail" alt="img"></p><h2 id="Transformeræ¨¡å‹"><a href="#Transformeræ¨¡å‹" class="headerlink" title="Transformeræ¨¡å‹"></a>Transformeræ¨¡å‹</h2><p><a href="https://shimo.im/docs/gPwkqCXrkJyRW89V" target="_blank" rel="noopener">https://shimo.im/docs/gPwkqCXrkJyRW89V</a></p><p>è¿™ä¸ªæ¨¡å‹éå¸¸é‡è¦</p><p>æ¨¡å‹ x â€“&gt; encoder decoder model â€“&gt; \hat{y}</p><p>cross entropy loss (\hat{y}, y)</p><p>è®­ç»ƒ P(y_i | x, <strong>y_1, â€¦, y_{i-1}</strong>) è®­ç»ƒçš„æ—¶å€™ï¼Œæˆ‘ä»¬çŸ¥é“y_1 â€¦ y_{i-1}</p><p>åœ¨é¢„æµ‹çš„æ—¶å€™ï¼Œæˆ‘ä»¬ä¸çŸ¥é“y_1 â€¦ y_{i-1}</p><p>æ€ä¹ˆæ ·ç»Ÿä¸€è®­ç»ƒå’Œæµ‹è¯•</p><h2 id="Model-Inference"><a href="#Model-Inference" class="headerlink" title="Model Inference"></a>Model Inference</h2><p>åœ¨å„ç±»æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œå…¶å®æ–‡æœ¬çš„ç”Ÿæˆä¸è®­ç»ƒæ˜¯ä¸¤ç§ä¸åŒçš„æƒ…å½¢ã€‚åœ¨è®­ç»ƒçš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å‡è®¾æ¨¡å‹åœ¨ç”Ÿæˆä¸‹ä¸€ä¸ªå•è¯çš„æ—¶å€™çŸ¥é“æ‰€æœ‰ä¹‹å‰çš„å•è¯ï¼ˆgroud truthï¼‰ã€‚ç„¶è€Œåœ¨çœŸæ­£ä½¿ç”¨æ¨¡å‹ç”Ÿæˆæ–‡æœ¬çš„æ—¶å€™ï¼Œæ¯ä¸€æ­¥ç”Ÿæˆçš„æ–‡æœ¬éƒ½æ¥è‡ªäºæ¨¡å‹æœ¬èº«ã€‚è¿™å…¶ä¸­è®­ç»ƒå’Œé¢„æµ‹çš„ä¸åŒå¯¼è‡´äº†æ¨¡å‹çš„æ•ˆæœå¯èƒ½ä¼šå¾ˆå·®ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œäººä»¬å‘æ˜äº†å„ç§æå‡æ¨¡å‹é¢„æµ‹æ°´å¹³çš„æ–¹æ³•ï¼Œä¾‹å¦‚Beam Searchã€‚</p><p><strong>Beam Search</strong></p><p>Kyunghyun Cho Lecture Notes Page 94-96 <a href="https://arxiv.org/pdf/1511.07916.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1511.07916.pdf</a></p><p>Encoder(æˆ‘å–œæ¬¢è‡ªç„¶è¯­è¨€å¤„ç†) â€“&gt; c</p><p>Decoder(c) â€“&gt; y_1</p><p>Decoder(c, y_1) â€“&gt; y_2</p><p>Decoder(c, y_1, y_2) â€“&gt; y_3</p><p>â€¦..</p><p>EOS</p><p>argmax_y P(y|x) </p><p>greedy search</p><p>argmax y_1</p><p>Beam æ¨ªæ¢</p><p>â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”</p><p>ä¸€ç§å›ºå®šå®½åº¦çš„è£…ç½®</p><p>â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”</p><p>åœ¨åç»­çš„è¯¾ç¨‹ä¸­æˆ‘ä»¬è¿˜ä¼šä»‹ç»ä¸€äº›åˆ«çš„æ–¹æ³•ç”¨äºç”Ÿæˆæ–‡æœ¬ã€‚</p><p>ç¾å›½æ€»ç»Ÿå’Œä¸­å›½ä¸»å¸­æ‰“ç”µè¯</p><p>â€“&gt; K = æ— ç©·å¤§ |V|^seq_len</p><p>American, U.S. , United</p><p>â€¦.</p><p>decoding step: K</p><p>K x |V| â€“&gt; K</p><p>K x |V| â€“&gt; K</p><h2 id="å¼€æºé¡¹ç›®"><a href="#å¼€æºé¡¹ç›®" class="headerlink" title="å¼€æºé¡¹ç›®"></a>å¼€æºé¡¹ç›®</h2><p>FairSeq <a href="https://github.com/pytorch/fairseq" target="_blank" rel="noopener">https://github.com/pytorch/fairseq</a></p><p>Tensor2Tensor <a href="https://github.com/tensorflow/tensor2tensor" target="_blank" rel="noopener">https://github.com/tensorflow/tensor2tensor</a></p><p>Trax <a href="https://github.com/google/trax" target="_blank" rel="noopener">https://github.com/google/trax</a></p><h1 id="æ–‡æœ¬æ‘˜è¦"><a href="#æ–‡æœ¬æ‘˜è¦" class="headerlink" title="æ–‡æœ¬æ‘˜è¦"></a>æ–‡æœ¬æ‘˜è¦</h1><p>æ–‡æœ¬æ‘˜è¦è¿™ä¸ªä»»åŠ¡å®šä¹‰éå¸¸ç®€å•ï¼Œç»™å®šä¸€æ®µé•¿æ–‡ç« ï¼Œæˆ‘ä»¬å¸Œæœ›ç”Ÿæˆä¸€æ®µæ¯”è¾ƒç²¾ç®€çš„æ–‡æœ¬æ‘˜è¦ï¼Œå¯ä»¥è¦†ç›–æ•´ç¯‡æ–‡ç« çš„ä¿¡æ¯ã€‚</p><p>æ–‡æœ¬æ‘˜è¦æŒ‰ç…§ä»»åŠ¡çš„å®šä¹‰å¤§è‡´å¯ä»¥åˆ†ä¸ºä¸¤ç±»ã€‚</p><ul><li><p>æŠ½å–å¼ï¼šç»™å®šä¸€ä¸ªåŒ…å«å¤šä¸ªå¥å­çš„é•¿æ–‡æœ¬ï¼Œé€‰æ‹©å…¶ä¸­çš„ä¸€äº›å¥å­ä½œä¸ºçŸ­æ–‡æœ¬ã€‚è¿™æœ¬è´¨ä¸Šæ˜¯ä¸ªåˆ†ç±»é—®é¢˜ï¼Œä¹Ÿå°±æ˜¯åˆ¤æ–­å“ªäº›å¥å­éœ€è¦ä¿ç•™ï¼Œå“ªäº›å¥å­éœ€è¦ä¸¢å¼ƒã€‚<strong>äºŒåˆ†ç±»ä»»åŠ¡</strong></p></li><li><p>ç”Ÿæˆå¼ï¼šä¸æŠ½å–å¼æ–‡æœ¬æ‘˜è¦ä¸åŒï¼Œè¿™é‡Œæˆ‘ä»¬ä¸ä»…ä»…æ˜¯å¸Œæœ›é€‰å‡ºä¸€äº›å¥å­ï¼Œè€Œæ˜¯å¸Œæœ›èƒ½å¤Ÿæ€»ç»“å½’çº³æ–‡æœ¬çš„ä¿¡æ¯ï¼Œç”¨è‡ªå·±çš„è¯å¤è¿°ä¸€éã€‚<strong>ç›´æ¥ä¸Štransformeræ¨¡å‹</strong></p></li></ul><p>gold standard</p><p>è¯„ä¼°æ‰‹æ®µ: <strong>ROUGE</strong></p><p>ROUGEè¯„ä¼°çš„æ˜¯ç³»ç»Ÿç”Ÿæˆæ–‡æœ¬å’Œå‚è€ƒæ–‡æœ¬ä¹‹é—´ n-gram overlap çš„ recallã€‚</p><p><strong>Candidate</strong> Summary</p><p>the cat was found under the bed</p><p><strong>Reference</strong> Summary</p><p>the cat was under the bed</p><p>é’ˆå¯¹è¿™ä¸€ä¸ªä¾‹å­ï¼ŒROUGE-1åˆ†æ•°ä¸º1ï¼Œ ROUGE-2ä¸º4/5ã€‚</p><p>s: the cat was found under the bed</p><p>p: <strong>the cat was under the bed</strong></p><p>ROUGE-Lï¼ŒåŸºäº longest common subsequenceçš„F1 score</p><p>ä¾‹å¦‚ä¸Šé¢è¿™ä¸ªæ¡ˆä¾‹ LCS  = 6</p><p>P = 6/7 </p><p>R = 6/6</p><p>F1 = 2 / (6/6 + 7/6 )  = 12/13</p><p>harmoic mean</p><p><img src="https://uploader.shimo.im/f/oNU6qvIsXX8cK7Ta.png!thumbnail" alt="img"></p><p><img src="https://uploader.shimo.im/f/65Raa96bt7kl0ldv.png!thumbnail" alt="img"></p><p><a href="https://arxiv.org/pdf/1908.08345.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1908.08345.pdf</a></p><p><img src="https://uploader.shimo.im/f/8YQylm0VFkgRXqzU.png!thumbnail" alt="img"></p><p><img src="https://uploader.shimo.im/f/vC7ZiGFfsBInlMtQ.png!thumbnail" alt="img"></p><p>ä¸ŠæœŸå­¦å‘˜çš„åšå®¢</p><p><a href="https://blog.csdn.net/Chen_Meng_/article/details/103756716" target="_blank" rel="noopener">https://blog.csdn.net/Chen_Meng_/article/details/103756716</a></p><p>CopyNet</p><p><a href="https://arxiv.org/pdf/1603.06393.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1603.06393.pdf</a></p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GRU </tag>
            
            <tag> BLUE </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>sentimentæƒ…æ„Ÿåˆ†æä»£ç æ³¨é‡Š</title>
      <link href="/2020/03/28/sentiment%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90%E4%BB%A3%E7%A0%81%E6%B3%A8%E9%87%8A/"/>
      <url>/2020/03/28/sentiment%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90%E4%BB%A3%E7%A0%81%E6%B3%A8%E9%87%8A/</url>
      
        <content type="html"><![CDATA[<h2 id="æƒ…æ„Ÿåˆ†æ"><a href="#æƒ…æ„Ÿåˆ†æ" class="headerlink" title="æƒ…æ„Ÿåˆ†æ"></a>æƒ…æ„Ÿåˆ†æ</h2><h3 id="ç¬¬ä¸€æ­¥ï¼šå¯¼å…¥è±†ç“£ç”µå½±æ•°æ®é›†ï¼Œåªæœ‰è®­ç»ƒé›†å’Œæµ‹è¯•é›†"><a href="#ç¬¬ä¸€æ­¥ï¼šå¯¼å…¥è±†ç“£ç”µå½±æ•°æ®é›†ï¼Œåªæœ‰è®­ç»ƒé›†å’Œæµ‹è¯•é›†" class="headerlink" title="ç¬¬ä¸€æ­¥ï¼šå¯¼å…¥è±†ç“£ç”µå½±æ•°æ®é›†ï¼Œåªæœ‰è®­ç»ƒé›†å’Œæµ‹è¯•é›†"></a>ç¬¬ä¸€æ­¥ï¼šå¯¼å…¥è±†ç“£ç”µå½±æ•°æ®é›†ï¼Œåªæœ‰è®­ç»ƒé›†å’Œæµ‹è¯•é›†</h3><ul><li><p>TorchTextä¸­çš„ä¸€ä¸ªé‡è¦æ¦‚å¿µæ˜¯<code>Field</code>ã€‚<code>Field</code>å†³å®šäº†ä½ çš„æ•°æ®ä¼šè¢«æ€æ ·å¤„ç†ã€‚åœ¨æˆ‘ä»¬çš„æƒ…æ„Ÿåˆ†ç±»ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬æ‰€éœ€è¦æ¥è§¦åˆ°çš„æ•°æ®æœ‰æ–‡æœ¬å­—ç¬¦ä¸²å’Œä¸¤ç§æƒ…æ„Ÿï¼Œâ€posâ€æˆ–è€…â€negâ€ã€‚</p></li><li><p><code>Field</code>çš„å‚æ•°åˆ¶å®šäº†æ•°æ®ä¼šè¢«æ€æ ·å¤„ç†ã€‚</p></li><li><p>æˆ‘ä»¬ä½¿ç”¨<code>TEXT</code> fieldæ¥å®šä¹‰å¦‚ä½•å¤„ç†ç”µå½±è¯„è®ºï¼Œä½¿ç”¨<code>LABEL</code> fieldæ¥å¤„ç†ä¸¤ä¸ªæƒ…æ„Ÿç±»åˆ«ã€‚</p></li><li><p>æˆ‘ä»¬çš„<code>TEXT</code> fieldå¸¦æœ‰<code>tokenize=&#39;spacy&#39;</code>ï¼Œè¿™è¡¨ç¤ºæˆ‘ä»¬ä¼šç”¨<a href="https://spacy.io/" target="_blank" rel="noopener">spaCy</a> tokenizeræ¥tokenizeè‹±æ–‡å¥å­ã€‚å¦‚æœæˆ‘ä»¬ä¸ç‰¹åˆ«å£°æ˜<code>tokenize</code>è¿™ä¸ªå‚æ•°ï¼Œé‚£ä¹ˆé»˜è®¤çš„åˆ†è¯æ–¹æ³•æ˜¯ä½¿ç”¨ç©ºæ ¼ã€‚</p></li><li><p>å®‰è£…spaCy</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install -U spacy</span><br><span class="line">python -m spacy download en</span><br></pre></td></tr></table></figure></li><li><p><code>LABEL</code>ç”±<code>LabelField</code>å®šä¹‰ã€‚è¿™æ˜¯ä¸€ç§ç‰¹åˆ«çš„ç”¨æ¥å¤„ç†labelçš„<code>Field</code>ã€‚æˆ‘ä»¬åé¢ä¼šè§£é‡Šdtypeã€‚</p></li><li><p>æ›´å¤šå…³äº<code>Fields</code>ï¼Œå‚è§<a href="https://github.com/pytorch/text/blob/master/torchtext/data/field.py" target="_blank" rel="noopener">https://github.com/pytorch/text/blob/master/torchtext/data/field.py</a></p></li><li><p>å’Œä¹‹å‰ä¸€æ ·ï¼Œæˆ‘ä»¬ä¼šè®¾å®šrandom seedsä½¿å®éªŒå¯ä»¥å¤ç°ã€‚</p></li><li><p>TorchTextæ”¯æŒå¾ˆå¤šå¸¸è§çš„è‡ªç„¶è¯­è¨€å¤„ç†æ•°æ®é›†ã€‚</p></li><li><p>ä¸‹é¢çš„ä»£ç ä¼šè‡ªåŠ¨ä¸‹è½½IMDbæ•°æ®é›†ï¼Œç„¶ååˆ†æˆtrain/testä¸¤ä¸ª<code>torchtext.datasets</code>ç±»åˆ«ã€‚æ•°æ®è¢«å‰é¢çš„<code>Fields</code>å¤„ç†ã€‚IMDbæ•°æ®é›†ä¸€å…±æœ‰50000ç”µå½±è¯„è®ºï¼Œæ¯ä¸ªè¯„è®ºéƒ½è¢«æ ‡æ³¨ä¸ºæ­£é¢çš„æˆ–è´Ÿé¢çš„ã€‚</p></li></ul><p><strong>å…ˆäº†è§£ä¸‹Spacyåº“ï¼š<a href="https://juejin.im/post/5971a4b9f265da6c42353332?utm_source=gold_browser_extension%5D" target="_blank" rel="noopener">spaCyä»‹ç»å’Œä½¿ç”¨æ•™ç¨‹</a></strong><br><strong>å†äº†è§£ä¸‹torchtextåº“ï¼š<a href="https://blog.csdn.net/u012436149/article/details/79310176" target="_blank" rel="noopener">torchtextä»‹ç»å’Œä½¿ç”¨æ•™ç¨‹</a>ï¼šè¿™ä¸ªæ–°æ‰‹å¿…çœ‹ï¼Œä¸çœ‹ä¸‹é¢ä»£ç å¬ä¸æ‡‚</strong></p><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!ls</span><br></pre></td></tr></table></figure><p>In [4]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchtext <span class="keyword">import</span> data</span><br><span class="line"></span><br><span class="line">SEED = <span class="number">1234</span></span><br><span class="line"></span><br><span class="line">torch.manual_seed(SEED) <span class="comment">#ä¸ºCPUè®¾ç½®éšæœºç§å­</span></span><br><span class="line">torch.cuda.manual_seed(SEED)<span class="comment">#ä¸ºGPUè®¾ç½®éšæœºç§å­</span></span><br><span class="line">torch.backends.cudnn.deterministic = <span class="literal">True</span>  <span class="comment">#åœ¨ç¨‹åºåˆšå¼€å§‹åŠ è¿™æ¡è¯­å¥å¯ä»¥æå‡ä¸€ç‚¹è®­ç»ƒé€Ÿåº¦ï¼Œæ²¡ä»€ä¹ˆé¢å¤–å¼€é”€ã€‚</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#é¦–å…ˆï¼Œæˆ‘ä»¬è¦åˆ›å»ºä¸¤ä¸ªField å¯¹è±¡ï¼šè¿™ä¸¤ä¸ªå¯¹è±¡åŒ…å«äº†æˆ‘ä»¬æ‰“ç®—å¦‚ä½•é¢„å¤„ç†æ–‡æœ¬æ•°æ®çš„ä¿¡æ¯ã€‚</span></span><br><span class="line">TEXT = data.Field(tokenize=<span class="string">'spacy'</span>)</span><br><span class="line"><span class="comment">#torchtext.data.Field : ç”¨æ¥å®šä¹‰å­—æ®µçš„å¤„ç†æ–¹æ³•ï¼ˆæ–‡æœ¬å­—æ®µï¼Œæ ‡ç­¾å­—æ®µï¼‰</span></span><br><span class="line"><span class="comment"># spaCy:è‹±è¯­åˆ†è¯å™¨,ç±»ä¼¼äºNLTKåº“ï¼Œå¦‚æœæ²¡æœ‰ä¼ é€’tokenizeå‚æ•°ï¼Œåˆ™é»˜è®¤åªæ˜¯åœ¨ç©ºæ ¼ä¸Šæ‹†åˆ†å­—ç¬¦ä¸²ã€‚</span></span><br><span class="line">LABEL = data.LabelField(dtype=torch.float)</span><br><span class="line"><span class="comment">#LabelFieldæ˜¯Fieldç±»çš„ä¸€ä¸ªç‰¹æ®Šå­é›†ï¼Œä¸“é—¨ç”¨äºå¤„ç†æ ‡ç­¾ã€‚</span></span><br></pre></td></tr></table></figure><p>In [2]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchtext <span class="keyword">import</span> datasets</span><br><span class="line">train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)</span><br><span class="line"><span class="comment"># åŠ è½½è±†ç“£ç”µå½±è¯„è®ºæ•°æ®é›†</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">downloading aclImdb_v1.tar.gz</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aclImdb_v1.tar.gz: <span class="number">100</span>%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| <span class="number">84.1</span>M/<span class="number">84.1</span>M [<span class="number">00</span>:<span class="number">03</span>&lt;<span class="number">00</span>:<span class="number">00</span>, <span class="number">22.8</span>MB/s]</span><br></pre></td></tr></table></figure><p>In [3]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(vars(train_data.examples[<span class="number">0</span>])) <span class="comment">#å¯ä»¥æŸ¥çœ‹æ•°æ®é›†é•¿å•¥æ ·å­</span></span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&apos;text&apos;: [&apos;This&apos;, &apos;movie&apos;, &apos;is&apos;, &apos;visually&apos;, &apos;stunning&apos;, &apos;.&apos;, &apos;Who&apos;, &apos;cares&apos;, &apos;if&apos;, &apos;she&apos;, &apos;can&apos;, &apos;act&apos;, &apos;or&apos;, &apos;not&apos;, &apos;.&apos;, &apos;Each&apos;, &apos;scene&apos;, &apos;is&apos;, &apos;a&apos;, &apos;work&apos;, &apos;of&apos;, &apos;art&apos;, &apos;composed&apos;, &apos;and&apos;, &apos;captured&apos;, &apos;by&apos;, &apos;John&apos;, &apos;Derek&apos;, &apos;.&apos;, &apos;The&apos;, &apos;locations&apos;, &apos;,&apos;, &apos;set&apos;, &apos;designs&apos;, &apos;,&apos;, &apos;and&apos;, &apos;costumes&apos;, &apos;function&apos;, &apos;perfectly&apos;, &apos;to&apos;, &apos;convey&apos;, &apos;what&apos;, &apos;is&apos;, &apos;found&apos;, &apos;in&apos;, &apos;a&apos;, &apos;love&apos;, &apos;story&apos;, &apos;comprised&apos;, &apos;of&apos;, &apos;beauty&apos;, &apos;,&apos;, &apos;youth&apos;, &apos;and&apos;, &apos;wealth&apos;, &apos;.&apos;, &apos;In&apos;, &apos;some&apos;, &apos;ways&apos;, &apos;I&apos;, &apos;would&apos;, &apos;like&apos;, &apos;to&apos;, &apos;see&apos;, &apos;this&apos;, &apos;movie&apos;, &apos;as&apos;, &apos;a&apos;, &apos;tribute&apos;, &apos;to&apos;, &apos;John&apos;, &apos;and&apos;, &apos;Bo&apos;, &apos;Derek&apos;, &quot;&apos;s&quot;, &apos;story&apos;, &apos;.&apos;, &apos;And&apos;, &apos;...&apos;, &apos;this&apos;, &apos;commentary&apos;, &apos;would&apos;, &apos;not&apos;, &apos;be&apos;, &apos;complete&apos;, &apos;without&apos;, &apos;mentioning&apos;, &apos;Anthony&apos;, &apos;Quinn&apos;, &quot;&apos;s&quot;, &apos;role&apos;, &apos;as&apos;, &apos;father&apos;, &apos;,&apos;, &apos;mentor&apos;, &apos;,&apos;, &apos;lover&apos;, &apos;,&apos;, &apos;and&apos;, &apos;his&apos;, &apos;portrayal&apos;, &apos;of&apos;, &apos;a&apos;, &apos;man&apos;, &apos;,&apos;, &apos;of&apos;, &apos;men&apos;, &apos;,&apos;, &apos;lost&apos;, &apos;to&apos;, &apos;a&apos;, &apos;bygone&apos;, &apos;era&apos;, &apos;when&apos;, &apos;men&apos;, &apos;were&apos;, &apos;men&apos;, &apos;.&apos;, &apos;There&apos;, &apos;are&apos;, &apos;some&apos;, &apos;of&apos;, &apos;us&apos;, &apos;who&apos;, &apos;find&apos;, &apos;value&apos;, &apos;in&apos;, &apos;strength&apos;, &apos;and&apos;, &apos;direction&apos;, &apos;wrapped&apos;, &apos;in&apos;, &apos;a&apos;, &apos;confidence&apos;, &apos;that&apos;, &apos;contributes&apos;, &apos;to&apos;, &apos;a&apos;, &apos;sense&apos;, &apos;of&apos;, &apos;confidence&apos;, &apos;,&apos;, &apos;containment&apos;, &apos;,&apos;, &apos;and&apos;, &apos;security&apos;, &apos;.&apos;, &apos;Yes&apos;, &apos;,&apos;, &apos;they&apos;, &apos;do&apos;, &apos;not&apos;, &apos;make&apos;, &apos;men&apos;, &apos;like&apos;, &apos;that&apos;, &apos;anymore&apos;, &apos;!&apos;, &apos;But&apos;, &apos;,&apos;, &apos;then&apos;, &apos;how&apos;, &apos;often&apos;, &apos;do&apos;, &apos;you&apos;, &apos;find&apos;, &apos;women&apos;, &apos;who&apos;, &apos;are&apos;, &apos;made&apos;, &apos;like&apos;, &apos;Bo&apos;, &apos;Derek&apos;, &apos;.&apos;], &apos;label&apos;: &apos;pos&apos;&#125;</span><br></pre></td></tr></table></figure><h2 id="ç¬¬äºŒæ­¥ï¼šè®­ç»ƒé›†åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†"><a href="#ç¬¬äºŒæ­¥ï¼šè®­ç»ƒé›†åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†" class="headerlink" title="ç¬¬äºŒæ­¥ï¼šè®­ç»ƒé›†åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†"></a>ç¬¬äºŒæ­¥ï¼šè®­ç»ƒé›†åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†</h2><ul><li>ç”±äºæˆ‘ä»¬ç°åœ¨åªæœ‰train/testè¿™ä¸¤ä¸ªåˆ†ç±»ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ªæ–°çš„validation setã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨<code>.split()</code>åˆ›å»ºæ–°çš„åˆ†ç±»ã€‚</li><li>é»˜è®¤çš„æ•°æ®åˆ†å‰²æ˜¯ 70ã€30ï¼Œå¦‚æœæˆ‘ä»¬å£°æ˜<code>split_ratio</code>ï¼Œå¯ä»¥æ”¹å˜splitä¹‹é—´çš„æ¯”ä¾‹ï¼Œ<code>split_ratio=0.8</code>è¡¨ç¤º80%çš„æ•°æ®æ˜¯è®­ç»ƒé›†ï¼Œ20%æ˜¯éªŒè¯é›†ã€‚</li><li>æˆ‘ä»¬è¿˜å£°æ˜<code>random_state</code>è¿™ä¸ªå‚æ•°ï¼Œç¡®ä¿æˆ‘ä»¬æ¯æ¬¡åˆ†å‰²çš„æ•°æ®é›†éƒ½æ˜¯ä¸€æ ·çš„ã€‚</li></ul><p>In [4]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line">train_data, valid_data = train_data.split(random_state=random.seed(SEED)) <span class="comment">#é»˜è®¤split_ratio=0.7</span></span><br></pre></td></tr></table></figure><p>In [5]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">f'Number of training examples: <span class="subst">&#123;len(train_data)&#125;</span>'</span>)</span><br><span class="line">print(<span class="string">f'Number of validation examples: <span class="subst">&#123;len(valid_data)&#125;</span>'</span>)</span><br><span class="line">print(<span class="string">f'Number of testing examples: <span class="subst">&#123;len(test_data)&#125;</span>'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Number of training examples: <span class="number">17500</span></span><br><span class="line">Number of validation examples: <span class="number">7500</span></span><br><span class="line">Number of testing examples: <span class="number">25000</span></span><br></pre></td></tr></table></figure><h2 id="ç¬¬ä¸‰æ­¥ï¼šç”¨è®­ç»ƒé›†å»ºç«‹vocabularyï¼Œå°±æ˜¯æŠŠæ¯ä¸ªå•è¯ä¸€ä¸€æ˜ å°„åˆ°ä¸€ä¸ªæ•°å­—ã€‚"><a href="#ç¬¬ä¸‰æ­¥ï¼šç”¨è®­ç»ƒé›†å»ºç«‹vocabularyï¼Œå°±æ˜¯æŠŠæ¯ä¸ªå•è¯ä¸€ä¸€æ˜ å°„åˆ°ä¸€ä¸ªæ•°å­—ã€‚" class="headerlink" title="ç¬¬ä¸‰æ­¥ï¼šç”¨è®­ç»ƒé›†å»ºç«‹vocabularyï¼Œå°±æ˜¯æŠŠæ¯ä¸ªå•è¯ä¸€ä¸€æ˜ å°„åˆ°ä¸€ä¸ªæ•°å­—ã€‚"></a>ç¬¬ä¸‰æ­¥ï¼šç”¨è®­ç»ƒé›†å»ºç«‹vocabularyï¼Œå°±æ˜¯æŠŠæ¯ä¸ªå•è¯ä¸€ä¸€æ˜ å°„åˆ°ä¸€ä¸ªæ•°å­—ã€‚</h2><ul><li>ä¸‹ä¸€æ­¥æˆ‘ä»¬éœ€è¦åˆ›å»º <em>vocabulary</em> ã€‚<em>vocabulary</em> å°±æ˜¯æŠŠæ¯ä¸ªå•è¯ä¸€ä¸€æ˜ å°„åˆ°ä¸€ä¸ªæ•°å­—ã€‚<img src="file:///Users/mmy/Downloads/assets/sentiment5.png" alt="img"></li><li>æˆ‘ä»¬ä½¿ç”¨æœ€å¸¸è§çš„25kä¸ªå•è¯æ¥æ„å»ºæˆ‘ä»¬çš„å•è¯è¡¨ï¼Œç”¨<code>max_size</code>è¿™ä¸ªå‚æ•°å¯ä»¥åšåˆ°è¿™ä¸€ç‚¹ã€‚</li><li>æ‰€æœ‰å…¶ä»–çš„å•è¯éƒ½ç”¨<code>&lt;unk&gt;</code>æ¥è¡¨ç¤ºã€‚</li></ul><p>In [6]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># TEXT.build_vocab(train_data, max_size=25000)</span></span><br><span class="line"><span class="comment"># LABEL.build_vocab(train_data)</span></span><br><span class="line">TEXT.build_vocab(train_data, max_size=<span class="number">25000</span>, vectors=<span class="string">"glove.6B.100d"</span>, unk_init=torch.Tensor.normal_)</span><br><span class="line"><span class="comment">#ä»é¢„è®­ç»ƒçš„è¯å‘é‡ï¼ˆvectorsï¼‰ ä¸­ï¼Œå°†å½“å‰(corpusè¯­æ–™åº“)è¯æ±‡è¡¨çš„è¯å‘é‡æŠ½å–å‡ºæ¥ï¼Œæ„æˆå½“å‰ corpus çš„ Vocabï¼ˆè¯æ±‡è¡¨ï¼‰ã€‚</span></span><br><span class="line"><span class="comment">#é¢„è®­ç»ƒçš„ vectors æ¥è‡ªgloveæ¨¡å‹ï¼Œæ¯ä¸ªå•è¯æœ‰100ç»´ã€‚gloveæ¨¡å‹è®­ç»ƒçš„è¯å‘é‡å‚æ•°æ¥è‡ªå¾ˆå¤§çš„è¯­æ–™åº“ï¼Œ</span></span><br><span class="line"><span class="comment">#è€Œæˆ‘ä»¬çš„ç”µå½±è¯„è®ºçš„è¯­æ–™åº“å°ä¸€ç‚¹ï¼Œæ‰€ä»¥è¯å‘é‡éœ€è¦æ›´æ–°ï¼Œgloveçš„è¯å‘é‡é€‚åˆç”¨åšåˆå§‹åŒ–å‚æ•°ã€‚</span></span><br><span class="line">LABEL.build_vocab(train_data)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">.vector_cache/glove<span class="number">.6</span>B.zip: <span class="number">862</span>MB [<span class="number">00</span>:<span class="number">23</span>, <span class="number">36.0</span>MB/s]                               </span><br><span class="line"><span class="number">100</span>%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| <span class="number">399597</span>/<span class="number">400000</span> [<span class="number">00</span>:<span class="number">25</span>&lt;<span class="number">00</span>:<span class="number">00</span>, <span class="number">16569.01</span>it/s]</span><br></pre></td></tr></table></figure><p>In [7]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">f"Unique tokens in TEXT vocabulary: <span class="subst">&#123;len(TEXT.vocab)&#125;</span>"</span>)</span><br><span class="line">print(<span class="string">f"Unique tokens in LABEL vocabulary: <span class="subst">&#123;len(LABEL.vocab)&#125;</span>"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Unique tokens in TEXT vocabulary: 25002</span><br><span class="line">Unique tokens in LABEL vocabulary: 2</span><br></pre></td></tr></table></figure><p>In [8]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">print(list(LABEL.vocab.stoi.items())) <span class="comment"># åªæœ‰ä¸¤ä¸ªç±»åˆ«å€¼</span></span><br><span class="line">print(list(TEXT.vocab.stoi.items())[:<span class="number">20</span>])</span><br><span class="line"><span class="comment">#è¯­æ–™åº“å•è¯é¢‘ç‡è¶Šé«˜ï¼Œç´¢å¼•è¶Šé å‰ã€‚å‰ä¸¤ä¸ªé»˜è®¤ä¸ºunkå’Œpadã€‚</span></span><br><span class="line">print(<span class="string">"------"</span>*<span class="number">10</span>)</span><br><span class="line">print(TEXT.vocab.freqs.most_common(<span class="number">20</span>))</span><br><span class="line"><span class="comment"># è¿™é‡Œå¯ä»¥çœ‹åˆ°unkå’Œpadæ²¡æœ‰è®¡æ•°</span></span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[(&apos;neg&apos;, 0), (&apos;pos&apos;, 1)]</span><br><span class="line">[(&apos;&lt;unk&gt;&apos;, 0), (&apos;&lt;pad&gt;&apos;, 1), (&apos;the&apos;, 2), (&apos;,&apos;, 3), (&apos;.&apos;, 4), (&apos;a&apos;, 5), (&apos;and&apos;, 6), (&apos;of&apos;, 7), (&apos;to&apos;, 8), (&apos;is&apos;, 9), (&apos;in&apos;, 10), (&apos;I&apos;, 11), (&apos;it&apos;, 12), (&apos;that&apos;, 13), (&apos;&quot;&apos;, 14), (&quot;&apos;s&quot;, 15), (&apos;this&apos;, 16), (&apos;-&apos;, 17), (&apos;/&gt;&lt;br&apos;, 18), (&apos;was&apos;, 19)]</span><br><span class="line">------------------------------------------------------------</span><br><span class="line">[(&apos;the&apos;, 201815), (&apos;,&apos;, 192511), (&apos;.&apos;, 165127), (&apos;a&apos;, 109096), (&apos;and&apos;, 108875), (&apos;of&apos;, 100402), (&apos;to&apos;, 93905), (&apos;is&apos;, 76001), (&apos;in&apos;, 61097), (&apos;I&apos;, 54439), (&apos;it&apos;, 53649), (&apos;that&apos;, 49325), (&apos;&quot;&apos;, 44431), (&quot;&apos;s&quot;, 43359), (&apos;this&apos;, 42423), (&apos;-&apos;, 37142), (&apos;/&gt;&lt;br&apos;, 35613), (&apos;was&apos;, 34947), (&apos;as&apos;, 30412), (&apos;movie&apos;, 29873)]</span><br></pre></td></tr></table></figure><p>In [9]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(TEXT.vocab.itos[:10]) #æŸ¥çœ‹TEXTå•è¯è¡¨</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&apos;&lt;unk&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;the&apos;, &apos;,&apos;, &apos;.&apos;, &apos;a&apos;, &apos;and&apos;, &apos;of&apos;, &apos;to&apos;, &apos;is&apos;]</span><br></pre></td></tr></table></figure><h2 id="ç¬¬å››æ­¥ï¼šåˆ›å»ºiteratorsï¼Œæ¯ä¸ªitartionéƒ½ä¼šè¿”å›ä¸€ä¸ªbatchçš„æ ·æœ¬ã€‚"><a href="#ç¬¬å››æ­¥ï¼šåˆ›å»ºiteratorsï¼Œæ¯ä¸ªitartionéƒ½ä¼šè¿”å›ä¸€ä¸ªbatchçš„æ ·æœ¬ã€‚" class="headerlink" title="ç¬¬å››æ­¥ï¼šåˆ›å»ºiteratorsï¼Œæ¯ä¸ªitartionéƒ½ä¼šè¿”å›ä¸€ä¸ªbatchçš„æ ·æœ¬ã€‚"></a>ç¬¬å››æ­¥ï¼šåˆ›å»ºiteratorsï¼Œæ¯ä¸ªitartionéƒ½ä¼šè¿”å›ä¸€ä¸ªbatchçš„æ ·æœ¬ã€‚</h2><ul><li>æœ€åä¸€æ­¥æ•°æ®çš„å‡†å¤‡æ˜¯åˆ›å»ºiteratorsã€‚æ¯ä¸ªitartionéƒ½ä¼šè¿”å›ä¸€ä¸ªbatchçš„examplesã€‚</li><li>æˆ‘ä»¬ä¼šä½¿ç”¨<code>BucketIterator</code>ã€‚<code>BucketIterator</code>ä¼šæŠŠé•¿åº¦å·®ä¸å¤šçš„å¥å­æ”¾åˆ°åŒä¸€ä¸ªbatchä¸­ï¼Œç¡®ä¿æ¯ä¸ªbatchä¸­ä¸å‡ºç°å¤ªå¤šçš„paddingã€‚</li><li>ä¸¥æ ¼æ¥è¯´ï¼Œæˆ‘ä»¬è¿™ä»½notebookä¸­çš„æ¨¡å‹ä»£ç éƒ½æœ‰ä¸€ä¸ªé—®é¢˜ï¼Œä¹Ÿå°±æ˜¯æˆ‘ä»¬æŠŠ<code>&lt;pad&gt;</code>ä¹Ÿå½“åšäº†æ¨¡å‹çš„è¾“å…¥è¿›è¡Œè®­ç»ƒã€‚æ›´å¥½çš„åšæ³•æ˜¯åœ¨æ¨¡å‹ä¸­æŠŠç”±<code>&lt;pad&gt;</code>äº§ç”Ÿçš„è¾“å‡ºç»™æ¶ˆé™¤æ‰ã€‚åœ¨è¿™èŠ‚è¯¾ä¸­æˆ‘ä»¬ç®€å•å¤„ç†ï¼Œç›´æ¥æŠŠ<code>&lt;pad&gt;</code>ä¹Ÿç”¨ä½œæ¨¡å‹è¾“å…¥äº†ã€‚ç”±äº<code>&lt;pad&gt;</code>æ•°é‡ä¸å¤šï¼Œæ¨¡å‹çš„æ•ˆæœä¹Ÿä¸å·®ã€‚</li><li>å¦‚æœæˆ‘ä»¬æœ‰GPUï¼Œè¿˜å¯ä»¥æŒ‡å®šæ¯ä¸ªiterationè¿”å›çš„tensoréƒ½åœ¨GPUä¸Šã€‚</li></ul><p>In [11]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">BATCH_SIZE = <span class="number">64</span></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">'cuda'</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#ç›¸å½“äºæŠŠæ ·æœ¬åˆ’åˆ†batchï¼ŒæŠŠç›¸ç­‰é•¿åº¦çš„å•è¯å°½å¯èƒ½çš„åˆ’åˆ†åˆ°ä¸€ä¸ªbatchï¼Œä¸å¤Ÿé•¿çš„å°±ç”¨paddingã€‚</span></span><br><span class="line">train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(</span><br><span class="line">    (train_data, valid_data, test_data), </span><br><span class="line">    batch_size=BATCH_SIZE,</span><br><span class="line">    device=device)</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Iteratorï¼šæ ‡å‡†è¿­ä»£å™¨</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">BucketIeratorï¼šç›¸æ¯”äºæ ‡å‡†è¿­ä»£å™¨ï¼Œä¼šå°†ç±»ä¼¼é•¿åº¦çš„æ ·æœ¬å½“åšä¸€æ‰¹æ¥å¤„ç†ï¼Œ</span></span><br><span class="line"><span class="string">å› ä¸ºåœ¨æ–‡æœ¬å¤„ç†ä¸­ç»å¸¸ä¼šéœ€è¦å°†æ¯ä¸€æ‰¹æ ·æœ¬é•¿åº¦è¡¥é½ä¸ºå½“å‰æ‰¹ä¸­æœ€é•¿åºåˆ—çš„é•¿åº¦ï¼Œ</span></span><br><span class="line"><span class="string">å› æ­¤å½“æ ·æœ¬é•¿åº¦å·®åˆ«è¾ƒå¤§æ—¶ï¼Œä½¿ç”¨BucketIeratorå¯ä»¥å¸¦æ¥å¡«å……æ•ˆç‡çš„æé«˜ã€‚</span></span><br><span class="line"><span class="string">é™¤æ­¤ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥åœ¨Fieldä¸­é€šè¿‡fix_lengthå‚æ•°æ¥å¯¹æ ·æœ¬è¿›è¡Œæˆªæ–­è¡¥é½æ“ä½œã€‚</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">BPTTIterator: åŸºäºBPTT(åŸºäºæ—¶é—´çš„åå‘ä¼ æ’­ç®—æ³•)çš„è¿­ä»£å™¨ï¼Œä¸€èˆ¬ç”¨äºè¯­è¨€æ¨¡å‹ä¸­ã€‚</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure><p>Out[11]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&apos;\nIteratorï¼šæ ‡å‡†è¿­ä»£å™¨\n\nBucketIeratorï¼šç›¸æ¯”äºæ ‡å‡†è¿­ä»£å™¨ï¼Œä¼šå°†ç±»ä¼¼é•¿åº¦çš„æ ·æœ¬å½“åšä¸€æ‰¹æ¥å¤„ç†ï¼Œ\nå› ä¸ºåœ¨æ–‡æœ¬å¤„ç†ä¸­ç»å¸¸ä¼šéœ€è¦å°†æ¯ä¸€æ‰¹æ ·æœ¬é•¿åº¦è¡¥é½ä¸ºå½“å‰æ‰¹ä¸­æœ€é•¿åºåˆ—çš„é•¿åº¦ï¼Œ\nå› æ­¤å½“æ ·æœ¬é•¿åº¦å·®åˆ«è¾ƒå¤§æ—¶ï¼Œä½¿ç”¨BucketIeratorå¯ä»¥å¸¦æ¥å¡«å……æ•ˆç‡çš„æé«˜ã€‚\né™¤æ­¤ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥åœ¨Fieldä¸­é€šè¿‡fix_lengthå‚æ•°æ¥å¯¹æ ·æœ¬è¿›è¡Œæˆªæ–­è¡¥é½æ“ä½œã€‚\n\nBPTTIterator: åŸºäºBPTT(åŸºäºæ—¶é—´çš„åå‘ä¼ æ’­ç®—æ³•)çš„è¿­ä»£å™¨ï¼Œä¸€èˆ¬ç”¨äºè¯­è¨€æ¨¡å‹ä¸­ã€‚\n&apos;</span><br></pre></td></tr></table></figure><p>In [12]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(next(iter(train_iterator)).label.shape)</span><br><span class="line">print(next(iter(train_iterator)).text.shape)<span class="comment"># </span></span><br><span class="line"><span class="comment"># å¤šè¿è¡Œä¸€æ¬¡å¯ä»¥å‘ç°ä¸€æ¡è¯„è®ºçš„å•è¯é•¿åº¦ä¼šå˜</span></span><br><span class="line"><span class="comment"># ä¸‹é¢textçš„ç»´åº¦983*64ï¼Œ983ä¸ºä¸€æ¡è¯„è®ºçš„å•è¯é•¿åº¦</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([<span class="number">64</span>])</span><br><span class="line">torch.Size([<span class="number">983</span>, <span class="number">64</span>])</span><br></pre></td></tr></table></figure><p>In [13]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å–å‡ºä¸€å¥è¯„è®º</span></span><br><span class="line">batch = next(iter(train_iterator))</span><br><span class="line">print(batch.text.shape) </span><br><span class="line">print([TEXT.vocab.itos[i] <span class="keyword">for</span> i <span class="keyword">in</span> batch.text[:,<span class="number">0</span>]])</span><br><span class="line"><span class="comment"># å¯ä»¥çœ‹åˆ°è¿™å¥è¯çš„é•¿åº¦æ˜¯1077ï¼Œæœ€åé¢æœ‰å¾ˆå¤špad</span></span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([1077, 64])</span><br><span class="line">[&apos;It&apos;, &apos;was&apos;, &apos;interesting&apos;, &apos;to&apos;, &apos;see&apos;, &apos;how&apos;, &apos;accurate&apos;, &apos;the&apos;, &apos;writing&apos;, &apos;was&apos;, &apos;on&apos;, &apos;the&apos;, &apos;geek&apos;, &apos;buzz&apos;, &apos;words&apos;, &apos;,&apos;, &apos;yet&apos;, &apos;very&apos;, &apos;naive&apos;, &apos;on&apos;, &apos;the&apos;, &apos;corporate&apos;, &apos;world&apos;, &apos;.&apos;, &apos;The&apos;, &apos;Justice&apos;, &apos;Department&apos;, &apos;would&apos;, &apos;catch&apos;, &apos;more&apos;, &apos;of&apos;, &apos;the&apos;, &apos;big&apos;, &apos;&lt;unk&gt;&apos;, &apos;giants&apos;, &apos;if&apos;, &apos;they&apos;, &apos;did&apos;, &apos;such&apos;, &apos;naive&apos;, &apos;things&apos;, &apos;to&apos;, &apos;win&apos;, &apos;.&apos;, &apos;The&apos;, &apos;real&apos;, &apos;corporate&apos;, &apos;world&apos;, &apos;is&apos;, &apos;much&apos;, &apos;more&apos;, &apos;subtle&apos;, &apos;and&apos;, &apos;interesting&apos;, &apos;,&apos;, &apos;yet&apos;, &apos;every&apos;, &apos;bit&apos;, &apos;as&apos;, &apos;sinister&apos;, &apos;.&apos;, &apos;I&apos;, &apos;seriously&apos;, &apos;doubt&apos;, &apos;ANY&apos;, &apos;&lt;unk&gt;&apos;, &apos;would&apos;, &apos;actually&apos;, &apos;kill&apos;, &apos;someone&apos;, &apos;directly&apos;, &apos;;&apos;, &apos;even&apos;, &apos;the&apos;, &apos;&lt;unk&gt;&apos;, &apos;is&apos;, &apos;more&apos;, &apos;&lt;unk&gt;&apos;, &apos;these&apos;, &apos;days&apos;, &apos;.&apos;, &apos;In&apos;, &apos;the&apos;, &apos;real&apos;, &apos;world&apos;, &apos;,&apos;, &apos;they&apos;, &apos;do&apos;, &apos;kill&apos;, &apos;people&apos;, &apos;with&apos;, &apos;&lt;unk&gt;&apos;, &apos;,&apos;, &apos;pollution&apos;, &apos;,&apos;, &apos;&lt;unk&gt;&apos;, &apos;,&apos;, &apos;&lt;unk&gt;&apos;, &apos;,&apos;, &apos;etc&apos;, &apos;.&apos;, &apos;This&apos;, &apos;movie&apos;, &apos;must&apos;, &apos;have&apos;, &apos;been&apos;, &apos;developed&apos;, &apos;by&apos;, &apos;some&apos;, &apos;garage&apos;, &apos;geeks&apos;, &apos;,&apos;, &apos;I&apos;, &apos;think&apos;, &apos;,&apos;, &apos;and&apos;, &apos;the&apos;, &apos;studios&apos;, &apos;did&apos;, &quot;n&apos;t&quot;, &apos;know&apos;, &apos;the&apos;, &apos;difference&apos;, &apos;.&apos;, &apos;They&apos;, &apos;just&apos;, &apos;wanted&apos;, &apos;something&apos;, &apos;to&apos;, &apos;capitalize&apos;, &apos;on&apos;, &apos;the&apos;, &apos;Microsoft&apos;, &apos;&lt;unk&gt;&apos;, &apos;case&apos;, &apos;in&apos;, &apos;the&apos;, &apos;news&apos;, &apos;.&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;, &apos;&lt;pad&gt;&apos;]</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="ç¬¬äº”æ­¥ï¼šåˆ›å»ºWord-Averagingæ¨¡å‹"><a href="#ç¬¬äº”æ­¥ï¼šåˆ›å»ºWord-Averagingæ¨¡å‹" class="headerlink" title="ç¬¬äº”æ­¥ï¼šåˆ›å»ºWord Averagingæ¨¡å‹"></a>ç¬¬äº”æ­¥ï¼šåˆ›å»ºWord Averagingæ¨¡å‹</h2><h3 id="Word-Averagingæ¨¡å‹"><a href="#Word-Averagingæ¨¡å‹" class="headerlink" title="Word Averagingæ¨¡å‹"></a>Word Averagingæ¨¡å‹</h3><ul><li>æˆ‘ä»¬é¦–å…ˆä»‹ç»ä¸€ä¸ªç®€å•çš„Word Averagingæ¨¡å‹ã€‚è¿™ä¸ªæ¨¡å‹éå¸¸ç®€å•ï¼Œæˆ‘ä»¬æŠŠæ¯ä¸ªå•è¯éƒ½é€šè¿‡<code>Embedding</code>å±‚æŠ•å°„æˆword embedding vectorï¼Œç„¶åæŠŠä¸€å¥è¯ä¸­çš„æ‰€æœ‰word vectoråšä¸ªå¹³å‡ï¼Œå°±æ˜¯æ•´ä¸ªå¥å­çš„vectorè¡¨ç¤ºäº†ã€‚æ¥ä¸‹æ¥æŠŠè¿™ä¸ªsentence vectorä¼ å…¥ä¸€ä¸ª<code>Linear</code>å±‚ï¼Œåšåˆ†ç±»å³å¯ã€‚</li></ul><p><img src="file:///Users/mmy/Downloads/assets/sentiment8.png" alt="img"></p><ul><li>æˆ‘ä»¬ä½¿ç”¨<a href="https://pytorch.org/docs/stable/nn.html?highlight=avg_pool2d#torch.nn.functional.avg_pool2d" target="_blank" rel="noopener"><code>avg_pool2d</code></a>æ¥åšaverage poolingã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æŠŠsentence lengthé‚£ä¸ªç»´åº¦å¹³å‡æˆ1ï¼Œç„¶åä¿ç•™embeddingè¿™ä¸ªç»´åº¦ã€‚</li></ul><p><img src="file:///Users/mmy/Downloads/assets/sentiment9.png" alt="img"></p><ul><li><code>avg_pool2d</code>çš„kernel sizeæ˜¯ (<code>embedded.shape[1]</code>, 1)ï¼Œæ‰€ä»¥å¥å­é•¿åº¦çš„é‚£ä¸ªç»´åº¦ä¼šè¢«å‹æ‰ã€‚</li></ul><p><img src="file:///Users/mmy/Downloads/assets/sentiment10.png" alt="img"></p><p><img src="file:///Users/mmy/Downloads/assets/sentiment11.png" alt="img"></p><p>In [5]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WordAVGModel</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, vocab_size, embedding_dim, output_dim, pad_idx)</span>:</span></span><br><span class="line">        <span class="comment">#åˆå§‹åŒ–å‚æ•°ï¼Œ</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)</span><br><span class="line">        <span class="comment">#vocab_size=è¯æ±‡è¡¨é•¿åº¦=25002ï¼Œembedding_dim=æ¯ä¸ªå•è¯çš„ç»´åº¦=100</span></span><br><span class="line">        <span class="comment">#padding_idxï¼šå¦‚æœæä¾›çš„è¯ï¼Œè¿™é‡Œå¦‚æœé‡åˆ°paddingçš„å•è¯å°±ç”¨0å¡«å……ã€‚</span></span><br><span class="line">        </span><br><span class="line">        self.fc = nn.Linear(embedding_dim, output_dim)</span><br><span class="line">        <span class="comment">#output_dimè¾“å‡ºçš„ç»´åº¦ï¼Œä¸€ä¸ªæ•°å°±å¯ä»¥äº†ï¼Œ=1</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, text)</span>:</span></span><br><span class="line">        <span class="comment"># text.shape = (seq_len,batch_size)</span></span><br><span class="line">        <span class="comment"># textä¸‹é¢ä¼šæŒ‡å®šï¼Œä¸ºä¸€ä¸ªbatchçš„æ•°æ®ï¼Œseq_lenä¸ºä¸€æ¡è¯„è®ºçš„å•è¯é•¿åº¦</span></span><br><span class="line">        embedded = self.embedding(text) </span><br><span class="line">        <span class="comment"># embedded = [seq_len, batch_size, embedding_dim] </span></span><br><span class="line">        embedded = embedded.permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>) </span><br><span class="line">        <span class="comment"># [batch_size, seq_len, embedding_dim]æ›´æ¢é¡ºåº</span></span><br><span class="line">        </span><br><span class="line">        pooled = F.avg_pool2d(embedded, (embedded.shape[<span class="number">1</span>], <span class="number">1</span>)).squeeze(<span class="number">1</span>) </span><br><span class="line">        <span class="comment"># [batch size, embedding_dim] æŠŠå•è¯é•¿åº¦çš„ç»´åº¦å‹æ‰ä¸º1ï¼Œå¹¶é™ç»´</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> self.fc(pooled)  </span><br><span class="line">        <span class="comment">#ï¼ˆbatch size, embedding_dimï¼‰*ï¼ˆembedding_dim, output_dimï¼‰=ï¼ˆbatch size,output_dimï¼‰</span></span><br></pre></td></tr></table></figure><p>In [6]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">INPUT_DIM = len(TEXT.vocab) <span class="comment">#25002</span></span><br><span class="line">EMBEDDING_DIM = <span class="number">100</span></span><br><span class="line">OUTPUT_DIM = <span class="number">1</span> <span class="comment"># å¤§äºæŸä¸ªå€¼æ˜¯æ­£ï¼Œå°äºæ˜¯è´Ÿ</span></span><br><span class="line">PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token] </span><br><span class="line"><span class="comment"># TEXT.pad_token = pad</span></span><br><span class="line"><span class="comment"># PAD_IDX = 1 ä¸ºpadçš„ç´¢å¼•</span></span><br><span class="line"></span><br><span class="line">model = WordAVGModel(INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM, PAD_IDX)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">---------------------------------------------------------------------------</span><br><span class="line">AttributeError                            Traceback (most recent call last)</span><br><span class="line">&lt;ipython-input<span class="number">-6</span>-d9889c88c56d&gt; <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">----&gt; 1 INPUT_DIM = len(TEXT.vocab) #25002</span><br><span class="line">      <span class="number">2</span> EMBEDDING_DIM = <span class="number">100</span></span><br><span class="line">      <span class="number">3</span> OUTPUT_DIM = <span class="number">1</span> <span class="comment"># å¤§äºæŸä¸ªå€¼æ˜¯æ­£ï¼Œå°äºæ˜¯è´Ÿ</span></span><br><span class="line">      <span class="number">4</span> PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]</span><br><span class="line">      <span class="number">5</span> <span class="comment"># TEXT.pad_token = pad</span></span><br><span class="line"></span><br><span class="line">AttributeError: <span class="string">'Field'</span> object has no attribute <span class="string">'vocab'</span></span><br></pre></td></tr></table></figure><p>In [16]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TEXT.pad_token</span><br></pre></td></tr></table></figure><p>Out[16]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&apos;&lt;pad&gt;&apos;</span><br></pre></td></tr></table></figure><p>In [17]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">count_parameters</span><span class="params">(model)</span>:</span> <span class="comment">#ç»Ÿè®¡å‚æ•°ï¼Œå¯ä»¥ä¸ç”¨ç®¡</span></span><br><span class="line">    <span class="keyword">return</span> sum(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters() <span class="keyword">if</span> p.requires_grad)</span><br><span class="line"></span><br><span class="line">print(<span class="string">f'The model has <span class="subst">&#123;count_parameters(model):,&#125;</span> trainable parameters'</span>)</span><br><span class="line"><span class="comment"># &#123;&#125;å¤§æ‹¬å·é‡Œè°ƒç”¨äº†å‡½æ•°</span></span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The model has 2,500,301 trainable parameters</span><br></pre></td></tr></table></figure><h2 id="ç¬¬å…­æ­¥ï¼šåˆå§‹åŒ–å‚æ•°"><a href="#ç¬¬å…­æ­¥ï¼šåˆå§‹åŒ–å‚æ•°" class="headerlink" title="ç¬¬å…­æ­¥ï¼šåˆå§‹åŒ–å‚æ•°"></a>ç¬¬å…­æ­¥ï¼šåˆå§‹åŒ–å‚æ•°</h2><p>In [18]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æŠŠæ¨¡å‹å‚æ•°åˆå§‹åŒ–æˆgloveçš„å‘é‡å‚æ•°</span></span><br><span class="line">pretrained_embeddings = TEXT.vocab.vectors  <span class="comment"># å–å‡ºglove embeddingè¯å‘é‡çš„å‚æ•°</span></span><br><span class="line">model.embedding.weight.data.copy_(pretrained_embeddings) <span class="comment">#é‡åˆ°_çš„è¯­å¥ç›´æ¥æ›¿æ¢ï¼Œä¸éœ€è¦å¦å¤–èµ‹å€¼=</span></span><br><span class="line"><span class="comment">#æŠŠä¸Šé¢vectors="glove.6B.100d"å–å‡ºçš„è¯å‘é‡ä½œä¸ºåˆå§‹åŒ–å‚æ•°ï¼Œæ•°é‡ä¸º25000*100ä¸ªå‚æ•°</span></span><br></pre></td></tr></table></figure><p>Out[18]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],</span><br><span class="line">        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],</span><br><span class="line">        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],</span><br><span class="line">        ...,</span><br><span class="line">        [-0.1419,  0.0282,  0.2185,  ..., -0.1100, -0.1250,  0.0282],</span><br><span class="line">        [-0.3326, -0.9215,  0.9239,  ...,  0.5057, -1.2898,  0.1782],</span><br><span class="line">        [-0.8304,  0.3732,  0.0726,  ..., -0.0122,  0.2313, -0.2783]])</span><br></pre></td></tr></table></figure><p>In [19]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token] <span class="comment"># UNK_IDX=0</span></span><br><span class="line"></span><br><span class="line">model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM) <span class="comment">#</span></span><br><span class="line">model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)</span><br><span class="line"><span class="comment">#è¯æ±‡è¡¨25002ä¸ªå•è¯ï¼Œå‰ä¸¤ä¸ªunkå’Œpadä¹Ÿéœ€è¦åˆå§‹åŒ–æˆEMBEDDING_DIMç»´çš„å‘é‡</span></span><br></pre></td></tr></table></figure><h2 id="ç¬¬ä¸ƒæ­¥ï¼šè®­ç»ƒæ¨¡å‹"><a href="#ç¬¬ä¸ƒæ­¥ï¼šè®­ç»ƒæ¨¡å‹" class="headerlink" title="ç¬¬ä¸ƒæ­¥ï¼šè®­ç»ƒæ¨¡å‹"></a>ç¬¬ä¸ƒæ­¥ï¼šè®­ç»ƒæ¨¡å‹</h2><p>In [20]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line">optimizer = optim.Adam(model.parameters()) <span class="comment">#å®šä¹‰ä¼˜åŒ–å™¨</span></span><br><span class="line">criterion = nn.BCEWithLogitsLoss()  <span class="comment">#å®šä¹‰æŸå¤±å‡½æ•°ï¼Œè¿™ä¸ªBCEWithLogitsLossç‰¹æ®Šæƒ…å†µï¼ŒäºŒåˆ†ç±»æŸå¤±å‡½æ•°</span></span><br><span class="line"><span class="comment"># nn.BCEWithLogitsLoss()çœ‹è¿™ä¸ªï¼šhttps://blog.csdn.net/qq_22210253/article/details/85222093</span></span><br><span class="line">model = model.to(device) <span class="comment">#é€åˆ°gpuä¸Šå»</span></span><br><span class="line">criterion = criterion.to(device) <span class="comment">#é€åˆ°gpuä¸Šå»</span></span><br></pre></td></tr></table></figure><p>è®¡ç®—é¢„æµ‹çš„å‡†ç¡®ç‡</p><p>In [21]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">binary_accuracy</span><span class="params">(preds, y)</span>:</span> <span class="comment">#è®¡ç®—å‡†ç¡®ç‡</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#round predictions to the closest integer</span></span><br><span class="line">    rounded_preds = torch.round(torch.sigmoid(preds))</span><br><span class="line">    <span class="comment">#.roundå‡½æ•°ï¼šå››èˆäº”å…¥</span></span><br><span class="line">    </span><br><span class="line">    correct = (rounded_preds == y).float() <span class="comment">#convert into float for division </span></span><br><span class="line">    acc = correct.sum()/len(correct)</span><br><span class="line">    <span class="keyword">return</span> acc</span><br></pre></td></tr></table></figure><p>In [22]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(model, iterator, optimizer, criterion)</span>:</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    epoch_loss = <span class="number">0</span></span><br><span class="line">    epoch_acc = <span class="number">0</span></span><br><span class="line">    total_len = <span class="number">0</span></span><br><span class="line">    model.train() <span class="comment">#model.train()ä»£è¡¨äº†è®­ç»ƒæ¨¡å¼</span></span><br><span class="line">    <span class="comment">#è¿™æ­¥ä¸€å®šè¦åŠ ï¼Œæ˜¯ä¸ºäº†åŒºåˆ†modelè®­ç»ƒå’Œæµ‹è¯•çš„æ¨¡å¼çš„ã€‚</span></span><br><span class="line">    <span class="comment">#æœ‰æ—¶å€™è®­ç»ƒæ—¶ä¼šç”¨åˆ°dropoutã€å½’ä¸€åŒ–ç­‰æ–¹æ³•ï¼Œä½†æ˜¯æµ‹è¯•çš„æ—¶å€™ä¸èƒ½ç”¨dropoutç­‰æ–¹æ³•ã€‚</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> iterator: <span class="comment">#iteratorä¸ºtrain_iterator</span></span><br><span class="line">        optimizer.zero_grad() <span class="comment">#åŠ è¿™æ­¥é˜²æ­¢æ¢¯åº¦å åŠ </span></span><br><span class="line">        </span><br><span class="line">        predictions = model(batch.text).squeeze(<span class="number">1</span>)</span><br><span class="line">        <span class="comment">#batch.text å°±æ˜¯ä¸Šé¢forwardå‡½æ•°çš„å‚æ•°text</span></span><br><span class="line">        <span class="comment"># squeeze(1)å‹ç¼©ç»´åº¦ï¼Œä¸ç„¶è·Ÿbatch.labelç»´åº¦å¯¹ä¸ä¸Š</span></span><br><span class="line">        </span><br><span class="line">        loss = criterion(predictions, batch.label)</span><br><span class="line">        acc = binary_accuracy(predictions, batch.label)</span><br><span class="line">        <span class="comment"># æ¯æ¬¡è¿­ä»£éƒ½è®¡ç®—ä¸€è¾¹å‡†ç¡®ç‡</span></span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        loss.backward() <span class="comment">#åå‘ä¼ æ’­</span></span><br><span class="line">        optimizer.step() <span class="comment">#æ¢¯åº¦ä¸‹é™</span></span><br><span class="line">        </span><br><span class="line">        epoch_loss += loss.item() * len(batch.label)</span><br><span class="line">        <span class="comment">#äºŒåˆ†ç±»æŸå¤±å‡½æ•°losså› ä¸ºå·²ç»å¹³å‡åŒ–äº†ï¼Œè¿™é‡Œéœ€è¦ä¹˜ä»¥len(batch.label)ï¼Œ</span></span><br><span class="line">        <span class="comment">#å¾—åˆ°ä¸€ä¸ªbatchçš„æŸå¤±ï¼Œç´¯åŠ å¾—åˆ°æ‰€æœ‰æ ·æœ¬æŸå¤±ã€‚</span></span><br><span class="line">        </span><br><span class="line">        epoch_acc += acc.item() * len(batch.label)</span><br><span class="line">        <span class="comment">#ï¼ˆacc.item()ï¼šä¸€ä¸ªbatchçš„æ­£ç¡®ç‡ï¼‰ *batchæ•° = æ­£ç¡®æ•°</span></span><br><span class="line">        <span class="comment"># ç´¯åŠ å¾—åˆ°æ‰€æœ‰è®­ç»ƒæ ·æœ¬æ­£ç¡®æ•°ã€‚</span></span><br><span class="line">        </span><br><span class="line">        total_len += len(batch.label)</span><br><span class="line">        <span class="comment">#è®¡ç®—train_iteratoræ‰€æœ‰æ ·æœ¬çš„æ•°é‡ï¼Œä¸å‡ºæ„å¤–åº”è¯¥æ˜¯17500</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> epoch_loss / total_len, epoch_acc / total_len</span><br><span class="line">    <span class="comment">#epoch_loss / total_len ï¼štrain_iteratoræ‰€æœ‰batchçš„å¹³å‡æŸå¤±</span></span><br><span class="line">    <span class="comment">#epoch_acc / total_len ï¼štrain_iteratoræ‰€æœ‰batchçš„å¹³å‡æ­£ç¡®ç‡</span></span><br></pre></td></tr></table></figure><p>In [23]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">(model, iterator, criterion)</span>:</span></span><br><span class="line">     </span><br><span class="line">    </span><br><span class="line">    epoch_loss = <span class="number">0</span></span><br><span class="line">    epoch_acc = <span class="number">0</span></span><br><span class="line">    total_len = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    model.eval()</span><br><span class="line">    <span class="comment">#è½¬æ¢æˆæµ‹è¯•æ¨¡å¼ï¼Œå†»ç»“dropoutå±‚æˆ–å…¶ä»–å±‚ã€‚</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> iterator: </span><br><span class="line">            <span class="comment">#iteratorä¸ºvalid_iterator</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">#æ²¡æœ‰åå‘ä¼ æ’­å’Œæ¢¯åº¦ä¸‹é™</span></span><br><span class="line">            predictions = model(batch.text).squeeze(<span class="number">1</span>)</span><br><span class="line">            loss = criterion(predictions, batch.label)</span><br><span class="line">            acc = binary_accuracy(predictions, batch.label)</span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line">            epoch_loss += loss.item() * len(batch.label)</span><br><span class="line">            epoch_acc += acc.item() * len(batch.label)</span><br><span class="line">            total_len += len(batch.label)</span><br><span class="line">    model.train() <span class="comment">#è°ƒå›è®­ç»ƒæ¨¡å¼   </span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> epoch_loss / total_len, epoch_acc / total_len</span><br></pre></td></tr></table></figure><p>In [24]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">epoch_time</span><span class="params">(start_time, end_time)</span>:</span>  <span class="comment">#æŸ¥çœ‹æ¯ä¸ªepochçš„æ—¶é—´</span></span><br><span class="line">    elapsed_time = end_time - start_time</span><br><span class="line">    elapsed_mins = int(elapsed_time / <span class="number">60</span>)</span><br><span class="line">    elapsed_secs = int(elapsed_time - (elapsed_mins * <span class="number">60</span>))</span><br><span class="line">    <span class="keyword">return</span> elapsed_mins, elapsed_secs</span><br></pre></td></tr></table></figure><h2 id="ç¬¬å…«æ­¥ï¼šæŸ¥çœ‹æ¨¡å‹è¿è¡Œç»“æœ"><a href="#ç¬¬å…«æ­¥ï¼šæŸ¥çœ‹æ¨¡å‹è¿è¡Œç»“æœ" class="headerlink" title="ç¬¬å…«æ­¥ï¼šæŸ¥çœ‹æ¨¡å‹è¿è¡Œç»“æœ"></a>ç¬¬å…«æ­¥ï¼šæŸ¥çœ‹æ¨¡å‹è¿è¡Œç»“æœ</h2><p>In [25]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åŒä¸Šï¼Œè¿™é‡Œç”¨çš„kaggleGPUè·‘çš„ï¼ŒèŠ±äº†2åˆ†é’Ÿã€‚</span></span><br><span class="line">N_EPOCHS = <span class="number">20</span></span><br><span class="line"></span><br><span class="line">best_valid_loss = float(<span class="string">'inf'</span>) <span class="comment">#æ— ç©·å¤§</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(N_EPOCHS):</span><br><span class="line"></span><br><span class="line">    start_time = time.time()</span><br><span class="line">    </span><br><span class="line">    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)</span><br><span class="line">    <span class="comment"># å¾—åˆ°è®­ç»ƒé›†æ¯ä¸ªepochçš„å¹³å‡æŸå¤±å’Œå‡†ç¡®ç‡</span></span><br><span class="line">    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)</span><br><span class="line">    <span class="comment"># å¾—åˆ°éªŒè¯é›†æ¯ä¸ªepochçš„å¹³å‡æŸå¤±å’Œå‡†ç¡®ç‡ï¼Œè¿™ä¸ªmodelé‡Œä¼ å…¥çš„å‚æ•°æ˜¯è®­ç»ƒå®Œçš„å‚æ•°</span></span><br><span class="line">    </span><br><span class="line">    end_time = time.time()</span><br><span class="line"></span><br><span class="line">    epoch_mins, epoch_secs = epoch_time(start_time, end_time)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> valid_loss &lt; best_valid_loss: <span class="comment">#åªè¦æ¨¡å‹æ•ˆæœå˜å¥½ï¼Œå°±å­˜æ¨¡å‹</span></span><br><span class="line">        best_valid_loss = valid_loss</span><br><span class="line">        torch.save(model.state_dict(), <span class="string">'wordavg-model.pt'</span>)</span><br><span class="line">    </span><br><span class="line">    print(<span class="string">f'Epoch: <span class="subst">&#123;epoch+<span class="number">1</span>:<span class="number">02</span>&#125;</span> | Epoch Time: <span class="subst">&#123;epoch_mins&#125;</span>m <span class="subst">&#123;epoch_secs&#125;</span>s'</span>)</span><br><span class="line">    print(<span class="string">f'\tTrain Loss: <span class="subst">&#123;train_loss:<span class="number">.3</span>f&#125;</span> | Train Acc: <span class="subst">&#123;train_acc*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>%'</span>)</span><br><span class="line">    print(<span class="string">f'\t Val. Loss: <span class="subst">&#123;valid_loss:<span class="number">.3</span>f&#125;</span> |  Val. Acc: <span class="subst">&#123;valid_acc*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>%'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 01 | Epoch Time: 0m 5s</span><br><span class="line">Train Loss: 0.684 | Train Acc: 58.78%</span><br><span class="line"> Val. Loss: 0.617 |  Val. Acc: 72.51%</span><br><span class="line">Epoch: 02 | Epoch Time: 0m 5s</span><br><span class="line">Train Loss: 0.642 | Train Acc: 72.62%</span><br><span class="line"> Val. Loss: 0.504 |  Val. Acc: 76.65%</span><br><span class="line">Epoch: 03 | Epoch Time: 0m 5s</span><br><span class="line">Train Loss: 0.569 | Train Acc: 78.81%</span><br><span class="line"> Val. Loss: 0.439 |  Val. Acc: 81.07%</span><br><span class="line">Epoch: 04 | Epoch Time: 0m 5s</span><br><span class="line">Train Loss: 0.497 | Train Acc: 82.97%</span><br><span class="line"> Val. Loss: 0.404 |  Val. Acc: 84.03%</span><br><span class="line">Epoch: 05 | Epoch Time: 0m 5s</span><br><span class="line">Train Loss: 0.435 | Train Acc: 85.95%</span><br><span class="line"> Val. Loss: 0.400 |  Val. Acc: 85.69%</span><br><span class="line">Epoch: 06 | Epoch Time: 0m 5s</span><br><span class="line">Train Loss: 0.388 | Train Acc: 87.73%</span><br><span class="line"> Val. Loss: 0.412 |  Val. Acc: 86.80%</span><br><span class="line">Epoch: 07 | Epoch Time: 0m 5s</span><br><span class="line">Train Loss: 0.349 | Train Acc: 88.83%</span><br><span class="line"> Val. Loss: 0.425 |  Val. Acc: 87.64%</span><br><span class="line">Epoch: 08 | Epoch Time: 0m 5s</span><br><span class="line">Train Loss: 0.319 | Train Acc: 89.84%</span><br><span class="line"> Val. Loss: 0.446 |  Val. Acc: 87.83%</span><br><span class="line">Epoch: 09 | Epoch Time: 0m 5s</span><br><span class="line">Train Loss: 0.293 | Train Acc: 90.54%</span><br><span class="line"> Val. Loss: 0.464 |  Val. Acc: 88.25%</span><br><span class="line">Epoch: 10 | Epoch Time: 0m 5s</span><br><span class="line">Train Loss: 0.272 | Train Acc: 91.19%</span><br><span class="line"> Val. Loss: 0.480 |  Val. Acc: 88.68%</span><br><span class="line">Epoch: 11 | Epoch Time: 0m 5s</span><br><span class="line">Train Loss: 0.254 | Train Acc: 91.82%</span><br><span class="line"> Val. Loss: 0.498 |  Val. Acc: 88.87%</span><br><span class="line">Epoch: 12 | Epoch Time: 0m 5s</span><br><span class="line">Train Loss: 0.238 | Train Acc: 92.53%</span><br><span class="line"> Val. Loss: 0.517 |  Val. Acc: 89.01%</span><br><span class="line">Epoch: 13 | Epoch Time: 0m 5s</span><br><span class="line">Train Loss: 0.222 | Train Acc: 93.03%</span><br><span class="line"> Val. Loss: 0.532 |  Val. Acc: 89.25%</span><br><span class="line">Epoch: 14 | Epoch Time: 0m 5s</span><br><span class="line">Train Loss: 0.210 | Train Acc: 93.47%</span><br><span class="line"> Val. Loss: 0.547 |  Val. Acc: 89.44%</span><br><span class="line">Epoch: 15 | Epoch Time: 0m 5s</span><br><span class="line">Train Loss: 0.198 | Train Acc: 93.95%</span><br><span class="line"> Val. Loss: 0.564 |  Val. Acc: 89.49%</span><br><span class="line">Epoch: 16 | Epoch Time: 0m 5s</span><br><span class="line">Train Loss: 0.186 | Train Acc: 94.31%</span><br><span class="line"> Val. Loss: 0.582 |  Val. Acc: 89.68%</span><br><span class="line">Epoch: 17 | Epoch Time: 0m 5s</span><br><span class="line">Train Loss: 0.175 | Train Acc: 94.74%</span><br><span class="line"> Val. Loss: 0.596 |  Val. Acc: 89.69%</span><br><span class="line">Epoch: 18 | Epoch Time: 0m 5s</span><br><span class="line">Train Loss: 0.166 | Train Acc: 95.09%</span><br><span class="line"> Val. Loss: 0.615 |  Val. Acc: 89.95%</span><br><span class="line">Epoch: 19 | Epoch Time: 0m 5s</span><br><span class="line">Train Loss: 0.156 | Train Acc: 95.36%</span><br><span class="line"> Val. Loss: 0.631 |  Val. Acc: 89.91%</span><br><span class="line">Epoch: 20 | Epoch Time: 0m 5s</span><br><span class="line">Train Loss: 0.147 | Train Acc: 95.75%</span><br><span class="line"> Val. Loss: 0.647 |  Val. Acc: 90.07%</span><br></pre></td></tr></table></figure><h2 id="ç¬¬ä¹æ­¥ï¼šé¢„æµ‹ç»“æœ"><a href="#ç¬¬ä¹æ­¥ï¼šé¢„æµ‹ç»“æœ" class="headerlink" title="ç¬¬ä¹æ­¥ï¼šé¢„æµ‹ç»“æœ"></a>ç¬¬ä¹æ­¥ï¼šé¢„æµ‹ç»“æœ</h2><p>In [26]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!ls</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">__notebook_source__.ipynb  wordavg-model.pt</span><br></pre></td></tr></table></figure><p>In [55]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kaggleä¸Šä¸‹è½½æ¨¡å‹æ–‡ä»¶åˆ°æœ¬åœ°ï¼Œè¿è¡Œä¸‹é¢ä»£ç ï¼Œç‚¹å‡»è¾“å‡ºçš„é“¾æ¥å°±è¡Œ</span></span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> HTML</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_download_link</span><span class="params">(title = <span class="string">"Download model file"</span>, filename = <span class="string">"CNN-model.pt"</span>)</span>:</span>  </span><br><span class="line">    html = <span class="string">'&lt;a href=&#123;filename&#125;&gt;&#123;title&#125;&lt;/a&gt;'</span></span><br><span class="line">    html = html.format(title=title,filename=filename)</span><br><span class="line">    <span class="keyword">return</span> HTML(html)</span><br><span class="line"></span><br><span class="line"><span class="comment"># create a link to download the dataframe which was saved with .to_csv method</span></span><br><span class="line">create_download_link(filename=<span class="string">'wordavg-model.pt'</span>)</span><br></pre></td></tr></table></figure><p>Out[55]:</p><p><a href="file:///Users/mmy/Downloads/wordavg-model.pt" target="_blank" rel="noopener">Download model file</a></p><p>In [1]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.load_state_dict(torch.load(&quot;wordavg-model.pt&quot;))</span><br><span class="line">#ç”¨ä¿å­˜çš„æ¨¡å‹å‚æ•°é¢„æµ‹æ•°æ®</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">---------------------------------------------------------------------------</span><br><span class="line">NameError                                 Traceback (most recent call last)</span><br><span class="line">&lt;ipython-input-1-f795a3e78d6a&gt; in &lt;module&gt;</span><br><span class="line">----&gt; 1 model.load_state_dict(torch.load(&quot;wordavg-model.pt&quot;))</span><br><span class="line">      2 #ç”¨ä¿å­˜çš„æ¨¡å‹å‚æ•°é¢„æµ‹æ•°æ®</span><br><span class="line"></span><br><span class="line">NameError: name &apos;model&apos; is not defined</span><br></pre></td></tr></table></figure><p>In [28]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> spacy  <span class="comment">#åˆ†è¯å·¥å…·ï¼Œè·ŸNLTKç±»ä¼¼</span></span><br><span class="line">nlp = spacy.load(<span class="string">'en'</span>) </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_sentiment</span><span class="params">(sentence)</span>:</span> <span class="comment"># ä¼ å…¥é¢„æµ‹çš„å¥å­I love This film bad </span></span><br><span class="line">    tokenized = [tok.text <span class="keyword">for</span> tok <span class="keyword">in</span> nlp.tokenizer(sentence)] <span class="comment">#åˆ†è¯</span></span><br><span class="line">    <span class="comment"># print(tokenized) = ['I', 'love', 'This', 'film', 'bad']</span></span><br><span class="line">    indexed = [TEXT.vocab.stoi[t] <span class="keyword">for</span> t <span class="keyword">in</span> tokenized] </span><br><span class="line">    <span class="comment">#sentenceçš„åœ¨25002ä¸­çš„ç´¢å¼•</span></span><br><span class="line">    </span><br><span class="line">    tensor = torch.LongTensor(indexed).to(device) <span class="comment">#seq_len</span></span><br><span class="line">    <span class="comment"># æ‰€æœ‰è¯å‘é‡éƒ½åº”è¯¥å˜æˆLongTensor</span></span><br><span class="line">    </span><br><span class="line">    tensor = tensor.unsqueeze(<span class="number">1</span>) </span><br><span class="line">    <span class="comment">#æ¨¡å‹çš„è¾“å…¥æ˜¯é»˜è®¤æœ‰batch_sizeçš„,éœ€è¦å‡ç»´ï¼Œseq_len * batch_sizeï¼ˆ1ï¼‰</span></span><br><span class="line">    </span><br><span class="line">    prediction = torch.sigmoid(model(tensor))</span><br><span class="line">    <span class="comment"># é¢„æµ‹å‡†ç¡®ç‡ï¼Œåœ¨0ï¼Œ1ä¹‹é—´ï¼Œéœ€è¦sigmoidä¸‹</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> prediction.item()</span><br></pre></td></tr></table></figure><p>In [29]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predict_sentiment(&quot;I love This film bad&quot;)</span><br></pre></td></tr></table></figure><p>Out[29]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.9373546242713928</span><br></pre></td></tr></table></figure><p>In [30]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predict_sentiment(&quot;This film is great&quot;)</span><br></pre></td></tr></table></figure><p>Out[30]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1.0</span><br></pre></td></tr></table></figure><h2 id="RNNæ¨¡å‹"><a href="#RNNæ¨¡å‹" class="headerlink" title="RNNæ¨¡å‹"></a>RNNæ¨¡å‹</h2><ul><li><p>ä¸‹é¢æˆ‘ä»¬å°è¯•æŠŠæ¨¡å‹æ¢æˆä¸€ä¸ª</p><p>recurrent neural network</p></li></ul><p>  (RNN)ã€‚RNNç»å¸¸ä¼šè¢«ç”¨æ¥encodeä¸€ä¸ªsequence</p><p>  â„ğ‘¡=RNN(ğ‘¥ğ‘¡,â„ğ‘¡âˆ’1)ht=RNN(xt,htâˆ’1)</p><ul><li><p>æˆ‘ä»¬ä½¿ç”¨æœ€åä¸€ä¸ªhidden state â„ğ‘‡hTæ¥è¡¨ç¤ºæ•´ä¸ªå¥å­ã€‚</p></li><li><p>ç„¶åæˆ‘ä»¬æŠŠâ„ğ‘‡hTé€šè¿‡ä¸€ä¸ªçº¿æ€§å˜æ¢ğ‘“fï¼Œç„¶åç”¨æ¥é¢„æµ‹å¥å­çš„æƒ…æ„Ÿã€‚</p></li></ul><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>In [32]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RNN</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, vocab_size, embedding_dim, hidden_dim, output_dim, </span></span></span><br><span class="line"><span class="function"><span class="params">                 n_layers, bidirectional, dropout, pad_idx)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)</span><br><span class="line">        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, </span><br><span class="line">                           bidirectional=bidirectional, dropout=dropout)</span><br><span class="line">        <span class="comment">#embedding_dimï¼šæ¯ä¸ªå•è¯ç»´åº¦</span></span><br><span class="line">        <span class="comment">#hidden_dimï¼šéšè—å±‚ç»´åº¦</span></span><br><span class="line">        <span class="comment">#num_layersï¼šç¥ç»ç½‘ç»œæ·±åº¦ï¼Œçºµå‘æ·±åº¦</span></span><br><span class="line">        <span class="comment">#bidirectionalï¼šæ˜¯å¦åŒå‘å¾ªç¯RNN</span></span><br><span class="line">        <span class="comment">#è¿™ä¸ªè‡ªå·±å…ˆå¾—ç†è§£LSTMå„ä¸ªç»´åº¦ï¼Œä¸ç„¶å®¹æ˜“æ™•ï¼ŒåŒå‘RNNç½‘ç»œå›¾ç¤ºçœ‹ä¸Šé¢ï¼Œå¯ä»¥å€Ÿé‰´ä¸‹</span></span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        self.fc = nn.Linear(hidden_dim*<span class="number">2</span>, output_dim)</span><br><span class="line">        <span class="comment"># è¿™é‡Œhidden_dimä¹˜ä»¥2æ˜¯å› ä¸ºæ˜¯åŒå‘ï¼Œéœ€è¦æ‹¼æ¥ä¸¤ä¸ªæ–¹å‘ï¼Œè·Ÿn_layersçš„å±‚æ•°æ— å…³ã€‚</span></span><br><span class="line"></span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, text)</span>:</span></span><br><span class="line">        <span class="comment"># text.shape=[seq_len, batch_size]</span></span><br><span class="line">        embedded = self.dropout(self.embedding(text)) <span class="comment">#[seq_len, batch_size, emb_dim]</span></span><br><span class="line">        output, (hidden, cell) = self.rnn(embedded)</span><br><span class="line">        <span class="comment"># output = [seq_len, batch size, hid_dim * num directions]</span></span><br><span class="line">        <span class="comment"># hidden = [num layers * num directions, batch_size, hid_dim]</span></span><br><span class="line">        <span class="comment"># cell = [num layers * num directions, batch_size, hid_dim]</span></span><br><span class="line">        <span class="comment"># è¿™é‡Œçš„num layers * num directionså¯ä»¥çœ‹ä¸Šé¢å›¾ï¼Œä¸Šé¢å›¾é™¤æ‰è¾“å…¥è¾“å‡ºå±‚åªæœ‰ä¸¤å±‚åŒå‘ç½‘ç»œã€‚</span></span><br><span class="line">        <span class="comment"># num layers = 2è¡¨ç¤ºéœ€è¦çºµå‘ä¸Šåœ¨åŠ ä¸¤å±‚åŒå‘ï¼Œæ€»å…±æœ‰4å±‚ç¥ç»å…ƒã€‚</span></span><br><span class="line">        <span class="comment"># å¯¹äºLSTMæ¨¡å‹çš„ä»»æ„ä¸€ä¸ªæ—¶é—´åºåˆ—tï¼Œhå±‚çš„è¾“å‡ºç»´åº¦</span></span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        <span class="comment">#concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers</span></span><br><span class="line">        <span class="comment">#and apply dropout</span></span><br><span class="line">        hidden = self.dropout(torch.cat((hidden[<span class="number">-2</span>,:,:], hidden[<span class="number">-1</span>,:,:]), dim=<span class="number">1</span>)) </span><br><span class="line">        <span class="comment"># hidden = [batch size, hid dim * num directions]ï¼Œ</span></span><br><span class="line">        <span class="comment"># çœ‹ä¸‹ä¸Šé¢å›¾ç¤ºï¼Œæœ€åå‰å‘å’Œåå‘è¾“å‡ºçš„éšè—å±‚ä¼šconcatåˆ°è¾“å‡ºå±‚ï¼Œ4å±‚ç¥ç»å…ƒæœ€åä¸¤å±‚ä½œä¸ºæœ€ç»ˆçš„è¾“å‡ºã€‚</span></span><br><span class="line">        <span class="comment"># è¿™é‡Œå› ä¸ºæˆ‘ä»¬åªéœ€è¦å¾—åˆ°æœ€åä¸€ä¸ªæ—¶é—´åºåˆ—çš„è¾“å‡ºï¼Œæ‰€ä»¥æœ€ç»ˆè¾“å‡ºçš„hiddenè·Ÿseq_lenæ— å…³ã€‚</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> self.fc(hidden.squeeze(<span class="number">0</span>)) <span class="comment"># åœ¨æ¥ä¸€ä¸ªå…¨è¿æ¥å±‚ï¼Œæœ€ç»ˆè¾“å‡º[batch size, output_dim]</span></span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>In [36]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">INPUT_DIM = len(TEXT.vocab)</span><br><span class="line">EMBEDDING_DIM = <span class="number">100</span></span><br><span class="line">HIDDEN_DIM = <span class="number">256</span></span><br><span class="line">OUTPUT_DIM = <span class="number">1</span></span><br><span class="line">N_LAYERS = <span class="number">2</span></span><br><span class="line">BIDIRECTIONAL = <span class="literal">True</span></span><br><span class="line">DROPOUT = <span class="number">0.5</span></span><br><span class="line">PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]</span><br><span class="line"></span><br><span class="line">model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, </span><br><span class="line">            N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)</span><br><span class="line">model</span><br></pre></td></tr></table></figure><p>Out[36]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">RNN(</span><br><span class="line">  (embedding): Embedding(<span class="number">25002</span>, <span class="number">100</span>, padding_idx=<span class="number">1</span>)</span><br><span class="line">  (rnn): LSTM(<span class="number">100</span>, <span class="number">256</span>, num_layers=<span class="number">2</span>, dropout=<span class="number">0.5</span>, bidirectional=<span class="literal">True</span>)</span><br><span class="line">  (fc): Linear(in_features=<span class="number">512</span>, out_features=<span class="number">1</span>, bias=<span class="literal">True</span>)</span><br><span class="line">  (dropout): Dropout(p=<span class="number">0.5</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>In [34]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">f'The model has <span class="subst">&#123;count_parameters(model):,&#125;</span> trainable parameters'</span>)</span><br><span class="line"><span class="comment"># æ¯”averge modelæ¨¡å‹å¤šäº†ä¸€å€çš„å‚æ•°</span></span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The model has 4,810,857 trainable parameters</span><br></pre></td></tr></table></figure><p>In [37]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åŒä¸Šåˆå§‹åŒ–</span></span><br><span class="line">model.embedding.weight.data.copy_(pretrained_embeddings)</span><br><span class="line">UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]</span><br><span class="line"></span><br><span class="line">model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)</span><br><span class="line">model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)</span><br><span class="line"></span><br><span class="line">print(model.embedding.weight.data)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],</span><br><span class="line">        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],</span><br><span class="line">        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],</span><br><span class="line">        ...,</span><br><span class="line">        [-0.1419,  0.0282,  0.2185,  ..., -0.1100, -0.1250,  0.0282],</span><br><span class="line">        [-0.3326, -0.9215,  0.9239,  ...,  0.5057, -1.2898,  0.1782],</span><br><span class="line">        [-0.8304,  0.3732,  0.0726,  ..., -0.0122,  0.2313, -0.2783]])</span><br></pre></td></tr></table></figure><h2 id="è®­ç»ƒRNNæ¨¡å‹"><a href="#è®­ç»ƒRNNæ¨¡å‹" class="headerlink" title="è®­ç»ƒRNNæ¨¡å‹"></a>è®­ç»ƒRNNæ¨¡å‹</h2><p>In [38]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">optimizer = optim.Adam(model.parameters())</span><br><span class="line">model = model.to(device)</span><br></pre></td></tr></table></figure><p>In [39]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åŒä¸Šï¼Œè¿™é‡Œç”¨çš„kaggleGPUè·‘çš„ï¼ŒèŠ±äº†40åˆ†é’Ÿã€‚</span></span><br><span class="line">N_EPOCHS = <span class="number">20</span></span><br><span class="line">best_valid_loss = float(<span class="string">'inf'</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(N_EPOCHS):</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)</span><br><span class="line">    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)</span><br><span class="line">    </span><br><span class="line">    end_time = time.time()</span><br><span class="line"></span><br><span class="line">    epoch_mins, epoch_secs = epoch_time(start_time, end_time)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> valid_loss &lt; best_valid_loss:</span><br><span class="line">        best_valid_loss = valid_loss</span><br><span class="line">        torch.save(model.state_dict(), <span class="string">'lstm-model.pt'</span>)</span><br><span class="line">    </span><br><span class="line">    print(<span class="string">f'Epoch: <span class="subst">&#123;epoch+<span class="number">1</span>:<span class="number">02</span>&#125;</span> | Epoch Time: <span class="subst">&#123;epoch_mins&#125;</span>m <span class="subst">&#123;epoch_secs&#125;</span>s'</span>)</span><br><span class="line">    print(<span class="string">f'\tTrain Loss: <span class="subst">&#123;train_loss:<span class="number">.3</span>f&#125;</span> | Train Acc: <span class="subst">&#123;train_acc*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>%'</span>)</span><br><span class="line">    print(<span class="string">f'\t Val. Loss: <span class="subst">&#123;valid_loss:<span class="number">.3</span>f&#125;</span> |  Val. Acc: <span class="subst">&#123;valid_acc*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>%'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 01 | Epoch Time: 2m 1s</span><br><span class="line">Train Loss: 0.667 | Train Acc: 59.09%</span><br><span class="line"> Val. Loss: 0.633 |  Val. Acc: 64.67%</span><br><span class="line">Epoch: 02 | Epoch Time: 2m 1s</span><br><span class="line">Train Loss: 0.663 | Train Acc: 60.33%</span><br><span class="line"> Val. Loss: 0.669 |  Val. Acc: 69.21%</span><br><span class="line">Epoch: 03 | Epoch Time: 2m 2s</span><br><span class="line">Train Loss: 0.650 | Train Acc: 61.06%</span><br><span class="line"> Val. Loss: 0.579 |  Val. Acc: 70.55%</span><br><span class="line">Epoch: 04 | Epoch Time: 2m 2s</span><br><span class="line">Train Loss: 0.493 | Train Acc: 77.43%</span><br><span class="line"> Val. Loss: 0.382 |  Val. Acc: 83.43%</span><br><span class="line">Epoch: 05 | Epoch Time: 2m 2s</span><br><span class="line">Train Loss: 0.394 | Train Acc: 83.71%</span><br><span class="line"> Val. Loss: 0.338 |  Val. Acc: 85.97%</span><br><span class="line">Epoch: 06 | Epoch Time: 2m 3s</span><br><span class="line">Train Loss: 0.338 | Train Acc: 86.26%</span><br><span class="line"> Val. Loss: 0.309 |  Val. Acc: 87.21%</span><br><span class="line">Epoch: 07 | Epoch Time: 2m 2s</span><br><span class="line">Train Loss: 0.292 | Train Acc: 88.37%</span><br><span class="line"> Val. Loss: 0.295 |  Val. Acc: 88.73%</span><br><span class="line">Epoch: 08 | Epoch Time: 2m 3s</span><br><span class="line">Train Loss: 0.252 | Train Acc: 90.26%</span><br><span class="line"> Val. Loss: 0.300 |  Val. Acc: 89.31%</span><br><span class="line">Epoch: 09 | Epoch Time: 2m 2s</span><br><span class="line">Train Loss: 0.246 | Train Acc: 90.51%</span><br><span class="line"> Val. Loss: 0.282 |  Val. Acc: 88.76%</span><br><span class="line">Epoch: 10 | Epoch Time: 2m 3s</span><br><span class="line">Train Loss: 0.205 | Train Acc: 92.37%</span><br><span class="line"> Val. Loss: 0.295 |  Val. Acc: 88.31%</span><br><span class="line">Epoch: 11 | Epoch Time: 2m 1s</span><br><span class="line">Train Loss: 0.203 | Train Acc: 92.46%</span><br><span class="line"> Val. Loss: 0.289 |  Val. Acc: 89.25%</span><br><span class="line">Epoch: 12 | Epoch Time: 2m 3s</span><br><span class="line">Train Loss: 0.178 | Train Acc: 93.58%</span><br><span class="line"> Val. Loss: 0.301 |  Val. Acc: 89.41%</span><br><span class="line">Epoch: 13 | Epoch Time: 2m 3s</span><br><span class="line">Train Loss: 0.158 | Train Acc: 94.43%</span><br><span class="line"> Val. Loss: 0.301 |  Val. Acc: 89.51%</span><br><span class="line">Epoch: 14 | Epoch Time: 2m 2s</span><br><span class="line">Train Loss: 0.158 | Train Acc: 94.63%</span><br><span class="line"> Val. Loss: 0.289 |  Val. Acc: 89.95%</span><br><span class="line">Epoch: 15 | Epoch Time: 2m 2s</span><br><span class="line">Train Loss: 0.142 | Train Acc: 95.00%</span><br><span class="line"> Val. Loss: 0.314 |  Val. Acc: 89.59%</span><br><span class="line">Epoch: 16 | Epoch Time: 2m 2s</span><br><span class="line">Train Loss: 0.123 | Train Acc: 95.62%</span><br><span class="line"> Val. Loss: 0.329 |  Val. Acc: 89.99%</span><br><span class="line">Epoch: 17 | Epoch Time: 2m 4s</span><br><span class="line">Train Loss: 0.107 | Train Acc: 96.16%</span><br><span class="line"> Val. Loss: 0.325 |  Val. Acc: 89.75%</span><br><span class="line">Epoch: 18 | Epoch Time: 2m 4s</span><br><span class="line">Train Loss: 0.100 | Train Acc: 96.66%</span><br><span class="line"> Val. Loss: 0.341 |  Val. Acc: 89.49%</span><br><span class="line">Epoch: 19 | Epoch Time: 2m 3s</span><br><span class="line">Train Loss: 0.096 | Train Acc: 96.63%</span><br><span class="line"> Val. Loss: 0.340 |  Val. Acc: 89.79%</span><br><span class="line">Epoch: 20 | Epoch Time: 2m 3s</span><br><span class="line">Train Loss: 0.080 | Train Acc: 97.31%</span><br><span class="line"> Val. Loss: 0.380 |  Val. Acc: 89.83%</span><br></pre></td></tr></table></figure><p>You may have noticed the loss is not really decreasing and the accuracy is poor. This is due to several issues with the model which weâ€™ll improve in the next notebook.</p><p>Finally, the metric we actually care about, the test loss and accuracy, which we get from our parameters that gave us the best validation loss.</p><p>In [40]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ä¸‹è½½æ–‡ä»¶åˆ°æœ¬åœ°</span></span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> HTML</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_download_link</span><span class="params">(title = <span class="string">"Download model file"</span>, filename = <span class="string">"wordavg-model.pt"</span>)</span>:</span>  </span><br><span class="line">    html = <span class="string">'&lt;a href=&#123;filename&#125;&gt;&#123;title&#125;&lt;/a&gt;'</span></span><br><span class="line">    html = html.format(title=title,filename=filename)</span><br><span class="line">    <span class="keyword">return</span> HTML(html)</span><br><span class="line"></span><br><span class="line"><span class="comment"># create a link to download the dataframe which was saved with .to_csv method</span></span><br><span class="line">create_download_link(filename=<span class="string">'lstm-model.pt'</span>)</span><br></pre></td></tr></table></figure><p>Out[40]:</p><p><a href="file:///Users/mmy/Downloads/lstm-model.pt" target="_blank" rel="noopener">Download model file</a></p><p>In [41]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.load_state_dict(torch.load(<span class="string">'lstm-model.pt'</span>))</span><br><span class="line">test_loss, test_acc = evaluate(model, test_iterator, criterion)</span><br><span class="line">print(<span class="string">f'Test Loss: <span class="subst">&#123;test_loss:<span class="number">.3</span>f&#125;</span> | Test Acc: <span class="subst">&#123;test_acc*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>%'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Test Loss: 0.304 | Test Acc: 88.11%</span><br></pre></td></tr></table></figure><p>In [44]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predict_sentiment(&quot;I feel This film bad&quot;)</span><br></pre></td></tr></table></figure><p>Out[44]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.3637591600418091</span><br></pre></td></tr></table></figure><p>In [43]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predict_sentiment(&quot;This film is great&quot;)</span><br></pre></td></tr></table></figure><p>Out[43]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.9947803020477295</span><br></pre></td></tr></table></figure><h2 id="CNNæ¨¡å‹"><a href="#CNNæ¨¡å‹" class="headerlink" title="CNNæ¨¡å‹"></a>CNNæ¨¡å‹</h2><p>In [45]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CNN</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, vocab_size, embedding_dim, n_filters, </span></span></span><br><span class="line"><span class="function"><span class="params">                 filter_sizes, output_dim, dropout, pad_idx)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        </span><br><span class="line">        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)</span><br><span class="line">        self.convs = nn.ModuleList([</span><br><span class="line">                                    nn.Conv2d(in_channels = <span class="number">1</span>, out_channels = n_filters, </span><br><span class="line">                                              kernel_size = (fs, embedding_dim)) </span><br><span class="line">                                    <span class="keyword">for</span> fs <span class="keyword">in</span> filter_sizes</span><br><span class="line">                                    ])</span><br><span class="line">        <span class="comment"># in_channelsï¼šè¾“å…¥çš„channelï¼Œæ–‡å­—éƒ½æ˜¯1</span></span><br><span class="line">        <span class="comment"># out_channelsï¼šè¾“å‡ºçš„channelç»´åº¦</span></span><br><span class="line">        <span class="comment"># fsï¼šæ¯æ¬¡æ»‘åŠ¨çª—å£è®¡ç®—ç”¨åˆ°å‡ ä¸ªå•è¯</span></span><br><span class="line">        <span class="comment"># for fs in filter_sizesæ‰“ç®—ç”¨å¥½å‡ ä¸ªå·ç§¯æ¨¡å‹æœ€åconcateèµ·æ¥çœ‹æ•ˆæœã€‚</span></span><br><span class="line">        </span><br><span class="line">        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, text)</span>:</span></span><br><span class="line">        text = text.permute(<span class="number">1</span>, <span class="number">0</span>) <span class="comment"># [batch size, sent len]</span></span><br><span class="line">        embedded = self.embedding(text) <span class="comment"># [batch size, sent len, emb dim]</span></span><br><span class="line">        embedded = embedded.unsqueeze(<span class="number">1</span>) <span class="comment"># [batch size, 1, sent len, emb dim]</span></span><br><span class="line">        <span class="comment"># å‡ç»´æ˜¯ä¸ºäº†å’Œnn.Conv2dçš„è¾“å…¥ç»´åº¦å»åˆï¼ŒæŠŠchannelåˆ—å‡ç»´ã€‚</span></span><br><span class="line">        conved = [F.relu(conv(embedded)).squeeze(<span class="number">3</span>) <span class="keyword">for</span> conv <span class="keyword">in</span> self.convs]</span><br><span class="line">        <span class="comment"># conved = [batch size, n_filters, sent len - filter_sizes+1]</span></span><br><span class="line">        <span class="comment"># æœ‰å‡ ä¸ªfilter_sizeså°±æœ‰å‡ ä¸ªconved</span></span><br><span class="line">    </span><br><span class="line">        </span><br><span class="line">        pooled = [F.max_pool1d(conv, conv.shape[<span class="number">2</span>]).squeeze(<span class="number">2</span>) <span class="keyword">for</span> conv <span class="keyword">in</span> conved]</span><br><span class="line">        <span class="comment"># æŠŠconvçš„ç¬¬ä¸‰ä¸ªç»´åº¦æœ€å¤§æ± åŒ–äº†</span></span><br><span class="line">        <span class="comment">#pooled_n = [batch size, n_filters]</span></span><br><span class="line">        </span><br><span class="line">        cat = self.dropout(torch.cat(pooled, dim=<span class="number">1</span>))</span><br><span class="line">        <span class="comment"># cat = [batch size, n_filters * len(filter_sizes)]</span></span><br><span class="line">        <span class="comment"># æŠŠ len(filter_sizes)ä¸ªå·ç§¯æ¨¡å‹concateèµ·æ¥ä¼ åˆ°å…¨è¿æ¥å±‚ã€‚</span></span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> self.fc(cat)</span><br></pre></td></tr></table></figure><p>In [47]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åŒä¸Š</span></span><br><span class="line">INPUT_DIM = len(TEXT.vocab)</span><br><span class="line">EMBEDDING_DIM = <span class="number">100</span></span><br><span class="line">N_FILTERS = <span class="number">100</span></span><br><span class="line">FILTER_SIZES = [<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]</span><br><span class="line">OUTPUT_DIM = <span class="number">1</span></span><br><span class="line">DROPOUT = <span class="number">0.5</span></span><br><span class="line">PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)</span><br><span class="line">model.embedding.weight.data.copy_(pretrained_embeddings)</span><br><span class="line">UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]</span><br><span class="line"></span><br><span class="line">model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)</span><br><span class="line">model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)</span><br><span class="line">model = model.to(device)</span><br><span class="line">print(<span class="string">f'The model has <span class="subst">&#123;count_parameters(model):,&#125;</span> trainable parameters'</span>)</span><br><span class="line"><span class="comment"># æ¯”averge modelæ¨¡å‹å‚æ•°å·®ä¸å¤š</span></span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The model has 2,620,801 trainable parameters</span><br></pre></td></tr></table></figure><p>In [48]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åŒä¸Šï¼Œéœ€è¦èŠ±8åˆ†é’Ÿå·¦å³</span></span><br><span class="line">optimizer = optim.Adam(model.parameters())</span><br><span class="line">criterion = nn.BCEWithLogitsLoss()</span><br><span class="line">criterion = criterion.to(device)</span><br><span class="line"></span><br><span class="line">N_EPOCHS = <span class="number">20</span></span><br><span class="line"></span><br><span class="line">best_valid_loss = float(<span class="string">'inf'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(N_EPOCHS):</span><br><span class="line"></span><br><span class="line">    start_time = time.time()</span><br><span class="line">    </span><br><span class="line">    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)</span><br><span class="line">    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)</span><br><span class="line">    </span><br><span class="line">    end_time = time.time()</span><br><span class="line"></span><br><span class="line">    epoch_mins, epoch_secs = epoch_time(start_time, end_time)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> valid_loss &lt; best_valid_loss:</span><br><span class="line">        best_valid_loss = valid_loss</span><br><span class="line">        torch.save(model.state_dict(), <span class="string">'CNN-model.pt'</span>)</span><br><span class="line">    </span><br><span class="line">    print(<span class="string">f'Epoch: <span class="subst">&#123;epoch+<span class="number">1</span>:<span class="number">02</span>&#125;</span> | Epoch Time: <span class="subst">&#123;epoch_mins&#125;</span>m <span class="subst">&#123;epoch_secs&#125;</span>s'</span>)</span><br><span class="line">    print(<span class="string">f'\tTrain Loss: <span class="subst">&#123;train_loss:<span class="number">.3</span>f&#125;</span> | Train Acc: <span class="subst">&#123;train_acc*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>%'</span>)</span><br><span class="line">    print(<span class="string">f'\t Val. Loss: <span class="subst">&#123;valid_loss:<span class="number">.3</span>f&#125;</span> |  Val. Acc: <span class="subst">&#123;valid_acc*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>%'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 01 | Epoch Time: 0m 19s</span><br><span class="line">Train Loss: 0.652 | Train Acc: 61.81%</span><br><span class="line"> Val. Loss: 0.527 |  Val. Acc: 76.20%</span><br><span class="line">Epoch: 02 | Epoch Time: 0m 19s</span><br><span class="line">Train Loss: 0.427 | Train Acc: 80.66%</span><br><span class="line"> Val. Loss: 0.358 |  Val. Acc: 84.36%</span><br><span class="line">Epoch: 03 | Epoch Time: 0m 19s</span><br><span class="line">Train Loss: 0.304 | Train Acc: 87.14%</span><br><span class="line"> Val. Loss: 0.318 |  Val. Acc: 86.45%</span><br><span class="line">Epoch: 04 | Epoch Time: 0m 19s</span><br><span class="line">Train Loss: 0.215 | Train Acc: 91.42%</span><br><span class="line"> Val. Loss: 0.313 |  Val. Acc: 86.92%</span><br><span class="line">Epoch: 05 | Epoch Time: 0m 19s</span><br><span class="line">Train Loss: 0.156 | Train Acc: 94.18%</span><br><span class="line"> Val. Loss: 0.326 |  Val. Acc: 87.01%</span><br><span class="line">Epoch: 06 | Epoch Time: 0m 19s</span><br><span class="line">Train Loss: 0.105 | Train Acc: 96.33%</span><br><span class="line"> Val. Loss: 0.344 |  Val. Acc: 87.16%</span><br><span class="line">Epoch: 07 | Epoch Time: 0m 19s</span><br><span class="line">Train Loss: 0.075 | Train Acc: 97.61%</span><br><span class="line"> Val. Loss: 0.372 |  Val. Acc: 87.28%</span><br><span class="line">Epoch: 08 | Epoch Time: 0m 19s</span><br><span class="line">Train Loss: 0.052 | Train Acc: 98.39%</span><br><span class="line"> Val. Loss: 0.403 |  Val. Acc: 87.21%</span><br><span class="line">Epoch: 09 | Epoch Time: 0m 19s</span><br><span class="line">Train Loss: 0.041 | Train Acc: 98.64%</span><br><span class="line"> Val. Loss: 0.433 |  Val. Acc: 87.09%</span><br><span class="line">Epoch: 10 | Epoch Time: 0m 19s</span><br><span class="line">Train Loss: 0.031 | Train Acc: 99.10%</span><br><span class="line"> Val. Loss: 0.462 |  Val. Acc: 87.01%</span><br><span class="line">Epoch: 11 | Epoch Time: 0m 19s</span><br><span class="line">Train Loss: 0.023 | Train Acc: 99.29%</span><br><span class="line"> Val. Loss: 0.495 |  Val. Acc: 86.93%</span><br><span class="line">Epoch: 12 | Epoch Time: 0m 19s</span><br><span class="line">Train Loss: 0.021 | Train Acc: 99.34%</span><br><span class="line"> Val. Loss: 0.530 |  Val. Acc: 86.84%</span><br><span class="line">Epoch: 13 | Epoch Time: 0m 19s</span><br><span class="line">Train Loss: 0.015 | Train Acc: 99.60%</span><br><span class="line"> Val. Loss: 0.559 |  Val. Acc: 86.73%</span><br><span class="line">Epoch: 14 | Epoch Time: 0m 19s</span><br><span class="line">Train Loss: 0.013 | Train Acc: 99.69%</span><br><span class="line"> Val. Loss: 0.597 |  Val. Acc: 86.48%</span><br><span class="line">Epoch: 15 | Epoch Time: 0m 19s</span><br><span class="line">Train Loss: 0.012 | Train Acc: 99.70%</span><br><span class="line"> Val. Loss: 0.608 |  Val. Acc: 86.63%</span><br><span class="line">Epoch: 16 | Epoch Time: 0m 19s</span><br><span class="line">Train Loss: 0.009 | Train Acc: 99.76%</span><br><span class="line"> Val. Loss: 0.640 |  Val. Acc: 86.77%</span><br><span class="line">Epoch: 17 | Epoch Time: 0m 19s</span><br><span class="line">Train Loss: 0.010 | Train Acc: 99.73%</span><br><span class="line"> Val. Loss: 0.674 |  Val. Acc: 86.51%</span><br><span class="line">Epoch: 18 | Epoch Time: 0m 19s</span><br><span class="line">Train Loss: 0.012 | Train Acc: 99.63%</span><br><span class="line"> Val. Loss: 0.704 |  Val. Acc: 86.71%</span><br><span class="line">Epoch: 19 | Epoch Time: 0m 19s</span><br><span class="line">Train Loss: 0.010 | Train Acc: 99.65%</span><br><span class="line"> Val. Loss: 0.757 |  Val. Acc: 86.44%</span><br><span class="line">Epoch: 20 | Epoch Time: 0m 20s</span><br><span class="line">Train Loss: 0.006 | Train Acc: 99.80%</span><br><span class="line"> Val. Loss: 0.756 |  Val. Acc: 86.55%</span><br></pre></td></tr></table></figure><p>In [49]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å‘ç°ä¸Šé¢ç»“æœè¿‡æ‹Ÿåˆäº†ï¼ŒåŒå­¦ä»¬å¯ä»¥è‡ªè¡Œè°ƒå‚</span></span><br><span class="line">model.load_state_dict(torch.load(<span class="string">'CNN-model.pt'</span>))</span><br><span class="line">test_loss, test_acc = evaluate(model, test_iterator, criterion)</span><br><span class="line">print(<span class="string">f'Test Loss: <span class="subst">&#123;test_loss:<span class="number">.3</span>f&#125;</span> | Test Acc: <span class="subst">&#123;test_acc*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>%'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Test Loss: 0.339 | Test Acc: 85.68%</span><br></pre></td></tr></table></figure><p>In [50]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predict_sentiment(&quot;I feel This film bad&quot;)</span><br></pre></td></tr></table></figure><p>Out[50]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.6535547375679016</span><br></pre></td></tr></table></figure><p>In [52]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">predict_sentiment(&quot;This film is great well&quot;) </span><br><span class="line"># æˆ‘åé¢åŠ äº†ä¸ªwellï¼Œä¸åŠ ä¼šæŠ¥é”™ï¼Œå› ä¸ºæˆ‘ä»¬çš„FILTER_SIZES = [3,4,5]æœ‰è®¾ç½®ä¸º5ï¼Œæ‰€ä»¥è¾“å‡ºçš„å¥å­é•¿åº¦ä¸èƒ½å°äº5</span><br></pre></td></tr></table></figure><p>Out[52]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.9950380921363831</span><br></pre></td></tr></table></figure><p>In [54]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kaggleä¸Šä¸‹è½½æ¨¡å‹æ–‡ä»¶åˆ°æœ¬åœ°</span></span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> HTML</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_download_link</span><span class="params">(title = <span class="string">"Download model file"</span>, filename = <span class="string">"CNN-model.pt"</span>)</span>:</span>  </span><br><span class="line">    html = <span class="string">'&lt;a href=&#123;filename&#125;&gt;&#123;title&#125;&lt;/a&gt;'</span></span><br><span class="line">    html = html.format(title=title,filename=filename)</span><br><span class="line">    <span class="keyword">return</span> HTML(html)</span><br><span class="line"></span><br><span class="line"><span class="comment"># create a link to download the dataframe which was saved with .to_csv method</span></span><br><span class="line">create_download_link(filename=<span class="string">'CNN-model.pt'</span>)</span><br></pre></td></tr></table></figure><p>Out[54]:</p><p><a href="file:///Users/mmy/Downloads/CNN-model.pt" target="_blank" rel="noopener">Download model file</a></p><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TorchText </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>èŠå¤©æœºå™¨äººäºŒ</title>
      <link href="/2020/03/11/%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA%E4%BA%8C/"/>
      <url>/2020/03/11/%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA%E4%BA%8C/</url>
      
        <content type="html"><![CDATA[<h2 id="æ¦‚è¿°"><a href="#æ¦‚è¿°" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h2><p>æ¯”è¾ƒè‘—åçš„èŠå¤©ç³»ç»Ÿ</p><p><img src="https://uploader.shimo.im/f/e5gmAxm4zzEpvbgO.png!thumbnail" alt="img"></p><p><img src="https://uploader.shimo.im/f/MEdcyUq5bw0bd0aG.png!thumbnail" alt="img"></p><p>èŠå¤©æœºå™¨äººçš„å†å²</p><ul><li><p>1950: Turing Test</p></li><li><p>1966: ELIZA, MIT chatbot</p></li><li><p>1995: ALICE, pattern recognition chatbot</p></li><li><p>2011-2012: Siri, Watson, Google Assistant</p></li><li><p>2015: Amazon Alexa, Microsoft Cortana</p></li><li><p>2016: Bot å…ƒå¹´ï¼š Microsoft Bot Framework, FB Messenger, Google Assistant â€¦</p></li><li><p>2017: ç™¾åº¦åº¦ç§˜ï¼Œè…¾è®¯äº‘å°å¾®ï¼Œé˜¿é‡Œå°èœœ â€¦</p></li></ul><p>ASR: Acoustic speech recognition: Speech â€“&gt; Text</p><p>SLU: Spoken Language Understanding</p><p><img src="https://uploader.shimo.im/f/5jqPVZomqwIRiaKY.png!thumbnail" alt="img"></p><p>èŠå¤©æœºå™¨äººæŒ‰ç…§å…¶åŠŸèƒ½ä¸»è¦å¯ä»¥åˆ†ä¸ºä¸¤ç±»</p><ul><li><p>ä»»åŠ¡å¯¼å‘çš„èŠå¤©æœºå™¨äºº(Task-Oriented Chatbot)</p></li><li><p><strong>æœ‰å…·ä½“çš„èŠå¤©ä»»åŠ¡ï¼Œä¾‹å¦‚é…’åº—ã€æœºç¥¨ã€é¥­åº—é¢„è®¢ï¼Œç”µè¯ç›®å½•</strong></p></li><li><p>ä¹Ÿå¯ä»¥åšä¸€äº›æ›´å¤æ‚çš„å·¥ä½œï¼Œä¾‹å¦‚å‡æœŸæ—¥ç¨‹å®‰æ’ï¼Œ<strong>è®¨ä»·è¿˜ä»·</strong></p></li><li><p>goal-oriented chatbot</p></li><li><p>éä»»åŠ¡å¯¼å‘çš„èŠå¤©æœºå™¨äºº(Non-Task-Oriented Chatbot)</p></li><li><p>æ²¡æœ‰å…·ä½“çš„èŠå¤©ç›®æ ‡ï¼Œä¸»è¦ç›®çš„æ˜¯é—²èŠï¼Œèƒ½å¤Ÿå’Œç”¨æˆ·æœ‰æ›´å¤šçš„äº¤äº’</p></li><li><p>ä¹Ÿæœ‰ä¸Šè¿°ä»»åŠ¡å¯¼å‘ä¸éä»»åŠ¡å¯¼å‘çš„æ··åˆèŠå¤©æœºå™¨äººï¼ŒåŒæ—¶å…·å¤‡ä¸¤ç§åŠŸèƒ½</p></li></ul><p>æŒ‰ç…§èŠå¤©æœºå™¨äººçš„èŠå¤©é¢†åŸŸ (Domain)</p><ul><li><p>å¯¹äºä»»åŠ¡å¯¼å‘çš„æœºå™¨äººï¼ŒèŠå¤©çš„é¢†åŸŸå°±æ˜¯ä»»åŠ¡çš„é¢†åŸŸ</p></li><li><p>å…³äºæŸä¸ªç‰¹å®šä»»åŠ¡çš„æ•°æ®åº“ï¼Œä¾‹å¦‚æœºç¥¨ä¿¡æ¯ï¼Œé…’åº—ä¿¡æ¯</p></li><li><p>ä¹Ÿå¯ä»¥åŒæ—¶åŒ…å«å¤šä¸ªé¢†åŸŸçš„ä¿¡æ¯</p></li><li><p>å¯¹äºéä»»åŠ¡å¯¼å‘çš„æœºå™¨äºº</p></li></ul><p>æŒ‰ç…§èŠå¤©çš„å‘èµ·æ–¹</p><ul><li><p>ç³»ç»Ÿä¸»å¯¼ï¼ˆSystem Initiativeï¼‰çš„èŠå¤©æœºå™¨äºº</p></li><li><p>é€‚ç”¨äºä¸€äº›ç®€å•çš„ä»»åŠ¡ï¼šä¾‹å¦‚å¾ˆå¤šå¤§å…¬å¸çš„è‡ªåŠ¨ç”µè¯è¯­éŸ³ç³»ç»Ÿ</p></li><li><p>ç”¨æˆ·ä¸»å¯¼ï¼ˆUser Initiativeï¼‰çš„èŠå¤©æœºå™¨äºº</p></li><li><p>ç”¨æˆ·ä¸»å¯¼èŠå¤©çš„ä¸»é¢˜</p></li><li><p>ç³»ç»Ÿéœ€è¦å»å°½é‡è¿åˆç”¨æˆ·çš„å–œå¥½ï¼Œé™ªä»–ä»¬èŠå¤©</p></li><li><p>ç³»ç»Ÿ/ç”¨æˆ·æ··åˆä¸»å¯¼ï¼ˆMixed Initiativeï¼‰</p></li></ul><p>Alexa Prize Challenge äºšé©¬é€Šä¸¾åŠçš„èŠå¤©æœºå™¨äººå¤§èµ›</p><p><a href="https://developer.amazon.com/alexaprize/challenges/past-challenges/2018/" target="_blank" rel="noopener">https://developer.amazon.com/alexaprize/challenges/past-challenges/2018/</a></p><p>DSTC 2 &amp; 3</p><p>å…³äºæ„å»ºèŠå¤©æœºå™¨äººçš„å»ºè®®</p><ul><li><p>è¿…é€Ÿåˆ›å»ºä¸€ä¸ªbaselineï¼Œåœ¨è¿™ä¸ªBaselineçš„åŸºç¡€ä¸Šå»ä¸æ–­æé«˜</p></li><li><p><strong>å¤šæµ‹è¯•è‡ªå·±çš„èŠå¤©æœºå™¨äºº</strong></p></li></ul><p><strong>èŠå¤©æœºå™¨äººçš„è¯„ä¼°æ–¹æ³•</strong></p><ul><li><p>å¯¹äºä»»åŠ¡å¯¼å‘æ€§èŠå¤©æœºå™¨äººï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»»åŠ¡æ˜¯å¦å®Œæˆæ¥è¯„ä¼°èŠå¤©æœºå™¨äººæ˜¯å¦æˆåŠŸ</p></li><li><p><strong>Efficiency</strong></p></li><li><p><strong>Effectiveness</strong></p></li><li><p>Usability</p></li><li><p>é’ˆå¯¹éä»»åŠ¡èŠå¤©æœºå™¨äºº</p></li><li><p><strong>è‡ªåŠ¨è¯„ä¼°</strong></p></li><li><p><strong>å¯¹è¯è¿›è¡Œçš„é•¿åº¦/è½®æ•°</strong></p></li><li><p>User sentiment analysis</p></li><li><p>Positive user responses / total user responses</p></li><li><p><strong>äººç±»è¯„ä¼°</strong> </p></li><li><p>Coherence</p></li><li><p>Appropriateness</p></li><li><p>Rating</p></li><li><p>åŸºäºå‚è€ƒç­”æ¡ˆçš„è¯„ä¼°æŒ‡æ ‡ï¼Œ<strong>BLEU, ROUGE, METEOR</strong> (æœ‰å¯èƒ½ä¸å¤ªå‡†ç¡®)</p></li></ul><p>ä¹Ÿæœ‰æ–‡ç« æŒ‡å‡ºï¼Œè¿™ç§åŸºäºå‚è€ƒç­”æ¡ˆçš„è¯„ä»·æŒ‡æ ‡ä¸èƒ½å¤Ÿå¾ˆå¥½åœ°åæ˜ èŠå¤©æœºå™¨äººçš„å¥½å</p><ul><li><p>How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation</p></li><li><p><a href="https://www.aclweb.org/anthology/D16-1230" target="_blank" rel="noopener">https://www.aclweb.org/anthology/D16-1230</a></p></li></ul><p>æ‰€ä»¥å¾ˆå¤šæ—¶å€™ï¼Œæˆ‘ä»¬å¯¹èŠå¤©æœºå™¨äººï¼Œå°¤å…¶æ˜¯é—²èŠæœºå™¨äººçš„è¯„ä¼°ä¾ç„¶ä¾èµ–äºäººç±»è¯„ä¼°ã€‚äººä»¬ä¹Ÿå¼€å§‹å°è¯•ä¸€äº›<strong>æ·±åº¦å­¦ä¹ çš„æ¨¡å‹</strong>æ¥é¢„æµ‹äººç±»ç»™æ¨¡å‹çš„æ‰“åˆ†ã€‚</p><p>æ„å»ºèŠå¤©æœºå™¨äººçš„ä¸‰å¤§æ¨¡å—</p><p><img src="https://uploader.shimo.im/f/xAwqqhmELsc4JfFY.png!thumbnail" alt="img"></p><ul><li><p>Coherence</p></li><li><p>User experience</p></li><li><p>Engagement Management</p></li></ul><h3 id="è‡ªç„¶è¯­è¨€ç†è§£ï¼ˆNatural-Language-Understandingï¼‰"><a href="#è‡ªç„¶è¯­è¨€ç†è§£ï¼ˆNatural-Language-Understandingï¼‰" class="headerlink" title="è‡ªç„¶è¯­è¨€ç†è§£ï¼ˆNatural Language Understandingï¼‰"></a>è‡ªç„¶è¯­è¨€ç†è§£ï¼ˆNatural Language Understandingï¼‰</h3><p>NLUçš„ä¸»è¦ä»»åŠ¡æ˜¯ä»æ–‡æœ¬ä¸­æå–ä¿¡æ¯ï¼ŒåŒ…æ‹¬å¯¹è¯<strong>æ–‡æœ¬çš„æ„å›¾</strong>ï¼Œæ–‡æœ¬ä¸­<strong>å…³é”®çš„ä¿¡æ¯</strong>ï¼Œä¾‹å¦‚<strong>å‘½åå®ä½“</strong>ï¼Œå¹¶ä¸”å°†è¿™äº›ä¿¡æ¯è½¬æˆæ¯”è¾ƒ<strong>æ ‡å‡†åŒ–</strong>çš„è¡¨ç¤ºæ–¹å¼ä»¥ä¾›åç»­èŠå¤©æœºå™¨äººæ¨¡å—ä½¿ç”¨ã€‚</p><p><strong>é¢ä¸´çš„æŒ‘æˆ˜</strong></p><ul><li><p><strong>å»é™¤å£è¯­åŒ–çš„è¡¨è¾¾</strong></p></li><li><p><strong>è¯è¯­é‡å¤</strong></p></li><li><p><strong>è®²è¯ä¸­è‡ªæˆ‘ä¿®æ­£</strong></p></li><li><p><strong>å£è¯­åŒ–çš„è¡¨è¿°å’Œåœé¡¿</strong></p></li></ul><h3 id="Frame-based-SLU-Spoken-Language-Understanding"><a href="#Frame-based-SLU-Spoken-Language-Understanding" class="headerlink" title="Frame-based SLU (Spoken Language Understanding)"></a>Frame-based SLU (Spoken Language Understanding)</h3><p>Meaning Representation Language</p><p>æŠŠè‡ªç„¶è¯­è¨€è½¬å˜æˆä¸€ç§å›ºå®šçš„ç»“æ„åŒ–æ•°æ®è¡¨è¾¾å½¢å¼</p><ul><li><p>æœ‰å›ºå®šçš„è¯­æ³•ç»“æ„</p></li><li><p>è®¡ç®—æœºå¯æ‰§è¡Œçš„è¯­è¨€</p></li></ul><p>Do you have any flights from <strong>Seattle</strong> to <strong>Boston</strong> on <strong>December 24th</strong>? </p><p>O O O O O O BDCity O BACity O BDDate IDDate</p><p>BiLSTM â€“&gt; Classification (CRF)</p><p><img src="https://uploader.shimo.im/f/m78yw5M7YBkbMIb8.png!thumbnail" alt="img"></p><p>Intent classification â€“&gt; ShowFlight</p><p>POS </p><p>è¿™ç§ä¿¡æ¯æŠ½å–çš„ä»»åŠ¡å¾€å¾€å¯ä»¥é€šè¿‡<strong>HMM, CRF</strong>ç­‰æ¨¡å‹å®ç°</p><p>other</p><p>B-Departure</p><p>I-Departure</p><p>B-Arrival</p><p>I-Arrival</p><p>B-Date</p><p>I-Date</p><p>conll-2003</p><h3 id="æ„å›¾è¯†åˆ«-Intent-Classification"><a href="#æ„å›¾è¯†åˆ«-Intent-Classification" class="headerlink" title="æ„å›¾è¯†åˆ« (Intent Classification)"></a>æ„å›¾è¯†åˆ« (Intent Classification)</h3><p>Coarse-grained</p><ul><li><p>æŠŠç”¨æˆ·çš„å½“å‰è®²è¯çš„æ„å›¾å½’ç±»åˆ°æˆ‘ä»¬æå‰æŒ‡å®šçš„ä¸€äº›ç±»åˆ«ä¸­å»</p></li><li><p>ç»™å®šä¸€å¥è¯ (utterance X)ï¼Œç»™å®šä¸€ç³»åˆ— intent classes: C_1, â€¦, C_Mã€‚é¢„æµ‹å½“å‰ utterance å±äºå“ªä¸€ä¸ªintentç±»åˆ«ã€‚</p></li><li><p>åŒæ ·çš„intentå¯èƒ½æœ‰å¾ˆå¤šä¸åŒçš„è¡¨è¾¾æ–¹å¼</p></li><li><p>æˆ‘æƒ³è¦é¢„è®¢åå¤©åŒ—äº¬åˆ°ä¸Šæµ·çš„æœºç¥¨</p></li><li><p>èƒ½å¸®æˆ‘è®¢ä¸€å¼ åå¤©ä»é¦–éƒ½æœºåœºåˆ°æµ¦ä¸œæœºåœºçš„æœºç¥¨å—ï¼Ÿ</p></li><li><p>åå¤©ä»åŒ—äº¬åˆ°è™¹æ¡¥çš„æœºç¥¨æœ‰å—ï¼Ÿ</p></li></ul><p><img src="https://uploader.shimo.im/f/ERAAvjjCqQ80MNQ1.png!thumbnail" alt="img"></p><h3 id="å‘½åå®ä½“è¯†åˆ«"><a href="#å‘½åå®ä½“è¯†åˆ«" class="headerlink" title="å‘½åå®ä½“è¯†åˆ«"></a>å‘½åå®ä½“è¯†åˆ«</h3><p>ä»ä¸€æ®µæ–‡æœ¬ä¸­æŠ½å–<strong>å‘½åå®ä½“</strong></p><p>å‘½åå®ä½“çš„ç±»åˆ«</p><ul><li>æœºæ„ã€ä»»åŠ¡ã€åœ°ç‚¹ã€æ—¶é—´ã€æ—¥æœŸã€é‡‘é’±ã€ç™¾åˆ†æ¯”</li></ul><p>ä¸»è¦çš„æ–¹æ³•</p><ul><li>åŸºäºHMM, CRF, RNN (LSTM) ç­‰æ¨¡å‹çš„ token æ ‡æ³¨æ–¹æ³•</li></ul><h3 id="å…³äº-semantic-parsing-å’Œ-slot-filling"><a href="#å…³äº-semantic-parsing-å’Œ-slot-filling" class="headerlink" title="å…³äº semantic parsing å’Œ slot filling"></a>å…³äº semantic parsing å’Œ slot filling</h3><p>semantic parsing: éç»“æ„åŒ–çš„è¯­è¨€è½¬æ¢æˆç»“æ„åŒ–çš„æŒ‡ä»¤</p><p><a href="https://nlpprogress.com/english/semantic_parsing.html" target="_blank" rel="noopener">https://nlpprogress.com/english/semantic_parsing.html</a></p><p><img src="https://uploader.shimo.im/f/qbDxmHsMGfcnMNQa.png!thumbnail" alt="img"></p><p>Find_Flight(Boston, New York)</p><p>semantic parsing</p><ul><li><p>intent classification </p></li><li><p>arguments parsing</p></li></ul><p>Open(â€œbaidumapâ€, city=â€Beijingâ€);</p><p>Open(â€œGoogle mapâ€, city=â€Beijingâ€);</p><p>Close(â€œGoogle mapâ€, city=â€Beijingâ€);</p><p>Install(â€œâ€)</p><p>BERT for Joint Intent Classification and Slot Filling</p><p><a href="https://arxiv.org/pdf/1902.10909.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1902.10909.pdf</a></p><h3 id="Dialogue-State-Tracking"><a href="#Dialogue-State-Tracking" class="headerlink" title="Dialogue State Tracking"></a>Dialogue State Tracking</h3><p>DSTC æ¯”èµ›å’Œæ•°æ®é›†</p><p><a href="http://camdial.org/~mh521/dstc/" target="_blank" rel="noopener">http://camdial.org/~mh521/dstc/</a></p><h1 id="å¯¹è¯ç®¡ç†"><a href="#å¯¹è¯ç®¡ç†" class="headerlink" title="å¯¹è¯ç®¡ç†"></a><strong>å¯¹è¯ç®¡ç†</strong></h1><p>ä»€ä¹ˆæ˜¯å¯¹è¯ç®¡ç†ï¼Ÿ</p><ul><li><p>ä¸€èˆ¬æ˜¯èŠå¤©æœºå™¨äººçš„ä¸­å¿ƒæ¨¡å—ï¼Œæ§åˆ¶æ•´ä¸ªèŠå¤©çš„è¿‡ç¨‹ã€‚ä¸Šé¢æ‰¿æ¥NLUï¼Œåé¢è¿ç€NLGï¼Œè´Ÿè´£<strong>å‚¨å­˜èŠå¤©çš„ä¿¡æ¯å’ŒçŠ¶æ€(slot filling)</strong>ï¼Œæ ¹æ®å·²æœ‰çš„ä¿¡æ¯ (å½“å‰èŠå¤©è®°å½•å’Œå¤–éƒ¨ä¿¡æ¯)ï¼Œå†³å®šä¸‹ä¸€æ­¥åšä»€ä¹ˆã€‚</p></li><li><p>è´Ÿè´£ä¸ä¸€äº›å¤–éƒ¨çš„<strong>çŸ¥è¯†åº“</strong>åšäº¤äº’ï¼Œä¾‹å¦‚Knowledge baseï¼Œå„ç§æ•°æ®åº“</p></li></ul><p>Dialogue <strong>Context</strong> Modeling</p><ul><li><p>èŠå¤©çš„è¿‡ç¨‹å¾€å¾€æ˜¯é«˜åº¦åŸºäºå¯¹è¯è®°å½•çš„ï¼Œå¾ˆå¤šæ—¶å€™æˆ‘ä»¬ä¼šç”¨ä»£è¯æŒ‡ä»£ä¹‹å‰çš„åè¯æˆ–å®ä½“</p></li><li><p>ä½ æƒ³èŠä¸€äº›å…³äºç§‘æŠ€çš„è¿˜æ˜¯æ°‘ç”Ÿçš„è¯é¢˜ï¼Ÿ</p></li><li><p>èŠç¬¬äºŒä¸ªå§ â€“&gt; æ°‘ç”Ÿ</p></li><li><p><strong>å…±æŒ‡æ¶ˆè§£</strong> (Coreference Resolution)</p></li><li><p>æœ‰æ—¶å€™æˆ‘ä»¬ä¼š<strong>çœç•¥</strong>ä¸€äº›æ˜¾è€Œæ˜“è§çš„ä¿¡æ¯</p></li><li><p>ä½ æ‰“ç®—ä»€ä¹ˆæ—¶å€™åƒé¥­ï¼Ÿ</p></li><li><p>æ™šä¸Š7ç‚¹ï¼ˆ<strong>åƒé¥­</strong>ï¼‰</p></li><li><p>æœ‰æ—¶å€™æˆ‘ä»¬ä¼šçœç•¥ä¸€äº›ä¿¡æ¯ï¼ˆå½“æˆ‘ä»¬å’Œä¸€äº›èŠå¤©æœºå™¨äººèŠå¤©çš„æ—¶å€™ï¼‰</p></li><li><p>æ”¾ç‚¹<strong>å¥½å¬</strong>çš„éŸ³ä¹ï¼ˆæ”¾ä»€ä¹ˆéŸ³ä¹ï¼Ÿæ ¹æ®å†å²è®°å½•æ”¾ï¼Ÿé€‰ç”¨æˆ·æœ€å–œæ¬¢çš„éŸ³ä¹ï¼Ÿï¼‰</p></li><li><p><strong>å¼€ç¯</strong> ï¼ˆå¼€ä»€ä¹ˆç¯ï¼ŸåºŠå¤´ç¯ï¼Ÿé¡¶ç¯ï¼Ÿå®¢å…çš„ç¯ï¼Ÿå§å®¤çš„ç¯ï¼Ÿï¼‰</p></li></ul><p>èŠå¤©<strong>context</strong>çš„æ¥æº</p><ul><li><p>èŠå¤©å†å²ï¼Œä¾‹å¦‚<strong>èŠå¤©å†å²</strong>çš„çº¯æ–‡æœ¬å†…å®¹ï¼ŒèŠå¤©è®°å½•ä¸­æåˆ°è¿‡çš„<strong>å‘½åå®ä½“</strong>ã€<strong>ä¸»é¢˜</strong>ç­‰ç­‰</p></li><li><p>ä»»åŠ¡è®°å½•</p></li><li><p>å¯¹äºä¸€ä¸ªä»»åŠ¡å‹èŠå¤©æœºå™¨äººæ¥è¯´ï¼ŒèŠå¤©æœºå™¨äººå¾€å¾€ä¼šä¿å­˜ä¸€äº›ç»“æ„åŒ–çš„èŠå¤©è®°å½•ï¼Œè¿™äº›è®°å½•æœ‰æ—¶å€™è¢«ç§°ä¸º <strong>form</strong>, frame, template, status graphã€‚ä¾‹å¦‚å¯¹äºä¸€ä¸ªè®¢æœºç¥¨èŠå¤©æœºå™¨äººæ¥è¯´ï¼Œå®ƒéœ€è¦æ”¶é›†ç”¨æˆ·çš„<strong>å§“åï¼Œèº«ä»½è¯å·ç ï¼Œå‡ºå‘æœºåœºï¼Œåˆ°è¾¾æœºåœºï¼Œèˆªç­æ—¶é—´è¦æ±‚ï¼Œä»·æ ¼è¦æ±‚</strong>ï¼Œç­‰ç­‰ã€‚ç„¶åæ‰å¯ä»¥å¸®åŠ©ç”¨æˆ·åšå†³ç­–ã€‚</p></li><li><p>æˆ‘ä»¬éœ€è¦çŸ¥é“å“ªäº›ä¿¡æ¯å·²ç»è¢«æ”¶é›†åˆ°äº†ï¼Œå“ªäº›ä¿¡æ¯è¿˜æ²¡æœ‰è¢«æ”¶é›†åˆ°ã€‚ç„¶åæ ¹æ®éœ€è¦æ”¶é›†çš„ä¿¡æ¯ç¡®å®šä¸‹ä¸€æ­¥æœºå™¨äººéœ€è¦è·Ÿç”¨æˆ·è¯´ä»€ä¹ˆã€‚</p></li></ul><p>Knowledge Base</p><p>æ ¹æ®<strong>èŠå¤©ä»»åŠ¡çš„ä¸åŒ</strong>ï¼ŒèŠå¤©æœºå™¨äººéœ€è¦ä¸åŒçš„Knowledge Base</p><ul><li><p>å¯¹äºèˆªç­è®¢ç¥¨æœºå™¨äººæ¥è¯´ï¼Œéœ€è¦èˆªç­ä¿¡æ¯çš„æ•°æ®åº“</p></li><li><p>å¯¹äºé…’åº—é¢„è®¢æœºå™¨äººæ¥è¯´ï¼Œéœ€è¦é…’åº—æ•°æ®åº“</p></li><li><p>å¯¹äºé—²èŠæœºå™¨äººæ¥è¯´ï¼Œå„ç§é—²èŠä¸­éœ€è¦ç”¨åˆ°çš„ä¿¡æ¯ï¼Œæ–°é—»ã€è´¢ç»ã€ç”µå½±å¨±ä¹ç­‰ç­‰</p></li></ul><p>Dialogue Control (Dialogue Act)   </p><p>æ ¹æ®Context, èŠå¤©å†å²ï¼Œknowledge base â€“&gt; action å¯èƒ½æ˜¯<strong>rule based å†³ç­–</strong>ï¼Œä¹Ÿå¯èƒ½æ˜¯åŸºäºæœºå™¨å­¦ä¹ æ¨¡å‹çš„å†³ç­–ã€‚</p><ul><li><p>æ ¹æ®å½“å‰ï¼ˆä»ç”¨æˆ·å’Œå…¶ä»–æ•°æ®æ¥æºï¼‰è·å–çš„ä¿¡æ¯ï¼Œå†³å®šä¸‹ä¸€æ­¥éœ€è¦é‡‡å–æ€æ ·çš„è¡ŒåŠ¨</p></li><li><p>å¯ä»¥åšçš„å†³ç­–æœ‰ï¼š</p></li><li><p>ä»ç”¨æˆ·å¤„<strong>æ”¶é›†æ›´å¤šçš„ä¿¡æ¯</strong></p></li><li><p>ä¸ç”¨æˆ·<strong>ç¡®è®¤</strong>ä¹‹å‰çš„ä¿¡æ¯</p></li><li><p><strong>å‘ç”¨æˆ·è¾“å‡ºä¸€äº›ä¿¡æ¯</strong></p></li><li><p>ä¸€äº›è®¾è®¡è¦ç´ </p></li><li><p>ç”±ç”¨æˆ·è¿˜æ˜¯ç³»ç»Ÿæ¥ä¸»å¯¼å¯¹è¯</p></li><li><p>æ˜¯å¦è¦å‘ç”¨æˆ·è§£é‡Šè‡ªå·±çš„åŠ¨ä½œ</p></li></ul><p>å¯¹è¯çš„ä¸»å¯¼æ–¹</p><ul><li><p>ç”¨æˆ·ä¸»å¯¼</p></li><li><p>ç”¨æˆ·æ¥æ§åˆ¶å¯¹è¯çš„è¿›ç¨‹</p></li><li><p>ç³»ç»Ÿä¸ä¼šè‡ªç”±å‘æŒ¥ï¼Œè€Œæ˜¯è·Ÿéšç”¨æˆ·çš„æ€è·¯</p></li><li><p>åœ¨ä¸€äº›<strong>QAç³»ç»Ÿå’ŒåŸºäºæœç´¢çš„ç³»ç»Ÿ</strong>ä¸­è¾ƒä¸ºå¸¸è§</p></li><li><p><strong>ç³»ç»Ÿä¸»å¯¼</strong></p></li><li><p>ç³»ç»Ÿæ§åˆ¶å¯¹è¯çš„è¿›ç¨‹</p></li><li><p>ç³»ç»Ÿå†³å®šäº†ç”¨æˆ·èƒ½è¯´ä»€ä¹ˆï¼Œä¸èƒ½è¯´ä»€ä¹ˆ</p></li><li><p>å¯¹äºç³»ç»Ÿå¬ä¸æ‡‚çš„è¯ï¼Œç³»ç»Ÿå¯ä»¥å¿½ç•¥æˆ–è€…å‘Šè¯‰ç”¨æˆ·è‡ªå·±æ— æ³•è§£å†³</p></li><li><p>åœ¨ä¸€äº›ç®€å•ä»»åŠ¡çš„æœºå™¨äººä¸­å¾ˆå¸¸è§</p></li><li><p>æ··åˆä¸»å¯¼</p></li><li><p>ä»¥ä¸Šä¸¤ç§ç³»ç»Ÿçš„æ··åˆç‰ˆï¼Œå¯ä»¥æ˜¯ç®€å•çš„ç»„åˆï¼Œä¹Ÿå¯ä»¥è®¾è®¡åœ°æ›´å¤æ‚</p></li></ul><p>Dialogue Control çš„ä¸€äº›æ–¹æ³•</p><ul><li><p><strong>åŸºäºFinite state machine</strong> </p></li><li><p><strong>åŸºäºFrame</strong></p></li><li><p><strong>åŸºäºç»Ÿè®¡å­¦æ¨¡å‹(æœºå™¨å­¦ä¹ ï¼‰</strong></p></li><li><p>AI planning</p></li></ul><h3 id="åŸºäº-Finite-State-çš„èŠå¤©æ§åˆ¶"><a href="#åŸºäº-Finite-State-çš„èŠå¤©æ§åˆ¶" class="headerlink" title="åŸºäº Finite-State çš„èŠå¤©æ§åˆ¶"></a>åŸºäº Finite-State çš„èŠå¤©æ§åˆ¶</h3><p>Finite State Automata æœ‰é™çŠ¶æ€æœº</p><ul><li><p>èŠå¤©æœºå™¨äººè·Ÿä»ä¸€ä¸ªç±»ä¼¼ finite state automata çš„ç³»ç»Ÿ</p></li><li><p>èŠå¤©æœºå™¨äººåœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šå¯ä»¥åšçš„äº‹æƒ…æ˜¯ç¡®å®šçš„</p></li><li><p>2018å¹´ Alexa Prize çš„ Tartan æ¨¡å‹ </p></li><li><p><a href="https://m.media-amazon.com/images/G/01/mobile-apps/dex/alexa/alexaprize/assets/pdf/2018/Tartan.pdf" target="_blank" rel="noopener">https://m.media-amazon.com/images/G/01/mobile-apps/dex/alexa/alexaprize/assets/pdf/2018/Tartan.pdf</a></p></li></ul><p><img src="https://uploader.shimo.im/f/J3a3dBGf89MpaIdI.png!thumbnail" alt="img"></p><p><img src="https://uploader.shimo.im/f/QThWtsbtshQkEqNS.png!thumbnail" alt="img"></p><ul><li><p>ç³»ç»Ÿå®Œå…¨æ§åˆ¶äº†æ•´åœºå¯¹è¯</p></li><li><p>ç³»ç»Ÿä¼šä¸€ç›´å‘ç”¨æˆ·æé—®</p></li><li><p>ç³»ç»Ÿä¼šå¿½ç•¥ä»»ä½•å®ƒä¸éœ€è¦çš„ä¿¡æ¯</p></li></ul><p>è¿™ç§æ§åˆ¶ç³»ç»Ÿçš„å¥½å¤„æ˜¯</p><ul><li><p>å®¹æ˜“è®¾è®¡å’Œå®ç°ï¼Œå®Œå…¨ä½¿ç”¨<strong>if-elseè¯­å¥</strong></p></li><li><p>åŠŸèƒ½éå¸¸ç¡®å®šï¼Œå¯æ§åˆ¶</p></li><li><p>å…¶ä¸­<strong>Stateçš„transitionå¯ä»¥åŸºäºéå¸¸å¤æ‚çš„æ¡ä»¶å’Œå¯¹è¯çŠ¶æ€</strong></p></li></ul><p>åå¤„æ˜¯</p><ul><li><p>æ²¡æœ‰ä»€ä¹ˆçµæ´»æ€§ï¼ŒçœŸçš„æ˜¯ä¸€ä¸ªæœºå™¨äºº</p></li><li><p>åªèƒ½æ”¯æŒç³»ç»Ÿä¸»å¯¼çš„å¯¹è¯</p></li></ul><h3 id="Frame-Based-Dialogue-Control"><a href="#Frame-Based-Dialogue-Control" class="headerlink" title="Frame-Based Dialogue Control"></a>Frame-Based Dialogue Control</h3><ul><li>é¢„å…ˆæŒ‡å®šäº†ä¸€å¼ <strong>è¡¨æ ¼ (Frame)</strong>ï¼ŒèŠå¤©æœºå™¨äººçš„ç›®æ ‡å°±æ˜¯æŠŠè¿™å¼ è¡¨æ ¼å¡«æ»¡</li></ul><p><img src="https://uploader.shimo.im/f/uQcxBjpZ5LEGAZfQ.png!thumbnail" alt="img"></p><p>æˆ‘ä»¬å¯ä»¥é¢„å…ˆæŒ‡å®šä¸€äº›é—®é¢˜ï¼Œç”¨æ¥ä»ç”¨æˆ·å¤„å¾—åˆ°æˆ‘ä»¬æƒ³è¦çš„ä¿¡æ¯</p><table><thead><tr><th><strong>Slot</strong></th><th><strong>Question</strong></th></tr></thead><tbody><tr><td>å‡ºå‘åœ°</td><td>ä½ ä»å“ªä¸ªåŸå¸‚æˆ–æœºåœºå‡ºå‘ï¼Ÿ</td></tr><tr><td>ç›®çš„åœ°</td><td>ä½ è¦å»å“ªä¸ªåŸå¸‚ï¼Ÿ</td></tr><tr><td>èµ·é£æ—¥æœŸ</td><td>ä½ çš„èµ·é£æ—¥æœŸæ˜¯ï¼Ÿ</td></tr><tr><td>èµ·é£æ—¶é—´</td><td>ä½ æƒ³å‡ ç‚¹é’Ÿèµ·é£ï¼Ÿ</td></tr><tr><td>èˆªç©ºå…¬å¸</td><td>ä½ æœ‰åå¥½çš„èˆªç©ºå…¬å¸å—ï¼Ÿ</td></tr><tr><td>å§“å</td><td>ä½ çš„åå­—å«ä»€ä¹ˆï¼Ÿ</td></tr><tr><td>è¯ä»¶å·ç </td><td>ä½ çš„èº«ä»½è¯å·ç æ˜¯å¤šå°‘ï¼Ÿ â€“&gt; æŠ¤ç…§</td></tr><tr><td></td><td></td></tr></tbody></table><p>æé—®çš„å…ˆåä¸éœ€è¦ç¡®å®šã€‚ç”¨æˆ·ä¹Ÿå¯ä»¥åŒæ—¶å›ç­”å¤šä¸ªé—®é¢˜ã€‚</p><p>æ ¹æ®å½“å‰æœªçŸ¥ä¿¡æ¯çš„ç»„åˆï¼Œç³»ç»Ÿå¯ä»¥æå‡ºä¸åŒçš„é—®é¢˜</p><ul><li><p>æœªçŸ¥ä¿¡æ¯ï¼ˆå‡ºå‘åœ°ã€ç›®çš„åœ°ï¼‰ï¼šä½ çš„æ—…è¡Œè·¯çº¿æ˜¯ï¼Ÿ</p></li><li><p>æœªçŸ¥ä¿¡æ¯ï¼ˆå‡ºå‘åœ°ï¼‰ï¼šä½ çš„å‡ºå‘åŸå¸‚æ˜¯å“ªé‡Œï¼Ÿ</p></li><li><p>æœªçŸ¥ä¿¡æ¯ï¼ˆç›®çš„åœ°ï¼‰ï¼šä½ çš„ç›®çš„åœ°æ˜¯å“ªé‡Œï¼Ÿ</p></li><li><p>å‡ºå‘åœ°+èµ·é£æ—¥æœŸï¼šä½ æ‰“ç®—å“ªå¤©ä»å“ªä¸ªæœºåœºå‡ºå‘ï¼Ÿ</p></li></ul><p>åªè¦è¿™å¼ mappingçš„è¡¨æ ¼è¶³å¤Ÿå…¨é¢ï¼Œæˆ‘ä»¬å°±å¯ä»¥å¤„ç†å„ç§æƒ…å†µã€‚</p><p><strong>Frame-Basedçš„æ–¹æ³•æ¯”Finite-Stateè¦</strong>çµæ´»ä¸€äº›ï¼Œä½†æœ¬è´¨ä¸Šè¿˜æ˜¯ä¸€ä¸ªéå¸¸å›ºå®šçš„æ–¹æ³•ï¼Œåœ¨æœ‰é™çš„ç©ºé—´é‡Œå®Œæˆä¸€é¡¹ç‰¹å®šçš„ä»»åŠ¡ã€‚</p><p>è¿™ä¸¤ç§æ–¹æ³•çš„ä¸»è¦ç¼ºé™·åœ¨äºï¼š</p><ul><li><strong>éœ€è¦èŠ±å¾ˆå¤šæ—¶é—´è€ƒè™‘å„ç§æƒ…å†µï¼Œäººä¸ºè®¾è®¡å¯¹è¯è·¯çº¿ï¼Œæœ‰å¯èƒ½ä¼šå‡ºç°ä¸€äº›æƒ…å†µæ²¡æœ‰è¢«è®¾è®¡åˆ°ã€‚</strong></li></ul><p>intent (entities), state â€“&gt; <strong>action</strong> , reward â€“&gt; intent (entities), state â€“&gt; <strong>action</strong> , reward â€“&gt; intent (entities), state â€“&gt; ? </p><p>optional below</p><h3 id="åŸºäºç»Ÿè®¡æ¨¡å‹çš„Dialogue-Control"><a href="#åŸºäºç»Ÿè®¡æ¨¡å‹çš„Dialogue-Control" class="headerlink" title="åŸºäºç»Ÿè®¡æ¨¡å‹çš„Dialogue Control"></a>åŸºäºç»Ÿè®¡æ¨¡å‹çš„Dialogue Control</h3><p>åŸºäºç»Ÿè®¡å­¦å’Œæ•°æ®çš„èŠå¤©æœºå™¨äººæ¨¡å‹</p><ul><li><p>ä¸€å¥—å›ºå®šçš„states S èŠå¤©å†å²</p></li><li><p>ä¸€å¥—å›ºå®šçš„actions A ä¸‹ä¸€å¥è¦è®²çš„è¯</p></li><li><p>ä¸€å¥—ç³»ç»Ÿperformanceçš„è¯„ä»·æŒ‡æ ‡ <strong>reward è‡ªå·±è®¾è®¡</strong></p></li><li><p>ä¸€ä¸ª<strong>policy</strong> \piï¼Œå†³å®šäº†åœ¨ä¸€ä¸ªstateä¸‹å¯ä»¥é‡‡å–æ€æ ·çš„action ï¼ˆå¯èƒ½æ˜¯ä¸€ä¸ªç¥ç»ç½‘ç»œï¼‰æ ¹æ®å½“å‰çš„èŠå¤©å†å²ï¼Œå†³å®šä¸‹ä¸€å¥è¯è®²ä»€ä¹ˆ</p></li></ul><p>è®­ç»ƒæ–¹æ³•</p><ul><li><p>ç›‘ç£å­¦ä¹ ï¼Œéœ€è¦å¾ˆå¤šçš„è®­ç»ƒæ•°æ®</p></li><li><p><strong>å¼ºåŒ–å­¦ä¹  (Reinforcement Learning)ï¼Œéœ€è¦ä¼˜åŒ–æ¨¡å‹çš„æœ€ç»ˆå›æŠ¥ (return)</strong></p></li><li><p><strong>é™¤äº†ä¸Šé¢çš„ä¿¡æ¯ä¹‹å¤–ï¼Œè¿˜è¦åŠ å…¥ä¸€ä¸ªå›æŠ¥å‡½æ•°</strong></p></li></ul><p>å…³äºå¦‚ä½•åš<strong>å¼ºåŒ–å­¦ä¹ </strong>ï¼Ÿæˆ‘ä»¬è¿™é‡Œä¸å†è¯¦ç»†å±•å¼€ï¼Œæ„Ÿå…´è¶£çš„åŒå­¦å¯ä»¥é˜…è¯»</p><ul><li><p><a href="https://hao-cheng.github.io/ee596_spr2019/slides/lecture_5-dialog_management.pdf" target="_blank" rel="noopener">https://hao-cheng.github.io/ee596_spr2019/slides/lecture_5-dialog_management.pdf</a></p></li><li><p><strong>David Silver</strong>çš„RLè¯¾ç¨‹ <a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html" target="_blank" rel="noopener">http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html</a></p></li><li><p>Richard Sutton</p></li><li><p><strong>å¼ºåŒ–å­¦ä¹ çŸ¥è¯†å¤§è®²å ‚</strong>  <a href="https://zhuanlan.zhihu.com/p/25498081" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/25498081</a></p></li></ul><p>è¿™ç¯‡æ¥è‡ªJiwei Liçš„æ–‡ç« å¼•ç”¨é‡å¾ˆé«˜</p><p>Deep Reinforcement Learning for Dialogue Generation</p><p><a href="https://aclweb.org/anthology/D16-1127" target="_blank" rel="noopener">https://aclweb.org/anthology/D16-1127</a></p><p>åœ¨é—²èŠæœºå™¨äººä¸­çš„Dialogue Control</p><ul><li><p>å¯èƒ½æ¶‰åŠåˆ°çš„è¯é¢˜ç©ºé—´è¾ƒå¤§ï¼ŒèŠå¤©çš„æ§åˆ¶æ¯”è¾ƒå¤æ‚</p></li><li><p>æ²¡æœ‰æ˜ç¡®çš„ä»»åŠ¡ç›®æ ‡ï¼Œå¾ˆéš¾å®šä¹‰rewardå‡½æ•°ï¼Œå¯èƒ½å”¯ä¸€çš„ç›®æ ‡å°±æ˜¯è®©èŠå¤©æ—¶é—´å˜é•¿</p></li></ul><p>å¸¸è§çš„åšæ³•</p><ul><li><p><strong>æŠŠèŠå¤©æœºå™¨äººåˆ†æˆå‡ ä¸ªä¸åŒçš„æ¨¡å—</strong>ï¼Œæ¯ä¸ª<strong>æ¨¡å—å¯ä»¥è´Ÿè´£ä¸€äº›èŠå¤©çš„å­è¯é¢˜</strong>ï¼Œæˆ–è€…ç”±ä¸€äº›ä¸åŒçš„æ¨¡å‹å®ç°</p></li><li><p>æœ‰ä¸€ä¸ªmasteræ¨¡å—è´Ÿè´£åˆ†é…èŠå¤©ä»»åŠ¡ç»™ä¸åŒçš„æ¨¡å—</p></li></ul><p>é˜¶æ¢¯åŒ–çš„æ¨¡å—</p><ul><li><p>èŠå¤©å†å²è®°å½•æ¨¡å— (Dialogue State/Context Tracking)</p></li><li><p><strong>Master Dialogue Manage</strong>r</p></li><li><p><strong>Miniskill Dialogue Manager</strong></p></li></ul><p>å¾ˆå¤šMiniskill Dialogue Manageræ˜¯ç”±finite-state-machineæ¥å®ç°çš„ï¼Œå¯ä»¥é€šè¿‡å¼•å…¥ä¸€äº›non-deterministic finite automataæ¥å¢åŠ èŠå¤©çš„ä¸°å¯Œåº¦å’Œå¤šæ ·æ€§</p><p><strong>action, slot values (key value pairs)</strong></p><p>dialogue history</p><h1 id="è‡ªç„¶è¯­è¨€ç”Ÿæˆ-Natural-Language-Generation-NLG"><a href="#è‡ªç„¶è¯­è¨€ç”Ÿæˆ-Natural-Language-Generation-NLG" class="headerlink" title="è‡ªç„¶è¯­è¨€ç”Ÿæˆ Natural Language Generation (NLG)"></a>è‡ªç„¶è¯­è¨€ç”Ÿæˆ Natural Language Generation (NLG)</h1><h2 id="Template-based"><a href="#Template-based" class="headerlink" title="Template based"></a>Template based</h2><p>display_flight_info </p><p>action: ask_departure_city</p><ul><li><p>ä½ è¦ä»å“ªä¸ªæœºåœºç¦»å¼€ï¼Ÿ</p></li><li><p>ä½ ä»å“ªé‡Œèµ·é£ï¼Ÿ</p></li></ul><p>ask_time</p><p>ä½¿ç”¨æ¨¡æ¿æ¥ç”Ÿæˆå¥å­</p><ul><li><p>[DEPARTURE-CITY]:  ä½ æ‰“ç®—å‡ ç‚¹é’Ÿç¦»å¼€ [DEPARTURE-CITY]?</p></li><li><p>[TOPIC]: ä¸å¦‚èŠèŠ [TOPIC]?</p></li></ul><h2 id="Retrieval-Based"><a href="#Retrieval-Based" class="headerlink" title="Retrieval Based"></a>Retrieval Based</h2><p>Response <strong>R**</strong>e<strong><strong>tr</strong></strong>i<strong>**eval</strong></p><ul><li><p>æ ¹æ®å½“å‰çš„å¯¹è¯åœºæ™¯/å†å²å†³å®šæå–æ€æ ·çš„å›å¤</p></li><li><p>åŸºäºretrievalè€Œä¸æ˜¯generationçš„æ–¹æ³•</p></li><li><p>å¯ä»¥ä½¿ç”¨æœºå™¨å­¦ä¹ çš„æ¨¡å‹æ¥è®­ç»ƒæŠ½å–æ¨¡å‹</p></li><li><p>å¯ä»¥æ ¹æ®<strong>similarity</strong> <strong>mat**</strong>c<strong><strong>hi</strong></strong>n<strong>**g</strong>çš„æ–¹æ³•ï¼šELMo, average, cosine similarity. Google universal sentence encoder. è‡ªå·±è®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Ÿ</p></li><li><p>å¯ä»¥åˆ©ç”¨ä¸€äº›åˆ«çš„åŸºäºæœç´¢çš„æ–¹æ³•</p></li></ul><p><img src="https://uploader.shimo.im/f/2QSr9OIvUKEFJ9B0.png!thumbnail" alt="img"></p><p>æ€è€ƒä¸€ä¸‹ä½ ä¼šæ€ä¹ˆæ„å»ºè¿™ä¸ªæ¨¡å‹ï¼Ÿ</p><p>å¯ä»¥ç”¨å®ƒæ¥åˆ¶ä½œä¸€ä¸ªé—®ç­”æœºå™¨äººï¼Œå›ç­”å¸¸è§çš„é—®é¢˜ã€‚</p><h2 id="åŸºäºæ·±åº¦å­¦ä¹ çš„èŠå¤©æœºå™¨äººï¼ˆåå‘å®éªŒæ€§è´¨ï¼‰"><a href="#åŸºäºæ·±åº¦å­¦ä¹ çš„èŠå¤©æœºå™¨äººï¼ˆåå‘å®éªŒæ€§è´¨ï¼‰" class="headerlink" title="åŸºäºæ·±åº¦å­¦ä¹ çš„èŠå¤©æœºå™¨äººï¼ˆåå‘å®éªŒæ€§è´¨ï¼‰"></a>åŸºäºæ·±åº¦å­¦ä¹ çš„èŠå¤©æœºå™¨äººï¼ˆåå‘å®éªŒæ€§è´¨ï¼‰</h2><p>ç”¨Seq2Seqæ¨¡å‹æ¥åšç”Ÿæˆ</p><p><img src="https://uploader.shimo.im/f/WV5HzLQb0DsDD4Cj.png!thumbnail" alt="img"></p><ul><li><p>å¤šæ ·æ€§å¾ˆå·®</p></li><li><p>å¾ˆéš¾æ§åˆ¶</p></li></ul><p>Hierarchical LSTM, Hierachical BERT? </p><p>åœ¨èŠå¤©æœºå™¨äººä¸­ä½¿ç”¨ç”Ÿæˆæ¨¡å‹æœ‰ä¸€ä¸ªå¾ˆå¤§çš„é—®é¢˜ï¼Œå°±æ˜¯ä½ æ— æ³•å®Œå…¨æŒæ§ç”Ÿæˆå¥å­çš„å„ç§å±æ€§ï¼Œæˆ‘ä»¬æ— æ³•çŸ¥é“æ¨¡å‹ä¼šç”Ÿæˆä»€ä¹ˆæ ·çš„å¥å­ã€‚è¿™ä¹Ÿå¯¼è‡´äº†åŸºäºç¥ç»ç½‘ç»œçš„æ¨¡å‹ï¼Œä¾‹å¦‚Seq2Seqï¼Œåœ¨æœ‰ä»»åŠ¡çš„èŠå¤©æœºå™¨äººä¸­å¹¶æ²¡æœ‰å¾—åˆ°éå¸¸å¤šçš„ä½¿ç”¨ï¼Œè€Œæ˜¯æ›´å¤šåœ°å‡ºç°åœ¨ä¸€äº›å¨±ä¹æ€§çš„é¡¹ç›®ä¹‹ä¸­ã€‚ä¾‹å¦‚å¦‚æœæˆ‘ä»¬æƒ³è¦è®­ç»ƒä¸€åªâ€œ<strong>å°é»„é¸¡</strong>â€ï¼Œé‚£ä¹ˆä½ å¯ä»¥å¤§èƒ†åœ°ä½¿ç”¨Seq2Seqç­‰ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚å¯æ˜¯å¦‚æœä½ æƒ³è¦</p><p>Jiwei Liçš„ä¸€ç³»åˆ—åŸºäºæ·±åº¦å­¦ä¹ çš„Dialogue Generation</p><p>Jiwei åœ¨ æ–¯å¦ç¦çš„slides <a href="https://web.stanford.edu/class/cs224s/lectures/224s.17.lec12.pdf" target="_blank" rel="noopener">h</a><a href="https://web.stanford.edu/class/cs224s/lectures/224s.17.lec12.pdf" target="_blank" rel="noopener">t</a><a href="https://web.stanford.edu/class/cs224s/lectures/224s.17.lec12.pdf" target="_blank" rel="noopener">tps://w</a><a href="https://web.stanford.edu/class/cs224s/lectures/224s.17.lec12.pdf" target="_blank" rel="noopener">e</a><a href="https://web.stanford.edu/class/cs224s/lectures/224s.17.lec12.pdf" target="_blank" rel="noopener">b.</a><a href="https://web.stanford.edu/class/cs224s/lectures/224s.17.lec12.pdf" target="_blank" rel="noopener">sta</a><a href="https://web.stanford.edu/class/cs224s/lectures/224s.17.lec12.pdf" target="_blank" rel="noopener">nford.edu/class/cs224s/lec</a><a href="https://web.stanford.edu/class/cs224s/lectures/224s.17.lec12.pdf" target="_blank" rel="noopener">t</a><a href="https://web.stanford.edu/class/cs224s/lectures/224s.17.lec12.pdf" target="_blank" rel="noopener">ur</a><a href="https://web.stanford.edu/class/cs224s/lectures/224s.17.lec12.pdf" target="_blank" rel="noopener">e</a><a href="https://web.stanford.edu/class/cs224s/lectures/224s.17.lec12.pdf" target="_blank" rel="noopener">s/224s.17.lec12.pdf</a></p><h3 id="Deep-Reinforcement-Learning-for-Dialogue-Generation"><a href="#Deep-Reinforcement-Learning-for-Dialogue-Generation" class="headerlink" title="Deep Reinforcement Learning for Dialogue Generation"></a><a href="https://arxiv.org/pdf/1606.01541.pdf" target="_blank" rel="noopener">Deep Reinfo</a><a href="https://arxiv.org/pdf/1606.01541.pdf" target="_blank" rel="noopener">r</a><a href="https://arxiv.org/pdf/1606.01541.pdf" target="_blank" rel="noopener">ce</a><a href="https://arxiv.org/pdf/1606.01541.pdf" target="_blank" rel="noopener">me</a><a href="https://arxiv.org/pdf/1606.01541.pdf" target="_blank" rel="noopener">nt</a><a href="https://arxiv.org/pdf/1606.01541.pdf" target="_blank" rel="noopener"> </a><a href="https://arxiv.org/pdf/1606.01541.pdf" target="_blank" rel="noopener">Le</a><a href="https://arxiv.org/pdf/1606.01541.pdf" target="_blank" rel="noopener">a</a><a href="https://arxiv.org/pdf/1606.01541.pdf" target="_blank" rel="noopener">r</a><a href="https://arxiv.org/pdf/1606.01541.pdf" target="_blank" rel="noopener">ning </a><a href="https://arxiv.org/pdf/1606.01541.pdf" target="_blank" rel="noopener">for D</a><a href="https://arxiv.org/pdf/1606.01541.pdf" target="_blank" rel="noopener">ia</a><a href="https://arxiv.org/pdf/1606.01541.pdf" target="_blank" rel="noopener">logu</a><a href="https://arxiv.org/pdf/1606.01541.pdf" target="_blank" rel="noopener">e </a><a href="https://arxiv.org/pdf/1606.01541.pdf" target="_blank" rel="noopener">Ge</a><a href="https://arxiv.org/pdf/1606.01541.pdf" target="_blank" rel="noopener">ne</a><a href="https://arxiv.org/pdf/1606.01541.pdf" target="_blank" rel="noopener">r</a><a href="https://arxiv.org/pdf/1606.01541.pdf" target="_blank" rel="noopener">at</a><a href="https://arxiv.org/pdf/1606.01541.pdf" target="_blank" rel="noopener">i</a><a href="https://arxiv.org/pdf/1606.01541.pdf" target="_blank" rel="noopener">o</a><a href="https://arxiv.org/pdf/1606.01541.pdf" target="_blank" rel="noopener">n</a></h3><p>ä½¿ç”¨æ·±åº¦å¢å¼ºå­¦ä¹ æ¥è®­ç»ƒèŠå¤©æœºå™¨äººã€‚</p><p>å¢å¼ºå­¦ä¹  Framework</p><p>action: ä¸‹ä¸€å¥è¦ç”Ÿæˆçš„è¯</p><p>state: å½“å‰çš„èŠå¤©å†å²ï¼Œåœ¨æœ¬æ–‡ä¸­ä½¿ç”¨æœ€è¿‘çš„ä¸¤å¥å¯¹è¯</p><p>policy: ä¸€ä¸ªåŸºäºLSTMçš„ Seq2Seq æ¨¡å‹</p><p>reward: å¯¹å½“å‰ç”Ÿæˆå¯¹è¯çš„è¯„ä»·æŒ‡æ ‡ï¼Œæœ¬æ–‡ä¸­é‡‡ç”¨äº†ä¸‰é¡¹æŒ‡æ ‡ã€‚</p><ul><li><p>Ease of answering: è¿™å¥å¯¹è¯æ˜¯ä¸æ˜¯å¾ˆå®¹æ˜“å›ç­”ï¼Œä¸è¦â€œæŠŠå¤©èŠæ­»â€ã€‚</p></li><li><p>Information Flow: å½“å‰ç”Ÿæˆçš„å¯¹è¯åº”è¯¥å’Œä¹‹å‰çš„èŠå¤©è®°å½•æœ‰æ‰€å˜åŒ–ã€‚</p></li><li><p>Semantic Coherenceï¼šä¸Šä¸‹æ–‡æ˜¯å¦è¿è´¯ã€‚</p></li></ul><h3 id="Adversarial-Learning-for-Neural-Dialogue-Generation"><a href="#Adversarial-Learning-for-Neural-Dialogue-Generation" class="headerlink" title="Adversarial Learning for Neural Dialogue Generation"></a><a href="https://arxiv.org/pdf/1701.06547.pdf" target="_blank" rel="noopener">Adve</a><a href="https://arxiv.org/pdf/1701.06547.pdf" target="_blank" rel="noopener">r</a><a href="https://arxiv.org/pdf/1701.06547.pdf" target="_blank" rel="noopener">s</a><a href="https://arxiv.org/pdf/1701.06547.pdf" target="_blank" rel="noopener">a</a><a href="https://arxiv.org/pdf/1701.06547.pdf" target="_blank" rel="noopener">rial L</a><a href="https://arxiv.org/pdf/1701.06547.pdf" target="_blank" rel="noopener">ea</a><a href="https://arxiv.org/pdf/1701.06547.pdf" target="_blank" rel="noopener">rning for N</a><a href="https://arxiv.org/pdf/1701.06547.pdf" target="_blank" rel="noopener">e</a><a href="https://arxiv.org/pdf/1701.06547.pdf" target="_blank" rel="noopener">ural</a><a href="https://arxiv.org/pdf/1701.06547.pdf" target="_blank" rel="noopener"> Dialogue </a><a href="https://arxiv.org/pdf/1701.06547.pdf" target="_blank" rel="noopener">Ge</a><a href="https://arxiv.org/pdf/1701.06547.pdf" target="_blank" rel="noopener">n</a><a href="https://arxiv.org/pdf/1701.06547.pdf" target="_blank" rel="noopener">era</a><a href="https://arxiv.org/pdf/1701.06547.pdf" target="_blank" rel="noopener">t</a><a href="https://arxiv.org/pdf/1701.06547.pdf" target="_blank" rel="noopener">i</a><a href="https://arxiv.org/pdf/1701.06547.pdf" target="_blank" rel="noopener">o</a><a href="https://arxiv.org/pdf/1701.06547.pdf" target="_blank" rel="noopener">n</a></h3><p>æŠŠGANçš„æƒ³æ³•ç”¨äºèŠå¤©æœºå™¨äººçš„è¯„ä¼°ä¸­ã€‚ä¸ä¸Šæ–‡ç›¸åŒï¼Œç”Ÿæˆå™¨æ˜¯ä¸€ä¸ªèŠå¤©æœºå™¨äººï¼Œå¯ä»¥ç”Ÿæˆå¯¹è¯ã€‚åˆ¤åˆ«å™¨æ˜¯ä¸€ä¸ªæ‰“åˆ†ç³»ç»Ÿï¼Œå¯ä»¥å¯¹èŠå¤©æœºå™¨äººç”Ÿæˆçš„å¯¹è¯è¿›è¡Œæ‰“åˆ†ã€‚ç„¶åä½¿ç”¨å¢å¼ºå­¦ä¹ (REINFORCE, Policy Gradientç®—æ³•)æ¥è®­ç»ƒç”Ÿæˆå™¨ã€‚</p><p>å…³äºå¦‚ä½•å®ç°policy gradient </p><p><a href="https://discuss.pytorch.org/t/whats-the-right-way-of-implementing-policy-gradient/4003/2" target="_blank" rel="noopener">http</a><a href="https://discuss.pytorch.org/t/whats-the-right-way-of-implementing-policy-gradient/4003/2" target="_blank" rel="noopener">s</a><a href="https://discuss.pytorch.org/t/whats-the-right-way-of-implementing-policy-gradient/4003/2" target="_blank" rel="noopener">://</a><a href="https://discuss.pytorch.org/t/whats-the-right-way-of-implementing-policy-gradient/4003/2" target="_blank" rel="noopener">di</a><a href="https://discuss.pytorch.org/t/whats-the-right-way-of-implementing-policy-gradient/4003/2" target="_blank" rel="noopener">scuss.py</a><a href="https://discuss.pytorch.org/t/whats-the-right-way-of-implementing-policy-gradient/4003/2" target="_blank" rel="noopener">t</a><a href="https://discuss.pytorch.org/t/whats-the-right-way-of-implementing-policy-gradient/4003/2" target="_blank" rel="noopener">orch.org/t/whats-th</a><a href="https://discuss.pytorch.org/t/whats-the-right-way-of-implementing-policy-gradient/4003/2" target="_blank" rel="noopener">e-</a><a href="https://discuss.pytorch.org/t/whats-the-right-way-of-implementing-policy-gradient/4003/2" target="_blank" rel="noopener">righ</a><a href="https://discuss.pytorch.org/t/whats-the-right-way-of-implementing-policy-gradient/4003/2" target="_blank" rel="noopener">t</a><a href="https://discuss.pytorch.org/t/whats-the-right-way-of-implementing-policy-gradient/4003/2" target="_blank" rel="noopener">-w</a><a href="https://discuss.pytorch.org/t/whats-the-right-way-of-implementing-policy-gradient/4003/2" target="_blank" rel="noopener">a</a><a href="https://discuss.pytorch.org/t/whats-the-right-way-of-implementing-policy-gradient/4003/2" target="_blank" rel="noopener">y-of-implemen</a><a href="https://discuss.pytorch.org/t/whats-the-right-way-of-implementing-policy-gradient/4003/2" target="_blank" rel="noopener">t</a><a href="https://discuss.pytorch.org/t/whats-the-right-way-of-implementing-policy-gradient/4003/2" target="_blank" rel="noopener">ing-policy-gradi</a><a href="https://discuss.pytorch.org/t/whats-the-right-way-of-implementing-policy-gradient/4003/2" target="_blank" rel="noopener">e</a><a href="https://discuss.pytorch.org/t/whats-the-right-way-of-implementing-policy-gradient/4003/2" target="_blank" rel="noopener">nt/4003/2</a></p><p>å‚è€ƒè¯¥é¡¹ç›® <a href="https://github.com/suragnair/seqGAN" target="_blank" rel="noopener">https://github.com/suragnair/seqGAN</a></p><h1 id="Alexa-Prize-Challenge"><a href="#Alexa-Prize-Challenge" class="headerlink" title="Alexa Prize Challenge"></a>Alexa Prize Challenge</h1><p>2018å¹´å† å†› <strong>Gunrock: Building A Human-Like Social Bot By Leveraging Large Scale Real User Data</strong></p><p><a href="https://m.media-amazon.com/images/G/01/mobile-apps/dex/alexa/alexaprize/assets/pdf/2018/Gunrock.pdf" target="_blank" rel="noopener">https://m.media-amazon.com/images/G/01/mobile-apps/dex/alexa/alexaprize/assets/pdf/2018/Gunrock.pdf</a></p><p><img src="https://uploader.shimo.im/f/APzsIXJhTrsQRYOw.png!thumbnail" alt="img"></p><p><img src="https://uploader.shimo.im/f/JZM2qSNuXLorcVr3.png!thumbnail" alt="img"></p><p>2017å¹´å† å†› Sounding Board â€“ University of Washingtonâ€™s Alexa Prize Submission</p><p><a href="https://m.media-amazon.com/images/G/01/mobile-apps/dex/alexa/alexaprize/assets/pdf/2017/Soundingboard.pdf" target="_blank" rel="noopener">https://m.media-amazon.com/images/G/01/mobile-apps/dex/alexa/alexaprize/assets/pdf/2017/Soundingboard.pdf</a></p><p><img src="https://uploader.shimo.im/f/xAwqqhmELsc4JfFY.png!thumbnail" alt="img"></p><p><img src="https://uploader.shimo.im/f/E7m8GJsDFTcXJ9xY.png!thumbnail" alt="img"></p><p>å‚è€ƒè¯¾ç¨‹èµ„æ–™</p><ul><li><p><a href="https://hao-cheng.github.io/ee596_spr2019/" target="_blank" rel="noopener">https://hao-cheng.github.io/ee596_spr2019/</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/30533380" target="_blank" rel="noopener">Neural Response Generation â€“ å…³äºå›å¤ç”Ÿæˆå·¥ä½œçš„ä¸€äº›æ€»ç»“</a></p></li><li><p>æ–¯å¦ç¦çš„è¯¾ç¨‹èµ„æ–™ <a href="https://web.stanford.edu/class/cs224s/lectures/224s.17.lec10.pdf" target="_blank" rel="noopener">https://web.stanford.edu/class/cs224s/lectures/224s.17.lec10.pdf</a></p></li><li><p>EMNLP 2018 tutorial <a href="http://www.ruiyan.me/pubs/tutorial-emnlp18.pdf" target="_blank" rel="noopener">http://www.ruiyan.me/pubs/tutorial-emnlp18.pdf</a></p></li></ul><p>ä¸­æ–‡èŠå¤©æœºå™¨äººçš„èµ„æ–™</p><ul><li><p><a href="https://blog.csdn.net/hfutdog/article/details/78155467" target="_blank" rel="noopener">https://blog.csdn.net/hfutdog/article/details/78155467</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/23356655" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/23356655</a></p></li></ul><p>ä¸€äº›å…¬å¸</p><ul><li><p>Gowild <a href="https://www.gowild.cn/home/ours/index.html" target="_blank" rel="noopener">https://www.gowild.cn/home/ours/index.html</a></p></li><li><p>Huggingface <a href="https://huggingface.co/" target="_blank" rel="noopener">https://huggingface.co/</a></p></li></ul><p>æ•°æ®é›†</p><ul><li><p>movie dialogue dataset</p></li><li><p>ubuntu dialogue dataset</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> èŠå¤©æœºå™¨äºº </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>èŠå¤©æœºå™¨äººä¸€</title>
      <link href="/2020/03/10/%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA%E4%B8%80/"/>
      <url>/2020/03/10/%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA%E4%B8%80/</url>
      
        <content type="html"><![CDATA[<h2 id="èŠå¤©æœºå™¨äºº"><a href="#èŠå¤©æœºå™¨äºº" class="headerlink" title="èŠå¤©æœºå™¨äºº"></a>èŠå¤©æœºå™¨äºº</h2><h3 id="æµè¡Œå¹³å°æ¡†æ¶ä¸å®æˆ˜"><a href="#æµè¡Œå¹³å°æ¡†æ¶ä¸å®æˆ˜" class="headerlink" title="æµè¡Œå¹³å°æ¡†æ¶ä¸å®æˆ˜"></a>æµè¡Œå¹³å°æ¡†æ¶ä¸å®æˆ˜</h3><p>è¿™å ‚è¯¾ä¸»è¦æ˜¯å¸¦å¤§å®¶ä¸€èµ·çœ‹çœ‹å›½å†…å¤–ä¸€äº›ä¸»æµçš„èŠå¤©æœºå™¨äººæ­å»ºå¹³å°ã€‚</p><h3 id="å›¾çµæœºå™¨äºº"><a href="#å›¾çµæœºå™¨äºº" class="headerlink" title="å›¾çµæœºå™¨äºº"></a>å›¾çµæœºå™¨äºº</h3><p>link: <a href="http://www.tuling123.com/" target="_blank" rel="noopener">http://www.tuling123.com/</a></p><p><img src="https://s1.ax1x.com/2020/06/09/t4iSHI.png" alt="title"></p><p>ä¼ è¯´ä¸­åœ¨ä¸­æ–‡è¯­å¢ƒä¸‹æ™ºèƒ½åº¦æœ€é«˜çš„æœºå™¨äººå¤§è„‘ã€‚</p><h4 id="ç”¨æ³•Demo"><a href="#ç”¨æ³•Demo" class="headerlink" title="ç”¨æ³•Demo"></a>ç”¨æ³•Demo</h4><ol><li>æ³¨å†Œ</li><li>åˆ›å»ºè‡ªå·±çš„æœºå™¨äºº</li><li>è¿æ¥å¾®ä¿¡å…¬ä¼—å·æˆ–QQ</li><li>ç¤¾åŒº</li></ol><h3 id="wxBot"><a href="#wxBot" class="headerlink" title="wxBot"></a>wxBot</h3><p>å›¾çµæœºå™¨äººå¾ˆæ£’ï¼ŒåŸºæœ¬å¸®æˆ‘ä»¬åšåˆ°äº†å‚»ç“œå¼æ¥å…¥ä¸»æµä¸­æ–‡ç¤¾äº¤è½¯ä»¶ã€‚</p><p>ä½†æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥å‘ç°ï¼Œè¿™é‡Œä¾æ—§æœ‰é™åˆ¶ï¼Œ</p><p>å®˜æ–¹æä¾›çš„å‚»ç“œå¼æœåŠ¡åªèƒ½æ¥å…¥å¾®ä¿¡å…¬ä¼—å·æˆ–è€…QQï¼Œ</p><p>å¦‚æœæœ‰æ›´å¤šçš„éœ€æ±‚ï¼Œé‚£æˆ‘ä»¬å°±å¾—è‡ªå·±åŠ¨æ‰‹äº†ã€‚</p><p>æ¯”å¦‚ï¼Œ<strong>å°†ä¸ªäººå¾®ä¿¡å˜æˆèŠå¤©æœºå™¨äºº</strong></p><p>è¿™é‡Œæˆ‘ä»¬ä»‹ç»ä¸€ä¸ªå¾ˆæ£’çš„GitHubé¡¹ç›®ï¼šWxBotï¼ˆcredit: @liuwonsï¼‰</p><p>link: <a href="https://github.com/liuwons/wxBot" target="_blank" rel="noopener">https://github.com/liuwons/wxBot</a></p><p>è¿™æ˜¯ä¸€ä¸ªæ˜¯ç”¨PythonåŒ…è£…Webå¾®ä¿¡åè®®å®ç°çš„å¾®ä¿¡æœºå™¨äººæ¡†æ¶ã€‚</p><p>æ¢å¥è¯è¯´ï¼Œå°±æ˜¯æ¨¡æ‹Ÿäº†æˆ‘ä»¬ç½‘é¡µç™»å½•å¾®ä¿¡çš„çŠ¶æ€ï¼Œå¹¶é€šè¿‡ç½‘é¡µå¾®ä¿¡åè®®ä¼ è¾“å¯¹è¯ã€‚</p><p>å¥½ï¼Œæ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥ç”¨wxbotå®ç°ä¸€äº›æœ‰è¶£çš„åŠŸèƒ½ï¼š</p><h3 id="ç¾¤èŠå¤©æœºå™¨äºº"><a href="#ç¾¤èŠå¤©æœºå™¨äºº" class="headerlink" title="ç¾¤èŠå¤©æœºå™¨äºº"></a>ç¾¤èŠå¤©æœºå™¨äºº</h3><p>ï¼ˆè½¬è½½è‡ªï¼š<a href="http://blog.csdn.net/tobacco5648/article/details/50802922" target="_blank" rel="noopener">http://blog.csdn.net/tobacco5648/article/details/50802922</a> ï¼‰</p><p>å®ç°æ•ˆæœ</p><p><img src="https://s1.ax1x.com/2020/06/09/t4PzDA.png" alt="title"></p><p>æœ‰ç‚¹åƒè°·æ­Œæ——ä¸‹çš„èŠå¤©å·¥å…· Allo</p><p><img src="https://s1.ax1x.com/2020/06/09/t4Pxud.jpg" alt="title"></p><p>ç®€å•è¯´å°±æ˜¯ï¼Œåœ¨ä½ èŠå¤©çš„æ—¶å€™ï¼Œå¯ä»¥éšæ—¶æŠŠå°æœºå™¨äººç»™atå‡ºæ¥ï¼Œå¹¶ä¸”æ‹‰å‡ºæ¥è·Ÿä½ èŠå¤©ã€‚</p><p>åŒæ—¶ï¼Œå¦‚æœè°ƒç”¨å›¾çµæœºå™¨äººçš„æœåŠ¡çš„è¯ï¼Œä½ å¯ä»¥è®©å®ƒåšå¾ˆå¤šå¤æ‚çš„å·¥ä½œï¼Œ</p><p>æ¯”å¦‚ï¼Œæ‰¾é™„è¿‘çš„å•†åº—å•Šï¼ŒæŸ¥ç«è½¦æ—¶åˆ»è¡¨å•Šï¼Œç­‰ç­‰ã€‚</p><h4 id="è¿è¡Œæ–¹æ³•"><a href="#è¿è¡Œæ–¹æ³•" class="headerlink" title="è¿è¡Œæ–¹æ³•"></a>è¿è¡Œæ–¹æ³•</h4><ol><li><p>ä¸‹è½½wxBotï¼Œ å®‰è£…pythonçš„ä¾èµ–åŒ…ã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pip install requests</span><br><span class="line">pip install pyqrcode</span><br><span class="line">pip install pypng</span><br><span class="line">pip install Pillow</span><br></pre></td></tr></table></figure></li><li><p>åœ¨å›¾çµæœºå™¨äººå®˜ç½‘æ³¨å†Œè´¦å·ï¼Œç”³è¯·å›¾çµAPI key</p></li><li><p>åœ¨bot.pyæ–‡ä»¶æ‰€åœ¨ç›®å½•ä¸‹æ–°å»ºconf.iniæ–‡ä»¶ï¼Œå†…å®¹ä¸º(keyå­—æ®µå†…å®¹ä¸ºç”³è¯·åˆ°çš„å›¾çµkey):</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[main]</span><br><span class="line">key=1d2678900f734aa0a23734ace8aec5b1</span><br></pre></td></tr></table></figure></li><li><p>æœ€åæˆ‘ä»¬è¿è¡Œbot.pyå³å¯</p></li></ol><p>è¿è¡Œä¹‹åï¼Œä½ çš„terminalä¼šè·³å‡ºä¸€ä¸ªäºŒç»´ç ã€‚</p><p>ä½ æŒ‰ç…§ç™»å½•ç½‘é¡µç‰ˆå¾®ä¿¡çš„æ–¹å¼ï¼Œæ‰«ä¸€ä¸‹ ç™»å½•ä¸€ä¸‹ã€‚</p><p>ä½ çš„å¾®ä¿¡å°±è¢«â€æ‰˜ç®¡â€œäº† &gt;.&lt;</p><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line"># coding: utf-8</span><br><span class="line"></span><br><span class="line">from wxbot import *</span><br><span class="line">import ConfigParser</span><br><span class="line">import json</span><br><span class="line"></span><br><span class="line">class TulingWXBot(WXBot):</span><br><span class="line">    # æ‹¿åˆ°API Key</span><br><span class="line">    def __init__(self):</span><br><span class="line">        WXBot.__init__(self)</span><br><span class="line"></span><br><span class="line">        self.tuling_key = &quot;&quot;</span><br><span class="line">        self.robot_switch = True</span><br><span class="line"></span><br><span class="line">        try:</span><br><span class="line">            cf = ConfigParser.ConfigParser()</span><br><span class="line">            cf.read(&apos;conf.ini&apos;)</span><br><span class="line">            self.tuling_key = cf.get(&apos;main&apos;, &apos;key&apos;)</span><br><span class="line">        except Exception:</span><br><span class="line">            pass</span><br><span class="line">        print &apos;tuling_key:&apos;, self.tuling_key</span><br><span class="line">    </span><br><span class="line">    # ä»å›¾çµAPIè¿”å›è‡ªåŠ¨å›å¤</span><br><span class="line">    def tuling_auto_reply(self, uid, msg):</span><br><span class="line">        if self.tuling_key:</span><br><span class="line">            # API url</span><br><span class="line">            url = &quot;http://www.tuling123.com/openapi/api&quot;</span><br><span class="line">            user_id = uid.replace(&apos;@&apos;, &apos;&apos;)[:30]</span><br><span class="line">            # API request</span><br><span class="line">            body = &#123;&apos;key&apos;: self.tuling_key, &apos;info&apos;: msg.encode(&apos;utf8&apos;), &apos;userid&apos;: user_id&#125;</span><br><span class="line">            r = requests.post(url, data=body)</span><br><span class="line">            respond = json.loads(r.text)</span><br><span class="line">            result = &apos;&apos;</span><br><span class="line">            # æ‹¿åˆ°å›å¤ï¼Œè¿›è¡Œå¤„ç†</span><br><span class="line">                # æŒ‰ç…§APIè¿”å›çš„codeè¿›è¡Œåˆ†ç±»</span><br><span class="line">                # æ˜¯å¦æ˜¯ä¸€ä¸ªlink</span><br><span class="line">                # è¿˜æ˜¯ä¸€å¥è¯</span><br><span class="line">                # è¿˜æ˜¯ä¸€ç»„(list)å›å¤</span><br><span class="line">            if respond[&apos;code&apos;] == 100000:</span><br><span class="line">                result = respond[&apos;text&apos;].replace(&apos;&lt;br&gt;&apos;, &apos;  &apos;)</span><br><span class="line">                result = result.replace(u&apos;\xa0&apos;, u&apos; &apos;)</span><br><span class="line">            elif respond[&apos;code&apos;] == 200000:</span><br><span class="line">                result = respond[&apos;url&apos;]</span><br><span class="line">            elif respond[&apos;code&apos;] == 302000:</span><br><span class="line">                for k in respond[&apos;list&apos;]:</span><br><span class="line">                    result = result + u&quot;ã€&quot; + k[&apos;source&apos;] + u&quot;ã€‘ &quot; +\</span><br><span class="line">                        k[&apos;article&apos;] + &quot;\t&quot; + k[&apos;detailurl&apos;] + &quot;\n&quot;</span><br><span class="line">            else:</span><br><span class="line">                result = respond[&apos;text&apos;].replace(&apos;&lt;br&gt;&apos;, &apos;  &apos;)</span><br><span class="line">                result = result.replace(u&apos;\xa0&apos;, u&apos; &apos;)</span><br><span class="line"></span><br><span class="line">            print &apos;    ROBOT:&apos;, result</span><br><span class="line">            return result</span><br><span class="line">        # åŠ äº†ä¸ªexceptionï¼Œå¦‚æœæ²¡æœ‰å›¾çµAPI Keyçš„è¯ï¼Œ</span><br><span class="line">        # é‚£å°±æ— è„‘å›çŸ¥é“äº†ã€‚</span><br><span class="line">        else:</span><br><span class="line">            return u&quot;çŸ¥é“å•¦&quot;</span><br><span class="line">    </span><br><span class="line">    # å¦‚æœï¼Œç”¨æˆ·ä¸æƒ³æœºå™¨äººç»§ç»­BBäº†ï¼Œ</span><br><span class="line">    # æˆ–è€…ï¼Œç”¨æˆ·æƒ³è¨€è¯­è°ƒå‡ºæœºå™¨äººï¼š</span><br><span class="line">    def auto_switch(self, msg):</span><br><span class="line">        msg_data = msg[&apos;content&apos;][&apos;data&apos;]</span><br><span class="line">        stop_cmd = [u&apos;é€€ä¸‹&apos;, u&apos;èµ°å¼€&apos;, u&apos;å…³é—­&apos;, u&apos;å…³æ‰&apos;, u&apos;ä¼‘æ¯&apos;, u&apos;æ»šå¼€&apos;]</span><br><span class="line">        start_cmd = [u&apos;å‡ºæ¥&apos;, u&apos;å¯åŠ¨&apos;, u&apos;å·¥ä½œ&apos;]</span><br><span class="line">        if self.robot_switch:</span><br><span class="line">            for i in stop_cmd:</span><br><span class="line">                if i == msg_data:</span><br><span class="line">                    self.robot_switch = False</span><br><span class="line">                    self.send_msg_by_uid(u&apos;[Robot]&apos; + u&apos;æœºå™¨äººå·²å…³é—­ï¼&apos;, msg[&apos;to_user_id&apos;])</span><br><span class="line">        else:</span><br><span class="line">            for i in start_cmd:</span><br><span class="line">                if i == msg_data:</span><br><span class="line">                    self.robot_switch = True</span><br><span class="line">                    self.send_msg_by_uid(u&apos;[Robot]&apos; + u&apos;æœºå™¨äººå·²å¼€å¯ï¼&apos;, msg[&apos;to_user_id&apos;])</span><br><span class="line">    </span><br><span class="line">    # ä»å¾®ä¿¡å›å¤</span><br><span class="line">    def handle_msg_all(self, msg):</span><br><span class="line">        if not self.robot_switch and msg[&apos;msg_type_id&apos;] != 1:</span><br><span class="line">            return</span><br><span class="line">        if msg[&apos;msg_type_id&apos;] == 1 and msg[&apos;content&apos;][&apos;type&apos;] == 0:  # reply to self</span><br><span class="line">            self.auto_switch(msg)</span><br><span class="line">        elif msg[&apos;msg_type_id&apos;] == 4 and msg[&apos;content&apos;][&apos;type&apos;] == 0:  # text message from contact</span><br><span class="line">            self.send_msg_by_uid(self.tuling_auto_reply(msg[&apos;user&apos;][&apos;id&apos;], msg[&apos;content&apos;][&apos;data&apos;]), msg[&apos;user&apos;][&apos;id&apos;])</span><br><span class="line">        elif msg[&apos;msg_type_id&apos;] == 3 and msg[&apos;content&apos;][&apos;type&apos;] == 0:  # group text message</span><br><span class="line">            if &apos;detail&apos; in msg[&apos;content&apos;]:</span><br><span class="line">                my_names = self.get_group_member_name(msg[&apos;user&apos;][&apos;id&apos;], self.my_account[&apos;UserName&apos;])</span><br><span class="line">                if my_names is None:</span><br><span class="line">                    my_names = &#123;&#125;</span><br><span class="line">                if &apos;NickName&apos; in self.my_account and self.my_account[&apos;NickName&apos;]:</span><br><span class="line">                    my_names[&apos;nickname2&apos;] = self.my_account[&apos;NickName&apos;]</span><br><span class="line">                if &apos;RemarkName&apos; in self.my_account and self.my_account[&apos;RemarkName&apos;]:</span><br><span class="line">                    my_names[&apos;remark_name2&apos;] = self.my_account[&apos;RemarkName&apos;]</span><br><span class="line"></span><br><span class="line">                is_at_me = False</span><br><span class="line">                for detail in msg[&apos;content&apos;][&apos;detail&apos;]:</span><br><span class="line">                    if detail[&apos;type&apos;] == &apos;at&apos;:</span><br><span class="line">                        for k in my_names:</span><br><span class="line">                            if my_names[k] and my_names[k] == detail[&apos;value&apos;]:</span><br><span class="line">                                is_at_me = True</span><br><span class="line">                                break</span><br><span class="line">                if is_at_me:</span><br><span class="line">                    src_name = msg[&apos;content&apos;][&apos;user&apos;][&apos;name&apos;]</span><br><span class="line">                    reply = &apos;to &apos; + src_name + &apos;: &apos;</span><br><span class="line">                    if msg[&apos;content&apos;][&apos;type&apos;] == 0:  # text message</span><br><span class="line">                        reply += self.tuling_auto_reply(msg[&apos;content&apos;][&apos;user&apos;][&apos;id&apos;], msg[&apos;content&apos;][&apos;desc&apos;])</span><br><span class="line">                    else:</span><br><span class="line">                        reply += u&quot;å¯¹ä¸èµ·ï¼Œåªè®¤å­—ï¼Œå…¶ä»–æ‚ä¸ƒæ‚å…«çš„æˆ‘éƒ½ä¸è®¤è¯†ï¼Œ,,Ô¾â€¸Ô¾,,&quot;</span><br><span class="line">                    self.send_msg_by_uid(reply, msg[&apos;user&apos;][&apos;id&apos;])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    bot = TulingWXBot()</span><br><span class="line">    bot.DEBUG = True</span><br><span class="line">    bot.conf[&apos;qr&apos;] = &apos;png&apos;</span><br><span class="line"></span><br><span class="line">    bot.run()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p>GitHubä¸Šè¿˜æœ‰ä¸å°‘ç›¸ä¼¼çš„é¡¹ç›®ï¼Œå¤§å®¶éƒ½å¯ä»¥å…³æ³¨ä¸€ä¸‹ï¼š</p><p><a href="https://github.com/feit/Weixinbot" target="_blank" rel="noopener">feit/Weixinbot</a> Nodejs å°è£…ç½‘é¡µç‰ˆå¾®ä¿¡çš„æ¥å£ï¼Œå¯ç¼–ç¨‹æ§åˆ¶å¾®ä¿¡æ¶ˆæ¯</p><p><a href="https://github.com/littlecodersh/ItChat" target="_blank" rel="noopener">littlecodersh/ItChat</a> å¾®ä¿¡ä¸ªäººå·æ¥å£ã€å¾®ä¿¡æœºå™¨äººåŠå‘½ä»¤è¡Œå¾®ä¿¡ï¼ŒCommand line talks through Wechat</p><p><a href="https://github.com/Urinx/WeixinBot" target="_blank" rel="noopener">Urinx/WeixinBot</a> ç½‘é¡µç‰ˆå¾®ä¿¡APIï¼ŒåŒ…å«ç»ˆç«¯ç‰ˆå¾®ä¿¡åŠå¾®ä¿¡æœºå™¨äºº</p><p><a href="https://github.com/zixia/wechaty" target="_blank" rel="noopener">zixia/wechaty</a> Wechaty is wechat for bot in Javascript(ES6). Itâ€™s a Personal Account Robot Framework/Library.</p><p><a href="https://coding.net/u/vivre/p/WxbotManage/git" target="_blank" rel="noopener">WxbotManage</a> åŸºäºWxbotçš„å¾®ä¿¡å¤šå¼€ç®¡ç†å’ŒWebapiç³»ç»Ÿ</p><h3 id="è‡ªå®šä¹‰APIæ¥å£"><a href="#è‡ªå®šä¹‰APIæ¥å£" class="headerlink" title="è‡ªå®šä¹‰APIæ¥å£"></a>è‡ªå®šä¹‰APIæ¥å£</h3><p>åˆšåˆšæˆ‘ä»¬è®²çš„éƒ¨åˆ†ï¼Œè¿˜éƒ½æ˜¯è°ƒç”¨å›¾çµæœºå™¨äººçš„APIã€‚</p><p>æˆ‘ä»¬æ¥çœ‹çœ‹ï¼Œå¦‚ä½•ä½¿ç”¨è‡ªå·±çš„ChatBotæ¨¡å‹ã€‚</p><p>æˆ‘ä»¬è¿™é‡Œç”¨ä¹‹å‰è®²è¿‡çš„Chatterbotåº“åšä¸ªä¾‹å­ã€‚</p><p>æ€è·¯è¿˜æ˜¯ä¸€æ ·ã€‚æˆ‘ä»¬ç”¨WxBotæ¥å¤„ç†å¾®ä¿¡ç«¯çš„å·¥ä½œï¼Œ</p><p>ç„¶åï¼Œæˆ‘ä»¬æ¶è®¾ä¸€ä¸ªAPIï¼Œæ¥æŠŠchatterbotçš„å›å¤ç»™ä¼ åˆ°å¾®ä¿¡å»ã€‚</p><p>è¿™é‡Œæˆ‘ä»¬ç”¨ä¸€ä¸ªç®€å•ç²—æš´çš„APIæ¡†æ¶ï¼šHugã€‚</p><p>å¤§å®¶ä¹Ÿå¯ä»¥ç”¨å…¶ä»–å„ç§æ¡†æ¶ï¼Œæ¯”å¦‚Flaskã€‚</p><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line"># coding: utf-8</span><br><span class="line"></span><br><span class="line"># å¯¼å…¥chatterbotè‡ªå¸¦çš„è¯­æ–™åº“</span><br><span class="line">from chatterbot import ChatBot</span><br><span class="line">from chatterbot.trainers import ChatterBotCorpusTrainer</span><br><span class="line">import hug</span><br><span class="line"></span><br><span class="line">deepThought = ChatBot(&quot;deepThought&quot;)</span><br><span class="line">deepThought.set_trainer(ChatterBotCorpusTrainer)</span><br><span class="line"># ä½¿ç”¨ä¸­æ–‡è¯­æ–™åº“è®­ç»ƒå®ƒ</span><br><span class="line">deepThought.train(&quot;chatterbot.corpus.chinese&quot;)  # è¯­æ–™åº“</span><br><span class="line"></span><br><span class="line"># APIæ¡†æ¶</span><br><span class="line">@hug.get()</span><br><span class="line">def get_response(user_input):</span><br><span class="line">    response = deepThought.get_response(user_input).text</span><br><span class="line">    return &#123;&quot;response&quot;:response&#125;</span><br></pre></td></tr></table></figure><p>hug -f bot_api.py</p><p>è·‘èµ·æ¥ä»¥åï¼Œä½ çš„terminalå¤§æ¦‚é•¿è¿™æ ·ï¼š</p><p><img src="https://s1.ax1x.com/2020/06/09/t4PjjH.png" alt="title"></p><p>äºæ˜¯ä½ å¯ä»¥åœ¨æµè§ˆå™¨ä¸­å°è¯•ï¼š</p><p><img src="https://s1.ax1x.com/2020/06/09/t4PXge.png" alt="title"></p><p>å¥½ï¼Œ</p><p>æ¥ä¸‹æ¥çš„éƒ¨åˆ†ï¼Œä¾æ—§æ˜¯æ„Ÿè°¢@liuwonsçš„wxbotï¼š</p><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line"># coding: utf-8</span><br><span class="line"></span><br><span class="line">from wxbot import WXBot</span><br><span class="line">import requests</span><br><span class="line"></span><br><span class="line"># base url</span><br><span class="line">bot_api=&quot;http://127.0.0.1:8000/get_response&quot;</span><br><span class="line"></span><br><span class="line"># å¤„ç†å›å¤</span><br><span class="line">class MyWXBot(WXBot):</span><br><span class="line">    def handle_msg_all(self, msg):</span><br><span class="line">        if msg[&apos;msg_type_id&apos;] == 4 and msg[&apos;content&apos;][&apos;type&apos;] == 0:</span><br><span class="line">            user_input = msg[&quot;content&quot;][&quot;data&quot;]</span><br><span class="line">            payload=&#123;&quot;user_input&quot;:user_input&#125;</span><br><span class="line">            response = requests.get(bot_api,params=payload).json()[&quot;response&quot;]</span><br><span class="line">            self.send_msg_by_uid(response, msg[&apos;user&apos;][&apos;id&apos;])</span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    bot = MyWXBot()</span><br><span class="line">    bot.DEBUG = True</span><br><span class="line">    bot.conf[&apos;qr&apos;] = &apos;png&apos;</span><br><span class="line">    bot.run()</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p>èŠèµ·æ¥å¤§æ¦‚æ˜¯è¿™ä¸ªèŠ‚å¥ã€‚</p><p><img src="https://s1.ax1x.com/2020/06/09/t4PL9O.jpg" alt="title"></p><p>å¥½ï¼Œå¦‚æ­¤ï¼Œæˆ‘ä»¬èƒ½åšçš„æ˜¾ç„¶ä¸ä»…ä»…æ˜¯ç”¨äº†ä¸ªchatterbot</p><p>å› ä¸ºæˆ‘ä»¬è¿™æ ·çš„ä¸€ä¸ªç»“æ„ï¼Œæˆ‘ä»¬å…¶å®å¯ä»¥æŠŠä»»ä½•èŠå¤©æ¨¡å‹åº”ç”¨è¿›æ¥ã€‚</p><p>ç®€å•é‚£æ¥è¯´ï¼Œ</p><p>Model &lt;â€“APIâ€“&gt; WxBot &lt;â€“webâ€“&gt; WeChat</p><p>æˆ‘ä»¬è¦åšçš„å°±æ˜¯å°è£…ä¸€ä¸‹æˆ‘ä»¬çš„æ¨¡å‹ï¼Œè®©å®ƒçœ‹åˆ°ä¸€å¥è¯ï¼Œç»™ä¸€ä¸ªå›å¤ã€‚</p><p>æˆ–è€…ç”šè‡³æ˜¯æŠŠVQAåŠ åˆ°å¾®ä¿¡æœºå™¨äººä¸­ï¼Œå‘å›¾ç‰‡å†å‘é—®é¢˜ï¼Œæ±‚å›å¤~</p><h3 id="ä¸€äº›æœ‰è¶£çš„å¾®ä¿¡æœºå™¨äººçš„idea"><a href="#ä¸€äº›æœ‰è¶£çš„å¾®ä¿¡æœºå™¨äººçš„idea" class="headerlink" title="ä¸€äº›æœ‰è¶£çš„å¾®ä¿¡æœºå™¨äººçš„idea"></a>ä¸€äº›æœ‰è¶£çš„å¾®ä¿¡æœºå™¨äººçš„idea</h3><ul><li>è·¨ç¾¤è½¬å‘ã€‚è¿™æ˜¯ä¸ªéå¸¸å®ç”¨çš„åŠŸèƒ½ã€‚å¯¹ç¾¤æ¥è¯´ï¼Œå› ä¸ºå¾®ä¿¡ä¸€ä¸ªç¾¤æœ€å¤š500äººï¼Œ è·¨ç¾¤è½¬å‘å¯ä»¥æœ‰æ•ˆåœ°æŠŠä¸¤ä¸ªç¾¤æ‹¼åˆ°ä¸€èµ·ï¼Œå®ç°æ›´å¹¿æ³›çš„è®¨è®ºã€‚å¯¹ä¸ªäººæ¥è¯´ï¼Œä¹Ÿå¯ä»¥ç”¨æœ‰é€‰æ‹©çš„è½¬å‘æ¥æŠŠä¿¡æ¯å½’æ¡£ã€‚æ¯”å¦‚çœ‹è€æ¿æˆ–è€…å¦¹å­åœ¨ä½ åŠ çš„å‡ ä¸ªç¾¤é‡Œæ¯å¤©éƒ½è¯´äº†å•¥ç­‰ç­‰ã€‚â€¨</li><li>èŠå¤©æ¶ˆæ¯çš„ä¸»é¢˜å½’å¹¶ï¼Œåˆ†æå’Œæœç´¢ã€‚å¾®ä¿¡èŠå¤©çš„åŸºæœ¬å•ä½æ˜¯æ¶ˆæ¯ï¼Œä½†æ¶ˆæ¯æœ¬èº«æ˜¯éå¸¸ç¢ç‰‡åŒ–çš„ï¼Œå¾ˆä¸é€‚åˆæœç´¢å’Œåˆ†æã€‚æœºå™¨äººå¯ä»¥æŠŠç›¸å…³ä¸»é¢˜çš„æ¶ˆæ¯å½’å¹¶èµ·æ¥ï¼Œä¸€æ–¹é¢å¯ä»¥å¤§å¹…å‡å°ä¿¡æ¯è¿‡è½½ï¼Œä¸€æ–¹é¢ä¹Ÿå¯ä»¥ä»ä¸­å¾—åˆ°æ›´æœ‰ä»·å€¼çš„ä¿¡æ¯ï¼ˆç±»ä¼¼è§†é¢‘åˆ†æé‡Œé¢æŠŠå¸§å˜æˆé•œå¤´ï¼‰ã€‚è¿™æ ·åˆ†æä»¥åå¯ä»¥åšçŸ¥è¯†å½’æ¡£ï¼Œç”¨OneNote/å°è±¡ç¬”è®°ç”šè‡³å…¬ä¼—å·æŠŠè®¨è®ºçš„æˆæœæ²‰æ·€ä¸‹æ¥ã€‚â€¨</li><li>èŠå¤©è„‰ç»œçš„æ¢³ç†ã€‚ç¾¤é‡Œçš„äººä¸€å¤šï¼Œç»å¸¸ä¼šå‡ºç°å‡ ä¸ªè¯é¢˜å¹¶è¡Œå‡ºç°çš„æƒ…å†µã€‚è¿™ç§æƒ…å†µå¯¹äºç†è§£å’Œæœç´¢éƒ½æ˜¯éå¸¸ä¸åˆ©çš„ã€‚æœºå™¨äººä¹Ÿéœ€è¦æŠŠèŠå¤©çš„è„‰ç»œè¿›è¡Œæ¢³ç†ï¼Œåœ¨åŒä¸€æ—¶é—´ï¼ŒæŠŠä¸åŒä¸»é¢˜åˆ†åˆ«å¼€ã€‚â€¨</li><li>åŸºæœ¬çš„ç»Ÿè®¡æ•°æ®ã€‚æ¯”å¦‚å‘è¨€æ—¶é—´çš„åˆ†å¸ƒï¼Œç¾¤çš„æ´»è·ƒåº¦ï¼Œæˆå‘˜çš„æ´»è·ƒåº¦ç­‰ç­‰ã€‚åšæˆæ¼‚äº®çš„å¯è§†åŒ–ï¼Œç”¨æˆ·åº”è¯¥ä¹Ÿä¼šå–œæ¬¢ï¼Œç»™äº§å“åŠ åˆ†ã€‚ </li></ul><h3 id="å›½é™…ä¸Šæ¯”è¾ƒä¸»æµçš„å‡ å¤§èŠå¤©æœºå™¨äººæ¡†æ¶"><a href="#å›½é™…ä¸Šæ¯”è¾ƒä¸»æµçš„å‡ å¤§èŠå¤©æœºå™¨äººæ¡†æ¶" class="headerlink" title="å›½é™…ä¸Šæ¯”è¾ƒä¸»æµçš„å‡ å¤§èŠå¤©æœºå™¨äººæ¡†æ¶"></a>å›½é™…ä¸Šæ¯”è¾ƒä¸»æµçš„å‡ å¤§èŠå¤©æœºå™¨äººæ¡†æ¶</h3><ul><li>wit.ai</li><li>api.ai</li><li>microsoft bot framework</li></ul><p>è™½ç„¶â€¦</p><p>ä½†æ˜¯æˆ‘ä»¬è¿˜æ˜¯è¦ç¨å¾®äº†è§£ä¸€ä¸‹è¡Œä¸šå†…çš„ä¸€äº›insightsï¼Œ</p><p>çœ‹çœ‹ç°åœ¨ä¸šå†…å¤§ç«çš„å„ç§ç‚’èŠå¤©æœºå™¨äººæ¦‚å¿µçš„startupséƒ½æ˜¯æ€ä¹ˆç©çš„ã€‚</p><p>æˆ‘ä»¬é€‰ç‚¹ç®€å•çš„å¼€å§‹ç©èµ·ã€‚</p><p>æœºå™¨äººç«¯ï¼šapi.aiï¼ŒèƒŒåæ˜¯è°·æ­Œ</p><p>èŠå¤©ç«¯ï¼Œæˆ‘ä»¬é€‰ä¸ªTelegramï¼Œä¸»æ‰“å®‰å…¨å’Œå¿«é€Ÿçš„ç”»é£æ¸…å¥‡çš„èŠå¤©è½¯ä»¶~</p><h4 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h4><ol><li>æ³¨å†Œapi.ai</li><li>åˆ›å»ºapi.aiæœºå™¨äºº</li><li>è®¾ç½®intents, entitiesç­‰ç­‰</li><li>åŠæ—¶æµ‹è¯•</li><li>èµ°èµ·telegram</li><li>è·Ÿæœºå™¨äººçˆ¸çˆ¸èŠå¤©, è®¾ç½®</li><li><img src="https://s1.ax1x.com/2020/06/09/t4Pb4K.png" alt="avatar"></li><li>integrate</li><li>æ‰˜ç®¡GitHub, Heroku</li><li>æ‰‹æœºç«¯è¯•è¯•ç©å„¿</li><li><img src="https://s1.ax1x.com/2020/06/09/t4PIBR.png" alt="avatar"></li></ol><h3 id="ç›´æ¥è°ƒç”¨api-aiè¿›ä½ è‡ªå·±çš„app-å¹³å°"><a href="#ç›´æ¥è°ƒç”¨api-aiè¿›ä½ è‡ªå·±çš„app-å¹³å°" class="headerlink" title="ç›´æ¥è°ƒç”¨api.aiè¿›ä½ è‡ªå·±çš„app/å¹³å°"></a>ç›´æ¥è°ƒç”¨api.aiè¿›ä½ è‡ªå·±çš„app/å¹³å°</h3><p>å…¶å®è¿™å‡ ä¸ªå¤§å¹³å°éƒ½æœ‰è‡ªå·±çš„å„ä¸ªè¯­è¨€çš„å®˜æ–¹æ”¯æŒåº“ï¼Œè®©ç”Ÿæ´»å˜å¾—ç°å¸¸ç®€å•ï¼š</p><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">!/usr/bin/env python</span><br><span class="line"> -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">import os.path</span><br><span class="line">import sys</span><br><span class="line">import json</span><br><span class="line">try:</span><br><span class="line">    import apiai</span><br><span class="line">except ImportError:</span><br><span class="line">    sys.path.append(</span><br><span class="line">        os.path.join(os.path.dirname(os.path.realpath(__file__)), os.pardir)</span><br><span class="line">    )</span><br><span class="line">    import apiai</span><br><span class="line">    </span><br><span class="line"># api token</span><br><span class="line">CLIENT_ACCESS_TOKEN = &apos;your client access token&apos;</span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    while(1):</span><br><span class="line">        ai = apiai.ApiAI(CLIENT_ACCESS_TOKEN)</span><br><span class="line">        request = ai.text_request()</span><br><span class="line">        request.lang = &apos;en&apos;  # ä¸­æ–‡è‹±æ–‡æ³•è¯­è¥¿è¯­ç­‰ç­‰å„ç§</span><br><span class="line"></span><br><span class="line">        # request.session_id = &quot;&lt;SESSION ID, UBIQUE FOR EACH USER&gt;&quot;</span><br><span class="line">        print(&quot;\n\nYour Input : &quot;,end=&quot; &quot;)</span><br><span class="line">        request.query = input()</span><br><span class="line"></span><br><span class="line">        print(&quot;\n\nBot\&apos;s response :&quot;,end=&quot; &quot;)</span><br><span class="line">        response = request.getresponse()</span><br><span class="line">        responsestr = response.read().decode(&apos;utf-8&apos;)</span><br><span class="line">        response_obj = json.loads(responsestr)</span><br><span class="line"></span><br><span class="line">        print(response_obj[&quot;result&quot;][&quot;fulfillment&quot;][&quot;speech&quot;])</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p>è·Ÿä¹‹å‰çš„æ€è·¯å…¶å®éƒ½å·®ä¸å¤šï¼Œ</p><p>å°±æ˜¯ç”¨æ¡†æ¶çš„APIè°ƒç”¨æ¥ä¼ é€ã€å¯¹è¯ã€ï¼Œè§£å†³é—®é¢˜</p><p>:P</p><p>å°±æ˜¯è¿™æ ·ï¼</p><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> wxBot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ç»“æ„åŒ–é¢„æµ‹</title>
      <link href="/2020/03/09/%E7%BB%93%E6%9E%84%E5%8C%96%E9%A2%84%E6%B5%8B/"/>
      <url>/2020/03/09/%E7%BB%93%E6%9E%84%E5%8C%96%E9%A2%84%E6%B5%8B/</url>
      
        <content type="html"><![CDATA[<p>Beam search: greedy</p><p>P(y|x): xä¸­æ–‡å¥å­, yè‹±æ–‡å¥å­</p><p>|V|^n 50000^20</p><p>sampling: </p><p>dynamic programming: HMM</p><h3 id="ä»€ä¹ˆæ˜¯ç»“æ„åŒ–é¢„æµ‹ï¼Ÿ"><a href="#ä»€ä¹ˆæ˜¯ç»“æ„åŒ–é¢„æµ‹ï¼Ÿ" class="headerlink" title="ä»€ä¹ˆæ˜¯ç»“æ„åŒ–é¢„æµ‹ï¼Ÿ"></a>ä»€ä¹ˆæ˜¯ç»“æ„åŒ–é¢„æµ‹ï¼Ÿ</h3><p>åˆ†ç±»å™¨</p><ul><li><p>å°†è¾“å…¥xåŒ¹é…åˆ°è¾“å‡ºy</p></li><li><p>ä¸€ç§ç®€å•çš„åˆ†ç±»å™¨</p></li><li><p>å¯¹ä»»æ„ä¸€ä¸ªè¾“å…¥xï¼Œè®¡ç®—æ¯ä¸ªå¯èƒ½çš„yçš„åˆ†æ•° score (x, y, \theta)ï¼Œå…¶ä¸­\thetaæ˜¯æ¨¡å‹å‚æ•°</p></li><li><p>é€‰æ‹©åˆ†æ•°æœ€é«˜çš„label yä½œä¸ºé¢„æµ‹çš„ç±»åˆ«</p></li><li><p>ä¸€èˆ¬æ¥è¯´ï¼Œå¦‚æœè¾“å‡ºç©ºé—´æ˜¯æŒ‡æ•°(exponential)çº§åˆ«æˆ–è€…æ— é™çš„ï¼Œæˆ‘ä»¬æŠŠè¿™ç±»é—®é¢˜æˆä¸ºç»“æ„åŒ–é¢„æµ‹(structured prediction)</p></li></ul><p>y = argmax_{candidate}(score(x, candidate, \theta))</p><p>ç»“æ„åŒ–é¢„æµ‹æ¡ˆä¾‹</p><ul><li><p>POS Tagging</p></li><li><p>Unlabeled Segmentation</p></li><li><p>èæ‹‰æ³¢å¨ƒç°åœ¨å±…ä½åœ¨ç¾å›½ä¸œå—éƒ¨çš„ä½›ç½—é‡Œè¾¾ã€‚ </p></li><li><p>èæ‹‰æ³¢å¨ƒ ç°åœ¨ å±…ä½ åœ¨ ç¾å›½ ä¸œå—éƒ¨ çš„ ä½›ç½—é‡Œè¾¾ ã€‚</p></li><li><p>Labeled Segmentation (Named Entity Recognition å‘½åå®ä½“è¯†åˆ«)</p></li><li><p>Some questioned if <strong>Tim Cook</strong>â€™s first product would be a breakaway hit for <strong>Apple</strong>.</p></li></ul><p><img src="https://uploader.shimo.im/f/0b2FQCgcQDoaFgYO.png!thumbnail" alt="img"></p><p><img src="https://uploader.shimo.im/f/2rIXUkEW7EABqhny.png!thumbnail" alt="img"></p><ul><li>Constituency Parsing</li></ul><p><img src="https://uploader.shimo.im/f/Y67R5D7B5xU9NIfx.png!thumbnail" alt="img"></p><ul><li>Coreference Resolution</li></ul><p><img src="https://uploader.shimo.im/f/JBZC4rYqXikNmCAF.png!thumbnail" alt="img"></p><ul><li><p>è¯­è¨€ç”Ÿæˆï¼šæœ‰å¾ˆå¤šNLPä»»åŠ¡æ¶‰åŠåˆ°ç”Ÿæˆä¸€æ®µè¯ï¼Œä¸€ä¸ªçŸ­è¯­ï¼Œä¸€ç¯‡æ–‡ç« ç­‰ç­‰</p></li><li><p>é—®ç­”ç³»ç»Ÿ</p></li><li><p>æ–‡æœ¬ç¿»è¯‘</p></li><li><p>æ–‡æœ¬æ‘˜è¦</p></li></ul><p>ä»€ä¹ˆæ˜¯ç»“æ„åŒ–é¢„æµ‹ï¼Ÿ</p><ul><li><p>æ¯”è¾ƒå®˜æ–¹çš„å®šä¹‰æ˜¯ï¼Œå½“parts functionsæ— æ³•è¢«æ‹†åˆ†æˆminimal partsçš„æ—¶å€™ï¼Œè¿™å°±æ˜¯ä¸€ä¸ªç»“æ„åŒ–é¢„æµ‹çš„é—®é¢˜ã€‚ä½†æ˜¯æˆ‘ä»¬è¿™é‡Œä¸è¯¦ç»†å±•å¼€ã€‚</p></li><li><p>partæ˜¯ä¸€ä¸ªé—®é¢˜çš„ä¸€éƒ¨åˆ†å­é—®é¢˜</p></li><li><p>parts functionï¼šç”¨æ¥æŠŠè¾“å…¥/è¾“å‡ºæ‹†åˆ†æˆparts</p></li><li><p>partså¯ä»¥é‡å </p></li><li><p>minimal partsï¼šè¯¥ä»»åŠ¡æœ€å°çš„parts</p></li><li><p>minimal partsæ˜¯ä¸é‡å çš„</p></li><li><p>ç»“æ„åŒ–score/losså‡½æ•°æ˜¯æ²¡æœ‰åŠæ³•æ‹†åˆ†æˆminimal partsçš„ã€‚å½“æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç»“æ„åŒ–çš„scoreæˆ–è€…æŸå¤±å‡½æ•°çš„æ—¶å€™ï¼Œæˆ‘ä»¬å°±åœ¨åšstructured predcitionã€‚</p></li></ul><h1 id="ç»“æ„åŒ–é¢„æµ‹è§£å†³çš„é—®é¢˜"><a href="#ç»“æ„åŒ–é¢„æµ‹è§£å†³çš„é—®é¢˜" class="headerlink" title="ç»“æ„åŒ–é¢„æµ‹è§£å†³çš„é—®é¢˜"></a>ç»“æ„åŒ–é¢„æµ‹è§£å†³çš„é—®é¢˜</h1><h2 id="åºåˆ—æ ‡ç­¾é—®é¢˜"><a href="#åºåˆ—æ ‡ç­¾é—®é¢˜" class="headerlink" title="åºåˆ—æ ‡ç­¾é—®é¢˜"></a>åºåˆ—æ ‡ç­¾é—®é¢˜</h2><ul><li><p>è¾“å…¥é•¿åº¦ä¸ºT</p></li><li><p>è¾“å‡ºé•¿åº¦ä¹Ÿæ˜¯T</p></li><li><p>æ¯ä¸ªä½ç½®å¯èƒ½çš„å€™é€‰æ˜¯Nä¸ªlabelä¸­çš„ä¸€ä¸ª</p></li><li><p>è¾“å‡ºç©ºé—´ä¸º N ^ T</p></li></ul><p>åºåˆ—æ ‡ç­¾çš„æ¡ˆä¾‹</p><ul><li><p>å‰å‘ç¥ç»ç½‘ç»œåšPOS tagging</p></li><li><p>è¾“å…¥æ˜¯ä¸€ä¸ªå•è¯å’Œå®ƒç›¸é‚»çš„å•è¯</p></li><li><p>è¾“å‡ºæ˜¯ä¸­å¿ƒè¯çš„POS tag</p></li><li><p>è®­ç»ƒloss: æ¯ä¸ªä½ç½®ä¸­å¿ƒè¯çš„log lossï¼Œæ¯ä¸ªä½ç½®çš„lossç›¸åŠ </p></li></ul><p><img src="https://uploader.shimo.im/f/MD4bUVFlbRIubgvg.png!thumbnail" alt="img"></p><ul><li>è¿™ä¸æ˜¯ä¸€ä¸ªâ€ç»“æ„åŒ–é¢„æµ‹â€œé—®é¢˜</li></ul><p>å¦‚æœæˆ‘ä»¬é‡‡ç”¨ä¸€ä¸ªRNNæ¨¡å‹æ¥åšè¯æ€§æ ‡æ³¨ï¼Œè¿™å°±æˆä¸ºäº†ä¸€ä¸ªç»“æ„åŒ–é¢„æµ‹çš„é—®é¢˜ã€‚</p><p><img src="https://uploader.shimo.im/f/Zw4WT0bR9vckZebr.png!thumbnail" alt="img"></p><p>å¦‚æœæˆ‘ä»¬ä½¿ç”¨HMMæ¨¡å‹ï¼Œè¿™ä¹Ÿæ˜¯ä¸€ä¸ªç»“æ„åŒ–é¢„æµ‹é—®é¢˜ã€‚</p><p><img src="https://uploader.shimo.im/f/LXDKAKfdUAk7t4HK.png!thumbnail" alt="img"></p><ul><li>ä¸è¦æŠŠè¯­è¨€å½“åšâ€œbag of wordsâ€ï¼Œå•è¯ä¹‹é—´æœ‰â€œç»“æ„â€ã€‚</li></ul><p>è®­ç»ƒå®Œæ¨¡å‹ä¹‹åï¼Œå¦‚ä½•å¾ˆå¥½åœ°å¿«é€Ÿåœ°åšæœç´¢ï¼Ÿ</p><p>Viterbi ç®—æ³• </p><p><a href="https://shimo.im/docs/TRvGRjwJP8TDrCjc" target="_blank" rel="noopener">https://shimo.im/docs/TRvGRjwJP8TDrCjc</a></p><p>å›¾è§£Viterbiç»´ç‰¹æ¯”ç®—æ³•</p><p><a href="https://zhuanlan.zhihu.com/p/63087935" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/63087935</a></p><p>Viterbiç®—æ³•çš„æ—¶é—´å¤æ‚åº¦æ¯”è¾ƒé«˜ã€‚ï¼ˆå›å¿†ä¸€ä¸‹Viterbiç®—æ³•çš„æ—¶é—´å¤æ‚åº¦æ˜¯å¤šå°‘ï¼Ÿï¼‰</p><p>æ‰€ä»¥äººä»¬å‘æ˜äº†ä¸€äº›è¿‘ä¼¼çš„ç®—æ³•ï¼Œä¾‹å¦‚greedy decodingï¼Œä»¥åŠBeam Seaechã€‚</p><h1 id="CRFæ¨¡å‹"><a href="#CRFæ¨¡å‹" class="headerlink" title="CRFæ¨¡å‹"></a>CRFæ¨¡å‹</h1><p><img src="https://uploader.shimo.im/f/0u599eTQh9YH50Mk.png!thumbnail" alt="img"></p><p>CRFçš„æ¡ä»¶æ¦‚ç‡å…¬å¼</p><p><img src="https://uploader.shimo.im/f/HsY8kd4QK9sSyi9W.png!thumbnail" alt="img"></p><p>åˆ†æ¯æ˜¯å¾ˆå¤§çš„</p><p>y æœ‰äº”ç§ä¸åŒçš„å¯èƒ½æ€§</p><p>20   5^20</p><p><img src="https://uploader.shimo.im/f/7JqSkdgEheIIZ6c9.png!thumbnail" alt="img"></p><p>å‚è€ƒèµ„æ–™</p><p><a href="http://www.robots.ox.ac.uk/~davidc/pubs/crfs_jan2015.pdf" target="_blank" rel="noopener">http://www.robots.ox.ac.uk/~davidc/pubs/crfs_jan2015.pdf</a></p><p><a href="http://www.cs.cmu.edu/~10715-f18/lectures/lecture2-crf.pdf" target="_blank" rel="noopener">http://www.cs.cmu.edu/~10715-f18/lectures/lecture2-crf.pdf</a></p><p><a href="http://www.davidsbatista.net/blog/2017/11/13/Conditional_Random_Fields/" target="_blank" rel="noopener">http://www.davidsbatista.net/blog/2017/11/13/Conditional_Random_Fields/</a></p><h2 id="Michael-Collinsâ€™-notes"><a href="#Michael-Collinsâ€™-notes" class="headerlink" title="Michael Collinsâ€™ notes"></a>Michael Collinsâ€™ notes</h2><p>Log Linear tagggers <a href="http://www.cs.columbia.edu/~mcollins/fall2014-loglineartaggers.pdf" target="_blank" rel="noopener">http://www.cs.columbia.edu/~mcollins/fall2014-loglineartaggers.pdf</a></p><p>CRF Model <a href="http://www.cs.columbia.edu/~mcollins/crf.pdf" target="_blank" rel="noopener">http://www.cs.columbia.edu/~mcollins/crf.pdf</a></p><p>Forward-Backwardç®—æ³• <a href="http://www.cs.columbia.edu/~mcollins/fb.pdf" target="_blank" rel="noopener">http://www.cs.columbia.edu/~mcollins/fb.pdf</a></p><h1 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h1><ul><li><p><a href="https://taehwanptl.github.io/" target="_blank" rel="noopener">Advanced Topics in Machine Learning: Structured Prediction</a></p></li><li><p><a href="http://www.cs.cmu.edu/~nasmith/slides/sp4nlp.icml09.pdf" target="_blank" rel="noopener">Noah Smithçš„è¯¾ä»¶</a></p></li><li><p><a href="https://www.zhihu.com/question/35866596/answer/236886066?hb_wx_block=0" target="_blank" rel="noopener">æ¡ä»¶éšæœºåœº</a></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Beam search </tag>
            
            <tag> CRF </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SVM</title>
      <link href="/2020/02/20/SVM/"/>
      <url>/2020/02/20/SVM/</url>
      
        <content type="html"><![CDATA[<ul><li><a href="https://zhuanlan.zhihu.com/p/36332083" target="_blank" rel="noopener">æ”€ç™»ä¼ ç»Ÿæœºå™¨å­¦ä¹ çš„ç å³°-SVM (ä¸Š)</a></li><li><a href="https://zhuanlan.zhihu.com/p/36379394" target="_blank" rel="noopener">æ”€ç™»ä¼ ç»Ÿæœºå™¨å­¦ä¹ çš„ç å³°-SVM (ä¸­)</a></li><li><a href="https://zhuanlan.zhihu.com/p/36535299" target="_blank" rel="noopener">æ”€ç™»ä¼ ç»Ÿæœºå™¨å­¦ä¹ çš„ç å³°-SVM (ä¸‹)</a></li></ul><h2 id="æœºå™¨å­¦ä¹ ä¸­çš„SVM"><a href="#æœºå™¨å­¦ä¹ ä¸­çš„SVM" class="headerlink" title="æœºå™¨å­¦ä¹ ä¸­çš„SVM"></a>æœºå™¨å­¦ä¹ ä¸­çš„SVM</h2><p>æ”¯æŒå‘é‡æœºæ˜¯ä¸€ç§ç»å…¸çš„äºŒåˆ†ç±»æ¨¡å‹ï¼ŒåŸºæœ¬æ¨¡å‹å®šä¹‰ä¸ºç‰¹å¾ç©ºé—´ä¸­æœ€å¤§é—´éš”çš„çº¿æ€§åˆ†ç±»å™¨ï¼Œå…¶å­¦ä¹ çš„ä¼˜åŒ–ç›®æ ‡ä¾¿æ˜¯é—´éš”æœ€å¤§åŒ–ï¼Œå› æ­¤æ”¯æŒå‘é‡æœºæœ¬èº«å¯ä»¥è½¬åŒ–ä¸ºä¸€ä¸ªå‡¸äºŒæ¬¡è§„åˆ’æ±‚è§£çš„é—®é¢˜ã€‚</p><h3 id="å‡½æ•°é—´éš”ä¸å‡ ä½•é—´éš”"><a href="#å‡½æ•°é—´éš”ä¸å‡ ä½•é—´éš”" class="headerlink" title="å‡½æ•°é—´éš”ä¸å‡ ä½•é—´éš”"></a>å‡½æ•°é—´éš”ä¸å‡ ä½•é—´éš”</h3><p>å¯¹äºäºŒåˆ†ç±»å­¦ä¹ ï¼Œå‡è®¾ç°åœ¨çš„æ•°æ®æ˜¯çº¿æ€§å¯åˆ†çš„ï¼Œè¿™æ—¶åˆ†ç±»å­¦ä¹ æœ€åŸºæœ¬çš„æƒ³æ³•å°±æ˜¯æ‰¾åˆ°ä¸€ä¸ªåˆé€‚çš„è¶…å¹³é¢ï¼Œè¯¥è¶…å¹³é¢èƒ½å¤Ÿå°†ä¸åŒç±»åˆ«çš„æ ·æœ¬åˆ†å¼€ï¼Œç±»ä¼¼äºŒç»´å¹³é¢ä½¿ç”¨ax+by+c=0æ¥è¡¨ç¤ºï¼Œè¶…å¹³é¢å®é™…ä¸Šè¡¨ç¤ºçš„å°±æ˜¯é«˜ç»´çš„å¹³é¢ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc72f6a2ec8a.png" alt="1.png"></p><p>å¯¹æ•°æ®ç‚¹è¿›è¡Œåˆ’åˆ†æ—¶ï¼Œæ˜“çŸ¥ï¼šå½“è¶…å¹³é¢è·ç¦»ä¸å®ƒæœ€è¿‘çš„æ•°æ®ç‚¹çš„é—´éš”è¶Šå¤§ï¼Œåˆ†ç±»çš„é²æ£’æ€§è¶Šå¥½ï¼Œå³å½“æ–°çš„æ•°æ®ç‚¹åŠ å…¥æ—¶ï¼Œè¶…å¹³é¢å¯¹è¿™äº›ç‚¹çš„é€‚åº”æ€§æœ€å¼ºï¼Œå‡ºé”™çš„å¯èƒ½æ€§æœ€å°ã€‚å› æ­¤éœ€è¦è®©æ‰€é€‰æ‹©çš„è¶…å¹³é¢èƒ½å¤Ÿæœ€å¤§åŒ–è¿™ä¸ªé—´éš”Gapï¼ˆå¦‚ä¸‹å›¾æ‰€ç¤ºï¼‰ï¼Œ å¸¸ç”¨çš„é—´éš”å®šä¹‰æœ‰ä¸¤ç§ï¼Œä¸€ç§ç§°ä¹‹ä¸ºå‡½æ•°é—´éš”ï¼Œä¸€ç§ä¸ºå‡ ä½•é—´éš”ï¼Œä¸‹é¢å°†åˆ†åˆ«ä»‹ç»è¿™ä¸¤ç§é—´éš”ï¼Œå¹¶å¯¹SVMä¸ºä»€ä¹ˆä¼šé€‰ç”¨å‡ ä½•é—´éš”åšäº†ä¸€äº›é˜è¿°ã€‚</p><p><img src="https://i.loli.net/2018/10/17/5bc72f6a06d5a.png" alt="2.png"></p><h4 id="å‡½æ•°é—´éš”"><a href="#å‡½æ•°é—´éš”" class="headerlink" title="å‡½æ•°é—´éš”"></a>å‡½æ•°é—´éš”</h4><p>åœ¨è¶…å¹³é¢wâ€™x+b=0ç¡®å®šçš„æƒ…å†µä¸‹ï¼Œ|wâ€™x<em>+b|èƒ½å¤Ÿä»£è¡¨ç‚¹x*è·ç¦»è¶…å¹³é¢çš„è¿œè¿‘ï¼Œæ˜“çŸ¥ï¼šå½“wâ€™x</em>+b&gt;0æ—¶ï¼Œè¡¨ç¤ºx<em>åœ¨è¶…å¹³é¢çš„ä¸€ä¾§ï¼ˆæ­£ç±»ï¼Œç±»æ ‡ä¸º1ï¼‰ï¼Œè€Œå½“wâ€™x</em>+b&lt;0æ—¶ï¼Œåˆ™è¡¨ç¤ºx<em>åœ¨è¶…å¹³é¢çš„å¦å¤–ä¸€ä¾§ï¼ˆè´Ÿç±»ï¼Œç±»åˆ«ä¸º-1ï¼‰ï¼Œå› æ­¤ï¼ˆwâ€™x</em>+bï¼‰y* çš„æ­£è´Ÿæ€§æ°èƒ½è¡¨ç¤ºæ•°æ®ç‚¹x<em>æ˜¯å¦è¢«åˆ†ç±»æ­£ç¡®ã€‚äºæ˜¯ä¾¿å¼•å‡ºäº†*</em>å‡½æ•°é—´éš”**çš„å®šä¹‰ï¼ˆfunctional marginï¼‰:</p><p><img src="https://i.loli.net/2018/10/17/5bc72f690a14b.png" alt="3.png"></p><p>è€Œè¶…å¹³é¢ï¼ˆw,bï¼‰å…³äºæ‰€æœ‰æ ·æœ¬ç‚¹ï¼ˆXiï¼ŒYiï¼‰çš„å‡½æ•°é—´éš”æœ€å°å€¼åˆ™ä¸ºè¶…å¹³é¢åœ¨è®­ç»ƒæ•°æ®é›†Tä¸Šçš„å‡½æ•°é—´éš”ï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc72f690ac26.png" alt="4.png"></p><p>å¯ä»¥çœ‹å‡ºï¼šè¿™æ ·å®šä¹‰çš„å‡½æ•°é—´éš”åœ¨å¤„ç†SVMä¸Šä¼šæœ‰é—®é¢˜ï¼Œå½“è¶…å¹³é¢çš„ä¸¤ä¸ªå‚æ•°wå’ŒbåŒæ¯”ä¾‹æ”¹å˜æ—¶ï¼Œå‡½æ•°é—´éš”ä¹Ÿä¼šè·Ÿç€æ”¹å˜ï¼Œä½†æ˜¯å®é™…ä¸Šè¶…å¹³é¢è¿˜æ˜¯åŸæ¥çš„è¶…å¹³é¢ï¼Œå¹¶æ²¡æœ‰å˜åŒ–ã€‚ä¾‹å¦‚ï¼šw1x1+w2x2+w3x3+b=0å…¶å®ç­‰ä»·äº2w1x1+2w2x2+2w3x3+2b=0ï¼Œä½†è®¡ç®—çš„å‡½æ•°é—´éš”å´ç¿»äº†ä¸€å€ã€‚ä»è€Œå¼•å‡ºäº†èƒ½çœŸæ­£åº¦é‡ç‚¹åˆ°è¶…å¹³é¢è·ç¦»çš„æ¦‚å¿µâ€“å‡ ä½•é—´éš”ï¼ˆgeometrical marginï¼‰ã€‚</p><h4 id="å‡ ä½•é—´éš”"><a href="#å‡ ä½•é—´éš”" class="headerlink" title="å‡ ä½•é—´éš”"></a>å‡ ä½•é—´éš”</h4><p><strong>å‡ ä½•é—´éš”</strong>ä»£è¡¨çš„åˆ™æ˜¯æ•°æ®ç‚¹åˆ°è¶…å¹³é¢çš„çœŸå®è·ç¦»ï¼Œå¯¹äºè¶…å¹³é¢wâ€™x+b=0ï¼Œwä»£è¡¨çš„æ˜¯è¯¥è¶…å¹³é¢çš„æ³•å‘é‡ï¼Œè®¾x<em>ä¸ºè¶…å¹³é¢å¤–ä¸€ç‚¹xåœ¨æ³•å‘é‡wæ–¹å‘ä¸Šçš„æŠ•å½±ç‚¹ï¼Œxä¸è¶…å¹³é¢çš„è·ç¦»ä¸ºrï¼Œåˆ™æœ‰x</em>=x-r(w/||w||)ï¼Œåˆx<em>åœ¨è¶…å¹³é¢ä¸Šï¼Œå³wâ€™x</em>+b=0ï¼Œä»£å…¥å³å¯å¾—ï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc72f697d499.png" alt="5.png"></p><p>ä¸ºäº†å¾—åˆ°rçš„ç»å¯¹å€¼ï¼Œä»¤rå‘ˆä¸Šå…¶å¯¹åº”çš„ç±»åˆ«yï¼Œå³å¯å¾—åˆ°å‡ ä½•é—´éš”çš„å®šä¹‰ï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc72f696fd10.png" alt="6.png"></p><p>ä»ä¸Šè¿°å‡½æ•°é—´éš”ä¸å‡ ä½•é—´éš”çš„å®šä¹‰å¯ä»¥çœ‹å‡ºï¼šå®è´¨ä¸Šå‡½æ•°é—´éš”å°±æ˜¯|wâ€™x+b|ï¼Œè€Œå‡ ä½•é—´éš”å°±æ˜¯ç‚¹åˆ°è¶…å¹³é¢çš„è·ç¦»ã€‚</p><h3 id="æœ€å¤§é—´éš”ä¸æ”¯æŒå‘é‡"><a href="#æœ€å¤§é—´éš”ä¸æ”¯æŒå‘é‡" class="headerlink" title="æœ€å¤§é—´éš”ä¸æ”¯æŒå‘é‡"></a>æœ€å¤§é—´éš”ä¸æ”¯æŒå‘é‡</h3><p>é€šè¿‡å‰é¢çš„åˆ†æå¯çŸ¥ï¼šå‡½æ•°é—´éš”ä¸é€‚åˆç”¨æ¥æœ€å¤§åŒ–é—´éš”ï¼Œå› æ­¤è¿™é‡Œæˆ‘ä»¬è¦æ‰¾çš„æœ€å¤§é—´éš”æŒ‡çš„æ˜¯å‡ ä½•é—´éš”ï¼Œäºæ˜¯æœ€å¤§é—´éš”åˆ†ç±»å™¨çš„ç›®æ ‡å‡½æ•°å®šä¹‰ä¸ºï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc72f69af163.png" alt="7.png"></p><p>ä¸€èˆ¬åœ°ï¼Œæˆ‘ä»¬ä»¤r^ä¸º1ï¼ˆè¿™æ ·åšçš„ç›®çš„æ˜¯ä¸ºäº†æ–¹ä¾¿æ¨å¯¼å’Œç›®æ ‡å‡½æ•°çš„ä¼˜åŒ–ï¼‰ï¼Œä»è€Œä¸Šè¿°ç›®æ ‡å‡½æ•°è½¬åŒ–ä¸ºï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc72f697bb1d.png" alt="8.png"></p><p>å¯¹äºy(wâ€™x+b)=1çš„æ•°æ®ç‚¹ï¼Œå³ä¸‹å›¾ä¸­ä½äºwâ€™x+b=1æˆ–wâ€™x+b=-1ä¸Šçš„æ•°æ®ç‚¹ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸º<strong>æ”¯æŒå‘é‡</strong>ï¼ˆsupport vectorï¼‰ï¼Œæ˜“çŸ¥ï¼šå¯¹äºæ‰€æœ‰çš„æ”¯æŒå‘é‡ï¼Œå®ƒä»¬æ°å¥½æ»¡è¶³y<em>(wâ€™x</em>+b)=1ï¼Œè€Œæ‰€æœ‰ä¸æ˜¯æ”¯æŒå‘é‡çš„ç‚¹ï¼Œæœ‰y<em>(wâ€™x</em>+b)&gt;1ã€‚</p><p><img src="https://i.loli.net/2018/10/17/5bc72f6a838c4.png" alt="9.png"></p><h3 id="ä»åŸå§‹ä¼˜åŒ–é—®é¢˜åˆ°å¯¹å¶é—®é¢˜"><a href="#ä»åŸå§‹ä¼˜åŒ–é—®é¢˜åˆ°å¯¹å¶é—®é¢˜" class="headerlink" title="ä»åŸå§‹ä¼˜åŒ–é—®é¢˜åˆ°å¯¹å¶é—®é¢˜"></a>ä»åŸå§‹ä¼˜åŒ–é—®é¢˜åˆ°å¯¹å¶é—®é¢˜</h3><p>å¯¹äºä¸Šè¿°å¾—åˆ°çš„ç›®æ ‡å‡½æ•°ï¼Œæ±‚1/||w||çš„æœ€å¤§å€¼ç›¸å½“äºæ±‚||w||^2çš„æœ€å°å€¼ï¼Œå› æ­¤å¾ˆå®¹æ˜“å°†åŸæ¥çš„ç›®æ ‡å‡½æ•°è½¬åŒ–ä¸ºï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc72f6978cbb.png" alt="10.png"></p><p>å³å˜ä¸ºäº†ä¸€ä¸ªå¸¦çº¦æŸçš„å‡¸äºŒæ¬¡è§„åˆ’é—®é¢˜ï¼ŒæŒ‰ä¹¦ä¸Šæ‰€è¯´å¯ä»¥ä½¿ç”¨ç°æˆçš„ä¼˜åŒ–è®¡ç®—åŒ…ï¼ˆQPä¼˜åŒ–åŒ…ï¼‰æ±‚è§£ï¼Œä½†ç”±äºSVMçš„ç‰¹æ®Šæ€§ï¼Œä¸€èˆ¬æˆ‘ä»¬å°†åŸé—®é¢˜å˜æ¢ä¸ºå®ƒçš„<strong>å¯¹å¶é—®é¢˜</strong>ï¼Œæ¥ç€å†å¯¹å…¶å¯¹å¶é—®é¢˜è¿›è¡Œæ±‚è§£ã€‚ä¸ºä»€ä¹ˆé€šè¿‡å¯¹å¶é—®é¢˜è¿›è¡Œæ±‚è§£ï¼Œæœ‰ä¸‹é¢ä¸¤ä¸ªåŸå› ï¼š</p><pre><code>* ä¸€æ˜¯å› ä¸ºä½¿ç”¨å¯¹å¶é—®é¢˜æ›´å®¹æ˜“æ±‚è§£ï¼›* äºŒæ˜¯å› ä¸ºé€šè¿‡å¯¹å¶é—®é¢˜æ±‚è§£å‡ºç°äº†å‘é‡å†…ç§¯çš„å½¢å¼ï¼Œä»è€Œèƒ½æ›´åŠ è‡ªç„¶åœ°å¼•å‡ºæ ¸å‡½æ•°ã€‚</code></pre><p>å¯¹å¶é—®é¢˜ï¼Œé¡¾åæ€ä¹‰ï¼Œå¯ä»¥ç†è§£æˆä¼˜åŒ–ç­‰ä»·çš„é—®é¢˜ï¼Œæ›´ä¸€èˆ¬åœ°ï¼Œæ˜¯å°†ä¸€ä¸ªåŸå§‹ç›®æ ‡å‡½æ•°çš„æœ€å°åŒ–è½¬åŒ–ä¸ºå®ƒçš„å¯¹å¶å‡½æ•°æœ€å¤§åŒ–çš„é—®é¢˜ã€‚å¯¹äºå½“å‰çš„ä¼˜åŒ–é—®é¢˜ï¼Œé¦–å…ˆæˆ‘ä»¬å†™å‡ºå®ƒçš„æœ—æ ¼æœ—æ—¥å‡½æ•°ï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc72f9332be7.png" alt="11.png"></p><p>ä¸Šå¼å¾ˆå®¹æ˜“éªŒè¯ï¼šå½“å…¶ä¸­æœ‰ä¸€ä¸ªçº¦æŸæ¡ä»¶ä¸æ»¡è¶³æ—¶ï¼ŒLçš„æœ€å¤§å€¼ä¸º âˆï¼ˆåªéœ€ä»¤å…¶å¯¹åº”çš„Î±ä¸º âˆå³å¯ï¼‰ï¼›å½“æ‰€æœ‰çº¦æŸæ¡ä»¶éƒ½æ»¡è¶³æ—¶ï¼ŒLçš„æœ€å¤§å€¼ä¸º1/2||w||^2ï¼ˆæ­¤æ—¶ä»¤æ‰€æœ‰çš„Î±ä¸º0ï¼‰ï¼Œå› æ­¤å®é™…ä¸ŠåŸé—®é¢˜ç­‰ä»·äºï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc72f93321c5.png" alt="12.png"></p><p>ç”±äºè¿™ä¸ªçš„æ±‚è§£é—®é¢˜ä¸å¥½åšï¼Œå› æ­¤ä¸€èˆ¬æˆ‘ä»¬å°†æœ€å°å’Œæœ€å¤§çš„ä½ç½®äº¤æ¢ä¸€ä¸‹ï¼ˆéœ€æ»¡è¶³KKTæ¡ä»¶ï¼‰ ï¼Œå˜æˆåŸé—®é¢˜çš„å¯¹å¶é—®é¢˜ï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc72f9330967.png" alt="13.png"></p><p>è¿™æ ·å°±å°†åŸé—®é¢˜çš„æ±‚æœ€å°å˜æˆäº†å¯¹å¶é—®é¢˜æ±‚æœ€å¤§ï¼ˆç”¨å¯¹å¶è¿™ä¸ªè¯è¿˜æ˜¯å¾ˆå½¢è±¡ï¼‰ï¼Œæ¥ä¸‹æ¥ä¾¿å¯ä»¥å…ˆæ±‚Lå¯¹wå’Œbçš„æå°ï¼Œå†æ±‚Lå¯¹Î±çš„æå¤§ã€‚</p><p>ï¼ˆ1ï¼‰é¦–å…ˆæ±‚Lå¯¹wå’Œbçš„æå°ï¼Œåˆ†åˆ«æ±‚Lå…³äºwå’Œbçš„åå¯¼ï¼Œå¯ä»¥å¾—å‡ºï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc72f9333e66.png" alt="14.png"></p><p>å°†ä¸Šè¿°ç»“æœä»£å…¥Lå¾—åˆ°ï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc72f935ae21.png" alt="15.png"></p><p>ï¼ˆ2ï¼‰æ¥ç€Lå…³äºÎ±æå¤§æ±‚è§£Î±ï¼ˆé€šè¿‡SMOç®—æ³•æ±‚è§£ï¼Œæ­¤å¤„ä¸åšæ·±å…¥ï¼‰ã€‚</p><p><img src="https://i.loli.net/2018/10/17/5bc72f9338a9d.png" alt="16.png"></p><p>ï¼ˆ3ï¼‰æœ€åä¾¿å¯ä»¥æ ¹æ®æ±‚è§£å‡ºçš„Î±ï¼Œè®¡ç®—å‡ºwå’Œbï¼Œä»è€Œå¾—åˆ°åˆ†ç±»è¶…å¹³é¢å‡½æ•°ã€‚</p><p><img src="https://i.loli.net/2018/10/17/5bc72f93419ca.png" alt="17.png"></p><p>åœ¨å¯¹æ–°çš„ç‚¹è¿›è¡Œé¢„æµ‹æ—¶ï¼Œå®é™…ä¸Šå°±æ˜¯å°†æ•°æ®ç‚¹x*ä»£å…¥åˆ†ç±»å‡½æ•°f(x)=wâ€™x+bä¸­ï¼Œè‹¥f(x)&gt;0ï¼Œåˆ™ä¸ºæ­£ç±»ï¼Œf(x)&lt;0ï¼Œåˆ™ä¸ºè´Ÿç±»ï¼Œæ ¹æ®å‰é¢æ¨å¯¼å¾—å‡ºçš„wä¸bï¼Œåˆ†ç±»å‡½æ•°å¦‚ä¸‹æ‰€ç¤ºï¼Œæ­¤æ—¶ä¾¿å‡ºç°äº†ä¸Šé¢æ‰€æåˆ°çš„å†…ç§¯å½¢å¼ã€‚</p><p><img src="https://i.loli.net/2018/10/17/5bc72f9353166.png" alt="18.png"></p><p>è¿™é‡Œå®é™…ä¸Šåªéœ€è®¡ç®—æ–°æ ·æœ¬ä¸æ”¯æŒå‘é‡çš„å†…ç§¯ï¼Œå› ä¸ºå¯¹äºéæ”¯æŒå‘é‡çš„æ•°æ®ç‚¹ï¼Œå…¶å¯¹åº”çš„æ‹‰æ ¼æœ—æ—¥ä¹˜å­ä¸€å®šä¸º0ï¼Œæ ¹æ®æœ€ä¼˜åŒ–ç†è®ºï¼ˆK-Tæ¡ä»¶ï¼‰ï¼Œå¯¹äºä¸ç­‰å¼çº¦æŸy(wâ€™x+b)-1â‰¥0ï¼Œæ»¡è¶³ï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc72f933c947.png" alt="19.png">        </p><h3 id="æ ¸å‡½æ•°"><a href="#æ ¸å‡½æ•°" class="headerlink" title="æ ¸å‡½æ•°"></a>æ ¸å‡½æ•°</h3><p>ç”±äºä¸Šè¿°çš„è¶…å¹³é¢åªèƒ½è§£å†³çº¿æ€§å¯åˆ†çš„é—®é¢˜ï¼Œå¯¹äºçº¿æ€§ä¸å¯åˆ†çš„é—®é¢˜ï¼Œä¾‹å¦‚ï¼šå¼‚æˆ–é—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨æ ¸å‡½æ•°å°†å…¶è¿›è¡Œæ¨å¹¿ã€‚ä¸€èˆ¬åœ°ï¼Œè§£å†³çº¿æ€§ä¸å¯åˆ†é—®é¢˜æ—¶ï¼Œå¸¸å¸¸é‡‡ç”¨<strong>æ˜ å°„</strong>çš„æ–¹å¼ï¼Œå°†ä½ç»´åŸå§‹ç©ºé—´æ˜ å°„åˆ°é«˜ç»´ç‰¹å¾ç©ºé—´ï¼Œä½¿å¾—æ•°æ®é›†åœ¨é«˜ç»´ç©ºé—´ä¸­å˜å¾—çº¿æ€§å¯åˆ†ï¼Œä»è€Œå†ä½¿ç”¨çº¿æ€§å­¦ä¹ å™¨åˆ†ç±»ã€‚å¦‚æœåŸå§‹ç©ºé—´ä¸ºæœ‰é™ç»´ï¼Œå³å±æ€§æ•°æœ‰é™ï¼Œé‚£ä¹ˆæ€»æ˜¯å­˜åœ¨ä¸€ä¸ªé«˜ç»´ç‰¹å¾ç©ºé—´ä½¿å¾—æ ·æœ¬çº¿æ€§å¯åˆ†ã€‚è‹¥âˆ…ä»£è¡¨ä¸€ä¸ªæ˜ å°„ï¼Œåˆ™åœ¨ç‰¹å¾ç©ºé—´ä¸­çš„åˆ’åˆ†å‡½æ•°å˜ä¸ºï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc72f934303e.png" alt="20.png"></p><p>æŒ‰ç…§åŒæ ·çš„æ–¹æ³•ï¼Œå…ˆå†™å‡ºæ–°ç›®æ ‡å‡½æ•°çš„æ‹‰æ ¼æœ—æ—¥å‡½æ•°ï¼Œæ¥ç€å†™å‡ºå…¶å¯¹å¶é—®é¢˜ï¼Œæ±‚Lå…³äºwå’Œbçš„æå¤§ï¼Œæœ€åè¿ç”¨SOMæ±‚è§£Î±ã€‚å¯ä»¥å¾—å‡ºï¼š</p><p>ï¼ˆ1ï¼‰åŸå¯¹å¶é—®é¢˜å˜ä¸ºï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc730cc68b3b.png" alt="21.png"></p><p>ï¼ˆ2ï¼‰åŸåˆ†ç±»å‡½æ•°å˜ä¸ºï¼š<br><img src="https://i.loli.net/2018/10/17/5bc730cc1b673.png" alt="22.png"></p><p>æ±‚è§£çš„è¿‡ç¨‹ä¸­ï¼Œåªæ¶‰åŠåˆ°äº†é«˜ç»´ç‰¹å¾ç©ºé—´ä¸­çš„å†…ç§¯è¿ç®—ï¼Œç”±äºç‰¹å¾ç©ºé—´çš„ç»´æ•°å¯èƒ½ä¼šéå¸¸å¤§ï¼Œä¾‹å¦‚ï¼šè‹¥åŸå§‹ç©ºé—´ä¸ºäºŒç»´ï¼Œæ˜ å°„åçš„ç‰¹å¾ç©ºé—´ä¸º5ç»´ï¼Œè‹¥åŸå§‹ç©ºé—´ä¸ºä¸‰ç»´ï¼Œæ˜ å°„åçš„ç‰¹å¾ç©ºé—´å°†æ˜¯19ç»´ï¼Œä¹‹åç”šè‡³å¯èƒ½å‡ºç°æ— ç©·ç»´ï¼Œæ ¹æœ¬æ— æ³•è¿›è¡Œå†…ç§¯è¿ç®—äº†ï¼Œæ­¤æ—¶ä¾¿å¼•å‡ºäº†<strong>æ ¸å‡½æ•°</strong>ï¼ˆKernelï¼‰çš„æ¦‚å¿µã€‚</p><p><img src="https://i.loli.net/2018/10/17/5bc730cc49adc.png" alt="23.png"></p><p>å› æ­¤ï¼Œæ ¸å‡½æ•°å¯ä»¥ç›´æ¥è®¡ç®—éšå¼æ˜ å°„åˆ°é«˜ç»´ç‰¹å¾ç©ºé—´åçš„å‘é‡å†…ç§¯ï¼Œè€Œä¸éœ€è¦æ˜¾å¼åœ°å†™å‡ºæ˜ å°„åçš„ç»“æœï¼Œå®ƒè™½ç„¶å®Œæˆäº†å°†ç‰¹å¾ä»ä½ç»´åˆ°é«˜ç»´çš„è½¬æ¢ï¼Œä½†æœ€ç»ˆå´æ˜¯åœ¨ä½ç»´ç©ºé—´ä¸­å®Œæˆå‘é‡å†…ç§¯è®¡ç®—ï¼Œä¸é«˜ç»´ç‰¹å¾ç©ºé—´ä¸­çš„è®¡ç®—ç­‰æ•ˆ<strong>ï¼ˆä½ç»´è®¡ç®—ï¼Œé«˜ç»´è¡¨ç°ï¼‰</strong>ï¼Œä»è€Œé¿å…äº†ç›´æ¥åœ¨é«˜ç»´ç©ºé—´æ— æ³•è®¡ç®—çš„é—®é¢˜ã€‚å¼•å…¥æ ¸å‡½æ•°åï¼ŒåŸæ¥çš„å¯¹å¶é—®é¢˜ä¸åˆ†ç±»å‡½æ•°åˆ™å˜ä¸ºï¼š</p><p>ï¼ˆ1ï¼‰å¯¹å¶é—®é¢˜ï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc730cc173b2.png" alt="24.png"></p><p>ï¼ˆ2ï¼‰åˆ†ç±»å‡½æ•°ï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc730cc05959.png" alt="25.png"></p><p>å› æ­¤ï¼Œåœ¨çº¿æ€§ä¸å¯åˆ†é—®é¢˜ä¸­ï¼Œæ ¸å‡½æ•°çš„é€‰æ‹©æˆäº†æ”¯æŒå‘é‡æœºçš„æœ€å¤§å˜æ•°ï¼Œè‹¥é€‰æ‹©äº†ä¸åˆé€‚çš„æ ¸å‡½æ•°ï¼Œåˆ™æ„å‘³ç€å°†æ ·æœ¬æ˜ å°„åˆ°äº†ä¸€ä¸ªä¸åˆé€‚çš„ç‰¹å¾ç©ºé—´ï¼Œåˆ™æå¯èƒ½å¯¼è‡´æ€§èƒ½ä¸ä½³ã€‚åŒæ—¶ï¼Œæ ¸å‡½æ•°éœ€è¦æ»¡è¶³ä»¥ä¸‹è¿™ä¸ªå¿…è¦æ¡ä»¶ï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc730ccc468c.png" alt="26.png"></p><p>ç”±äºæ ¸å‡½æ•°çš„æ„é€ ååˆ†å›°éš¾ï¼Œé€šå¸¸æˆ‘ä»¬éƒ½æ˜¯ä»ä¸€äº›å¸¸ç”¨çš„æ ¸å‡½æ•°ä¸­é€‰æ‹©ï¼Œä¸‹é¢åˆ—å‡ºäº†å‡ ç§å¸¸ç”¨çš„æ ¸å‡½æ•°ï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc730ccc541a.png" alt="27.png"></p><h3 id="è½¯é—´éš”æ”¯æŒå‘é‡æœº"><a href="#è½¯é—´éš”æ”¯æŒå‘é‡æœº" class="headerlink" title="è½¯é—´éš”æ”¯æŒå‘é‡æœº"></a>è½¯é—´éš”æ”¯æŒå‘é‡æœº</h3><p>å‰é¢çš„è®¨è®ºä¸­ï¼Œæˆ‘ä»¬ä¸»è¦è§£å†³äº†ä¸¤ä¸ªé—®é¢˜ï¼šå½“æ•°æ®çº¿æ€§å¯åˆ†æ—¶ï¼Œç›´æ¥ä½¿ç”¨æœ€å¤§é—´éš”çš„è¶…å¹³é¢åˆ’åˆ†ï¼›å½“æ•°æ®çº¿æ€§ä¸å¯åˆ†æ—¶ï¼Œåˆ™é€šè¿‡æ ¸å‡½æ•°å°†æ•°æ®æ˜ å°„åˆ°é«˜ç»´ç‰¹å¾ç©ºé—´ï¼Œä½¿ä¹‹çº¿æ€§å¯åˆ†ã€‚ç„¶è€Œåœ¨ç°å®é—®é¢˜ä¸­ï¼Œå¯¹äºæŸäº›æƒ…å½¢è¿˜æ˜¯å¾ˆéš¾å¤„ç†ï¼Œä¾‹å¦‚æ•°æ®ä¸­æœ‰<strong>å™ªå£°</strong>çš„æƒ…å½¢ï¼Œå™ªå£°æ•°æ®ï¼ˆ<strong>outlier</strong>ï¼‰æœ¬èº«å°±åç¦»äº†æ­£å¸¸ä½ç½®ï¼Œä½†æ˜¯åœ¨å‰é¢çš„SVMæ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬è¦æ±‚æ‰€æœ‰çš„æ ·æœ¬æ•°æ®éƒ½å¿…é¡»æ»¡è¶³çº¦æŸï¼Œå¦‚æœä¸è¦è¿™äº›å™ªå£°æ•°æ®è¿˜å¥½ï¼Œå½“åŠ å…¥è¿™äº›outlieråå¯¼è‡´åˆ’åˆ†è¶…å¹³é¢è¢«æŒ¤æ­ªäº†ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå¯¹æ”¯æŒå‘é‡æœºçš„æ³›åŒ–æ€§èƒ½é€ æˆå¾ˆå¤§çš„å½±å“ã€‚</p><p><img src="https://i.loli.net/2018/10/17/5bc730ccce68e.png" alt="28.png"></p><p>ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦å…è®¸æŸä¸€äº›æ•°æ®ç‚¹ä¸æ»¡è¶³çº¦æŸï¼Œå³å¯ä»¥åœ¨ä¸€å®šç¨‹åº¦ä¸Šåç§»è¶…å¹³é¢ï¼ŒåŒæ—¶ä½¿å¾—ä¸æ»¡è¶³çº¦æŸçš„æ•°æ®ç‚¹å°½å¯èƒ½å°‘ï¼Œè¿™ä¾¿å¼•å‡ºäº†<strong>â€œè½¯é—´éš”â€æ”¯æŒå‘é‡æœº</strong>çš„æ¦‚å¿µ</p><pre><code>* å…è®¸æŸäº›æ•°æ®ç‚¹ä¸æ»¡è¶³çº¦æŸy(w&apos;x+b)â‰¥1ï¼›* åŒæ—¶åˆä½¿å¾—ä¸æ»¡è¶³çº¦æŸçš„æ ·æœ¬å°½å¯èƒ½å°‘ã€‚</code></pre><p>è¿™æ ·ä¼˜åŒ–ç›®æ ‡å˜ä¸ºï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc730cc6c9fe.png" alt="29.png"></p><p>å¦‚åŒé˜¶è·ƒå‡½æ•°ï¼Œ0/1æŸå¤±å‡½æ•°è™½ç„¶è¡¨ç¤ºæ•ˆæœæœ€å¥½ï¼Œä½†æ˜¯æ•°å­¦æ€§è´¨ä¸ä½³ã€‚å› æ­¤å¸¸ç”¨å…¶å®ƒå‡½æ•°ä½œä¸ºâ€œæ›¿ä»£æŸå¤±å‡½æ•°â€ã€‚</p><p><img src="https://i.loli.net/2018/10/17/5bc730cc5e5a9.png" alt="30.png"></p><p>æ”¯æŒå‘é‡æœºä¸­çš„æŸå¤±å‡½æ•°ä¸º<strong>hingeæŸå¤±</strong>ï¼Œå¼•å…¥<strong>â€œæ¾å¼›å˜é‡â€</strong>ï¼Œç›®æ ‡å‡½æ•°ä¸çº¦æŸæ¡ä»¶å¯ä»¥å†™ä¸ºï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc7317aa3411.png" alt="31.png"></p><p>å…¶ä¸­Cä¸ºä¸€ä¸ªå‚æ•°ï¼Œæ§åˆ¶ç€ç›®æ ‡å‡½æ•°ä¸æ–°å¼•å…¥æ­£åˆ™é¡¹ä¹‹é—´çš„æƒé‡ï¼Œè¿™æ ·æ˜¾ç„¶æ¯ä¸ªæ ·æœ¬æ•°æ®éƒ½æœ‰ä¸€ä¸ªå¯¹åº”çš„æ¾å¼›å˜é‡ï¼Œç”¨ä»¥è¡¨ç¤ºè¯¥æ ·æœ¬ä¸æ»¡è¶³çº¦æŸçš„ç¨‹åº¦ï¼Œå°†æ–°çš„ç›®æ ‡å‡½æ•°è½¬åŒ–ä¸ºæ‹‰æ ¼æœ—æ—¥å‡½æ•°å¾—åˆ°ï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc7317a4c96e.png" alt="32.png"></p><p>æŒ‰ç…§ä¸ä¹‹å‰ç›¸åŒçš„æ–¹æ³•ï¼Œå…ˆè®©Læ±‚å…³äºwï¼Œbä»¥åŠæ¾å¼›å˜é‡çš„æå°ï¼Œå†ä½¿ç”¨SMOæ±‚å‡ºÎ±ï¼Œæœ‰ï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc7317a6dff2.png" alt="33.png"></p><p>å°†wä»£å…¥LåŒ–ç®€ï¼Œä¾¿å¾—åˆ°å…¶å¯¹å¶é—®é¢˜ï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc7317ab6646.png" alt="34.png"></p><p>å°†â€œè½¯é—´éš”â€ä¸‹äº§ç”Ÿçš„å¯¹å¶é—®é¢˜ä¸åŸå¯¹å¶é—®é¢˜å¯¹æ¯”å¯ä»¥å‘ç°ï¼šæ–°çš„å¯¹å¶é—®é¢˜åªæ˜¯çº¦æŸæ¡ä»¶ä¸­çš„Î±å¤šå‡ºäº†ä¸€ä¸ªä¸Šé™Cï¼Œå…¶å®ƒçš„å®Œå…¨ç›¸åŒï¼Œå› æ­¤åœ¨å¼•å…¥æ ¸å‡½æ•°å¤„ç†çº¿æ€§ä¸å¯åˆ†é—®é¢˜æ—¶ï¼Œä¾¿èƒ½ä½¿ç”¨ä¸â€œç¡¬é—´éš”â€æ”¯æŒå‘é‡æœºå®Œå…¨ç›¸åŒçš„æ–¹æ³•ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>word-embedding</title>
      <link href="/2020/02/11/word-embedding/"/>
      <url>/2020/02/11/word-embedding/</url>
      
        <content type="html"><![CDATA[<h3 id="è¯å‘é‡"><a href="#è¯å‘é‡" class="headerlink" title="è¯å‘é‡"></a>è¯å‘é‡</h3><p>å­¦ä¹ ç›®æ ‡</p><ul><li>å­¦ä¹ è¯å‘é‡çš„æ¦‚å¿µ</li><li>ç”¨Skip-thoughtæ¨¡å‹è®­ç»ƒè¯å‘é‡</li><li>å­¦ä¹ ä½¿ç”¨PyTorch datasetå’Œdataloader</li><li>å­¦ä¹ å®šä¹‰PyTorchæ¨¡å‹</li><li>å­¦ä¹ torch.nnä¸­å¸¸è§çš„Module<ul><li>Embedding</li></ul></li><li>å­¦ä¹ å¸¸è§çš„PyTorch operations<ul><li>bmm</li><li>logsigmoid</li></ul></li><li>ä¿å­˜å’Œè¯»å–PyTorchæ¨¡å‹</li></ul><p>ä½¿ç”¨çš„è®­ç»ƒæ•°æ®å¯ä»¥ä»ä»¥ä¸‹é“¾æ¥ä¸‹è½½åˆ°ã€‚</p><p>é“¾æ¥:<a href="https://pan.baidu.com/s/1tFeK3mXuVXEy3EMarfeWvg" target="_blank" rel="noopener">https://pan.baidu.com/s/1tFeK3mXuVXEy3EMarfeWvg</a> å¯†ç :v2z5</p><p>åœ¨è¿™ä¸€ä»½notebookä¸­ï¼Œæˆ‘ä»¬ä¼šï¼ˆå°½å¯èƒ½ï¼‰å°è¯•å¤ç°è®ºæ–‡<a href="http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf" target="_blank" rel="noopener">Distributed Representations of Words and Phrases and their Compositionality</a>ä¸­è®­ç»ƒè¯å‘é‡çš„æ–¹æ³•. æˆ‘ä»¬ä¼šå®ç°Skip-gramæ¨¡å‹ï¼Œå¹¶ä¸”ä½¿ç”¨è®ºæ–‡ä¸­noice contrastive samplingçš„ç›®æ ‡å‡½æ•°ã€‚</p><p>è¿™ç¯‡è®ºæ–‡æœ‰å¾ˆå¤šæ¨¡å‹å®ç°çš„ç»†èŠ‚ï¼Œè¿™äº›ç»†èŠ‚å¯¹äºè¯å‘é‡çš„å¥½åè‡³å…³é‡è¦ã€‚æˆ‘ä»¬è™½ç„¶æ— æ³•å®Œå…¨å¤ç°è®ºæ–‡ä¸­çš„å®éªŒç»“æœï¼Œä¸»è¦æ˜¯ç”±äºè®¡ç®—èµ„æºç­‰å„ç§ç»†èŠ‚åŸå› ï¼Œä½†æ˜¯æˆ‘ä»¬è¿˜æ˜¯å¯ä»¥å¤§è‡´å±•ç¤ºå¦‚ä½•è®­ç»ƒè¯å‘é‡ã€‚</p><p>ä»¥ä¸‹æ˜¯ä¸€äº›æˆ‘ä»¬æ²¡æœ‰å®ç°çš„ç»†èŠ‚</p><ul><li>subsamplingï¼šå‚è€ƒè®ºæ–‡section 2.3</li></ul><p>In [1]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from torch import nn</span><br></pre></td></tr></table></figure><p>In [2]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn  <span class="comment">#ç¥ç»ç½‘ç»œå·¥å…·ç®±torch.nn </span></span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F  <span class="comment">#ç¥ç»ç½‘ç»œå‡½æ•°torch.nn.functional</span></span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> tud  <span class="comment">#Pytorchè¯»å–è®­ç»ƒé›†éœ€è¦ç”¨åˆ°torch.utils.dataç±»</span></span><br></pre></td></tr></table></figure><p><strong>ä¸¤ä¸ªæ¨¡å—çš„åŒºåˆ«ï¼š</strong><a href="https://blog.csdn.net/hawkcici160/article/details/80140059" target="_blank" rel="noopener">torch.nn å’Œ torch.functional çš„åŒºåˆ«</a></p><p>In [3]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.nn.parameter <span class="keyword">import</span> Parameter  <span class="comment">#å‚æ•°æ›´æ–°å’Œä¼˜åŒ–å‡½æ•°</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter <span class="comment">#Counter è®¡æ•°å™¨</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> math </span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> scipy <span class="comment">#SciPyæ˜¯åŸºäºNumPyå¼€å‘çš„é«˜çº§æ¨¡å—ï¼Œå®ƒæä¾›äº†è®¸å¤šæ•°å­¦ç®—æ³•å’Œå‡½æ•°çš„å®ç°</span></span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics.pairwise <span class="keyword">import</span> cosine_similarity <span class="comment">#ä½™å¼¦ç›¸ä¼¼åº¦å‡½æ•°</span></span><br></pre></td></tr></table></figure><p>å¼€å§‹çœ‹ä»£ç å‰ï¼Œè¯·ç¡®ä¿å¯¹word2vecæœ‰äº†è§£ã€‚</p><p><a href="https://blog.csdn.net/lilong117194/article/details/81979522" target="_blank" rel="noopener">CBOWæ¨¡å‹ç†è§£</a></p><p><a href="https://www.jianshu.com/p/da235893e4a5" target="_blank" rel="noopener">Skip-Gramæ¨¡å‹ç†è§£</a></p><p>è´Ÿä¾‹é‡‡æ ·å°±æ˜¯Skip-Gramæ¨¡å‹çš„è¾“å‡ºä¸æ˜¯å‘¨å›´è¯çš„æ¦‚ç‡äº†ï¼Œæ˜¯æ­£ä¾‹å’Œè´Ÿä¾‹çš„æ¦‚ç‡</p><p>In [4]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">USE_CUDA = torch.cuda.is_available() <span class="comment">#æœ‰GPUå¯ä»¥ç”¨</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ä¸ºäº†ä¿è¯å®éªŒç»“æœå¯ä»¥å¤ç°ï¼Œæˆ‘ä»¬ç»å¸¸ä¼šæŠŠå„ç§random seedå›ºå®šåœ¨æŸä¸€ä¸ªå€¼</span></span><br><span class="line">random.seed(<span class="number">53113</span>)</span><br><span class="line">np.random.seed(<span class="number">53113</span>)</span><br><span class="line">torch.manual_seed(<span class="number">53113</span>)</span><br><span class="line"><span class="keyword">if</span> USE_CUDA:</span><br><span class="line">    torch.cuda.manual_seed(<span class="number">53113</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># è®¾å®šä¸€äº›è¶…å‚æ•°   </span></span><br><span class="line">K = <span class="number">10</span> <span class="comment"># number of negative samples è´Ÿæ ·æœ¬éšæœºé‡‡æ ·æ•°é‡</span></span><br><span class="line">C = <span class="number">3</span> <span class="comment"># nearby words threshold æŒ‡å®šå‘¨å›´ä¸‰ä¸ªå•è¯è¿›è¡Œé¢„æµ‹</span></span><br><span class="line">NUM_EPOCHS = <span class="number">2</span> <span class="comment"># The number of epochs of training è¿­ä»£è½®æ•°</span></span><br><span class="line">MAX_VOCAB_SIZE = <span class="number">30000</span> <span class="comment"># the vocabulary size è¯æ±‡è¡¨å¤šå¤§</span></span><br><span class="line">BATCH_SIZE = <span class="number">128</span> <span class="comment"># the batch size æ¯è½®è¿­ä»£1ä¸ªbatchçš„æ•°é‡</span></span><br><span class="line">LEARNING_RATE = <span class="number">0.2</span> <span class="comment"># the initial learning rate #å­¦ä¹ ç‡</span></span><br><span class="line">EMBEDDING_SIZE = <span class="number">100</span> <span class="comment">#è¯å‘é‡ç»´åº¦</span></span><br><span class="line">       </span><br><span class="line">    </span><br><span class="line">LOG_FILE = <span class="string">"word-embedding.log"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># tokenizeå‡½æ•°ï¼ŒæŠŠä¸€ç¯‡æ–‡æœ¬è½¬åŒ–æˆä¸€ä¸ªä¸ªå•è¯</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">word_tokenize</span><span class="params">(text)</span>:</span> </span><br><span class="line">    <span class="keyword">return</span> text.split()</span><br></pre></td></tr></table></figure><ul><li>ä»æ–‡æœ¬æ–‡ä»¶ä¸­è¯»å–æ‰€æœ‰çš„æ–‡å­—ï¼Œé€šè¿‡è¿™äº›æ–‡æœ¬åˆ›å»ºä¸€ä¸ªvocabulary</li><li>ç”±äºå•è¯æ•°é‡å¯èƒ½å¤ªå¤§ï¼Œæˆ‘ä»¬åªé€‰å–æœ€å¸¸è§çš„MAX_VOCAB_SIZEä¸ªå•è¯</li><li>æˆ‘ä»¬æ·»åŠ ä¸€ä¸ªUNKå•è¯è¡¨ç¤ºæ‰€æœ‰ä¸å¸¸è§çš„å•è¯</li><li>æˆ‘ä»¬éœ€è¦è®°å½•å•è¯åˆ°indexçš„mappingï¼Œä»¥åŠindexåˆ°å•è¯çš„mappingï¼Œå•è¯çš„countï¼Œå•è¯çš„(normalized) frequencyï¼Œä»¥åŠå•è¯æ€»æ•°ã€‚</li></ul><p>In [5]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">"./text8/text8.train.txt"</span>, <span class="string">"r"</span>) <span class="keyword">as</span> fin: <span class="comment">#è¯»å…¥æ–‡ä»¶</span></span><br><span class="line">    text = fin.read() <span class="comment"># ä¸€æ¬¡æ€§è¯»å…¥æ–‡ä»¶æ‰€æœ‰å†…å®¹</span></span><br><span class="line">    </span><br><span class="line">text = [w <span class="keyword">for</span> w <span class="keyword">in</span> word_tokenize(text.lower())] </span><br><span class="line"><span class="comment">#åˆ†è¯ï¼Œåœ¨è¿™é‡Œç±»ä¼¼äºtext.split()</span></span><br><span class="line"><span class="comment">#print(len(text)) # 15313011ï¼Œæœ‰è¾£ä¹ˆå¤šå•è¯</span></span><br><span class="line"></span><br><span class="line">vocab = dict(Counter(text).most_common(MAX_VOCAB_SIZE<span class="number">-1</span>))</span><br><span class="line"><span class="comment">#å­—å…¸æ ¼å¼ï¼ŒæŠŠï¼ˆMAX_VOCAB_SIZE-1ï¼‰ä¸ªæœ€é¢‘ç¹å‡ºç°çš„å•è¯å–å‡ºæ¥ï¼Œ-1æ˜¯ç•™ç»™ä¸å¸¸è§çš„å•è¯</span></span><br><span class="line"><span class="comment">#print(len(vocab)) # 29999</span></span><br><span class="line"></span><br><span class="line">vocab[<span class="string">"&lt;unk&gt;"</span>] = len(text) - np.sum(list(vocab.values()))</span><br><span class="line"><span class="comment">#unkè¡¨ç¤ºä¸å¸¸è§å•è¯æ•°=æ€»å•è¯æ•°-å¸¸è§å•è¯æ•°</span></span><br><span class="line"><span class="comment"># print(vocab["&lt;unk&gt;"]) # 617111</span></span><br><span class="line">print(vocab[<span class="string">"&lt;unk&gt;"</span>])</span><br><span class="line">idx_to_word = [word <span class="keyword">for</span> word <span class="keyword">in</span> vocab.keys()] </span><br><span class="line"><span class="comment">#å–å‡ºå­—å…¸çš„æ‰€æœ‰æœ€å¸¸è§30000å•è¯</span></span><br><span class="line"></span><br><span class="line">word_to_idx = &#123;word:i <span class="keyword">for</span> i, word <span class="keyword">in</span> enumerate(idx_to_word)&#125;</span><br><span class="line"><span class="comment">#å–å‡ºæ‰€æœ‰å•è¯çš„å•è¯å’Œå¯¹åº”çš„ç´¢å¼•ï¼Œç´¢å¼•å€¼ä¸å•è¯å‡ºç°æ¬¡æ•°ç›¸åï¼Œæœ€å¸¸è§å•è¯ç´¢å¼•ä¸º0ã€‚</span></span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">617111</span><br></pre></td></tr></table></figure><p>In [1]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#print(vocab)</span></span><br></pre></td></tr></table></figure><p>In [2]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#print(list(word_to_idx.items())[29900:]) </span></span><br><span class="line"><span class="comment"># æ•²é»‘æ¿ï¼šå­—å…¸æ˜¯æ€ä¹ˆåƒåˆ—è¡¨é‚£æ ·åˆ‡ç‰‡çš„</span></span><br></pre></td></tr></table></figure><p>In [9]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">word_counts = np.array([count <span class="keyword">for</span> count <span class="keyword">in</span> vocab.values()], dtype=np.float32)</span><br><span class="line"><span class="comment">#vocabæ‰€æœ‰å•è¯çš„é¢‘æ•°values</span></span><br><span class="line"></span><br><span class="line">word_freqs = word_counts / np.sum(word_counts)</span><br><span class="line"><span class="comment">#æ‰€æœ‰å•è¯çš„è¯é¢‘æ¦‚ç‡å€¼</span></span><br><span class="line"><span class="comment"># print(np.sum(word_freqs))=1</span></span><br><span class="line"></span><br><span class="line">word_freqs = word_freqs ** (<span class="number">3.</span>/<span class="number">4.</span>)</span><br><span class="line"><span class="comment">#è®ºæ–‡é‡Œä¹˜ä»¥3/4æ¬¡æ–¹</span></span><br><span class="line"><span class="comment"># print(np.sum(word_freqs)) = 7.7</span></span><br><span class="line"></span><br><span class="line">word_freqs = word_freqs / np.sum(word_freqs) <span class="comment"># ç”¨æ¥åš negative sampling</span></span><br><span class="line"><span class="comment"># é‡æ–°è®¡ç®—æ‰€æœ‰å•è¯çš„é¢‘ç‡ï¼Œè€å¸ˆè¿™é‡Œä»£ç å¥½åƒå†™é”™äº†</span></span><br><span class="line"><span class="comment"># print(np.sum(word_freqs)) = 1</span></span><br><span class="line"></span><br><span class="line">VOCAB_SIZE = len(idx_to_word) <span class="comment">#è¯æ±‡è¡¨å•è¯æ•°30000=MAX_VOCAB_SIZE</span></span><br><span class="line">VOCAB_SIZE</span><br></pre></td></tr></table></figure><p>Out[9]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">30000</span><br></pre></td></tr></table></figure><h3 id="å®ç°Dataloader"><a href="#å®ç°Dataloader" class="headerlink" title="å®ç°Dataloader"></a>å®ç°Dataloader</h3><p>ä¸€ä¸ªdataloaderéœ€è¦ä»¥ä¸‹å†…å®¹ï¼š</p><ul><li>æŠŠæ‰€æœ‰textç¼–ç æˆæ•°å­—ï¼Œç„¶åç”¨subsamplingé¢„å¤„ç†è¿™äº›æ–‡å­—ã€‚</li><li>ä¿å­˜vocabularyï¼Œå•è¯countï¼Œnormalized word frequency</li><li>æ¯ä¸ªiteration sampleä¸€ä¸ªä¸­å¿ƒè¯</li><li>æ ¹æ®å½“å‰çš„ä¸­å¿ƒè¯è¿”å›contextå•è¯</li><li>æ ¹æ®ä¸­å¿ƒè¯sampleä¸€äº›negativeå•è¯</li><li>è¿”å›å•è¯çš„counts</li></ul><p>è¿™é‡Œæœ‰ä¸€ä¸ªå¥½çš„tutorialä»‹ç»å¦‚ä½•ä½¿ç”¨<a href="https://pytorch.org/tutorials/beginner/data_loading_tutorial.html" target="_blank" rel="noopener">PyTorch dataloader</a>. ä¸ºäº†ä½¿ç”¨dataloaderï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰ä»¥ä¸‹ä¸¤ä¸ªfunction:</p><ul><li><code>__len__</code> functionéœ€è¦è¿”å›æ•´ä¸ªæ•°æ®é›†ä¸­æœ‰å¤šå°‘ä¸ªitem</li><li><code>__get__</code> æ ¹æ®ç»™å®šçš„indexè¿”å›ä¸€ä¸ªitem</li></ul><p>æœ‰äº†dataloaderä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥è½»æ¾éšæœºæ‰“ä¹±æ•´ä¸ªæ•°æ®é›†ï¼Œæ‹¿åˆ°ä¸€ä¸ªbatchçš„æ•°æ®ç­‰ç­‰ã€‚</p><p>torch.utils.data.DataLoaderç†è§£ï¼š<a href="https://blog.csdn.net/qq_36653505/article/details/83351808" target="_blank" rel="noopener">https://blog.csdn.net/qq_36653505/article/details/83351808</a></p><p>In [10]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WordEmbeddingDataset</span><span class="params">(tud.Dataset)</span>:</span> <span class="comment">#tud.Datasetçˆ¶ç±»</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, text, word_to_idx, idx_to_word, word_freqs, word_counts)</span>:</span></span><br><span class="line">        <span class="string">''' text: a list of words, all text from the training dataset</span></span><br><span class="line"><span class="string">            word_to_idx: the dictionary from word to idx</span></span><br><span class="line"><span class="string">            idx_to_word: idx to word mapping</span></span><br><span class="line"><span class="string">            word_freq: the frequency of each word</span></span><br><span class="line"><span class="string">            word_counts: the word counts</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        super(WordEmbeddingDataset, self).__init__() <span class="comment">#åˆå§‹åŒ–æ¨¡å‹</span></span><br><span class="line">        self.text_encoded = [word_to_idx.get(t, VOCAB_SIZE<span class="number">-1</span>) <span class="keyword">for</span> t <span class="keyword">in</span> text]</span><br><span class="line">        <span class="comment">#å­—å…¸ get() å‡½æ•°è¿”å›æŒ‡å®šé”®çš„å€¼ï¼ˆç¬¬ä¸€ä¸ªå‚æ•°ï¼‰ï¼Œå¦‚æœå€¼ä¸åœ¨å­—å…¸ä¸­è¿”å›é»˜è®¤å€¼ï¼ˆç¬¬äºŒä¸ªå‚æ•°ï¼‰ã€‚</span></span><br><span class="line">        <span class="comment">#å–å‡ºtexté‡Œæ¯ä¸ªå•è¯word_to_idxå­—å…¸é‡Œå¯¹åº”çš„ç´¢å¼•,ä¸åœ¨å­—å…¸é‡Œè¿”å›"&lt;unk&gt;"çš„ç´¢å¼•=29999</span></span><br><span class="line">        <span class="comment"># è¿™æ ·texté‡Œçš„æ‰€æœ‰è¯éƒ½ç¼–ç å¥½äº†ï¼Œä»å•è¯è½¬åŒ–ä¸ºäº†å‘é‡ï¼Œ</span></span><br><span class="line">        <span class="comment"># å…±æœ‰15313011ä¸ªå•è¯ï¼Œè¯å‘é‡å–å€¼èŒƒå›´æ˜¯0ï½29999ï¼Œ0æ˜¯æœ€å¸¸è§å•è¯å‘é‡ã€‚</span></span><br><span class="line">        </span><br><span class="line">        self.text_encoded = torch.Tensor(self.text_encoded).long()</span><br><span class="line">        <span class="comment">#å˜æˆtensorç±»å‹ï¼Œè¿™é‡Œå˜æˆlongtensorï¼Œä¹Ÿå¯ä»¥torch.LongTensor(self.text_encoded)</span></span><br><span class="line">        </span><br><span class="line">        self.word_to_idx = word_to_idx <span class="comment">#ä¿å­˜æ•°æ®</span></span><br><span class="line">        self.idx_to_word = idx_to_word  <span class="comment">#ä¿å­˜æ•°æ®</span></span><br><span class="line">        self.word_freqs = torch.Tensor(word_freqs) <span class="comment">#ä¿å­˜æ•°æ®</span></span><br><span class="line">        self.word_counts = torch.Tensor(word_counts) <span class="comment">#ä¿å­˜æ•°æ®</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span> <span class="comment">#æ•°æ®é›†æœ‰å¤šå°‘ä¸ªitem </span></span><br><span class="line">        <span class="comment">#é­”æ³•å‡½æ•°__len__</span></span><br><span class="line">        <span class="string">''' è¿”å›æ•´ä¸ªæ•°æ®é›†ï¼ˆæ‰€æœ‰å•è¯ï¼‰çš„é•¿åº¦</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="keyword">return</span> len(self.text_encoded) <span class="comment">#æ‰€æœ‰å•è¯çš„æ€»æ•°</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, idx)</span>:</span></span><br><span class="line">        <span class="comment">#é­”æ³•å‡½æ•°__getitem__ï¼Œè¿™ä¸ªå‡½æ•°è·Ÿæ™®é€šå‡½æ•°ä¸ä¸€æ ·</span></span><br><span class="line">        <span class="string">''' è¿™ä¸ªfunctionè¿”å›ä»¥ä¸‹æ•°æ®ç”¨äºè®­ç»ƒ</span></span><br><span class="line"><span class="string">            - ä¸­å¿ƒè¯</span></span><br><span class="line"><span class="string">            - è¿™ä¸ªå•è¯é™„è¿‘çš„(positive)å•è¯</span></span><br><span class="line"><span class="string">            - éšæœºé‡‡æ ·çš„Kä¸ªå•è¯ä½œä¸ºnegative sample</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        center_word = self.text_encoded[idx] </span><br><span class="line">        <span class="comment">#ä¸­å¿ƒè¯</span></span><br><span class="line">        <span class="comment">#è¿™é‡Œ__getitem__å‡½æ•°æ˜¯ä¸ªè¿­ä»£å™¨ï¼Œidxä»£è¡¨äº†æ‰€æœ‰çš„å•è¯ç´¢å¼•ã€‚</span></span><br><span class="line">        </span><br><span class="line">        pos_indices = list(range(idx-C, idx)) + list(range(idx+<span class="number">1</span>, idx+C+<span class="number">1</span>))</span><br><span class="line">        <span class="comment">#å‘¨å›´è¯çš„ç´¢å¼•ï¼Œæ¯”å¦‚idx=0æ—¶ã€‚pos_indices = [-3, -2, -1, 1, 2, 3] </span></span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        pos_indices = [i%len(self.text_encoded) <span class="keyword">for</span> i <span class="keyword">in</span> pos_indices]</span><br><span class="line">        <span class="comment">#è¶…å‡ºè¯æ±‡æ€»æ•°æ—¶ï¼Œéœ€è¦ç‰¹åˆ«å¤„ç†ï¼Œå–ä½™æ•°ï¼Œæ¯”å¦‚pos_indices = [15313009,15313010,15313011,1,2,3]</span></span><br><span class="line">        </span><br><span class="line">        pos_words = self.text_encoded[pos_indices]</span><br><span class="line">        <span class="comment">#å‘¨å›´è¯ï¼Œå°±æ˜¯å¸Œæœ›å‡ºç°çš„æ­£ä¾‹å•è¯</span></span><br><span class="line">        </span><br><span class="line">        neg_words = torch.multinomial(self.word_freqs, K * pos_words.shape[<span class="number">0</span>], <span class="literal">True</span>)</span><br><span class="line">        <span class="comment">#è´Ÿä¾‹é‡‡æ ·å•è¯ï¼Œtorch.multinomialä½œç”¨æ˜¯æŒ‰ç…§self.word_freqsçš„æ¦‚ç‡åšK * pos_words.shape[0]æ¬¡å–å€¼ï¼Œ</span></span><br><span class="line">        <span class="comment">#è¾“å‡ºçš„æ˜¯self.word_freqså¯¹åº”çš„ä¸‹æ ‡ã€‚å–æ ·æ–¹å¼é‡‡ç”¨æœ‰æ”¾å›çš„é‡‡æ ·ï¼Œå¹¶ä¸”self.word_freqsæ•°å€¼è¶Šå¤§ï¼Œå–æ ·æ¦‚ç‡è¶Šå¤§ã€‚</span></span><br><span class="line">        <span class="comment">#æ¯ä¸ªæ­£ç¡®çš„å•è¯é‡‡æ ·Kä¸ªï¼Œpos_words.shape[0]æ˜¯æ­£ç¡®å•è¯æ•°é‡=6</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> center_word, pos_words, neg_words</span><br></pre></td></tr></table></figure><p>åˆ›å»ºdatasetå’Œdataloader</p><p>In [11]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataset = WordEmbeddingDataset(text, word_to_idx, idx_to_word, word_freqs, word_counts)</span><br><span class="line"># list(dataset) å¯ä»¥æŠŠå°è¯•æ‰“å°ä¸‹center_word, pos_words, neg_wordsçœ‹çœ‹</span><br></pre></td></tr></table></figure><p>torch.utils.data.DataLoaderç†è§£ï¼š<a href="https://blog.csdn.net/qq_36653505/article/details/83351808" target="_blank" rel="noopener">https://blog.csdn.net/qq_36653505/article/details/83351808</a></p><p>In [12]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataloader = tud.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=<span class="literal">True</span>, num_workers=<span class="number">4</span>)</span><br></pre></td></tr></table></figure><p>In [13]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(next(iter(dataloader))[<span class="number">0</span>].shape) <span class="comment"># ä¸€ä¸ªbatchä¸­é—´è¯ç»´åº¦</span></span><br><span class="line">print(next(iter(dataloader))[<span class="number">1</span>].shape) <span class="comment"># ä¸€ä¸ªbatchå‘¨å›´è¯ç»´åº¦</span></span><br><span class="line">print(next(iter(dataloader))[<span class="number">2</span>].shape) <span class="comment"># ä¸€ä¸ªbatchè´Ÿæ ·æœ¬ç»´åº¦</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([<span class="number">128</span>])</span><br><span class="line">torch.Size([<span class="number">128</span>, <span class="number">6</span>])</span><br><span class="line">torch.Size([<span class="number">128</span>, <span class="number">60</span>])</span><br></pre></td></tr></table></figure><h3 id="å®šä¹‰PyTorchæ¨¡å‹"><a href="#å®šä¹‰PyTorchæ¨¡å‹" class="headerlink" title="å®šä¹‰PyTorchæ¨¡å‹"></a>å®šä¹‰PyTorchæ¨¡å‹</h3><p>In [14]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EmbeddingModel</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, vocab_size, embed_size)</span>:</span></span><br><span class="line">        <span class="string">''' åˆå§‹åŒ–è¾“å‡ºå’Œè¾“å‡ºembedding</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        super(EmbeddingModel, self).__init__()</span><br><span class="line">        self.vocab_size = vocab_size  <span class="comment">#30000</span></span><br><span class="line">        self.embed_size = embed_size  <span class="comment">#100</span></span><br><span class="line">        </span><br><span class="line">        initrange = <span class="number">0.5</span> / self.embed_size</span><br><span class="line">        self.out_embed = nn.Embedding(self.vocab_size, self.embed_size, sparse=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment">#æ¨¡å‹è¾“å‡ºnn.Embedding(30000, 100)</span></span><br><span class="line">        self.out_embed.weight.data.uniform_(-initrange, initrange)</span><br><span class="line">        <span class="comment">#æƒé‡åˆå§‹åŒ–çš„ä¸€ç§æ–¹æ³•</span></span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        self.in_embed = nn.Embedding(self.vocab_size, self.embed_size, sparse=<span class="literal">False</span>)</span><br><span class="line">         <span class="comment">#æ¨¡å‹è¾“å…¥nn.Embedding(30000, 100)</span></span><br><span class="line">        self.in_embed.weight.data.uniform_(-initrange, initrange)</span><br><span class="line">        <span class="comment">#æƒé‡åˆå§‹åŒ–çš„ä¸€ç§æ–¹æ³•</span></span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, input_labels, pos_labels, neg_labels)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        input_labels: ä¸­å¿ƒè¯, [batch_size]</span></span><br><span class="line"><span class="string">        pos_labels: ä¸­å¿ƒè¯å‘¨å›´ context window å‡ºç°è¿‡çš„å•è¯ [batch_size * (window_size * 2)]</span></span><br><span class="line"><span class="string">        neg_labelss: ä¸­å¿ƒè¯å‘¨å›´æ²¡æœ‰å‡ºç°è¿‡çš„å•è¯ï¼Œä» negative sampling å¾—åˆ° [batch_size, (window_size * 2 * K)]</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        return: loss, [batch_size]</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        </span><br><span class="line">        batch_size = input_labels.size(<span class="number">0</span>)  <span class="comment">#input_labelsæ˜¯è¾“å…¥çš„æ ‡ç­¾ï¼Œtud.DataLoader()è¿”å›çš„ã€‚å·²ç»è¢«åˆ†æˆbatchäº†ã€‚</span></span><br><span class="line">        </span><br><span class="line">        input_embedding = self.in_embed(input_labels) </span><br><span class="line">        <span class="comment"># B * embed_size</span></span><br><span class="line">        <span class="comment">#è¿™é‡Œä¼°è®¡è¿›è¡Œäº†è¿ç®—ï¼šï¼ˆ128,30000ï¼‰*ï¼ˆ30000,100ï¼‰= 128(Batch) * 100 (embed_size)</span></span><br><span class="line">        </span><br><span class="line">        pos_embedding = self.out_embed(pos_labels) <span class="comment"># B * (2*C=6) * embed_size </span></span><br><span class="line">        <span class="comment"># è¿™é‡Œä¼°è®¡è¿›è¡Œäº†è¿ç®—ï¼šï¼ˆ128,6,30000ï¼‰*ï¼ˆ128,30000,100ï¼‰= 128(Batch) * 6 * 100 (embed_size)</span></span><br><span class="line">        <span class="comment">#åŒä¸Šï¼Œå¢åŠ äº†ç»´åº¦(2*C)ï¼Œè¡¨ç¤ºä¸€ä¸ªbatchæœ‰128ç»„å‘¨å›´è¯å•è¯ï¼Œä¸€ç»„å‘¨å›´è¯æœ‰(2*C)ä¸ªå•è¯ï¼Œæ¯ä¸ªå•è¯æœ‰embed_sizeä¸ªç»´åº¦ã€‚</span></span><br><span class="line">        </span><br><span class="line">        neg_embedding = self.out_embed(neg_labels) <span class="comment"># B * (2*C * K) * embed_size</span></span><br><span class="line">        <span class="comment">#åŒä¸Šï¼Œå¢åŠ äº†ç»´åº¦(2*C*K)</span></span><br><span class="line">      </span><br><span class="line">    </span><br><span class="line">        <span class="comment">#torch.bmm()ä¸ºbatché—´çš„çŸ©é˜µç›¸ä¹˜ï¼ˆb,n.m)*(b,m,p)=(b,n,p)</span></span><br><span class="line">        log_pos = torch.bmm(pos_embedding, input_embedding.unsqueeze(<span class="number">2</span>)).squeeze() <span class="comment"># B * (2*C)</span></span><br><span class="line">        <span class="comment"># log_pos = (128,6,100)*(128,100,1) = (128,6,1) = (128,6)</span></span><br><span class="line">        <span class="comment"># è¿™é‡Œå¦‚æœæ²¡æœ‰è´Ÿé‡‡æ ·ï¼Œåªæœ‰å‘¨å›´å•è¯æ¥è®­ç»ƒçš„è¯ï¼Œæ¯ä¸ªå‘¨å›´å•è¯30000ä¸ªone-hotå‘é‡çš„ç»´åº¦</span></span><br><span class="line">        <span class="comment"># è€Œè´Ÿé‡‡æ ·å¤§å¤§é™ä½äº†ç»´åº¦ï¼Œæ¯ä¸ªå‘¨å›´å•è¯ä»…ä»…åªæœ‰ä¸€ä¸ªç»´åº¦ã€‚æ¯ä¸ªæ ·æœ¬è¾“å‡ºå…±æœ‰2*Cä¸ªç»´åº¦</span></span><br><span class="line">        log_neg = torch.bmm(neg_embedding, -input_embedding.unsqueeze(<span class="number">2</span>)).squeeze() <span class="comment"># B * (2*C*K)</span></span><br><span class="line">        <span class="comment"># log_neg = (128,6*K,100)*(128,100,1) = (128,6*K,1) = (128,6*K)ï¼Œæ³¨æ„è¿™é‡Œæœ‰ä¸ªè´Ÿå·ï¼ŒåŒºåˆ«ä¸æ­£æ ·æœ¬</span></span><br><span class="line">        <span class="comment"># unsqueeze(2)æŒ‡å®šä½ç½®å‡ç»´ï¼Œ.squeeze()å‹ç¼©ç»´åº¦ã€‚</span></span><br><span class="line">        <span class="comment"># è€Œè´Ÿé‡‡æ ·é™ä½äº†ç»´åº¦ï¼Œæ¯ä¸ªè´Ÿä¾‹å•è¯ä»…ä»…åªæœ‰ä¸€ä¸ªç»´åº¦ï¼Œæ¯ä¸ªæ ·æœ¬è¾“å‡ºå…±æœ‰2*C*Kä¸ªç»´åº¦</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#ä¸‹é¢lossè®¡ç®—å°±æ˜¯è®ºæ–‡é‡Œçš„å…¬å¼</span></span><br><span class="line">        log_pos = F.logsigmoid(log_pos).sum(<span class="number">1</span>)</span><br><span class="line">        log_neg = F.logsigmoid(log_neg).sum(<span class="number">1</span>) <span class="comment"># batch_size     </span></span><br><span class="line">        loss = log_pos + log_neg <span class="comment"># æ­£æ ·æœ¬æŸå¤±å’Œè´Ÿæ ·æœ¬æŸå¤±å’Œå°½é‡æœ€å¤§</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> -loss <span class="comment"># æœ€å¤§è½¬åŒ–æˆæœ€å°</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#å–å‡ºself.in_embedæ•°æ®å‚æ•°ï¼Œç»´åº¦ï¼šï¼ˆ30000,100ï¼‰ï¼Œå°±æ˜¯æˆ‘ä»¬è¦è®­ç»ƒçš„è¯å‘é‡</span></span><br><span class="line">    <span class="comment"># è¿™é‡Œæœ¬æ¥æ¨¡å‹è®­ç»ƒæœ‰ä¸¤ä¸ªçŸ©é˜µçš„ï¼Œself.in_embedå’Œself.out_embedä¸¤ä¸ª</span></span><br><span class="line">    <span class="comment"># åªæ˜¯ä½œè€…è®¤ä¸ºè¾“å…¥çŸ©é˜µæ¯”è¾ƒå¥½ï¼Œå°±èˆå¼ƒäº†è¾“å‡ºçŸ©é˜µã€‚</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">input_embeddings</span><span class="params">(self)</span>:</span>   </span><br><span class="line">        <span class="keyword">return</span> self.in_embed.weight.data.cpu().numpy()</span><br></pre></td></tr></table></figure><p>å®šä¹‰ä¸€ä¸ªæ¨¡å‹ä»¥åŠæŠŠæ¨¡å‹ç§»åŠ¨åˆ°GPU</p><p>In [15]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model = EmbeddingModel(VOCAB_SIZE, EMBEDDING_SIZE)</span><br><span class="line"><span class="comment">#å¾—åˆ°modelï¼Œæœ‰å‚æ•°ï¼Œæœ‰lossï¼Œå¯ä»¥ä¼˜åŒ–äº†</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> USE_CUDA:</span><br><span class="line">    model = model.cuda()</span><br></pre></td></tr></table></figure><p>In [28]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.iloc[:, <span class="number">0</span>:<span class="number">2</span>].index</span><br></pre></td></tr></table></figure><p>Out[28]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RangeIndex(start=<span class="number">0</span>, stop=<span class="number">353</span>, step=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">"wordsim353.csv"</span>, sep=<span class="string">","</span>)</span><br><span class="line"><span class="comment"># else:</span></span><br><span class="line"><span class="comment">#     data = pd.read_csv("simlex-999.txt", sep="\t")</span></span><br><span class="line">print(data.head())</span><br><span class="line">human_similarity = []</span><br><span class="line">model_similarity = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> data.iloc[:, <span class="number">0</span>:<span class="number">2</span>].index:</span><br><span class="line">    print(i)</span><br></pre></td></tr></table></figure><p>ä¸‹é¢æ˜¯è¯„ä¼°æ¨¡å‹çš„ä»£ç ï¼Œä»¥åŠè®­ç»ƒæ¨¡å‹çš„ä»£ç </p><p>In [16]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">(filename, embedding_weights)</span>:</span> </span><br><span class="line">    <span class="comment"># ä¼ å…¥çš„æœ‰ä¸‰ä¸ªæ–‡ä»¶è¯¾é€‰æ‹©,ä¸¤ä¸ªtxtï¼Œä¸€ä¸ªcsvï¼Œå¯ä»¥å…ˆè‡ªå·±æ‰“å¼€çœ‹çœ‹</span></span><br><span class="line">    <span class="comment"># embedding_weightsæ˜¯è®­ç»ƒä¹‹åçš„embeddingå‘é‡ã€‚</span></span><br><span class="line">    <span class="keyword">if</span> filename.endswith(<span class="string">".csv"</span>):</span><br><span class="line">        data = pd.read_csv(filename, sep=<span class="string">","</span>) <span class="comment"># csvæ–‡ä»¶æ‰“å¼€</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        data = pd.read_csv(filename, sep=<span class="string">"\t"</span>) <span class="comment"># txtæ–‡ä»¶æ‰“å¼€ï¼Œä»¥\tåˆ¶è¡¨ç¬¦åˆ†å‰²</span></span><br><span class="line">    human_similarity = []</span><br><span class="line">    model_similarity = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> data.iloc[:, <span class="number">0</span>:<span class="number">2</span>].index: <span class="comment"># è¿™é‡Œåªæ˜¯å–å‡ºè¡Œç´¢å¼•ï¼Œç”¨data.indexä¹Ÿå¯ä»¥</span></span><br><span class="line">        word1, word2 = data.iloc[i, <span class="number">0</span>], data.iloc[i, <span class="number">1</span>] <span class="comment"># ä¾æ¬¡å–å‡ºæ¯è¡Œçš„2ä¸ªå•è¯</span></span><br><span class="line">        <span class="keyword">if</span> word1 <span class="keyword">not</span> <span class="keyword">in</span> word_to_idx <span class="keyword">or</span> word2 <span class="keyword">not</span> <span class="keyword">in</span> word_to_idx:</span><br><span class="line">            <span class="comment"># å¦‚æœå–å‡ºçš„å•è¯ä¸åœ¨æˆ‘ä»¬å»ºçš„30000ä¸‡ä¸ªè¯æ±‡è¡¨ï¼Œå°±èˆå¼ƒï¼Œè¯„ä¼°ä¸äº†</span></span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            word1_idx, word2_idx = word_to_idx[word1], word_to_idx[word2]</span><br><span class="line">            <span class="comment"># å¦åˆ™ï¼Œåˆ†åˆ«å–å‡ºè¿™ä¸¤ä¸ªå•è¯å¯¹åº”çš„å‘é‡ï¼Œ</span></span><br><span class="line">            word1_embed, word2_embed = embedding_weights[[word1_idx]], embedding_weights[[word2_idx]]</span><br><span class="line">            <span class="comment"># åœ¨åˆ†åˆ«å–å‡ºè¿™ä¸¤ä¸ªå•è¯å¯¹åº”çš„embeddingå‘é‡ï¼Œå…·ä½“ä¸ºå•¥æ˜¯è¿™ç§å–å‡ºæ–¹å¼[[word1_idx]]ï¼Œå¯ä»¥è‡ªè¡Œç ”ç©¶</span></span><br><span class="line">            model_similarity.append(float(sklearn.metrics.pairwise.cosine_similarity(word1_embed, word2_embed)))</span><br><span class="line">            <span class="comment"># ç”¨ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—è¿™ä¸¤ä¸ª100ç»´å‘é‡çš„ç›¸ä¼¼åº¦ã€‚è¿™ä¸ªæ˜¯æ¨¡å‹ç®—å‡ºæ¥çš„ç›¸ä¼¼åº¦</span></span><br><span class="line">            human_similarity.append(float(data.iloc[i, <span class="number">2</span>]))</span><br><span class="line">            <span class="comment"># è¿™ä¸ªæ˜¯äººç±»ç»Ÿè®¡å¾—åˆ°çš„ç›¸ä¼¼åº¦</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> scipy.stats.spearmanr(human_similarity, model_similarity)<span class="comment"># , model_similarity</span></span><br><span class="line">    <span class="comment"># å› ä¸ºç›¸ä¼¼åº¦æ˜¯æµ®ç‚¹æ•°ï¼Œä¸æ˜¯0 1 è¿™äº›å›ºå®šæ ‡ç­¾å€¼ï¼Œæ‰€ä»¥ä¸èƒ½ç”¨å‡†ç¡®åº¦è¯„ä¼°æŒ‡æ ‡</span></span><br><span class="line">    <span class="comment"># scipy.stats.spearmanrç½‘å€ï¼šhttps://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html</span></span><br><span class="line">    <span class="comment"># scipy.stats.spearmanrè¯„ä¼°ä¸¤ä¸ªåˆ†å¸ƒçš„ç›¸ä¼¼åº¦ï¼Œæœ‰ä¸¤ä¸ªè¿”å›å€¼correlation, pvalue</span></span><br><span class="line">    <span class="comment"># correlationæ˜¯è¯„ä¼°ç›¸å…³æ€§çš„æŒ‡æ ‡ï¼ˆ-1ï¼Œ1ï¼‰ï¼Œè¶Šæ¥è¿‘1è¶Šç›¸å…³ï¼Œpvalueå€¼å¤§å®¶å¯ä»¥è‡ªå·±æœç´¢ç†è§£</span></span><br></pre></td></tr></table></figure><p>è®­ç»ƒæ¨¡å‹ï¼š</p><ul><li>æ¨¡å‹ä¸€èˆ¬éœ€è¦è®­ç»ƒè‹¥å¹²ä¸ªepoch</li><li>æ¯ä¸ªepochæˆ‘ä»¬éƒ½æŠŠæ‰€æœ‰çš„æ•°æ®åˆ†æˆè‹¥å¹²ä¸ªbatch</li><li>æŠŠæ¯ä¸ªbatchçš„è¾“å…¥å’Œè¾“å‡ºéƒ½åŒ…è£…æˆcuda tensor</li><li>forward passï¼Œé€šè¿‡è¾“å…¥çš„å¥å­é¢„æµ‹æ¯ä¸ªå•è¯çš„ä¸‹ä¸€ä¸ªå•è¯</li><li>ç”¨æ¨¡å‹çš„é¢„æµ‹å’Œæ­£ç¡®çš„ä¸‹ä¸€ä¸ªå•è¯è®¡ç®—cross entropy loss</li><li>æ¸…ç©ºæ¨¡å‹å½“å‰gradient</li><li>backward pass</li><li>æ›´æ–°æ¨¡å‹å‚æ•°</li><li>æ¯éš”ä¸€å®šçš„iterationè¾“å‡ºæ¨¡å‹åœ¨å½“å‰iterationçš„lossï¼Œä»¥åŠåœ¨éªŒè¯æ•°æ®é›†ä¸Šåšæ¨¡å‹çš„è¯„ä¼°</li></ul><p>In [17]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i, (input_labels, pos_labels, neg_labels) <span class="keyword">in</span> enumerate(dataloader):</span><br><span class="line">        print(input_labels.shape, pos_labels.shape, neg_labels.shape)</span><br><span class="line">        <span class="keyword">if</span> i&gt;<span class="number">5</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([<span class="number">128</span>]) torch.Size([<span class="number">128</span>, <span class="number">6</span>]) torch.Size([<span class="number">128</span>, <span class="number">60</span>])</span><br><span class="line">torch.Size([<span class="number">128</span>]) torch.Size([<span class="number">128</span>, <span class="number">6</span>]) torch.Size([<span class="number">128</span>, <span class="number">60</span>])</span><br><span class="line">torch.Size([<span class="number">128</span>]) torch.Size([<span class="number">128</span>, <span class="number">6</span>]) torch.Size([<span class="number">128</span>, <span class="number">60</span>])</span><br><span class="line">torch.Size([<span class="number">128</span>]) torch.Size([<span class="number">128</span>, <span class="number">6</span>]) torch.Size([<span class="number">128</span>, <span class="number">60</span>])</span><br><span class="line">torch.Size([<span class="number">128</span>]) torch.Size([<span class="number">128</span>, <span class="number">6</span>]) torch.Size([<span class="number">128</span>, <span class="number">60</span>])</span><br><span class="line">torch.Size([<span class="number">128</span>]) torch.Size([<span class="number">128</span>, <span class="number">6</span>]) torch.Size([<span class="number">128</span>, <span class="number">60</span>])</span><br><span class="line">torch.Size([<span class="number">128</span>]) torch.Size([<span class="number">128</span>, <span class="number">6</span>]) torch.Size([<span class="number">128</span>, <span class="number">60</span>])</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)</span><br><span class="line"><span class="comment">#éšæœºæ¢¯åº¦ä¸‹é™</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> range(NUM_EPOCHS): <span class="comment">#å¼€å§‹è¿­ä»£</span></span><br><span class="line">    <span class="keyword">for</span> i, (input_labels, pos_labels, neg_labels) <span class="keyword">in</span> enumerate(dataloader):</span><br><span class="line">        <span class="comment">#print(input_labels, pos_labels, neg_labels)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># TODO</span></span><br><span class="line">        input_labels = input_labels.long() <span class="comment">#longtensor</span></span><br><span class="line">        pos_labels = pos_labels.long()</span><br><span class="line">        neg_labels = neg_labels.long()</span><br><span class="line">        <span class="keyword">if</span> USE_CUDA: <span class="comment"># å˜æˆcudaç±»å‹</span></span><br><span class="line">            input_labels = input_labels.cuda()</span><br><span class="line">            pos_labels = pos_labels.cuda()</span><br><span class="line">            neg_labels = neg_labels.cuda()</span><br><span class="line">       </span><br><span class="line">        <span class="comment">#ä¸‹é¢ç¬¬ä¸€èŠ‚è¯¾éƒ½è®²è¿‡çš„   </span></span><br><span class="line">        optimizer.zero_grad() <span class="comment">#æ¢¯åº¦å½’é›¶</span></span><br><span class="line">        loss = model(input_labels, pos_labels, neg_labels).mean() </span><br><span class="line">        <span class="comment"># modelè¿”å›çš„æ˜¯ä¸€ä¸ªbatchæ‰€æœ‰æ ·æœ¬çš„æŸå¤±ï¼Œéœ€è¦æ±‚ä¸ªå¹³å‡</span></span><br><span class="line">        </span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">       </span><br><span class="line">        <span class="comment">#æ‰“å°ç»“æœã€‚</span></span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">with</span> open(LOG_FILE, <span class="string">"a"</span>) <span class="keyword">as</span> fout: <span class="comment"># å†™è¿›æ—¥å¿—æ–‡ä»¶ï¼ŒLOG_FILEå‰é¢å®šä¹‰äº†</span></span><br><span class="line">                fout.write(<span class="string">"epoch: &#123;&#125;, iter: &#123;&#125;, loss: &#123;&#125;\n"</span>.format(e, i, loss.item()))</span><br><span class="line">                print(<span class="string">"epoch: &#123;&#125;, iter: &#123;&#125;, loss: &#123;&#125;"</span>.format(e, i, loss.item()))</span><br><span class="line">                <span class="comment"># è®­ç»ƒè¿‡ç¨‹ï¼Œæˆ‘æ²¡è·‘ï¼Œæœ¬åœ°è‚¯å®šè·‘ä¸åŠ¨çš„</span></span><br><span class="line">            </span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">2000</span> == <span class="number">0</span>: <span class="comment"># æ¯è¿‡2000ä¸ªbatchå°±è¯„ä¼°ä¸€æ¬¡æ•ˆæœ</span></span><br><span class="line">            embedding_weights = model.input_embeddings() </span><br><span class="line">            <span class="comment"># å–å‡ºï¼ˆ30000ï¼Œ100ï¼‰è®­ç»ƒçš„è¯å‘é‡</span></span><br><span class="line">            sim_simlex = evaluate(<span class="string">"simlex-999.txt"</span>, embedding_weights)</span><br><span class="line">            sim_men = evaluate(<span class="string">"men.txt"</span>, embedding_weights)</span><br><span class="line">            sim_353 = evaluate(<span class="string">"wordsim353.csv"</span>, embedding_weights)</span><br><span class="line">            <span class="keyword">with</span> open(LOG_FILE, <span class="string">"a"</span>) <span class="keyword">as</span> fout:</span><br><span class="line">                print(<span class="string">"epoch: &#123;&#125;, iteration: &#123;&#125;, simlex-999: &#123;&#125;, men: &#123;&#125;, sim353: &#123;&#125;, nearest to monster: &#123;&#125;\n"</span>.format(</span><br><span class="line">                    e, i, sim_simlex, sim_men, sim_353, find_nearest(<span class="string">"monster"</span>)))</span><br><span class="line">                fout.write(<span class="string">"epoch: &#123;&#125;, iteration: &#123;&#125;, simlex-999: &#123;&#125;, men: &#123;&#125;, sim353: &#123;&#125;, nearest to monster: &#123;&#125;\n"</span>.format(</span><br><span class="line">                    e, i, sim_simlex, sim_men, sim_353, find_nearest(<span class="string">"monster"</span>)))</span><br><span class="line">                </span><br><span class="line">    embedding_weights = model.input_embeddings() <span class="comment"># è°ƒç”¨æœ€ç»ˆè®­ç»ƒå¥½çš„embedingè¯å‘é‡</span></span><br><span class="line">    np.save(<span class="string">"embedding-&#123;&#125;"</span>.format(EMBEDDING_SIZE), embedding_weights) <span class="comment"># ä¿å­˜å‚æ•°</span></span><br><span class="line">    torch.save(model.state_dict(), <span class="string">"embedding-&#123;&#125;.th"</span>.format(EMBEDDING_SIZE)) <span class="comment"># ä¿å­˜å‚æ•°</span></span><br></pre></td></tr></table></figure><p>In [11]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.load_state_dict(torch.load(<span class="string">"embedding-&#123;&#125;.th"</span>.format(EMBEDDING_SIZE))) <span class="comment"># åŠ è½½æ¨¡å‹</span></span><br></pre></td></tr></table></figure><h2 id="åœ¨-MEN-å’Œ-Simplex-999-æ•°æ®é›†ä¸Šåšè¯„ä¼°"><a href="#åœ¨-MEN-å’Œ-Simplex-999-æ•°æ®é›†ä¸Šåšè¯„ä¼°" class="headerlink" title="åœ¨ MEN å’Œ Simplex-999 æ•°æ®é›†ä¸Šåšè¯„ä¼°"></a>åœ¨ MEN å’Œ Simplex-999 æ•°æ®é›†ä¸Šåšè¯„ä¼°</h2><p>In [12]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ä»£ç åŒä¸Š</span></span><br><span class="line">embedding_weights = model.input_embeddings()</span><br><span class="line">print(<span class="string">"simlex-999"</span>, evaluate(<span class="string">"simlex-999.txt"</span>, embedding_weights))</span><br><span class="line">print(<span class="string">"men"</span>, evaluate(<span class="string">"men.txt"</span>, embedding_weights))</span><br><span class="line">print(<span class="string">"wordsim353"</span>, evaluate(<span class="string">"wordsim353.csv"</span>, embedding_weights))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">simlex<span class="number">-999</span> SpearmanrResult(correlation=<span class="number">0.17251697429101504</span>, pvalue=<span class="number">7.863946056740345e-08</span>)</span><br><span class="line">men SpearmanrResult(correlation=<span class="number">0.1778096817088841</span>, pvalue=<span class="number">7.565661657312768e-20</span>)</span><br><span class="line">wordsim353 SpearmanrResult(correlation=<span class="number">0.27153702278146635</span>, pvalue=<span class="number">8.842165885381714e-07</span>)</span><br></pre></td></tr></table></figure><h2 id="å¯»æ‰¾nearest-neighbors"><a href="#å¯»æ‰¾nearest-neighbors" class="headerlink" title="å¯»æ‰¾nearest neighbors"></a>å¯»æ‰¾nearest neighbors</h2><p>In [13]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_nearest</span><span class="params">(word)</span>:</span></span><br><span class="line">    index = word_to_idx[word] </span><br><span class="line">    embedding = embedding_weights[index] <span class="comment"># å–å‡ºè¿™ä¸ªå•è¯çš„embeddingå‘é‡</span></span><br><span class="line">    cos_dis = np.array([scipy.spatial.distance.cosine(e, embedding) <span class="keyword">for</span> e <span class="keyword">in</span> embedding_weights])</span><br><span class="line">    <span class="comment"># è®¡ç®—æ‰€æœ‰30000ä¸ªembeddingå‘é‡ä¸ä¼ å…¥å•è¯embeddingå‘é‡çš„ç›¸ä¼¼åº¦è·ç¦»</span></span><br><span class="line">    <span class="keyword">return</span> [idx_to_word[i] <span class="keyword">for</span> i <span class="keyword">in</span> cos_dis.argsort()[:<span class="number">10</span>]] <span class="comment"># è¿”å›å‰10ä¸ªæœ€ç›¸ä¼¼çš„</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> word <span class="keyword">in</span> [<span class="string">"good"</span>, <span class="string">"fresh"</span>, <span class="string">"monster"</span>, <span class="string">"green"</span>, <span class="string">"like"</span>, <span class="string">"america"</span>, <span class="string">"chicago"</span>, <span class="string">"work"</span>, <span class="string">"computer"</span>, <span class="string">"language"</span>]:</span><br><span class="line">    print(word, find_nearest(word))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">good [&apos;good&apos;, &apos;bad&apos;, &apos;perfect&apos;, &apos;hard&apos;, &apos;questions&apos;, &apos;alone&apos;, &apos;money&apos;, &apos;false&apos;, &apos;truth&apos;, &apos;experience&apos;]</span><br><span class="line">fresh [&apos;fresh&apos;, &apos;grain&apos;, &apos;waste&apos;, &apos;cooling&apos;, &apos;lighter&apos;, &apos;dense&apos;, &apos;mild&apos;, &apos;sized&apos;, &apos;warm&apos;, &apos;steel&apos;]</span><br><span class="line">monster [&apos;monster&apos;, &apos;giant&apos;, &apos;robot&apos;, &apos;hammer&apos;, &apos;clown&apos;, &apos;bull&apos;, &apos;demon&apos;, &apos;triangle&apos;, &apos;storyline&apos;, &apos;slogan&apos;]</span><br><span class="line">green [&apos;green&apos;, &apos;blue&apos;, &apos;yellow&apos;, &apos;white&apos;, &apos;cross&apos;, &apos;orange&apos;, &apos;black&apos;, &apos;red&apos;, &apos;mountain&apos;, &apos;gold&apos;]</span><br><span class="line">like [&apos;like&apos;, &apos;unlike&apos;, &apos;etc&apos;, &apos;whereas&apos;, &apos;animals&apos;, &apos;soft&apos;, &apos;amongst&apos;, &apos;similarly&apos;, &apos;bear&apos;, &apos;drink&apos;]</span><br><span class="line">america [&apos;america&apos;, &apos;africa&apos;, &apos;korea&apos;, &apos;india&apos;, &apos;australia&apos;, &apos;turkey&apos;, &apos;pakistan&apos;, &apos;mexico&apos;, &apos;argentina&apos;, &apos;carolina&apos;]</span><br><span class="line">chicago [&apos;chicago&apos;, &apos;boston&apos;, &apos;illinois&apos;, &apos;texas&apos;, &apos;london&apos;, &apos;indiana&apos;, &apos;massachusetts&apos;, &apos;florida&apos;, &apos;berkeley&apos;, &apos;michigan&apos;]</span><br><span class="line">work [&apos;work&apos;, &apos;writing&apos;, &apos;job&apos;, &apos;marx&apos;, &apos;solo&apos;, &apos;label&apos;, &apos;recording&apos;, &apos;nietzsche&apos;, &apos;appearance&apos;, &apos;stage&apos;]</span><br><span class="line">computer [&apos;computer&apos;, &apos;digital&apos;, &apos;electronic&apos;, &apos;audio&apos;, &apos;video&apos;, &apos;graphics&apos;, &apos;hardware&apos;, &apos;software&apos;, &apos;computers&apos;, &apos;program&apos;]</span><br><span class="line">language [&apos;language&apos;, &apos;languages&apos;, &apos;alphabet&apos;, &apos;arabic&apos;, &apos;grammar&apos;, &apos;pronunciation&apos;, &apos;dialect&apos;, &apos;programming&apos;, &apos;chinese&apos;, &apos;spelling&apos;]</span><br></pre></td></tr></table></figure><h2 id="å•è¯ä¹‹é—´çš„å…³ç³»"><a href="#å•è¯ä¹‹é—´çš„å…³ç³»" class="headerlink" title="å•è¯ä¹‹é—´çš„å…³ç³»"></a>å•è¯ä¹‹é—´çš„å…³ç³»</h2><p>In [14]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">man_idx = word_to_idx[<span class="string">"man"</span>] </span><br><span class="line">king_idx = word_to_idx[<span class="string">"king"</span>] </span><br><span class="line">woman_idx = word_to_idx[<span class="string">"woman"</span>]</span><br><span class="line">embedding = embedding_weights[woman_idx] - embedding_weights[man_idx] + embedding_weights[king_idx]</span><br><span class="line">cos_dis = np.array([scipy.spatial.distance.cosine(e, embedding) <span class="keyword">for</span> e <span class="keyword">in</span> embedding_weights])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> cos_dis.argsort()[:<span class="number">20</span>]:</span><br><span class="line">    print(idx_to_word[i])</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">king</span><br><span class="line">henry</span><br><span class="line">charles</span><br><span class="line">pope</span><br><span class="line">queen</span><br><span class="line">iii</span><br><span class="line">prince</span><br><span class="line">elizabeth</span><br><span class="line">alexander</span><br><span class="line">constantine</span><br><span class="line">edward</span><br><span class="line">son</span><br><span class="line">iv</span><br><span class="line">louis</span><br><span class="line">emperor</span><br><span class="line">mary</span><br><span class="line">james</span><br><span class="line">joseph</span><br><span class="line">frederick</span><br><span class="line">francis</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> word-embedding </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>é…’åº—è¯„ä»·æƒ…æ„Ÿåˆ†ç±»ä¸CNNæ¨¡å‹</title>
      <link href="/2020/02/08/%E9%85%92%E5%BA%97%E8%AF%84%E4%BB%B7%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB%E4%B8%8ECNN%E6%A8%A1%E5%9E%8B/"/>
      <url>/2020/02/08/%E9%85%92%E5%BA%97%E8%AF%84%E4%BB%B7%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB%E4%B8%8ECNN%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h4 id="é…’åº—è¯„ä»·æƒ…æ„Ÿåˆ†ç±»ä¸CNNæ¨¡å‹"><a href="#é…’åº—è¯„ä»·æƒ…æ„Ÿåˆ†ç±»ä¸CNNæ¨¡å‹" class="headerlink" title="é…’åº—è¯„ä»·æƒ…æ„Ÿåˆ†ç±»ä¸CNNæ¨¡å‹"></a>é…’åº—è¯„ä»·æƒ…æ„Ÿåˆ†ç±»ä¸CNNæ¨¡å‹</h4><p>å‚è€ƒäº†<a href="https://github.com/bentrevett/pytorch-sentiment-analysis" target="_blank" rel="noopener">https://github.com/bentrevett/pytorch-sentiment-analysis</a></p><p>æˆ‘ä»¬ä¼šç”¨PyTorchæ¨¡å‹æ¥åšæƒ…æ„Ÿåˆ†æ(æ£€æµ‹ä¸€æ®µæ–‡å­—çš„æƒ…æ„Ÿæ˜¯æ­£é¢çš„è¿˜æ˜¯è´Ÿé¢çš„)ã€‚æˆ‘ä»¬ä¼šä½¿ç”¨<a href="https://github.com/SophonPlus/ChineseNlpCorpus/blob/master/datasets/ChnSentiCorp_htl_all/intro.ipynb" target="_blank" rel="noopener">ChnSentiCorp_htl</a>æ•°æ®é›†ï¼Œå³é…’åº—è¯„è®ºæ•°æ®é›†ã€‚</p><p>æ•°æ®ä¸‹è½½é“¾æ¥ï¼š<a href="https://raw.githubusercontent.com/SophonPlus/ChineseNlpCorpus/master/datasets/ChnSentiCorp_htl_all/ChnSentiCorp_htl_all.csv" target="_blank" rel="noopener">https://raw.githubusercontent.com/SophonPlus/ChineseNlpCorpus/master/datasets/ChnSentiCorp_htl_all/ChnSentiCorp_htl_all.csv</a></p><p>æ¨¡å‹ä»ç®€å•åˆ°å¤æ‚ï¼Œæˆ‘ä»¬ä¼šä¾æ¬¡æ„å»ºï¼š</p><ul><li>Word Averagingæ¨¡å‹</li><li>RNN/LSTMæ¨¡å‹</li><li>CNNæ¨¡å‹</li></ul><h2 id="å‡†å¤‡æ•°æ®"><a href="#å‡†å¤‡æ•°æ®" class="headerlink" title="å‡†å¤‡æ•°æ®"></a>å‡†å¤‡æ•°æ®</h2><ul><li>é¦–å…ˆè®©æˆ‘ä»¬åŠ è½½æ•°æ®ï¼Œæ¥çœ‹çœ‹è¿™ä¸€æ‰¹é…’åº—è¯„ä»·æ•°æ®é•¿å¾—æ€æ ·</li></ul><p>In [1]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">path = &quot;ChnSentiCorp_htl_all.csv&quot;</span><br><span class="line">pd_all = pd.read_csv(path)</span><br><span class="line"></span><br><span class="line">print(&apos;è¯„è®ºæ•°ç›®ï¼ˆæ€»ä½“ï¼‰ï¼š%d&apos; % pd_all.shape[0])</span><br><span class="line">print(&apos;è¯„è®ºæ•°ç›®ï¼ˆæ­£å‘ï¼‰ï¼š%d&apos; % pd_all[pd_all.label==1].shape[0])</span><br><span class="line">print(&apos;è¯„è®ºæ•°ç›®ï¼ˆè´Ÿå‘ï¼‰ï¼š%d&apos; % pd_all[pd_all.label==0].shape[0])</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">è¯„è®ºæ•°ç›®ï¼ˆæ€»ä½“ï¼‰ï¼š7766</span><br><span class="line">è¯„è®ºæ•°ç›®ï¼ˆæ­£å‘ï¼‰ï¼š5322</span><br><span class="line">è¯„è®ºæ•°ç›®ï¼ˆè´Ÿå‘ï¼‰ï¼š2444</span><br></pre></td></tr></table></figure><p>In [2]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd_all.sample(5)</span><br></pre></td></tr></table></figure><p>Out[2]:</p><table><thead><tr><th align="right"></th><th align="right">label</th><th align="right">review</th></tr></thead><tbody><tr><td align="right">914</td><td align="right">1</td><td align="right">åœ°ç‚¹çœ‹ä¸Šå»ä¸é”™ï¼Œåœ¨åŒ—äº¬è¥¿å®¢ç«™å¯¹é¢ï¼Œä½†å‡ºè¡Œååˆ†ä¸ä¾¿ï¼Œå‘¨è¾¹æ²¡æœ‰åœ°é“ï¼Œé—¨å£å‡ºç§Ÿè½¦å€’æ˜¯æŒºå¤šï¼Œä½†å°±æ˜¯ä¸â€¦</td></tr><tr><td align="right">7655</td><td align="right">0</td><td align="right">é…’åº—ä½ç½®è¾ƒååƒ»ï¼Œç¯å¢ƒæ¸…å‡€ï¼Œäº¤é€šä¹Ÿæ–¹ä¾¿ï¼Œä½†é…’åº—åŠå‘¨è¾¹å°±é¤é€‰æ‹©ä¸å¤š;æµ´åœºæµ·æ°´ä¸­æœ‰æ°´è‰,æ°´äº¦å¤ªæµ…,â€¦</td></tr><tr><td align="right">3424</td><td align="right">1</td><td align="right">é…’åº—ç»™äººæ„Ÿè§‰å¾ˆæ¸©æ¬£,æœåŠ¡å‘˜ä¹ŸæŒºæœ‰ç¤¼è²Œ,æˆ¿é—´å†…çš„èˆ’é€‚åº¦ä¹Ÿéå¸¸ä¸é”™,ç¦»å¼€æå…¬é€’ä¹Ÿå¾ˆè¿‘,ä¸‹æ¬¡æ¥è‹å·â€¦</td></tr><tr><td align="right">4854</td><td align="right">1</td><td align="right">ç¦»æ•…å®«ä¸å¤ªè¿œï¼Œèµ°è·¯å¤§æ¦‚10åˆ†é’Ÿä¸åˆ°ç‚¹ï¼Œç¯å¢ƒè¿˜å¥½ï¼Œæœ‰ä¸€ç‚¹éå¸¸ä¸å¥½çš„æ˜¯çª—å¸˜å°±åªæœ‰ä¸€å±‚ï¼Œæ—©ä¸Šå¾ˆæ—©å°±â€¦</td></tr><tr><td align="right">5852</td><td align="right">0</td><td align="right">å®¾é¦†èƒŒé¢å°±æ˜¯çœé“,äº¤é€šæ˜¯æ–¹ä¾¿çš„,åœè½¦åœºå¾ˆå¤§ä¹Ÿå¾ˆæ–¹ä¾¿,ä½†æ™šä¸Šå°¤å…¶åŠå¤œè·¯è¿‡çš„æ±½è½¦å£°éŸ³å¾ˆå“,æ‹–æ‹‰æœºâ€¦</td></tr></tbody></table><p>In [3]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import pkuseg</span><br><span class="line"></span><br><span class="line">seg = pkuseg.pkuseg()           # ä»¥é»˜è®¤é…ç½®åŠ è½½æ¨¡å‹</span><br><span class="line">text = seg.cut(&apos;æˆ‘çˆ±åŒ—äº¬å¤©å®‰é—¨&apos;)  # è¿›è¡Œåˆ†è¯</span><br><span class="line">print(text)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&apos;æˆ‘&apos;, &apos;çˆ±&apos;, &apos;åŒ—äº¬&apos;, &apos;å¤©å®‰é—¨&apos;]</span><br></pre></td></tr></table></figure><p>ä¸‹é¢æˆ‘ä»¬å…ˆæ‰‹å·¥æŠŠæ•°æ®åˆ†æˆtrain, dev, testä¸‰ä¸ªéƒ¨åˆ†</p><p>In [4]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">pd_all_shuf = pd_all.sample(frac=1)</span><br><span class="line"></span><br><span class="line"># æ€»å…±æœ‰å¤šå°‘ins</span><br><span class="line">total_num_ins = pd_all_shuf.shape[0]</span><br><span class="line">pd_train = pd_all_shuf.iloc[:int(total_num_ins*0.8)]</span><br><span class="line">pd_dev = pd_all_shuf.iloc[int(total_num_ins*0.8):int(total_num_ins*0.9)]</span><br><span class="line">pd_test = pd_all_shuf.iloc[int(total_num_ins*0.9):]</span><br><span class="line"></span><br><span class="line"># text, label</span><br><span class="line">train_text = [seg.cut(str(text)) for text in pd_train.review.tolist()]</span><br><span class="line">dev_text = [seg.cut(str(text)) for text in pd_dev.review.tolist()]</span><br><span class="line">test_text = [seg.cut(str(text)) for text in pd_test.review.tolist()]</span><br><span class="line">train_label = pd_train.label.tolist()</span><br><span class="line">dev_label = pd_dev.label.tolist()</span><br><span class="line">test_label = pd_test.label.tolist()</span><br></pre></td></tr></table></figure><p>In [6]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_label[0]</span><br></pre></td></tr></table></figure><p>Out[6]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0</span><br></pre></td></tr></table></figure><p>æˆ‘ä»¬ä»è®­ç»ƒæ•°æ®æ„é€ å‡ºä¸€ä¸ªç”±å•è¯åˆ°indexçš„å•è¯è¡¨</p><p>In [7]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">from collections import Counter</span><br><span class="line">def build_vocab(sents, max_words=50000):</span><br><span class="line">    word_counts = Counter()</span><br><span class="line">    for sent in sents:</span><br><span class="line">        for word in sent:</span><br><span class="line">            word_counts[word] += 1</span><br><span class="line">    itos = [w for w, c in word_counts.most_common(max_words)]</span><br><span class="line">    itos = [&quot;UNK&quot;, &quot;PAD&quot;] + itos</span><br><span class="line">    stoi = &#123;w:i for i, w in enumerate(itos)&#125;</span><br><span class="line">    return itos, stoi</span><br><span class="line"></span><br><span class="line">itos, stoi = build_vocab(train_text)</span><br></pre></td></tr></table></figure><p>æŸ¥çœ‹ä¸€ä¸‹æ¯”è¾ƒé«˜é¢‘çš„å•è¯</p><p>In [8]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">itos[:10]</span><br></pre></td></tr></table></figure><p>Out[8]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&apos;UNK&apos;, &apos;PAD&apos;, &apos;ï¼Œ&apos;, &apos;çš„&apos;, &apos;ã€‚&apos;, &apos;äº†&apos;, &apos;,&apos;, &apos;é…’åº—&apos;, &apos;æ˜¯&apos;, &apos;å¾ˆ&apos;]</span><br></pre></td></tr></table></figure><p>In [10]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stoi[&quot;é…’åº—&quot;]</span><br></pre></td></tr></table></figure><p>Out[10]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">7</span><br></pre></td></tr></table></figure><p>æˆ‘ä»¬æŠŠæ–‡æœ¬ä¸­çš„å•è¯éƒ½è½¬æ¢æˆindex</p><p>In [12]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_idx = [[stoi.get(word, stoi.get(&quot;UNK&quot;)) for word in text] for text in train_text ]</span><br><span class="line">dev_idx = [[stoi.get(word, stoi.get(&quot;UNK&quot;)) for word in text] for text in dev_text ]</span><br><span class="line">test_idx = [[stoi.get(word, stoi.get(&quot;UNK&quot;)) for word in text] for text in test_text ]</span><br></pre></td></tr></table></figure><p>æŠŠæ•°æ®å’Œlabeléƒ½è½¬æˆbatch</p><p>In [15]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">def get_minibatches(text_idx, labels, batch_size=64, sort=True):</span><br><span class="line">    if sort:</span><br><span class="line">        text_idx_and_labels = sorted(list(zip(text_idx, labels)), key=lambda x: len(x[0]))</span><br><span class="line">        </span><br><span class="line">    text_idx_batches = []</span><br><span class="line">    label_batches = []</span><br><span class="line">    for i in range(0, len(text_idx), batch_size):</span><br><span class="line">        text_batch = [t for t, l in text_idx_and_labels[i:i+batch_size]]</span><br><span class="line">        label_batch = [l for t, l in text_idx_and_labels[i:i+batch_size]]</span><br><span class="line">        max_len = max([len(t) for t in text_batch])</span><br><span class="line">        text_batch_np = np.ones((len(text_batch), max_len), dtype=np.int) # batch_size * max_seq_ength</span><br><span class="line">        for i, t in enumerate(text_batch):</span><br><span class="line">            text_batch_np[i, :len(t)] = t</span><br><span class="line">        text_idx_batches.append(text_batch_np)</span><br><span class="line">        label_batches.append(np.array(label_batch))</span><br><span class="line">        </span><br><span class="line">    return text_idx_batches, label_batches</span><br><span class="line"></span><br><span class="line">train_batches, train_label_batches = get_minibatches(train_idx, train_label)</span><br><span class="line">dev_batches, dev_label_batches = get_minibatches(dev_idx, dev_label)</span><br><span class="line">test_batches, test_label_batches = get_minibatches(test_idx, test_label)</span><br></pre></td></tr></table></figure><p>In [17]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_batches[20]</span><br></pre></td></tr></table></figure><p>Out[17]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">array([[  80,  177,  149, ...,  191,    3,    1],</span><br><span class="line">       [  49,   18,   20, ...,   53,    4,    1],</span><br><span class="line">       [   7,   18,   17, ...,  702,    4,    1],</span><br><span class="line">       ...,</span><br><span class="line">       [1107, 2067,   10, ...,  748,  172,  442],</span><br><span class="line">       [ 241,    9,   19, ...,   17,   44,   30],</span><br><span class="line">       [3058,   20,    6, ...,    9,   19,   98]])</span><br></pre></td></tr></table></figure><p>In [18]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_label_batches[20]</span><br></pre></td></tr></table></figure><p>Out[18]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,</span><br><span class="line">       1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,</span><br><span class="line">       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1])</span><br></pre></td></tr></table></figure><ul><li>å’Œä¹‹å‰ä¸€æ ·ï¼Œæˆ‘ä»¬ä¼šè®¾å®šrandom seedsä½¿å®éªŒå¯ä»¥å¤ç°ã€‚</li></ul><p>In [19]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">from torchtext import data</span><br><span class="line">import random</span><br><span class="line"></span><br><span class="line">SEED = 1234</span><br><span class="line"></span><br><span class="line">torch.manual_seed(SEED)</span><br><span class="line">torch.cuda.manual_seed(SEED)</span><br><span class="line">torch.backends.cudnn.deterministic = True</span><br><span class="line"></span><br><span class="line">device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br></pre></td></tr></table></figure><h2 id="Word-Averagingæ¨¡å‹"><a href="#Word-Averagingæ¨¡å‹" class="headerlink" title="Word Averagingæ¨¡å‹"></a>Word Averagingæ¨¡å‹</h2><ul><li>æˆ‘ä»¬é¦–å…ˆä»‹ç»ä¸€ä¸ªç®€å•çš„Word Averagingæ¨¡å‹ã€‚è¿™ä¸ªæ¨¡å‹éå¸¸ç®€å•ï¼Œæˆ‘ä»¬æŠŠæ¯ä¸ªå•è¯éƒ½é€šè¿‡<code>Embedding</code>å±‚æŠ•å°„æˆword embedding vectorï¼Œç„¶åæŠŠä¸€å¥è¯ä¸­çš„æ‰€æœ‰word vectoråšä¸ªå¹³å‡ï¼Œå°±æ˜¯æ•´ä¸ªå¥å­çš„vectorè¡¨ç¤ºäº†ã€‚æ¥ä¸‹æ¥æŠŠè¿™ä¸ªsentence vectorä¼ å…¥ä¸€ä¸ª<code>Linear</code>å±‚ï¼Œåšåˆ†ç±»å³å¯ã€‚</li></ul><p>In [32]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line"></span><br><span class="line">class WordAVGModel(nn.Module):</span><br><span class="line">    def __init__(self, vocab_size, embedding_size, output_size, pad_idx, dropout_p=0.2):</span><br><span class="line">        super(WordAVGModel, self).__init__()</span><br><span class="line">        self.embed = nn.Embedding(vocab_size, embedding_size, padding_idx=pad_idx)</span><br><span class="line">        self.linear = nn.Linear(embedding_size, output_size)</span><br><span class="line">        self.dropout = nn.Dropout(dropout_p) # è¿™ä¸ªå‚æ•°ç»å¸¸æ‹¿æ¥è°ƒèŠ‚</span><br><span class="line">    </span><br><span class="line">    def forward(self, text, mask):</span><br><span class="line">        # text: batch_size * max_seq_len</span><br><span class="line">        # mask: batch_size * max_seq_len</span><br><span class="line">        embedded = self.embed(text) # [batch_size, max_seq_len, embedding_size]</span><br><span class="line">        embedded = self.dropout(embedded)</span><br><span class="line">        # dropout</span><br><span class="line">        mask = (1. - mask.float()).unsqueeze(2) # [batch_size, seq_len, 1], 1 represents word, 0 represents padding</span><br><span class="line">        embedded = embedded * mask # [batch_size, seq_len, embedding_size]</span><br><span class="line">        # æ±‚å¹³å‡</span><br><span class="line">        sent_embed = embedded.sum(1) / (mask.sum(1) + 1e-9) # é˜²æ­¢mask.sumä¸º0ï¼Œé‚£ä¹ˆä¸èƒ½é™¤ä»¥é›¶ã€‚</span><br><span class="line">        # dropout</span><br><span class="line">        return self.linear(sent_embed)</span><br></pre></td></tr></table></figure><p>In [75]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line"></span><br><span class="line">class WordMaxModel(nn.Module):</span><br><span class="line">    def __init__(self, vocab_size, embedding_size, output_size, pad_idx, dropout_p=0.2):</span><br><span class="line">        super(WordMaxModel, self).__init__()</span><br><span class="line">        self.embed = nn.Embedding(vocab_size, embedding_size, padding_idx=pad_idx)</span><br><span class="line">        self.linear = nn.Linear(embedding_size, output_size)</span><br><span class="line">        self.dropout = nn.Dropout(dropout_p) # è¿™ä¸ªå‚æ•°ç»å¸¸æ‹¿æ¥è°ƒèŠ‚</span><br><span class="line">    </span><br><span class="line">    def forward(self, text, mask):</span><br><span class="line">        # text: batch_size * max_seq_len</span><br><span class="line">        # mask: batch_size * max_seq_len</span><br><span class="line">        embedded = self.embed(text) # [batch_size, max_seq_len, embedding_size]</span><br><span class="line">        embedded = self.dropout(embedded)</span><br><span class="line">        embedded.masked_fill(mask.unsqueeze(2), -999999)</span><br><span class="line">        # dropout</span><br><span class="line">        sent_embed = torch.max(embedded, 1)[0]</span><br><span class="line">        # dropout</span><br><span class="line">        return self.linear(sent_embed)</span><br></pre></td></tr></table></figure><p>In [76]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">VOCAB_SIZE = len(itos)</span><br><span class="line">EMBEDDING_SIZE = 100</span><br><span class="line">OUTPUT_SIZE = 1</span><br><span class="line">PAD_IDX = stoi[&quot;PAD&quot;]</span><br><span class="line"></span><br><span class="line">model = WordMaxModel(vocab_size=VOCAB_SIZE, </span><br><span class="line">                     embedding_size=EMBEDDING_SIZE, </span><br><span class="line">                     output_size=OUTPUT_SIZE, </span><br><span class="line">                     pad_idx=PAD_IDX)</span><br></pre></td></tr></table></figure><p>In [77]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">VOCAB_SIZE</span><br></pre></td></tr></table></figure><p>Out[77]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">24001</span><br></pre></td></tr></table></figure><p>In [78]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># model</span><br><span class="line">def count_parameters(model):</span><br><span class="line">    return sum(p.numel() for p in model.parameters() if p.requires_grad)</span><br><span class="line"></span><br><span class="line">count_parameters(model)</span><br></pre></td></tr></table></figure><p>Out[78]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2400201</span><br></pre></td></tr></table></figure><p>In [79]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UNK_IDX = stoi[&quot;UNK&quot;]</span><br></pre></td></tr></table></figure><h2 id="è®­ç»ƒæ¨¡å‹"><a href="#è®­ç»ƒæ¨¡å‹" class="headerlink" title="è®­ç»ƒæ¨¡å‹"></a>è®­ç»ƒæ¨¡å‹</h2><p>In [80]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">optimizer = torch.optim.Adam(model.parameters())</span><br><span class="line">crit = nn.BCEWithLogitsLoss()</span><br><span class="line"></span><br><span class="line">model = model.to(device)</span><br><span class="line"># crit = crit.to(device)</span><br></pre></td></tr></table></figure><p>è®¡ç®—é¢„æµ‹çš„å‡†ç¡®ç‡</p><p>In [81]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def binary_accuracy(preds, y):</span><br><span class="line">    rounded_preds = torch.round(torch.sigmoid(preds))</span><br><span class="line">    correct = (rounded_preds == y).float()</span><br><span class="line">    acc = correct.sum() / len(correct)</span><br><span class="line">    return acc</span><br></pre></td></tr></table></figure><p>In [82]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">def train(model, text_idxs, labels, optimizer, crit):</span><br><span class="line">    epoch_loss, epoch_acc = 0., 0.</span><br><span class="line">    model.train()</span><br><span class="line">    total_len = 0.</span><br><span class="line">    for text, label in zip(text_idxs, labels):</span><br><span class="line">        text = torch.from_numpy(text).to(device)</span><br><span class="line">        label = torch.from_numpy(label).to(device)</span><br><span class="line">        mask = text == PAD_IDX</span><br><span class="line">        preds = model(text, mask).squeeze() # [batch_size, sent_length]</span><br><span class="line">        loss = crit(preds, label.float()) </span><br><span class="line">        acc = binary_accuracy(preds, label)</span><br><span class="line">        </span><br><span class="line">        # sgd</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">#         print(&quot;batch loss: &#123;&#125;&quot;.format(loss.item()))</span><br><span class="line">        </span><br><span class="line">        epoch_loss += loss.item() * len(label)</span><br><span class="line">        epoch_acc += acc.item() * len(label)</span><br><span class="line">        total_len += len(label)</span><br><span class="line">        </span><br><span class="line">    return epoch_loss / total_len, epoch_acc / total_len</span><br></pre></td></tr></table></figure><p>In [83]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">def evaluate(model, text_idxs, labels, crit):</span><br><span class="line">    epoch_loss, epoch_acc = 0., 0.</span><br><span class="line">    model.eval()</span><br><span class="line">    total_len = 0.</span><br><span class="line">    for text, label in zip(text_idxs, labels):</span><br><span class="line">        text = torch.from_numpy(text).to(device)</span><br><span class="line">        label = torch.from_numpy(label).to(device)</span><br><span class="line">        mask = text == PAD_IDX</span><br><span class="line">        with torch.no_grad():</span><br><span class="line">            preds = model(text, mask).squeeze()</span><br><span class="line">        loss = crit(preds, label.float())</span><br><span class="line">        acc = binary_accuracy(preds, label)</span><br><span class="line">        </span><br><span class="line">        epoch_loss += loss.item() * len(label)</span><br><span class="line">        epoch_acc += acc.item() * len(label)</span><br><span class="line">        total_len += len(label)</span><br><span class="line">    model.train()</span><br><span class="line">        </span><br><span class="line">    return epoch_loss / total_len, epoch_acc / total_len</span><br></pre></td></tr></table></figure><p>In [84]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">N_EPOCHS = 10</span><br><span class="line">best_valid_acc = 0.</span><br><span class="line">for epoch in range(N_EPOCHS):</span><br><span class="line">    train_loss, train_acc = train(model, train_batches, train_label_batches, optimizer, crit)</span><br><span class="line">    valid_loss, valid_acc = evaluate(model, dev_batches, dev_label_batches, crit)</span><br><span class="line">    </span><br><span class="line">    if valid_acc &gt; best_valid_acc:</span><br><span class="line">        best_valid_acc = valid_acc</span><br><span class="line">        torch.save(model.state_dict(), &quot;wordavg-model.pth&quot;)</span><br><span class="line">        </span><br><span class="line">    print(&quot;Epoch&quot;, epoch, &quot;Train Loss&quot;, train_loss, &quot;Train Acc&quot;, train_acc)</span><br><span class="line">    print(&quot;Epoch&quot;, epoch, &quot;Valid Loss&quot;, valid_loss, &quot;Valid Acc&quot;, valid_acc)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Epoch 0 Train Loss 0.6241851981347865 Train Acc 0.6785254346426272</span><br><span class="line">Epoch 0 Valid Loss 0.7439712684126895 Valid Acc 0.396396396434752</span><br><span class="line">Epoch 1 Train Loss 0.6111872896254639 Train Acc 0.6775595621377978</span><br><span class="line">Epoch 1 Valid Loss 0.7044879783381213 Valid Acc 0.4761904762288318</span><br><span class="line">Epoch 2 Train Loss 0.5826128212314072 Train Acc 0.7041210560206053</span><br><span class="line">Epoch 2 Valid Loss 0.667004818775172 Valid Acc 0.5791505791889348</span><br><span class="line">Epoch 3 Train Loss 0.5516750626769744 Train Acc 0.7293947198969736</span><br><span class="line">Epoch 3 Valid Loss 0.6347547087583456 Valid Acc 0.6473616476684924</span><br><span class="line">Epoch 4 Train Loss 0.5236469646921791 Train Acc 0.7512878300064392</span><br><span class="line">Epoch 4 Valid Loss 0.5953507212444928 Valid Acc 0.7348777351845799</span><br><span class="line">Epoch 5 Train Loss 0.4969042095152394 Train Acc 0.7707662588538313</span><br><span class="line">Epoch 5 Valid Loss 0.5561252224092471 Valid Acc 0.7786357789426237</span><br><span class="line">Epoch 6 Train Loss 0.46501466702892946 Train Acc 0.797005795235029</span><br><span class="line">Epoch 6 Valid Loss 0.5206214915217887 Valid Acc 0.8018018021086468</span><br><span class="line">Epoch 7 Train Loss 0.43595607032794303 Train Acc 0.8163232453316163</span><br><span class="line">Epoch 7 Valid Loss 0.4846100037776058 Valid Acc 0.8159588161889497</span><br><span class="line">Epoch 8 Train Loss 0.40671270164611334 Train Acc 0.8386992916934964</span><br><span class="line">Epoch 8 Valid Loss 0.45964578196809097 Valid Acc 0.8211068213369549</span><br><span class="line">Epoch 9 Train Loss 0.38044816804408105 Train Acc 0.8539922730199614</span><br><span class="line">Epoch 9 Valid Loss 0.4279780917953187 Valid Acc 0.8416988419289755</span><br></pre></td></tr></table></figure><p>In [85]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.load_state_dict(torch.load(&quot;wordavg-model.pth&quot;))</span><br></pre></td></tr></table></figure><p>Out[85]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;All keys matched successfully&gt;</span><br></pre></td></tr></table></figure><p>In [86]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">def predict_sentiment(model, sentence):</span><br><span class="line">    model.eval()</span><br><span class="line">    indexed = [stoi.get(t, PAD_IDX) for t in seg.cut(sentence)]</span><br><span class="line">    tensor = torch.LongTensor(indexed).to(device) # seq_len</span><br><span class="line">    tensor = tensor.unsqueeze(0) # batch_size* seq_len </span><br><span class="line">    mask = tensor == PAD_IDX</span><br><span class="line">#     print(tensor, &quot;\n&quot;, mask)</span><br><span class="line">    with torch.no_grad():</span><br><span class="line">        pred = torch.sigmoid(model(tensor, mask))</span><br><span class="line">    return pred.item()</span><br></pre></td></tr></table></figure><p>In [88]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predict_sentiment(model, &quot;è¿™ä¸ªé…’åº—éå¸¸è„ä¹±å·®ï¼Œä¸æ¨è&quot;)</span><br></pre></td></tr></table></figure><p>Out[88]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.6831367611885071</span><br></pre></td></tr></table></figure><p>In [90]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predict_sentiment(model, &quot;è¿™ä¸ªé…’åº—éå¸¸å¥½ï¼Œå¼ºçƒˆæ¨èï¼&quot;)</span><br></pre></td></tr></table></figure><p>Out[90]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.8252924680709839</span><br></pre></td></tr></table></figure><p>In [91]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predict_sentiment(model, &quot;æˆ¿é—´è®¾å¤‡å¤ªç ´,è¿å–·å¤´éƒ½æ˜¯ä¸å¥½ç”¨,ç©ºè°ƒå‡ ä¹æ„Ÿè§‰ä¸åˆ°,è™½ç„¶æˆ‘å¼€äº†æœ€å¤§å¦å¤–å°±æ˜¯è®¾å¤‡ç»´ä¿®ä¸åŠæ—¶,æ´—æ¾¡ç”¨å“æ„Ÿè§‰éƒ½æ˜¯å»‰ä»·è´§,å‘³é“å¾ˆå¥‡æ€ªçš„æ´—å¤´æ¶²ç­‰ç­‰...æ€»ä½“æ„Ÿè§‰æœåŠ¡è¿˜å¯ä»¥,è®¾å¤‡æ‹›å¾…æ‰€æ°´å¹³...&quot;)</span><br></pre></td></tr></table></figure><p>Out[91]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.5120517611503601</span><br></pre></td></tr></table></figure><p>In [92]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predict_sentiment(model, &quot;æˆ¿é—´ç¨å°ï¼Œä½†æ¸…æ´ï¼Œéå¸¸å®æƒ ã€‚ä¸è¶³ä¹‹å¤„æ˜¯ï¼šåŒäººæˆ¿çš„æ´—æ¾¡ç”¨å“åªæœ‰ä¸€å¥—.å®¾é¦†åé¦ˆ2008å¹´8æœˆ5æ—¥ï¼šå°Šæ•¬çš„å®¾å®¢ï¼šæ‚¨å¥½ï¼æ„Ÿè°¢æ‚¨é€‰æ‹©å…¥ä½é‡‘é™µæº§é˜³å®¾é¦†ï¼å¯¹äºé…’åº—åŒäººæˆ¿å†…çš„æ´—æ¼±ç”¨å“åªæœ‰ä¸€å¥—çš„é—®é¢˜ï¼Œæˆ‘ä»¬å·²ç»å¬é›†é…’åº—ç›¸å…³éƒ¨é—¨å¯¹æ­¤é—®é¢˜è¿›è¡Œäº†ç ”ç©¶å’Œæ•´æ”¹ã€‚åŠªåŠ›å°†æˆ‘ä»¬çš„ç®¡ç†ä¸æœåŠ¡å·¥ä½œåšåˆ°ä½ï¼Œè¿›ä¸€æ­¥å…³æ³¨å®¾å®¢ï¼Œå…³æ³¨ç»†èŠ‚ï¼å†æ¬¡å‘æ‚¨è¡¨ç¤ºæˆ‘ä»¬æœ€è¡·å¿ƒçš„æ„Ÿè°¢ï¼æœŸå¾…æ‚¨èƒ½å†æ¬¡æ¥æº§é˜³å¹¶å…¥ä½é‡‘é™µæº§é˜³å®¾é¦†ï¼è®©æˆ‘ä»¬æœ‰ç»™æ‚¨æä¾›æ›´åŠ ä¼˜è´¨æœåŠ¡çš„æœºä¼šï¼é¡ºç¥æ‚¨å·¥ä½œé¡ºåˆ©ï¼èº«ä½“å¥åº·ï¼é‡‘é™µæº§é˜³å®¾é¦†å®¢åŠ¡å…³ç³»ä¸»ä»»&quot;)</span><br></pre></td></tr></table></figure><p>Out[92]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.7319579124450684</span><br></pre></td></tr></table></figure><p>In [93]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predict_sentiment(model, &quot;è¯¥é…’åº—å¯¹å»æº§é˜³å…¬åŠ¡æˆ–æ—…æ¸¸çš„äººéƒ½å¾ˆé€‚åˆï¼Œè‡ªåŠ©æ—©é¤å¾ˆä¸°å¯Œï¼Œé…’åº—å†…éƒ¨ç¯å¢ƒå’ŒæœåŠ¡å¾ˆå¥½ã€‚å”¯ä¸€çš„ä¸è¶³æ˜¯é…’åº—å¤§é—¨å£åœ¨æ™šä¸Šæ—¶å¤ªä¹±ï¼Œå„ç§è½¦è¾†å’Œäººåœ¨é—¨å£æŒ¤æˆä¸€å›¢ã€‚è¡¥å……ç‚¹è¯„2008å¹´5æœˆ9æ—¥ï¼šæˆ¿é—´æ·‹æµ´æ°´å‹ä¸ç¨³ï¼Œä¸€ä¼šçƒ­ã€ä¸€ä¼šå†·ï¼Œå¾ˆä¸å¥½è°ƒæ•´ã€‚å®¾é¦†åé¦ˆ2008å¹´5æœˆ13æ—¥ï¼šéå¸¸æ„Ÿè°¢æ‚¨é€‰æ‹©å…¥ä½é‡‘é™µæº§é˜³å®¾é¦†ã€‚æ‚¨ç»™äºˆæˆ‘ä»¬çš„è‚¯å®šä¸èµèµè®©æˆ‘ä»¬å€å—é¼“èˆï¼Œä¹Ÿä½¿æˆ‘ä»¬æ›´åŠ è‡ªä¿¡åœ°å»åšå¥½æ¯ä¸€å¤©çš„æœåŠ¡å·¥ä½œã€‚æ­£æ˜¯æœ‰è®¸å¤šåƒæ‚¨ä¸€æ ·çš„å®¾å®¢ç»™äºˆæˆ‘ä»¬ä¸æ–­çš„é¼“åŠ±å’Œèµèµï¼Œé…’åº—çš„æœåŠ¡å“è´¨æ‰èƒ½å¾—ä»¥ä¸æ–­æå‡ã€‚å¯¹äºé…’åº—å¤§é—¨å£çš„ç§©åºå’Œæˆ¿é—´æ·‹æµ´æ°´çš„é—®é¢˜æˆ‘ä»¬å·²åšå‡ºäº†ç›¸åº”çš„æªæ–½ã€‚å†æ¬¡å‘æ‚¨è¡¨ç¤ºæˆ‘ä»¬æœ€è¡·å¿ƒçš„æ„Ÿè°¢ï¼æˆ‘ä»¬æœŸå¾…æ‚¨çš„å†æ¬¡å…‰ä¸´ï¼&quot;)</span><br></pre></td></tr></table></figure><p>Out[93]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.793725311756134</span><br></pre></td></tr></table></figure><p>In [94]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predict_sentiment(model, &quot;ç¯å¢ƒä¸é”™ï¼Œå®¤å†…è‰²è°ƒå¾ˆæ¸©é¦¨ï¼ŒMMå¾ˆæ»¡æ„ï¼å°±æ˜¯çª—æˆ·æ”¶æ‹¾å¾—å¤ªé©¬è™äº†ï¼Œæ‹‰å¼€çª—å¸˜å°±è§‰å¾—å¾ˆå‡Œä¹±çš„æ„Ÿè§‰ã€‚æœ€ä¸è¶³çš„åœ°æ–¹å°±æ˜¯æ·‹æµ´äº†ï¼Œä¸€æ˜¯åœ°æ–¹å¤ªå°äº†ï¼ŒäºŒæ˜¯æ´—æ¾¡æ—¶æ°´æ—¶å¤§æ—¶å°çš„ï¼Œä¸­é—´è¿˜åœäº†å‡ ç§’ï¼ï¼&quot;)</span><br></pre></td></tr></table></figure><p>Out[94]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.7605408430099487</span><br></pre></td></tr></table></figure><p>In [95]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.load_state_dict(torch.load(&quot;wordavg-model.pth&quot;))</span><br><span class="line">test_loss, test_acc = evaluate(model, test_batches, test_label_batches, crit)</span><br><span class="line">print(&quot;CNN model test loss: &quot;, test_loss, &quot;accuracy:&quot;, test_acc)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CNN model test loss:  0.44893962796897346 accuracy: 0.8133848134615247</span><br></pre></td></tr></table></figure><h2 id="RNNæ¨¡å‹"><a href="#RNNæ¨¡å‹" class="headerlink" title="RNNæ¨¡å‹"></a>RNNæ¨¡å‹</h2><ul><li><p>ä¸‹é¢æˆ‘ä»¬å°è¯•æŠŠæ¨¡å‹æ¢æˆä¸€ä¸ª</p><p>recurrent neural network</p></li></ul><p>  (RNN)ã€‚RNNç»å¸¸ä¼šè¢«ç”¨æ¥encodeä¸€ä¸ªsequence</p><p>  â„ğ‘¡=RNN(ğ‘¥ğ‘¡,â„ğ‘¡âˆ’1)ht=RNN(xt,htâˆ’1)</p><ul><li><p>æˆ‘ä»¬ä½¿ç”¨æœ€åä¸€ä¸ªhidden state â„ğ‘‡hTæ¥è¡¨ç¤ºæ•´ä¸ªå¥å­ã€‚</p></li><li><p>ç„¶åæˆ‘ä»¬æŠŠâ„ğ‘‡hTé€šè¿‡ä¸€ä¸ªçº¿æ€§å˜æ¢ğ‘“fï¼Œç„¶åç”¨æ¥é¢„æµ‹å¥å­çš„æƒ…æ„Ÿã€‚</p></li></ul><p><img src="file:///Users/mmy/Downloads/assets/sentiment1.png" alt="img"></p><p><img src="file:///Users/mmy/Downloads/assets/sentiment7.png" alt="img"></p><p>In [57]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">class RNNModel(nn.Module):</span><br><span class="line">    def __init__(self, vocab_size, embedding_size, output_size, pad_idx, hidden_size, dropout, avg_hidden=True):</span><br><span class="line">        super(RNNModel, self).__init__()</span><br><span class="line">        self.embed = nn.Embedding(vocab_size, embedding_size, padding_idx=pad_idx)</span><br><span class="line">        self.lstm = nn.LSTM(embedding_size, hidden_size, bidirectional=True, num_layers=2, batch_first=True)</span><br><span class="line">        self.linear = nn.Linear(hidden_size*2, output_size)</span><br><span class="line">            </span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line">        self.avg_hidden = avg_hidden</span><br><span class="line">    </span><br><span class="line">    def forward(self, text, mask):</span><br><span class="line">        embedded = self.embed(text) # [batch_size, seq_len, embedding_size] å…¶ä¸­åŒ…å«ä¸€äº›pad</span><br><span class="line">        embedded  = self.dropout(embedded)</span><br><span class="line">        </span><br><span class="line">        # mask: batch_size * seq_length</span><br><span class="line">        seq_length = (1. - mask.float()).sum(1)</span><br><span class="line">        embedded = torch.nn.utils.rnn.pack_padded_sequence(</span><br><span class="line">            input=embedded,</span><br><span class="line">            lengths=seq_length,</span><br><span class="line">            batch_first=True,</span><br><span class="line">            enforce_sorted=False</span><br><span class="line">        ) # batch_size * seq_len * ...,    seq_len * batch_size * ...</span><br><span class="line">        output, (hidden, cell) = self.lstm(embedded)</span><br><span class="line">        output, seq_length = torch.nn.utils.rnn.pad_packed_sequence(</span><br><span class="line">            sequence=output,</span><br><span class="line">            batch_first=True,</span><br><span class="line">            padding_value=0,</span><br><span class="line">            total_length=mask.shape[1]</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        # output: [batch_size, seq_length, hidden_dim * num_directions]</span><br><span class="line">        # hidden: [num_layers * num_directions, batch_size, hidden_dim]</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        if self.avg_hidden:</span><br><span class="line">            hidden = torch.sum(output * (1. - mask.float()).unsqueeze(2), 1) / torch.sum((1. - mask.float()), 1).unsqueeze(1)</span><br><span class="line">        else:</span><br><span class="line">            # æ‹¿æœ€åä¸€ä¸ªhidden stateä½œä¸ºå¥å­çš„è¡¨ç¤º</span><br><span class="line">            # hidden: 2 * batch_size * hidden_size</span><br><span class="line">            hidden = torch.cat([hidden[-1], hidden[-2]], dim=1)</span><br><span class="line">            hidden = self.dropout(hidden.squeeze())</span><br><span class="line">        return self.linear(hidden)</span><br></pre></td></tr></table></figure><p>In [58]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = RNNModel(vocab_size=VOCAB_SIZE, </span><br><span class="line">                 embedding_size=EMBEDDING_SIZE, </span><br><span class="line">                 output_size=OUTPUT_SIZE, </span><br><span class="line">                 pad_idx=PAD_IDX, </span><br><span class="line">                 hidden_size=100, </span><br><span class="line">                 dropout=0.5)</span><br></pre></td></tr></table></figure><h2 id="è®­ç»ƒRNNæ¨¡å‹"><a href="#è®­ç»ƒRNNæ¨¡å‹" class="headerlink" title="è®­ç»ƒRNNæ¨¡å‹"></a>è®­ç»ƒRNNæ¨¡å‹</h2><p>In [59]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">optimizer = torch.optim.Adam(model.parameters()) # L2</span><br><span class="line">crit = nn.BCEWithLogitsLoss()</span><br><span class="line"></span><br><span class="line">model = model.to(device)</span><br><span class="line">crit = crit.to(device)</span><br></pre></td></tr></table></figure><p>In [60]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">N_EPOCHS = 10</span><br><span class="line">best_valid_acc = 0.</span><br><span class="line">for epoch in range(N_EPOCHS):</span><br><span class="line">    train_loss, train_acc = train(model, train_batches, train_label_batches, optimizer, crit)</span><br><span class="line">    valid_loss, valid_acc = evaluate(model, dev_batches, dev_label_batches, crit)</span><br><span class="line">    </span><br><span class="line">    if valid_acc &gt; best_valid_acc:</span><br><span class="line">        best_valid_acc = valid_acc</span><br><span class="line">        torch.save(model.state_dict(), &quot;lstm-model.pth&quot;)</span><br><span class="line">        </span><br><span class="line">    print(&quot;Epoch&quot;, epoch, &quot;Train Loss&quot;, train_loss, &quot;Train Acc&quot;, train_acc)</span><br><span class="line">    print(&quot;Epoch&quot;, epoch, &quot;Valid Loss&quot;, valid_loss, &quot;Valid Acc&quot;, valid_acc)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Epoch 0 Train Loss 0.5140281977456996 Train Acc 0.7472633612363168</span><br><span class="line">Epoch 0 Valid Loss 0.7321655497894631 Valid Acc 0.8133848134615247</span><br><span class="line">Epoch 1 Train Loss 0.4205178504441526 Train Acc 0.8209916291049582</span><br><span class="line">Epoch 1 Valid Loss 0.5658483397086155 Valid Acc 0.8391248392782616</span><br><span class="line">Epoch 2 Train Loss 0.3576773465620036 Train Acc 0.8473921442369607</span><br><span class="line">Epoch 2 Valid Loss 0.6089477152437777 Valid Acc 0.8545688548756996</span><br><span class="line">Epoch 3 Train Loss 0.3190276817504391 Train Acc 0.8647778493238892</span><br><span class="line">Epoch 3 Valid Loss 0.5731698980355968 Valid Acc 0.8622908625977073</span><br><span class="line">Epoch 4 Train Loss 0.2850390273336434 Train Acc 0.8881197681905988</span><br><span class="line">Epoch 4 Valid Loss 0.6073675444073966 Valid Acc 0.8622908625209961</span><br><span class="line">Epoch 5 Train Loss 0.26827128295812463 Train Acc 0.8884417256922086</span><br><span class="line">Epoch 5 Valid Loss 0.4971172449057934 Valid Acc 0.8700128701662925</span><br><span class="line">Epoch 6 Train Loss 0.23699480644442233 Train Acc 0.9059884095299421</span><br><span class="line">Epoch 6 Valid Loss 0.5370476412343549 Valid Acc 0.8635778636545748</span><br><span class="line">Epoch 7 Train Loss 0.22414902945487483 Train Acc 0.9072762395363811</span><br><span class="line">Epoch 7 Valid Loss 0.48257371315317876 Valid Acc 0.8725868726635838</span><br><span class="line">Epoch 8 Train Loss 0.2119196125996435 Train Acc 0.9162910495814552</span><br><span class="line">Epoch 8 Valid Loss 0.59562370292315 Valid Acc 0.8468468471536919</span><br><span class="line">Epoch 9 Train Loss 0.20756761220698194 Train Acc 0.9207984546039922</span><br><span class="line">Epoch 9 Valid Loss 0.6451035161122699 Valid Acc 0.8700128701662925</span><br></pre></td></tr></table></figure><p>In [62]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predict_sentiment(model, &quot;æ²ˆé˜³å¸‚æ”¿åºœçš„é…’åº—ï¼Œæ¯”è¾ƒå¤§æ°”ï¼Œäº¤é€šä¾¿åˆ©ï¼Œå‡ºé—¨å¾€å·¦å°±æ˜¯åŒ—é™µå…¬å›­ï¼Œç¯å¢ƒå¥½ã€‚&quot;)</span><br></pre></td></tr></table></figure><p>Out[62]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.9994519352912903</span><br></pre></td></tr></table></figure><p>In [63]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predict_sentiment(model, &quot;è¿™ä¸ªé…’åº—éå¸¸è„ä¹±å·®ï¼Œä¸æ¨èï¼&quot;)</span><br></pre></td></tr></table></figure><p>Out[63]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.01588270254433155</span><br></pre></td></tr></table></figure><p>In [68]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predict_sentiment(model, &quot;è¿™ä¸ªé…’åº—ä¸ä¹±ï¼Œéå¸¸æ¨èï¼&quot;)</span><br></pre></td></tr></table></figure><p>Out[68]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.04462616145610809</span><br></pre></td></tr></table></figure><p>åœ¨testä¸Šåšæ¨¡å‹é¢„æµ‹</p><p>In [69]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.load_state_dict(torch.load(&quot;lstm-model.pth&quot;))</span><br><span class="line">test_loss, test_acc = evaluate(model, test_batches, test_label_batches, crit)</span><br><span class="line">print(&quot;CNN model test loss: &quot;, test_loss, &quot;accuracy:&quot;, test_acc)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CNN model test loss:  0.5639284941220376 accuracy: 0.8481338484406932</span><br></pre></td></tr></table></figure><h2 id="CNNæ¨¡å‹"><a href="#CNNæ¨¡å‹" class="headerlink" title="CNNæ¨¡å‹"></a>CNNæ¨¡å‹</h2><p>In [70]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">class CNN(nn.Module):</span><br><span class="line">    def __init__(self, vocab_size, embedding_size, output_size, pad_idx, num_filters, filter_sizes, dropout):</span><br><span class="line">        super(CNN, self).__init__()</span><br><span class="line">        self.filter_sizes = filter_sizes</span><br><span class="line">        self.embed = nn.Embedding(vocab_size, embedding_size, padding_idx=pad_idx)</span><br><span class="line">        self.convs = nn.ModuleList([</span><br><span class="line">            nn.Conv2d(in_channels=1, out_channels=num_filters, </span><br><span class="line">                          kernel_size=(fs, embedding_size)) </span><br><span class="line">            for fs in filter_sizes</span><br><span class="line">        ]) # 3ä¸ªCNN </span><br><span class="line">        # fså®é™…ä¸Šå°±æ˜¯n-gramçš„n</span><br><span class="line">#         self.conv = nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(filter_size, embedding_size))</span><br><span class="line">        self.linear = nn.Linear(num_filters * len(filter_sizes), output_size)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line">    </span><br><span class="line">    def forward(self, text, mask):</span><br><span class="line">        embedded = self.embed(text) # [batch_size, seq_len, embedding_size]</span><br><span class="line">        embedded = embedded.unsqueeze(1) # # [batch_size, 1, seq_len, embedding_size]</span><br><span class="line">#         conved = F.relu(self.conv(embedded)) # [batch_size, num_filters, seq_len-filter_size+1, 1]</span><br><span class="line">#         conved = conved.squeeze(3) # [batch_size, num_filters, seq_len-filter_size+1]</span><br><span class="line">        conved = [</span><br><span class="line">            F.relu(conv(embedded)).squeeze(3) for conv in self.convs</span><br><span class="line">        ] # [batch_size, num_filters, seq_len-filter_size+1]</span><br><span class="line">    </span><br><span class="line">        # [2, 5, 1, 1]</span><br><span class="line">    </span><br><span class="line">        # mask [[0, 0, 1, 1]]</span><br><span class="line">        # fs: 2</span><br><span class="line">        # [0, 0, 1]</span><br><span class="line">        conved = [</span><br><span class="line">            conv.masked_fill(mask[:, :-filter_size+1].unsqueeze(1) , -999999) for (conv, filter_size) in zip(conved, self.filter_sizes)</span><br><span class="line">        ]</span><br><span class="line">        # max over time pooling</span><br><span class="line">#         pooled = F.max_pool1d(conved, conved.shape[2]) # [batch_size, num_filters, 1]</span><br><span class="line">#         pooled = pooled.squeeze(2)</span><br><span class="line">        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]</span><br><span class="line">        pooled = torch.cat(pooled, dim=1) # batch_size, 3*num_filters</span><br><span class="line">        pooled = self.dropout(pooled)</span><br><span class="line">        </span><br><span class="line">        return self.linear(pooled)</span><br><span class="line">    </span><br><span class="line">#     Conv1d? 1x1 Conv2d?</span><br></pre></td></tr></table></figure><p>In [71]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">model = CNN(vocab_size=VOCAB_SIZE, </span><br><span class="line">           embedding_size=EMBEDDING_SIZE, </span><br><span class="line">           output_size=OUTPUT_SIZE, </span><br><span class="line">           pad_idx=PAD_IDX,</span><br><span class="line">           num_filters=100, </span><br><span class="line">           filter_sizes=[3,4,5],  # 3-gram, 4-gram, 5-gram</span><br><span class="line">           dropout=0.5)</span><br><span class="line"></span><br><span class="line">optimizer = torch.optim.Adam(model.parameters())</span><br><span class="line">crit = nn.BCEWithLogitsLoss()</span><br><span class="line"></span><br><span class="line">model = model.to(device)</span><br><span class="line">crit = crit.to(device)</span><br><span class="line"></span><br><span class="line">N_EPOCHS = 10</span><br><span class="line">best_valid_acc = 0.</span><br><span class="line">for epoch in range(N_EPOCHS):</span><br><span class="line">    train_loss, train_acc = train(model, train_batches, train_label_batches, optimizer, crit)</span><br><span class="line">    valid_loss, valid_acc = evaluate(model, dev_batches, dev_label_batches, crit)</span><br><span class="line">    </span><br><span class="line">    if valid_acc &gt; best_valid_acc:</span><br><span class="line">        best_valid_acc = valid_acc</span><br><span class="line">        torch.save(model.state_dict(), &quot;cnn-model.pth&quot;)</span><br><span class="line">        </span><br><span class="line">    print(&quot;Epoch&quot;, epoch, &quot;Train Loss&quot;, train_loss, &quot;Train Acc&quot;, train_acc)</span><br><span class="line">    print(&quot;Epoch&quot;, epoch, &quot;Valid Loss&quot;, valid_loss, &quot;Valid Acc&quot;, valid_acc)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Epoch 0 Train Loss 0.5229088294452341 Train Acc 0.7443657437218287</span><br><span class="line">Epoch 0 Valid Loss 0.39319338566087847 Valid Acc 0.8108108110409445</span><br><span class="line">Epoch 1 Train Loss 0.3683148011498043 Train Acc 0.837894397939472</span><br><span class="line">Epoch 1 Valid Loss 0.3534783678778964 Valid Acc 0.840411840565263</span><br><span class="line">Epoch 2 Train Loss 0.3185185533801318 Train Acc 0.8644558918222794</span><br><span class="line">Epoch 2 Valid Loss 0.34023444222207233 Valid Acc 0.8545688547222771</span><br><span class="line">Epoch 3 Train Loss 0.27130810793366883 Train Acc 0.8889246619446233</span><br><span class="line">Epoch 3 Valid Loss 0.30879392936116173 Valid Acc 0.8648648650182874</span><br><span class="line">Epoch 4 Train Loss 0.24334710945314694 Train Acc 0.9034127495170637</span><br><span class="line">Epoch 4 Valid Loss 0.3020249246553718 Valid Acc 0.8790218791753015</span><br><span class="line">Epoch 5 Train Loss 0.2156534520195556 Train Acc 0.912105602060528</span><br><span class="line">Epoch 5 Valid Loss 0.326562241774575 Valid Acc 0.8571428572962797</span><br><span class="line">Epoch 6 Train Loss 0.189559489642123 Train Acc 0.9245009658725049</span><br><span class="line">Epoch 6 Valid Loss 0.28917587651095644 Valid Acc 0.885456885610308</span><br><span class="line">Epoch 7 Train Loss 0.16508568145445063 Train Acc 0.9356084996780425</span><br><span class="line">Epoch 7 Valid Loss 0.2982815937876241 Valid Acc 0.8790218791753015</span><br><span class="line">Epoch 8 Train Loss 0.14198238390007764 Train Acc 0.9452672247263362</span><br><span class="line">Epoch 8 Valid Loss 0.2929042390184513 Valid Acc 0.8880308881843105</span><br><span class="line">Epoch 9 Train Loss 0.11862559608529824 Train Acc 0.9552479072762395</span><br><span class="line">Epoch 9 Valid Loss 0.29382622203618247 Valid Acc 0.886743886820598</span><br></pre></td></tr></table></figure><p>In [72]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.load_state_dict(torch.load(&quot;cnn-model.pth&quot;))</span><br><span class="line">test_loss, test_acc = evaluate(model, test_batches, test_label_batches, crit)</span><br><span class="line">print(&quot;CNN model test loss: &quot;, test_loss, &quot;accuracy:&quot;, test_acc)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CNN model test loss:  0.32514461861537386 accuracy: 0.8674388674388674</span><br></pre></td></tr></table></figure><p>In [74]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predict_sentiment(model, &quot;é…’åº—ä½äºæ˜†æ˜ä¸­å¿ƒåŒº,åœ°ç†ä½ç½®ä¸é”™,å¯æƒœé…’åº—æœåŠ¡æœ‰äº›å·®,ç¬¬ä¸€å¤©æ™šä¸Šå¯èƒ½å…¥ä½çš„å®¢äººä¸å¤š,ç©ºè°ƒæ ¹æœ¬æ²¡å¼€,æ‰“äº†ç”µè¯é—®,è¯´æ˜¯ä¸­å¤®ç©ºè°ƒè¦æ™šä¸Šç»Ÿä¸€å¼€,ç»“æœæ™šä¸Šä¹Ÿæ²¡å¼€,å°±çƒ­äº†ä¸€æ™šä¸Š,ç¬¬äºŒå¤©æœ‰å¼€ä¼šçš„å…¥ä½,æ™šä¸Šå°±æœ‰äº†ç©ºè°ƒ,ä¸å¾—ä¸è¯´é…’åº—ç»æµå¸ä½œçš„å¥½.æˆ¿é—´çš„åºŠå¤ªç¡¬,ç¡çš„ä¸å¥½.é…’åº—çš„æ—©é¤å°±å¦‚å…¶ä»–äººè¯„ä»·ä¸€æ ·,æƒ³æ³•çš„éš¾åƒ.ä¸è¿‡æºç¨‹çš„é¢„è®¢ä»·é’±è¿˜ä¸é”™.&quot;)</span><br></pre></td></tr></table></figure><p>Out[74]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.893503725528717</span><br></pre></td></tr></table></figure><p>learning representation</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CNN </tag>
            
            <tag> RNN/LSTM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NLPæŠ€æœ¯åŸºç¡€æ•´ç†</title>
      <link href="/2020/01/28/NLP%E6%8A%80%E6%9C%AF%E5%9F%BA%E7%A1%80%E6%95%B4%E7%90%86/"/>
      <url>/2020/01/28/NLP%E6%8A%80%E6%9C%AF%E5%9F%BA%E7%A1%80%E6%95%B4%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h2 id="ä»€ä¹ˆæ˜¯è‡ªç„¶è¯­è¨€å¤„ç†ï¼Ÿ"><a href="#ä»€ä¹ˆæ˜¯è‡ªç„¶è¯­è¨€å¤„ç†ï¼Ÿ" class="headerlink" title="ä»€ä¹ˆæ˜¯è‡ªç„¶è¯­è¨€å¤„ç†ï¼Ÿ"></a>ä»€ä¹ˆæ˜¯è‡ªç„¶è¯­è¨€å¤„ç†ï¼Ÿ</h2><p>è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰æ˜¯ä¸€é—¨èè¯­è¨€å­¦ã€è®¡ç®—æœºç§‘å­¦ã€äººå·¥æ™ºèƒ½äºä¸€ä½“çš„ï¼ˆå®éªŒæ€§ï¼‰ç§‘å­¦ï¼Œè§£å†³çš„æ˜¯â€œè®©æœºå™¨å¯ä»¥ç†è§£è‡ªç„¶è¯­è¨€â€ã€‚</p><p>NLP = NLU + NLG</p><h2 id="NLPé—®é¢˜çš„éš¾ç‚¹"><a href="#NLPé—®é¢˜çš„éš¾ç‚¹" class="headerlink" title="NLPé—®é¢˜çš„éš¾ç‚¹"></a>NLPé—®é¢˜çš„éš¾ç‚¹</h2><ul><li>è‡ªç„¶è¯­è¨€æœ‰æ­§ä¹‰ï¼ˆambiguityï¼‰ï¼ŒåŒæ ·çš„å«ä¹‰åˆæœ‰ä¸åŒçš„è¡¨è¾¾æ–¹å¼ï¼ˆvariabilityï¼‰<ul><li>ambiguityï¼šåŒæ ·çš„ä¸€æ®µè¡¨è¿°èƒ½è¡¨ç¤ºä¸åŒçš„æ„æ€</li><li>variabilityï¼šä¸åŒçš„è¡¨è¾¾æ–¹å¼æ˜¯åŒä¸€ä¸ªæ„æ€</li></ul></li></ul><p>coreference resolution</p><p>çˆ¸çˆ¸å·²ç»æŠ±ä¸åŠ¨<strong>å°æ˜</strong>äº†ï¼Œå› ä¸º<strong>ä»–</strong>å¤ªèƒ–äº†ã€‚</p><p><strong>çˆ¸çˆ¸</strong>å·²ç»æŠ±ä¸åŠ¨å°æ˜äº†ï¼Œå› ä¸º<strong>ä»–</strong>å¤ªè™šå¼±äº†ã€‚</p><p>WSC: GPT-2</p><h2 id="æœºå™¨å­¦ä¹ ä¸NLP"><a href="#æœºå™¨å­¦ä¹ ä¸NLP" class="headerlink" title="æœºå™¨å­¦ä¹ ä¸NLP"></a>æœºå™¨å­¦ä¹ ä¸NLP</h2><p>ä½¿ç”¨æœºå™¨å­¦ä¹ çš„æ–¹æ³•è®©æ¨¡å‹èƒ½å¤Ÿå­¦åˆ°è¾“å…¥å’Œè¾“å‡ºä¹‹é—´çš„æ˜ å°„å…³ç³»ã€‚åœ¨NLPä¸­ï¼Œè¾“å…¥ä¸€èˆ¬éƒ½æ˜¯è¯­è¨€æ–‡å­—ï¼Œè€Œè¾“å‡ºåˆ™æ˜¯å„ç§ä¸åŒçš„labelã€‚</p><h2 id="å•è¯"><a href="#å•è¯" class="headerlink" title="å•è¯"></a>å•è¯</h2><p>è‡ªç„¶è¯­è¨€çš„åŸºæœ¬æ„æˆå•å…ƒã€‚</p><h2 id="åˆ†è¯"><a href="#åˆ†è¯" class="headerlink" title="åˆ†è¯"></a>åˆ†è¯</h2><p>è‹±æ–‡ä¸­çš„å•è¯ä¸€èˆ¬ç”¨ç©ºæ ¼éš”å¼€ï¼ˆæ ‡ç‚¹ç¬¦å·ç­‰ç‰¹æ®Šæƒ…å†µé™¤å¤–ï¼‰ï¼Œæ‰€ä»¥å¤©ç„¶åœ°å®Œæˆäº†åˆ†è¯ã€‚ä¸­æ–‡çš„åˆ†è¯åˆ™ä¸é‚£ä¹ˆè‡ªç„¶ï¼Œéœ€è¦äººä¸ºåˆ†è¯ã€‚æ¯”è¾ƒå¥½ç”¨çš„åˆ†è¯å·¥å…·ï¼š<a href="https://github.com/lancopku/pkuseg-python" target="_blank" rel="noopener">https://github.com/lancopku/pkuseg-python</a> </p><p>jieba</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">pip install pkuseg</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> pkuseg</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>seg = pkuseg.pkuseg()           <span class="comment"># ä»¥é»˜è®¤é…ç½®åŠ è½½æ¨¡å‹</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>text = seg.cut(<span class="string">'æˆ‘çˆ±åŒ—äº¬å¤©å®‰é—¨'</span>)  <span class="comment"># è¿›è¡Œåˆ†è¯</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(text)</span><br><span class="line">[<span class="string">'æˆ‘'</span>, <span class="string">'çˆ±'</span>, <span class="string">'åŒ—äº¬'</span>, <span class="string">'å¤©å®‰é—¨'</span>]</span><br></pre></td></tr></table></figure><p>è‹±æ–‡åˆ†è¯å¯ä»¥ä½¿ç”¨NLTK</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> nltk</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sentence = â€œhello, world<span class="string">"</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; tokens = nltk.word_tokenize(sentence)</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; tokens</span></span><br><span class="line"><span class="string">['hello', â€˜,', 'world']</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; sents = nltk.sent_tokenize(documents)</span></span><br></pre></td></tr></table></figure><p>NLTKè¿˜æœ‰ä¸€äº›å¥½ç”¨çš„åŠŸèƒ½ï¼Œä¾‹å¦‚POS Tagging</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> nltk</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>text = nltk.word_tokenize(<span class="string">'what does the fox say'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>text</span><br><span class="line">[<span class="string">'what'</span>, <span class="string">'does'</span>, <span class="string">'the'</span>, <span class="string">'fox'</span>, <span class="string">'say'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>nltk.pos_tag(text)</span><br><span class="line">[(<span class="string">'what'</span>, <span class="string">'WDT'</span>), (<span class="string">'does'</span>, <span class="string">'VBZ'</span>), (<span class="string">'the'</span>, <span class="string">'DT'</span>), (<span class="string">'fox'</span>, <span class="string">'NNS'</span>), (<span class="string">'say'</span>, <span class="string">'VBP'</span>)]</span><br></pre></td></tr></table></figure><p>Named Entity Recognition</p><p><img src="https://uploader.shimo.im/f/56iORCYdcewm9en3.png!thumbnail" alt="img"></p><p>å»é™¤åœç”¨è¯</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> stopwords</span><br><span class="line"><span class="comment"># å…ˆtokenä¸€æŠŠï¼Œå¾—åˆ°ä¸€ä¸ªword_list</span></span><br><span class="line"><span class="comment"># ...</span></span><br><span class="line"><span class="comment"># ç„¶åfilterä¸€æŠŠ</span></span><br><span class="line">filtered_words = </span><br><span class="line">[word <span class="keyword">for</span> word <span class="keyword">in</span> word_list <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> stopwords.words(<span class="string">'english'</span>)]</span><br></pre></td></tr></table></figure><p>one hot vector [0, 0, 0, 1, 0, 0â€¦]</p><h2 id="Bag-of-Wordså’ŒTF-IDF"><a href="#Bag-of-Wordså’ŒTF-IDF" class="headerlink" title="Bag of Wordså’ŒTF-IDF"></a>Bag of Wordså’ŒTF-IDF</h2><p>è¯åŒ…æ¨¡å‹</p><p>vocab: 50000ä¸ªå•è¯</p><p>æ–‡æœ¬â€“&gt; 50000ç»´å‘é‡</p><p>{a: 0, an: 1, the:2, â€¦.}</p><p>[100, 50, 30, â€¦]</p><p><strong>TF: Term Frequency</strong>, è¡¡é‡ä¸€ä¸ªtermåœ¨æ–‡æ¡£ä¸­å‡ºç°å¾—æœ‰å¤šé¢‘ç¹ã€‚</p><p>TF(t) = (tå‡ºç°åœ¨æ–‡æ¡£ä¸­çš„æ¬¡æ•°) / (æ–‡æ¡£ä¸­çš„termæ€»æ•°)</p><p>æ–‡æ¡£ä¸€ä¸ª10000ä¸ªå•è¯ï¼Œ100ä¸ªthe</p><p>TF(the) = 0.01</p><p><strong>IDF: Inverse Document Frequency</strong>, è¡¡é‡ä¸€ä¸ªtermæœ‰å¤šé‡è¦ã€‚</p><p>æœ‰äº›è¯å‡ºç°çš„å¾ˆå¤šï¼Œä½†æ˜¯ä¿¡æ¯é‡å¯èƒ½ä¸å¤§ï¼Œæ¯”å¦‚â€™isâ€™ï¼Œâ€™theâ€˜ï¼Œâ€™andâ€˜ä¹‹ç±»ã€‚</p><p>ä¸ºäº†å¹³è¡¡ï¼Œæˆ‘ä»¬æŠŠç½•è§çš„è¯çš„é‡è¦æ€§ï¼ˆweightï¼‰è°ƒé«˜ï¼ŒæŠŠå¸¸è§è¯çš„é‡è¦æ€§è°ƒä½ã€‚</p><p>IDF(t) = lg(æ–‡æ¡£æ€»æ•° / å«æœ‰tçš„æ–‡æ¡£æ€»æ•° + 1)</p><p>è¯­æ–™ä¸€å…±åœ¨3ç¯‡æ–‡ç« ä¸­å‡ºç°ï¼Œä½†æ˜¯æˆ‘ä»¬ä¸€å…±æœ‰100,000ç¯‡æ–‡ç« ã€‚IDF(julyedu) = log(100,000/3)</p><p><strong>TF-IDF = TF * IDF</strong></p><p>TFIDFè¯åŒ…</p><p>a, 100*0.000001</p><p>[0.0001, ]</p><h2 id="Distributional-Word-Vectors-è¯å‘é‡"><a href="#Distributional-Word-Vectors-è¯å‘é‡" class="headerlink" title="Distributional Word Vectors è¯å‘é‡"></a>Distributional Word Vectors è¯å‘é‡</h2><p>distributional semantics</p><p>â€œThe distributional hypothesis in linguistics is derived from the semantic theory of language usage, i.e. words that are used and occur in the same contexts tend to purport similar meanings.â€</p><p>å¦‚æœä¸¤ä¸ªå•è¯æ€»æ˜¯åœ¨åŒæ ·çš„è¯­å¢ƒä¸‹å‡ºç°ï¼Œé‚£ä¹ˆè¡¨ç¤ºä»–ä»¬ä¹‹é—´å­˜åœ¨æŸç§ç›¸å…³æ€§/ç›¸ä¼¼æ€§ã€‚</p><p>Counting Context Words</p><p><img src="https://uploader.shimo.im/f/OClAoRm660cjqZR3.png!thumbnail" alt="img"></p><p>50000 * 50000</p><p>50000*300  </p><p>300*300</p><p>300*50000</p><p>åœ¨æˆ‘ä»¬å®šä¹‰çš„å›ºå®šå¤§å°çš„context windowä¸‹å‡ºç°çš„å•è¯ç»„ï¼Œå°±æ˜¯co-occuring word pairsã€‚</p><p>å¯¹äºå¥å­çš„å¼€å¤´å’Œç»“å°¾ï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸¤ä¸ªç‰¹æ®Šçš„ç¬¦å·  &lt;s&gt;   å’Œ  &lt;/s&gt;ã€‚</p><h2 id="å•è¯ç›¸ä¼¼åº¦"><a href="#å•è¯ç›¸ä¼¼åº¦" class="headerlink" title="å•è¯ç›¸ä¼¼åº¦"></a>å•è¯ç›¸ä¼¼åº¦</h2><p>ä½¿ç”¨è¯å‘é‡é—´çš„cosineç›¸ä¼¼åº¦ï¼ˆcosine å¤¹è§’ï¼‰, u, væ˜¯ä¸¤ä¸ªè¯å‘é‡</p><p><img src="https://uploader.shimo.im/f/tQdVXIYvqV4KYDft.png!thumbnail" alt="img">= cosine(u, v)</p><p>å•è¯â€cookedâ€å‘¨å›´context windowsæœ€å¸¸è§çš„å•è¯</p><p><img src="https://uploader.shimo.im/f/5yQkBDvdSLMwl5D7.png!thumbnail" alt="img"></p><p>Pointwise Mutual Information (PMI)</p><p><img src="https://uploader.shimo.im/f/5y0BeYWd6FcaIvsY.png!thumbnail" alt="img"></p><p>ç‹¬ç«‹ P(x)*P(y) = P(x, y)</p><p>PMIè¡¨ç¤ºäº†äº‹ä»¶ x å’Œäº‹ä»¶ y ä¹‹é—´æ˜¯å¦å­˜åœ¨ç›¸å…³æ€§ã€‚</p><p>ä¸ â€œcookedâ€ PMIå€¼æœ€é«˜çš„å•è¯</p><p><img src="https://uploader.shimo.im/f/ywl7Mm0fkBYm9phX.png!thumbnail" alt="img"></p><h2 id="å¦‚ä½•è¯„ä¼°è¯å‘é‡çš„å¥½åï¼Ÿ"><a href="#å¦‚ä½•è¯„ä¼°è¯å‘é‡çš„å¥½åï¼Ÿ" class="headerlink" title="å¦‚ä½•è¯„ä¼°è¯å‘é‡çš„å¥½åï¼Ÿ"></a>å¦‚ä½•è¯„ä¼°è¯å‘é‡çš„å¥½åï¼Ÿ</h2><p>æ ‡å‡†åŒ–çš„å•è¯ç›¸ä¼¼åº¦æ•°æ®é›†</p><ul><li>Assign a numerical similarity score between 0 and 10 (0 = words are totally    unrelated, 10 = words are VERY closely related).</li></ul><p><img src="https://uploader.shimo.im/f/ToYFke24QkcZ1Nnc.png!thumbnail" alt="img"><img src="https://uploader.shimo.im/f/QTXGcqteVe4Gw2ly.png!thumbnail" alt="img"></p><p>cosine(journey, voyage) = </p><p>cosine(king, queen) = </p><p>spearmanâ€™s R åˆ†æ•°</p><p><strong>Sparse vs. dense vectors</strong></p><p>æ ¹æ®context windowå®šä¹‰çš„è¯å‘é‡éå¸¸é•¿ï¼Œ<strong>å¾ˆå¤šä½ç½®ä¸Šéƒ½æ˜¯0.</strong> è¡¨ç¤ºæˆ‘ä»¬çš„ä¿¡æ¯å¯†åº¦æ˜¯å¾ˆä½çš„</p><ul><li><p>ä½ç»´åº¦è¯å‘é‡æ›´å®¹æ˜“è®­ç»ƒæ¨¡å‹ï¼Œå ç”¨çš„å†…å­˜/ç¡¬ç›˜ä¹Ÿä¼šæ¯”è¾ƒå°ã€‚</p></li><li><p>ä½ç»´åº¦è¯å‘é‡èƒ½å¤Ÿå­¦åˆ°ä¸€äº›å•è¯é—´çš„å…³ç³»ï¼Œä¾‹å¦‚æœ‰äº›å•è¯ä¹‹é—´æ˜¯è¿‘ä¹‰è¯ã€‚</p></li></ul><p>é™ç»´ç®—æ³•</p><ul><li><p>PCA</p></li><li><p>SVD</p></li><li><p>Brown cluster</p></li><li><p><strong>Word2Vec</strong></p></li></ul><h2 id="Contextualized-Word-Vectors"><a href="#Contextualized-Word-Vectors" class="headerlink" title="Contextualized Word Vectors"></a>Contextualized Word Vectors</h2><p>è¿‘ä¸¤å¹´éå¸¸æµè¡Œçš„åšæ³•ï¼Œä¸ä»…ä»…æ˜¯é’ˆå¯¹å•ä¸ªå•è¯è®­ç»ƒè¯å‘é‡ï¼Œè€Œæ˜¯æ ¹æ®å•è¯å‡ºç°çš„è¯­å¢ƒç»™å‡ºè¯å‘é‡ï¼Œæ˜¯çš„è¯¥è¯å‘é‡æ—¢åŒ…å«å½“å‰å•è¯çš„ä¿¡æ¯ï¼ŒåˆåŒ…å«å•è¯å‘¨å›´contextçš„ä¿¡æ¯ã€‚</p><ul><li><p>BERT, RoBERTa, ALBERT, T5</p></li><li><p>GPT2</p></li></ul><h2 id="æ–‡æœ¬åˆ†ç±»"><a href="#æ–‡æœ¬åˆ†ç±»" class="headerlink" title="æ–‡æœ¬åˆ†ç±»"></a>æ–‡æœ¬åˆ†ç±»</h2><p>NLPæ•°æ®é›†</p><ul><li>NLPæ•°æ®é›†ä¸€èˆ¬åŒ…å«è¾“å…¥ï¼ˆinputsï¼Œä¸€èˆ¬æ˜¯æ–‡å­—ï¼‰å’Œè¾“å‡ºï¼ˆoutputsï¼Œä¸€èˆ¬æ˜¯æŸç§æ ‡æ³¨ï¼‰ã€‚</li></ul><p>æ ‡æ³¨</p><ul><li><p>ç›‘ç£å­¦ä¹ éœ€è¦æ ‡æ³¨è¿‡çš„æ•°æ®é›†ï¼Œè¿™äº›æ ‡æ³¨ä¸€èˆ¬è¢«ç§°ä¸ºground truthã€‚</p></li><li><p>åœ¨è‡ªç„¶è¯­è¨€å¤„ç†æ•°æ®é›†ä¸­ï¼Œæ ‡æ³¨å¾€å¾€æ˜¯ç”±äººæ‰‹åŠ¨æ ‡æ³¨çš„</p></li><li><p>äººä»¬å¾€å¾€ä¼šå¯¹æ•°æ®çš„æ ‡æ³¨æœ‰ä¸åŒçš„æ„è§ï¼Œå› ä¸ºå¾ˆå¤šæ—¶å€™ä¸åŒçš„äººå¯¹åŒæ ·çš„è¯­è¨€ä¼šæœ‰ä¸åŒçš„ç†è§£ã€‚æ‰€ä»¥æˆ‘ä»¬ä¹Ÿä¼šæŠŠè¿™äº›æ ‡æ³¨ç§°ä¸ºgold standardï¼Œè€Œä¸æ˜¯ground truthã€‚</p></li></ul><p>NLPæ•°æ®é›†å¦‚ä½•æ„å»º</p><ul><li><p>ä»˜é’±è¯·äººæ ‡æ³¨</p><ul><li>æ¯”è¾ƒä¼ ç»Ÿçš„åšæ³•</li><li>ç ”ç©¶å‘˜å†™ä¸‹æ ‡æ³¨çš„guidelineï¼Œç„¶åèŠ±é’±è¯·äººæ ‡æ³¨ï¼ˆä»¥å‰ä¸€èˆ¬è¯·ä¸€äº›ä¸“ä¸šçš„è¯­è¨€å­¦å®¶ï¼‰</li><li>æ ‡æ³¨çš„è´¨é‡ä¼šæ¯”è¾ƒé«˜ï¼Œä½†æ˜¯æˆæœ¬ä¹Ÿé«˜</li><li>ä¾‹å¦‚ï¼ŒPenn Treebank(1993)</li></ul></li><li><p>Croudsourcing</p><ul><li>ç°åœ¨æ¯”è¾ƒæµè¡Œ</li><li>ä¸€èˆ¬ä¸ä¸“é—¨è®­ç»ƒæ ‡æ³¨è€…ï¼ˆannotatorï¼‰ï¼Œä½†æ˜¯å¯ä»¥å¯¹åŒä¸€æ¡æ•°æ®å–å¾—å¤šæ¡æ ·æœ¬</li><li>ä¾‹å¦‚ï¼ŒStanford Sentiment Treebank</li></ul></li><li><p>è‡ªç„¶æ‹¥æœ‰æ ‡æ³¨çš„æ•°æ®é›†</p><ul><li>æ³•å¾‹æ–‡ä»¶çš„ä¸­è‹±æ–‡ç‰ˆæœ¬ï¼Œå¯ä»¥ç”¨äºè®­ç»ƒç¿»è¯‘æ¨¡å‹</li><li>æŠ¥çº¸çš„å†…å®¹åˆ†ç±»</li><li>èŠå¤©è®°å½•</li><li>æ–‡æœ¬æ‘˜è¦ï¼ˆæ–°é—»çš„å…¨æ–‡å’Œæ‘˜è¦ï¼‰</li></ul></li></ul><p>æ ‡æ³¨è€…åŒæ„åº¦ Annotator Agreement</p><ul><li>ç»™å®šä¸¤ä¸ªæ ‡æ³¨è€…ç»™å‡ºçš„æ‰€æœ‰æ ‡æ³¨ï¼Œå¦‚ä½•è®¡ç®—ä»–ä»¬ä¹‹é—´çš„æ ‡æ³¨æ˜¯å¦æ¯”è¾ƒç»Ÿä¸€ï¼Ÿ<ul><li>ç›¸åŒæ ‡æ³¨çš„ç™¾åˆ†æ¯”ï¼Ÿ</li><li>Cohenâ€™s Kappa</li></ul></li></ul><p><img src="https://uploader.shimo.im/f/tPj4cDeD0qwzoRl8.png!thumbnail" alt="img"></p><p>æ¥è‡ªç»´åŸºç™¾ç§‘</p><ul><li>ä¹Ÿæœ‰æ›´å¤šåˆ«çš„æµ‹é‡æ–¹æ³•</li></ul><h2 id="å¸¸è§çš„æ–‡æœ¬åˆ†ç±»æ•°æ®é›†"><a href="#å¸¸è§çš„æ–‡æœ¬åˆ†ç±»æ•°æ®é›†" class="headerlink" title="å¸¸è§çš„æ–‡æœ¬åˆ†ç±»æ•°æ®é›†"></a>å¸¸è§çš„æ–‡æœ¬åˆ†ç±»æ•°æ®é›†</h2><p>è‹±æ–‡ï¼š</p><ul><li>AGNEWS, DBPedia, TREC: <a href="http://nlpprogress.com/english/text_classification.html" target="_blank" rel="noopener">http://nlpprogress.com/english/text_classification.html</a></li></ul><p>ä¸­æ–‡ï¼š</p><ul><li><a href="https://github.com/SophonPlus/ChineseNlpCorpus" target="_blank" rel="noopener">https://github.com/SophonPlus/ChineseNlpCorpus</a></li></ul><h2 id="æ–‡æœ¬åˆ†ç±»æ¨¡å‹"><a href="#æ–‡æœ¬åˆ†ç±»æ¨¡å‹" class="headerlink" title="æ–‡æœ¬åˆ†ç±»æ¨¡å‹"></a>æ–‡æœ¬åˆ†ç±»æ¨¡å‹</h2><p>ä»€ä¹ˆæ˜¯ä¸€ä¸ªåˆ†ç±»å™¨ï¼Ÿ</p><ul><li><p>ä¸€ä¸ªä»è¾“å…¥ï¼ˆinputsï¼‰ç‰¹å¾xæŠ•å°„åˆ°æ ‡æ³¨yçš„å‡½æ•°</p></li><li><p>ä¸€ä¸ªç®€å•çš„åˆ†ç±»å™¨ï¼š</p><ul><li>å¯¹äºè¾“å…¥<strong>x</strong>ï¼Œç»™æ¯ä¸€ä¸ªlabel yæ‰“ä¸€ä¸ªåˆ†æ•°ï¼Œscore(<strong>x</strong>, y, <strong>w</strong>)ï¼Œå…¶ä¸­<strong>w</strong>æ˜¯æ¨¡å‹çš„å‚æ•°</li><li>åˆ†ç±»é—®é¢˜ä¹Ÿå°±æ˜¯é€‰å‡ºåˆ†æ•°æœ€é«˜çš„yï¼šclassify(<strong>x, w</strong>) = argmax_y score(<strong>x</strong>, y, <strong>w</strong>)</li></ul></li></ul><p>Modeling, Inference, Learning</p><p><img src="https://uploader.shimo.im/f/ZMjjEt9ljYYZOe0M.png!thumbnail" alt="img"></p><h2 id="Modeling"><a href="#Modeling" class="headerlink" title="Modeling"></a>Modeling</h2><p>äºŒå…ƒæƒ…æ„Ÿåˆ†ç±»</p><p>classify(<strong>x, w</strong>)  = argmax_y score(<strong>x,</strong> y, <strong>w</strong>)</p><p>å¦‚æœæˆ‘ä»¬é‡‡ç”¨çº¿æ€§æ¨¡å‹ï¼Œé‚£ä¹ˆæ¨¡å‹å¯ä»¥è¢«å†™ä¸º</p><p><img src="https://uploader.shimo.im/f/OS6m4GnrJW8nxTQx.png!thumbnail" alt="img"></p><p>ç°åœ¨çš„é—®é¢˜æ˜¯ï¼Œæˆ‘ä»¬å¦‚ä½•å®šä¹‰fï¼Ÿå¯¹äºæ¯”è¾ƒå¸¸è§çš„æœºå™¨å­¦ä¹ é—®é¢˜ï¼Œæˆ‘ä»¬çš„è¾“å…¥å¾€å¾€æ˜¯æ ¼å¼å›ºå®šçš„ï¼Œä½†æ˜¯NLPçš„è¾“å…¥ä¸€èˆ¬æ˜¯é•¿åº¦ä¸å›ºå®šçš„æ–‡æœ¬ã€‚è¿™é‡Œå°±æ¶‰åŠåˆ°å¦‚ä½•æŠŠæ–‡æœ¬è½¬æ¢æˆç‰¹å¾ï¼ˆfeatureï¼‰ã€‚</p><ul><li><p>è¿‡å»25å¹´ï¼šç‰¹å¾å·¥ç¨‹ï¼ˆfeature engineeringï¼‰ï¼Œäººä¸ºå®šåˆ¶ï¼Œæ¯”è¾ƒå¤æ‚ï¼Œåªé€‚ç”¨äºæŸä¸€ç±»é—®é¢˜</p></li><li><p>è¿‡å»5å¹´ï¼šè¡¨ç¤ºå­¦ä¹ ï¼ˆrepresentation learningï¼‰, ICLRï¼Œ international conference for learning representations</p></li></ul><p>å¸¸è§çš„featuresï¼š</p><p>f1: æ–‡æœ¬æ˜¯æ­£é¢æƒ…æ„Ÿï¼Œæ–‡æœ¬åŒ…å«â€œå¥½â€</p><p>f2: æ–‡æœ¬æ˜¯è´Ÿé¢æƒ…æ„Ÿï¼Œæ–‡æœ¬åŒ…å«â€œå¥½â€</p><p>ã€‚ã€‚ã€‚</p><h2 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h2><p>æ¯”è¾ƒç›´è§‚ï¼Œç»™å®šä¸€æ®µè¯ï¼Œåœ¨æ¯ä¸ªLabelä¸Šæ‰“åˆ†ï¼Œç„¶åå–åˆ†æ•°æœ€å¤§çš„labelä½œä¸ºé¢„æµ‹ã€‚</p><h2 id="Learning"><a href="#Learning" class="headerlink" title="Learning"></a>Learning</h2><ul><li><p>æ ¹æ®è®­ç»ƒæ•°æ®å¾—åˆ°æ¨¡å‹æƒé‡<strong>w</strong></p></li><li><p>æŠŠæ•°æ®åˆ†ä¸ºè®­ç»ƒé›†ï¼ˆtrainï¼‰ï¼ŒéªŒè¯é›†ï¼ˆdev, valï¼‰æµ‹è¯•é›†ï¼ˆtestï¼‰</p></li><li><p>åœ¨NLPä¸­ï¼Œæˆ‘ä»¬å¸¸å¸¸ä½¿ç”¨ä¸€ç§learning framework: Empirical Risk Minimization</p><ul><li>æŸå¤±å‡½æ•°ï¼ˆcost functionï¼‰ï¼šå¯¹æ¯”æ¨¡å‹çš„é¢„æµ‹å’Œgold standardï¼Œè®¡ç®—ä¸€ä¸ªåˆ†æ•°<img src="https://uploader.shimo.im/f/d4DeJ9HiUWo9s7Lm.png!thumbnail" alt="img"></li><li>æŸå¤±å‡½æ•°ä¸æˆ‘ä»¬çœŸæ­£ä¼˜åŒ–çš„ç›®æ ‡è¦å°½é‡ä¿æŒä¸€è‡´</li><li>ä¸€èˆ¬æ¥è¯´å¦‚æœcostä¸º0ï¼Œè¡¨ç¤ºæˆ‘ä»¬çš„æ¨¡å‹é¢„æµ‹å®Œå…¨æ­£ç¡®</li><li>å¯¹äºæ–‡æœ¬åˆ†ç±»æ¥è¯´ï¼Œæˆ‘ä»¬åº”è¯¥ä½¿ç”¨æ€æ ·çš„æŸå¤±å‡½æ•°å‘¢ï¼Ÿ</li></ul></li></ul><p>é”™è¯¯ç‡ï¼š<img src="https://uploader.shimo.im/f/E9r4QuAPgOgrMABu.png!thumbnail" alt="img"></p><p>Risk Minimization:</p><p>ç»™å®šè®­ç»ƒæ•°æ® <img src="https://uploader.shimo.im/f/osePhB4L13wW9hVW.png!thumbnail" alt="img">xè¡¨ç¤ºè¾“å…¥ï¼Œyè¡¨ç¤ºlabel</p><p>æˆ‘ä»¬çš„ç›®æ ‡æ˜¯<img src="https://uploader.shimo.im/f/HsQ3wAnDSF05627e.png!thumbnail" alt="img"></p><p>Empirical Risk Minimization <img src="https://uploader.shimo.im/f/j8m6S8mQx20BXvuG.png!thumbnail" alt="img"></p><p>æˆ‘ä»¬ä¹‹å‰å®šä¹‰çš„0-1æŸå¤±å‡½æ•°æ˜¯å¾ˆéš¾ä¼˜åŒ–çš„ï¼Œå› ä¸º0-1lossä¸è¿ç»­ï¼Œæ‰€ä»¥æ— æ³•ä½¿ç”¨åŸºäºæ¢¯åº¦çš„ä¼˜åŒ–æ–¹æ³•ã€‚</p><p>loss.backward() # \d loss / \d w = gradient</p><p>optimizer.step() # w - learning_rate*gradient</p><p>cost = -score(x, y_label, w) é—®é¢˜ï¼šæ²¡æœ‰è€ƒè™‘åˆ°labelä¹‹é—´çš„å…³ç³»ï¼</p><p>ä¸€äº›å…¶ä»–çš„æŸå¤±å‡½æ•°</p><p><strong>perceptron loss</strong></p><p><img src="https://uploader.shimo.im/f/Z0tFJCnDmosbrqSl.png!thumbnail" alt="img"></p><p><strong>hinge loss</strong></p><p><img src="https://uploader.shimo.im/f/4NtGiIfAhsUB1CD0.png!thumbnail" alt="img"></p><p><img src="https://uploader.shimo.im/f/IYZsqDJtKqE1xTNS.png!thumbnail" alt="img"></p><h3 id="Log-Loss-Cross-Entropy-Loss"><a href="#Log-Loss-Cross-Entropy-Loss" class="headerlink" title="Log Loss/Cross Entropy Loss"></a>Log Loss/Cross Entropy Loss</h3><p><img src="https://uploader.shimo.im/f/t5msLvPFMsQMSZ7n.png!thumbnail" alt="img"></p><p>æˆ‘ä»¬ä¹‹å‰åªæœ‰score(x, y, w)ï¼Œæ€ä¹ˆæ ·å®šä¹‰p_w(y | z)</p><ul><li><p>è®©gold standard labelçš„æ¡ä»¶æ¦‚ç‡å°½å¯èƒ½å¤§</p></li><li><p>ä½¿ç”¨softmaxæŠŠscoreè½¬åŒ–æˆæ¦‚ç‡</p></li><li><p>å…¶ä¸­çš„score functionå¯ä»¥æ˜¯å„ç§å‡½æ•°ï¼Œä¾‹å¦‚ä¸€ä¸ªç¥ç»ç½‘ç»œ</p></li></ul><p>æŸå¤±å‡½æ•°å¾€å¾€ä¼šç»“åˆregularization æ­£åˆ™é¡¹</p><ul><li><p>L2 regularization <img src="https://uploader.shimo.im/f/pZ2L5AVPvWE5Hksz.png!thumbnail" alt="img"></p></li><li><p>L1 regularization <img src="https://uploader.shimo.im/f/fG2yM4re1x8ZURLk.png!thumbnail" alt="img"></p></li></ul><p>æ¨¡å‹è®­ç»ƒ</p><ul><li>(stochastic, batch) gradient descent</li></ul><h2 id="è¯­è¨€æ¨¡å‹"><a href="#è¯­è¨€æ¨¡å‹" class="headerlink" title="è¯­è¨€æ¨¡å‹"></a>è¯­è¨€æ¨¡å‹</h2><p>è¯­è¨€æ¨¡å‹ï¼šç»™å¥å­è®¡ç®—ä¸€ä¸ªæ¦‚ç‡</p><p>ä¸ºä»€ä¹ˆä¼šæœ‰è¿™æ ·ä¸€ä¸ªå¥‡æ€ªçš„ä»»åŠ¡ï¼Ÿ</p><ul><li><p>æœºå™¨ç¿»è¯‘ï¼šPï¼ˆæˆ‘å–œæ¬¢åƒæ°´æœï¼‰&gt; Pï¼ˆæˆ‘å–œæ¬¢å–æ°´æœï¼‰</p></li><li><p>æ‹¼å†™æ£€æŸ¥ï¼šPï¼ˆæˆ‘æƒ³åƒé¥­ï¼‰&gt; Pï¼ˆæˆ‘åƒåƒé¥­ï¼‰</p></li><li><p>è¯­éŸ³è¯†åˆ«ï¼šP ï¼ˆæˆ‘çœ‹è§äº†ä¸€æ¶é£æœºï¼‰&gt; Pï¼ˆæˆ‘çœ‹è§äº†ä¸€æ¶æ–æµï¼‰</p></li><li><p>summarizaton, question answering, etc. </p></li></ul><p>æ–‡æœ¬è‡ªåŠ¨è¡¥å…¨ã€‚ã€‚ã€‚</p><h2 id="æ¦‚ç‡è¯­è¨€æ¨¡å‹ï¼ˆprobablistic-language-modelingï¼‰"><a href="#æ¦‚ç‡è¯­è¨€æ¨¡å‹ï¼ˆprobablistic-language-modelingï¼‰" class="headerlink" title="æ¦‚ç‡è¯­è¨€æ¨¡å‹ï¼ˆprobablistic language modelingï¼‰"></a>æ¦‚ç‡è¯­è¨€æ¨¡å‹ï¼ˆprobablistic language modelingï¼‰</h2><ul><li><p>ç›®æ ‡ï¼šè®¡ç®—ä¸€ä¸²å•è¯è¿æˆä¸€ä¸ªå¥å­çš„æ¦‚ç‡ P(<strong>w</strong>) = P(w_1, â€¦, w_n)</p></li><li><p>ç›¸å…³çš„ä»»åŠ¡ P(w_4|w_1, â€¦, w_3) </p></li><li><p>è¿™ä¸¤ä¸ªä»»åŠ¡çš„æ¨¡å‹éƒ½ç§°ä¹‹ä¸ºè¯­è¨€æ¨¡å‹</p></li></ul><p>æ¡ä»¶æ¦‚ç‡</p><p><img src="https://uploader.shimo.im/f/jnAscu6ZX6Ua0iKb.png!thumbnail" alt="img"></p><p>é©¬å°”ç§‘å¤«å‡è®¾</p><ul><li><p>ä¸Šè¿°æ¡ä»¶æ¦‚ç‡å…¬å¼åªå–å†³äºæœ€è¿‘çš„n-1ä¸ªå•è¯ P(w_i|w_1, â€¦, w_{i-1}) = P(w_i | w_{i-n+1}, â€¦, w_{i-1})</p></li><li><p>æˆ‘ä»¬åˆ›å»ºå‡ºäº†n-gramæ¨¡å‹</p></li><li><p>ç®€å•çš„æ¡ˆä¾‹ï¼Œbigramæ¨¡å‹</p></li></ul><p><img src="https://uploader.shimo.im/f/I2HL7hp9YtQpnrCY.png!thumbnail" alt="img"></p><p>ä¸€äº›Smoothingæ–¹æ³•</p><ul><li>â€œAdd-1â€ estimation</li></ul><p><img src="https://uploader.shimo.im/f/K8GCxNZ0tvAHbT6k.png!thumbnail" alt="img"></p><ul><li><p>Backoffï¼Œå¦‚æœä¸€äº›trigramå­˜åœ¨ï¼Œå°±æ˜¯ç”¨trigramï¼Œå¦‚æœä¸å­˜åœ¨ï¼Œå°±æ˜¯ç”¨bigramï¼Œå¦‚æœbigramä¹Ÿä¸å­˜åœ¨ï¼Œå°±é€€è€Œæ±‚å…¶æ¬¡ä½¿ç”¨unigramã€‚</p></li><li><p>interpolationï¼šæ··åˆä½¿ç”¨unigram, bigram, trigram</p></li></ul><p>Perplexity: ç”¨äºè¯„ä¼°è¯­è¨€æ¨¡å‹çš„å¥½åã€‚è¯„ä¼°çš„è¯­è¨€ï¼Œæˆ‘ç°åœ¨ç»™ä½ ä¸€å¥—æ¯”è¾ƒå¥½çš„è¯­è¨€ï¼Œæˆ‘å¸Œæœ›è‡ªå·±çš„è¯­è¨€æ¨¡å‹èƒ½å¤Ÿç»™è¿™æ®µè¯å°½å¯èƒ½é«˜çš„åˆ†æ•°ã€‚</p><p><img src="https://uploader.shimo.im/f/tq4vTXGrt80lNPky.png!thumbnail" alt="img"> l è¶Šå¤§è¶Šå¥½ï¼Œ-l è¶Šå°è¶Šå¥½</p><p><img src="https://uploader.shimo.im/f/QGDnJuSZy4U48KFA.png!thumbnail" alt="img">PP è¶Šå°è¶Šå¥½ å›°æƒ‘åº¦</p><p>perplexityè¶Šä½ = æ¨¡å‹è¶Šå¥½</p><h2 id="ç®€å•çš„Trigramç¥ç»ç½‘ç»œè¯­è¨€æ¨¡å‹"><a href="#ç®€å•çš„Trigramç¥ç»ç½‘ç»œè¯­è¨€æ¨¡å‹" class="headerlink" title="ç®€å•çš„Trigramç¥ç»ç½‘ç»œè¯­è¨€æ¨¡å‹"></a>ç®€å•çš„Trigramç¥ç»ç½‘ç»œè¯­è¨€æ¨¡å‹</h2><p><img src="https://uploader.shimo.im/f/CJrPG8AsEUktoMmU.png!thumbnail" alt="img"></p><p>è¿™ä¸ªæ¨¡å‹å¯ä»¥ä½¿ç”¨log lossæ¥è®­ç»ƒã€‚</p><p>æˆ‘ä»¬è¿˜å¯ä»¥åœ¨è¿™ä¸ªæ¨¡å‹çš„åŸºç¡€ä¸Šå¢åŠ hidden layer </p><p><img src="https://uploader.shimo.im/f/bV1ttfAFazcOcXpj.png!thumbnail" alt="img"></p><h2 id="å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRecurrent-Neural-Networksï¼‰"><a href="#å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRecurrent-Neural-Networksï¼‰" class="headerlink" title="å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRecurrent Neural Networksï¼‰"></a>å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRecurrent Neural Networksï¼‰</h2><p><img src="https://uploader.shimo.im/f/WUuDdC1NvcoEvYtG.png!thumbnail" alt="img"></p><p>åŸºäºå¾ªç¯ç¥ç»ç½‘ç»œçš„è¯­è¨€æ¨¡å‹</p><p><img src="https://uploader.shimo.im/f/xveC6xbloAUcZNsk.png!thumbnail" alt="img"></p><p><img src="https://uploader.shimo.im/f/4OYGZmwTiZIi45JQ.png!thumbnail" alt="img"></p><p>Long Short-term Memory</p><p><img src="https://uploader.shimo.im/f/LAcBJG4tRCEhosvb.png!thumbnail" alt="img"></p><p>Gates</p><p><img src="https://uploader.shimo.im/f/ALMg6pQ29vIRto5c.png!thumbnail" alt="img"></p><p>Gated Recurrent Unit (GRU)</p><p><img src="https://uploader.shimo.im/f/F7xsa6NCDqQwhXLD.png!thumbnail" alt="img"></p><p><a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">https://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></p><h1 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h1><p><img src="https://uploader.shimo.im/f/w3BqZxsJscgnTdOo.png!thumbnail" alt="img"></p><p>æˆ‘ä»¬çš„ç›®æ ‡æ˜¯åˆ©ç”¨æ²¡æœ‰æ ‡æ³¨è¿‡çš„çº¯æ–‡æœ¬è®­ç»ƒæœ‰ç”¨çš„è¯å‘é‡ï¼ˆword vectorsï¼‰</p><p>skip-gram (window size = 5)</p><blockquote><p>agriculture is the tradional mainstay of the cambodian economy . but benares has been destroyed by an earthquake.</p></blockquote><p><img src="https://uploader.shimo.im/f/HCdEvmDFLjQaKEjy.png!thumbnail" alt="img"></p><p>skip-gramä¸­ä½¿ç”¨çš„score function</p><p><img src="https://uploader.shimo.im/f/2zIZmqQGMHspT70Y.png!thumbnail" alt="img"></p><p>æ¨¡å‹å‚æ•°ï¼Œæ‰€æœ‰çš„å•è¯çš„è¯å‘é‡ï¼ŒåŒ…æ‹¬è¾“å…¥å‘é‡å’Œè¾“å‡ºå‘é‡</p><h2 id="learning"><a href="#learning" class="headerlink" title="learning"></a>learning</h2><p><img src="https://uploader.shimo.im/f/N7MJfS38rIYSTgPJ.png!thumbnail" alt="img"></p><p><img src="https://uploader.shimo.im/f/gONaJMt6zNYKXwOw.png!thumbnail" alt="img"></p><p>æ³¨æ„è¿™ä¸ªæ¦‚ç‡æ¨¡å‹éœ€è¦æ±‡æ€»å•è¯è¡¨ä¸­çš„æ‰€æœ‰å•è¯ï¼Œè®¡ç®—é‡éå¸¸ä¹‹å¤§</p><h2 id="Negative-Sampling"><a href="#Negative-Sampling" class="headerlink" title="Negative Sampling"></a>Negative Sampling</h2><p><img src="https://uploader.shimo.im/f/3z40P9PADe4YxhYr.png!thumbnail" alt="img"></p><p>éšæœºç”Ÿæˆä¸€äº›è´Ÿä¾‹ï¼Œç„¶åä¼˜åŒ–ä»¥ä¸ŠæŸå¤±å‡½æ•°</p><p><img src="https://uploader.shimo.im/f/sa2fnlo4tvA5zP4I.png!thumbnail" alt="img"></p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> è¯­è¨€æ¨¡å‹ </tag>
            
            <tag> RNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CNN-Image-Classification</title>
      <link href="/2020/01/18/CNN-Image-Classification/"/>
      <url>/2020/01/18/CNN-Image-Classification/</url>
      
        <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line">print(<span class="string">"PyTorch Version: "</span>,torch.__version__)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PyTorch Version:  1.0.0</span><br></pre></td></tr></table></figure><p>é¦–å…ˆæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªåŸºäºConvNetçš„ç®€å•ç¥ç»ç½‘ç»œ</p><p>In [4]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">20</span>, <span class="number">5</span>, <span class="number">1</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">20</span>, <span class="number">50</span>, <span class="number">5</span>, <span class="number">1</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">4</span>*<span class="number">4</span>*<span class="number">50</span>, <span class="number">500</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">500</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = F.relu(self.conv1(x))</span><br><span class="line">        x = F.max_pool2d(x, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        x = F.relu(self.conv2(x))</span><br><span class="line">        x = F.max_pool2d(x, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        x = x.view(<span class="number">-1</span>, <span class="number">4</span>*<span class="number">4</span>*<span class="number">50</span>)</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        <span class="keyword">return</span> F.log_softmax(x, dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>NLL lossçš„å®šä¹‰</p><p>â„“(ğ‘¥,ğ‘¦)=ğ¿={ğ‘™1,â€¦,ğ‘™ğ‘}âŠ¤,ğ‘™ğ‘›=âˆ’ğ‘¤ğ‘¦ğ‘›ğ‘¥ğ‘›,ğ‘¦ğ‘›,ğ‘¤ğ‘=weight[ğ‘]â‹…ğŸ™{ğ‘â‰ ignore_index}â„“(x,y)=L={l1,â€¦,lN}âŠ¤,ln=âˆ’wynxn,yn,wc=weight[c]â‹…1{câ‰ ignore_index}</p><p>In [7]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(model, device, train_loader, optimizer, epoch, log_interval=<span class="number">100</span>)</span>:</span></span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> batch_idx, (data, target) <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">        data, target = data.to(device), target.to(device)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        output = model(data)</span><br><span class="line">        loss = F.nll_loss(output, target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="keyword">if</span> batch_idx % log_interval == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:0f&#125;%)]\tLoss: &#123;:.6f&#125;"</span>.format(</span><br><span class="line">                epoch, batch_idx * len(data), len(train_loader.dataset), </span><br><span class="line">                <span class="number">100.</span> * batch_idx / len(train_loader), loss.item()</span><br><span class="line">            ))</span><br></pre></td></tr></table></figure><p>In [8]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(model, device, test_loader)</span>:</span></span><br><span class="line">    model.eval()</span><br><span class="line">    test_loss = <span class="number">0</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data, target <span class="keyword">in</span> test_loader:</span><br><span class="line">            data, target = data.to(device), target.to(device)</span><br><span class="line">            output = model(data)</span><br><span class="line">            test_loss += F.nll_loss(output, target, reduction=<span class="string">'sum'</span>).item() <span class="comment"># sum up batch loss</span></span><br><span class="line">            pred = output.argmax(dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>) <span class="comment"># get the index of the max log-probability</span></span><br><span class="line">            correct += pred.eq(target.view_as(pred)).sum().item()</span><br><span class="line"></span><br><span class="line">    test_loss /= len(test_loader.dataset)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'\nTest set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)\n'</span>.format(</span><br><span class="line">        test_loss, correct, len(test_loader.dataset),</span><br><span class="line">        <span class="number">100.</span> * correct / len(test_loader.dataset)))</span><br></pre></td></tr></table></figure><p>In [13]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">53113</span>)</span><br><span class="line"></span><br><span class="line">use_cuda = torch.cuda.is_available()</span><br><span class="line">device = torch.device(<span class="string">"cuda"</span> <span class="keyword">if</span> use_cuda <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line">batch_size = test_batch_size = <span class="number">32</span></span><br><span class="line">kwargs = &#123;<span class="string">'num_workers'</span>: <span class="number">1</span>, <span class="string">'pin_memory'</span>: <span class="literal">True</span>&#125; <span class="keyword">if</span> use_cuda <span class="keyword">else</span> &#123;&#125;</span><br><span class="line">train_loader = torch.utils.data.DataLoader(</span><br><span class="line">    datasets.MNIST(<span class="string">'./mnist_data'</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>,</span><br><span class="line">                   transform=transforms.Compose([</span><br><span class="line">                       transforms.ToTensor(),</span><br><span class="line">                       transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))</span><br><span class="line">                   ])),</span><br><span class="line">    batch_size=batch_size, shuffle=<span class="literal">True</span>, **kwargs)</span><br><span class="line">test_loader = torch.utils.data.DataLoader(</span><br><span class="line">    datasets.MNIST(<span class="string">'./mnist_data'</span>, train=<span class="literal">False</span>, transform=transforms.Compose([</span><br><span class="line">                       transforms.ToTensor(),</span><br><span class="line">                       transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))</span><br><span class="line">                   ])),</span><br><span class="line">    batch_size=test_batch_size, shuffle=<span class="literal">True</span>, **kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">lr = <span class="number">0.01</span></span><br><span class="line">momentum = <span class="number">0.5</span></span><br><span class="line">model = Net().to(device)</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)</span><br><span class="line"></span><br><span class="line">epochs = <span class="number">2</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>, epochs + <span class="number">1</span>):</span><br><span class="line">    train(model, device, train_loader, optimizer, epoch)</span><br><span class="line">    test(model, device, test_loader)</span><br><span class="line"></span><br><span class="line">save_model = <span class="literal">True</span></span><br><span class="line"><span class="keyword">if</span> (save_model):</span><br><span class="line">    torch.save(model.state_dict(),<span class="string">"mnist_cnn.pt"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">Train Epoch: 1 [0/60000 (0.000000%)]Loss: 2.297938</span><br><span class="line">Train Epoch: 1 [3200/60000 (5.333333%)]Loss: 0.567845</span><br><span class="line">Train Epoch: 1 [6400/60000 (10.666667%)]Loss: 0.206370</span><br><span class="line">Train Epoch: 1 [9600/60000 (16.000000%)]Loss: 0.094653</span><br><span class="line">Train Epoch: 1 [12800/60000 (21.333333%)]Loss: 0.180530</span><br><span class="line">Train Epoch: 1 [16000/60000 (26.666667%)]Loss: 0.041645</span><br><span class="line">Train Epoch: 1 [19200/60000 (32.000000%)]Loss: 0.135092</span><br><span class="line">Train Epoch: 1 [22400/60000 (37.333333%)]Loss: 0.054001</span><br><span class="line">Train Epoch: 1 [25600/60000 (42.666667%)]Loss: 0.111863</span><br><span class="line">Train Epoch: 1 [28800/60000 (48.000000%)]Loss: 0.059039</span><br><span class="line">Train Epoch: 1 [32000/60000 (53.333333%)]Loss: 0.089227</span><br><span class="line">Train Epoch: 1 [35200/60000 (58.666667%)]Loss: 0.186015</span><br><span class="line">Train Epoch: 1 [38400/60000 (64.000000%)]Loss: 0.093208</span><br><span class="line">Train Epoch: 1 [41600/60000 (69.333333%)]Loss: 0.077090</span><br><span class="line">Train Epoch: 1 [44800/60000 (74.666667%)]Loss: 0.038075</span><br><span class="line">Train Epoch: 1 [48000/60000 (80.000000%)]Loss: 0.036247</span><br><span class="line">Train Epoch: 1 [51200/60000 (85.333333%)]Loss: 0.052358</span><br><span class="line">Train Epoch: 1 [54400/60000 (90.666667%)]Loss: 0.013201</span><br><span class="line">Train Epoch: 1 [57600/60000 (96.000000%)]Loss: 0.036660</span><br><span class="line"></span><br><span class="line">Test set: Average loss: 0.0644, Accuracy: 9802/10000 (98%)</span><br><span class="line"></span><br><span class="line">Train Epoch: 2 [0/60000 (0.000000%)]Loss: 0.054402</span><br><span class="line">Train Epoch: 2 [3200/60000 (5.333333%)]Loss: 0.032239</span><br><span class="line">Train Epoch: 2 [6400/60000 (10.666667%)]Loss: 0.092350</span><br><span class="line">Train Epoch: 2 [9600/60000 (16.000000%)]Loss: 0.058544</span><br><span class="line">Train Epoch: 2 [12800/60000 (21.333333%)]Loss: 0.029762</span><br><span class="line">Train Epoch: 2 [16000/60000 (26.666667%)]Loss: 0.012521</span><br><span class="line">Train Epoch: 2 [19200/60000 (32.000000%)]Loss: 0.101891</span><br><span class="line">Train Epoch: 2 [22400/60000 (37.333333%)]Loss: 0.127773</span><br><span class="line">Train Epoch: 2 [25600/60000 (42.666667%)]Loss: 0.009259</span><br><span class="line">Train Epoch: 2 [28800/60000 (48.000000%)]Loss: 0.013482</span><br><span class="line">Train Epoch: 2 [32000/60000 (53.333333%)]Loss: 0.039676</span><br><span class="line">Train Epoch: 2 [35200/60000 (58.666667%)]Loss: 0.016707</span><br><span class="line">Train Epoch: 2 [38400/60000 (64.000000%)]Loss: 0.168691</span><br><span class="line">Train Epoch: 2 [41600/60000 (69.333333%)]Loss: 0.056318</span><br><span class="line">Train Epoch: 2 [44800/60000 (74.666667%)]Loss: 0.008174</span><br><span class="line">Train Epoch: 2 [48000/60000 (80.000000%)]Loss: 0.075149</span><br><span class="line">Train Epoch: 2 [51200/60000 (85.333333%)]Loss: 0.205798</span><br><span class="line">Train Epoch: 2 [54400/60000 (90.666667%)]Loss: 0.019762</span><br><span class="line">Train Epoch: 2 [57600/60000 (96.000000%)]Loss: 0.012056</span><br><span class="line"></span><br><span class="line">Test set: Average loss: 0.0464, Accuracy: 9850/10000 (98%)</span><br></pre></td></tr></table></figure><p>In [15]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">53113</span>)</span><br><span class="line"></span><br><span class="line">use_cuda = torch.cuda.is_available()</span><br><span class="line">device = torch.device(<span class="string">"cuda"</span> <span class="keyword">if</span> use_cuda <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line">batch_size = test_batch_size = <span class="number">32</span></span><br><span class="line">kwargs = &#123;<span class="string">'num_workers'</span>: <span class="number">1</span>, <span class="string">'pin_memory'</span>: <span class="literal">True</span>&#125; <span class="keyword">if</span> use_cuda <span class="keyword">else</span> &#123;&#125;</span><br><span class="line">train_loader = torch.utils.data.DataLoader(</span><br><span class="line">    datasets.FashionMNIST(<span class="string">'./fashion_mnist_data'</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>,</span><br><span class="line">                   transform=transforms.Compose([</span><br><span class="line">                       transforms.ToTensor(),</span><br><span class="line">                       transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))</span><br><span class="line">                   ])),</span><br><span class="line">    batch_size=batch_size, shuffle=<span class="literal">True</span>, **kwargs)</span><br><span class="line">test_loader = torch.utils.data.DataLoader(</span><br><span class="line">    datasets.FashionMNIST(<span class="string">'./fashion_mnist_data'</span>, train=<span class="literal">False</span>, transform=transforms.Compose([</span><br><span class="line">                       transforms.ToTensor(),</span><br><span class="line">                       transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))</span><br><span class="line">                   ])),</span><br><span class="line">    batch_size=test_batch_size, shuffle=<span class="literal">True</span>, **kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">lr = <span class="number">0.01</span></span><br><span class="line">momentum = <span class="number">0.5</span></span><br><span class="line">model = Net().to(device)</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)</span><br><span class="line"></span><br><span class="line">epochs = <span class="number">2</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>, epochs + <span class="number">1</span>):</span><br><span class="line">    train(model, device, train_loader, optimizer, epoch)</span><br><span class="line">    test(model, device, test_loader)</span><br><span class="line"></span><br><span class="line">save_model = <span class="literal">True</span></span><br><span class="line"><span class="keyword">if</span> (save_model):</span><br><span class="line">    torch.save(model.state_dict(),<span class="string">"fashion_mnist_cnn.pt"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz</span><br><span class="line">Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz</span><br><span class="line">Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz</span><br><span class="line">Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz</span><br><span class="line">Processing...</span><br><span class="line">Done!</span><br><span class="line">Train Epoch: 1 [0/60000 (0.000000%)]Loss: 2.279603</span><br><span class="line">Train Epoch: 1 [3200/60000 (5.333333%)]Loss: 0.962251</span><br><span class="line">Train Epoch: 1 [6400/60000 (10.666667%)]Loss: 1.019635</span><br><span class="line">Train Epoch: 1 [9600/60000 (16.000000%)]Loss: 0.544330</span><br><span class="line">Train Epoch: 1 [12800/60000 (21.333333%)]Loss: 0.629807</span><br><span class="line">Train Epoch: 1 [16000/60000 (26.666667%)]Loss: 0.514437</span><br><span class="line">Train Epoch: 1 [19200/60000 (32.000000%)]Loss: 0.555741</span><br><span class="line">Train Epoch: 1 [22400/60000 (37.333333%)]Loss: 0.528186</span><br><span class="line">Train Epoch: 1 [25600/60000 (42.666667%)]Loss: 0.656440</span><br><span class="line">Train Epoch: 1 [28800/60000 (48.000000%)]Loss: 0.294654</span><br><span class="line">Train Epoch: 1 [32000/60000 (53.333333%)]Loss: 0.293626</span><br><span class="line">Train Epoch: 1 [35200/60000 (58.666667%)]Loss: 0.227645</span><br><span class="line">Train Epoch: 1 [38400/60000 (64.000000%)]Loss: 0.473842</span><br><span class="line">Train Epoch: 1 [41600/60000 (69.333333%)]Loss: 0.724678</span><br><span class="line">Train Epoch: 1 [44800/60000 (74.666667%)]Loss: 0.519580</span><br><span class="line">Train Epoch: 1 [48000/60000 (80.000000%)]Loss: 0.465854</span><br><span class="line">Train Epoch: 1 [51200/60000 (85.333333%)]Loss: 0.378200</span><br><span class="line">Train Epoch: 1 [54400/60000 (90.666667%)]Loss: 0.503832</span><br><span class="line">Train Epoch: 1 [57600/60000 (96.000000%)]Loss: 0.616502</span><br><span class="line"></span><br><span class="line">Test set: Average loss: 0.4365, Accuracy: 8425/10000 (84%)</span><br><span class="line"></span><br><span class="line">Train Epoch: 2 [0/60000 (0.000000%)]Loss: 0.385171</span><br><span class="line">Train Epoch: 2 [3200/60000 (5.333333%)]Loss: 0.329045</span><br><span class="line">Train Epoch: 2 [6400/60000 (10.666667%)]Loss: 0.308792</span><br><span class="line">Train Epoch: 2 [9600/60000 (16.000000%)]Loss: 0.360471</span><br><span class="line">Train Epoch: 2 [12800/60000 (21.333333%)]Loss: 0.445865</span><br><span class="line">Train Epoch: 2 [16000/60000 (26.666667%)]Loss: 0.357145</span><br><span class="line">Train Epoch: 2 [19200/60000 (32.000000%)]Loss: 0.376523</span><br><span class="line">Train Epoch: 2 [22400/60000 (37.333333%)]Loss: 0.389735</span><br><span class="line">Train Epoch: 2 [25600/60000 (42.666667%)]Loss: 0.308655</span><br><span class="line">Train Epoch: 2 [28800/60000 (48.000000%)]Loss: 0.352300</span><br><span class="line">Train Epoch: 2 [32000/60000 (53.333333%)]Loss: 0.499613</span><br><span class="line">Train Epoch: 2 [35200/60000 (58.666667%)]Loss: 0.282398</span><br><span class="line">Train Epoch: 2 [38400/60000 (64.000000%)]Loss: 0.330232</span><br><span class="line">Train Epoch: 2 [41600/60000 (69.333333%)]Loss: 0.430427</span><br><span class="line">Train Epoch: 2 [44800/60000 (74.666667%)]Loss: 0.406084</span><br><span class="line">Train Epoch: 2 [48000/60000 (80.000000%)]Loss: 0.443538</span><br><span class="line">Train Epoch: 2 [51200/60000 (85.333333%)]Loss: 0.348947</span><br><span class="line">Train Epoch: 2 [54400/60000 (90.666667%)]Loss: 0.424920</span><br><span class="line">Train Epoch: 2 [57600/60000 (96.000000%)]Loss: 0.231494</span><br><span class="line"></span><br><span class="line">Test set: Average loss: 0.3742, Accuracy: 8652/10000 (87%)</span><br></pre></td></tr></table></figure><h3 id="CNNæ¨¡å‹çš„è¿ç§»å­¦ä¹ "><a href="#CNNæ¨¡å‹çš„è¿ç§»å­¦ä¹ " class="headerlink" title="CNNæ¨¡å‹çš„è¿ç§»å­¦ä¹ "></a>CNNæ¨¡å‹çš„è¿ç§»å­¦ä¹ </h3><ul><li>å¾ˆå¤šæ—¶å€™å½“æˆ‘ä»¬éœ€è¦è®­ç»ƒä¸€ä¸ªæ–°çš„å›¾åƒåˆ†ç±»ä»»åŠ¡ï¼Œæˆ‘ä»¬ä¸ä¼šå®Œå…¨ä»ä¸€ä¸ªéšæœºçš„æ¨¡å‹å¼€å§‹è®­ç»ƒï¼Œè€Œæ˜¯åˆ©ç”¨_é¢„è®­ç»ƒ_çš„æ¨¡å‹æ¥åŠ é€Ÿè®­ç»ƒçš„è¿‡ç¨‹ã€‚æˆ‘ä»¬ç»å¸¸ä½¿ç”¨åœ¨<code>ImageNet</code>ä¸Šçš„é¢„è®­ç»ƒæ¨¡å‹ã€‚</li><li>è¿™æ˜¯ä¸€ç§transfer learningçš„æ–¹æ³•ã€‚æˆ‘ä»¬å¸¸ç”¨ä»¥ä¸‹ä¸¤ç§æ–¹æ³•åšè¿ç§»å­¦ä¹ ã€‚<ul><li>fine tuning: ä»ä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹å¼€å§‹ï¼Œæˆ‘ä»¬æ”¹å˜ä¸€äº›æ¨¡å‹çš„æ¶æ„ï¼Œç„¶åç»§ç»­è®­ç»ƒæ•´ä¸ªæ¨¡å‹çš„å‚æ•°ã€‚</li><li>feature extraction: æˆ‘ä»¬ä¸å†æ”¹å˜ä¸è®­ç»ƒæ¨¡å‹çš„å‚æ•°ï¼Œè€Œæ˜¯åªæ›´æ–°æˆ‘ä»¬æ”¹å˜è¿‡çš„éƒ¨åˆ†æ¨¡å‹å‚æ•°ã€‚æˆ‘ä»¬ä¹‹æ‰€ä»¥å«å®ƒfeature extractionæ˜¯å› ä¸ºæˆ‘ä»¬æŠŠé¢„è®­ç»ƒçš„CNNæ¨¡å‹å½“åšä¸€ä¸ªç‰¹å¾æå–æ¨¡å‹ï¼Œåˆ©ç”¨æå–å‡ºæ¥çš„ç‰¹å¾åšæ¥å®Œæˆæˆ‘ä»¬çš„è®­ç»ƒä»»åŠ¡ã€‚</li></ul></li></ul><p>ä»¥ä¸‹æ˜¯æ„å»ºå’Œè®­ç»ƒè¿ç§»å­¦ä¹ æ¨¡å‹çš„åŸºæœ¬æ­¥éª¤ï¼š</p><ul><li>åˆå§‹åŒ–é¢„è®­ç»ƒæ¨¡å‹</li><li>æŠŠæœ€åä¸€å±‚çš„è¾“å‡ºå±‚æ”¹å˜æˆæˆ‘ä»¬æƒ³è¦åˆ†çš„ç±»åˆ«æ€»æ•°</li><li>å®šä¹‰ä¸€ä¸ªoptimizeræ¥æ›´æ–°å‚æ•°</li><li>æ¨¡å‹è®­ç»ƒ</li></ul><p>In [87]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms, models</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line">print(<span class="string">"Torchvision Version: "</span>,torchvision.__version__)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Torchvision Version:  0.2.0</span><br></pre></td></tr></table></figure><h2 id="æ•°æ®"><a href="#æ•°æ®" class="headerlink" title="æ•°æ®"></a>æ•°æ®</h2><p>æˆ‘ä»¬ä¼šä½¿ç”¨<em>hymenoptera_data</em>æ•°æ®é›†ï¼Œ<a href="https://download.pytorch.org/tutorial/hymenoptera_data.zip" target="_blank" rel="noopener">ä¸‹è½½</a>.</p><p>è¿™ä¸ªæ•°æ®é›†åŒ…æ‹¬ä¸¤ç±»å›¾ç‰‡, <strong>bees</strong> å’Œ <strong>ants</strong>, è¿™äº›æ•°æ®éƒ½è¢«å¤„ç†æˆäº†å¯ä»¥ä½¿ç”¨<code>ImageFolder &lt;https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.ImageFolder&gt;</code>æ¥è¯»å–çš„æ ¼å¼ã€‚æˆ‘ä»¬åªéœ€è¦æŠŠ<code>data_dir</code>è®¾ç½®æˆæ•°æ®çš„æ ¹ç›®å½•ï¼Œç„¶åæŠŠ<code>model_name</code>è®¾ç½®æˆæˆ‘ä»¬æƒ³è¦ä½¿ç”¨çš„ä¸è®­ç»ƒæ¨¡å‹ï¼š :: [resnet, alexnet, vgg, squeezenet, densenet, inception]</p><p>å…¶ä»–çš„å‚æ•°æœ‰ï¼š</p><ul><li><code>num_classes</code>è¡¨ç¤ºæ•°æ®é›†åˆ†ç±»çš„ç±»åˆ«æ•°</li><li><code>batch_size</code></li><li><code>num_epochs</code></li><li><code>feature_extract</code>è¡¨ç¤ºæˆ‘ä»¬è®­ç»ƒçš„æ—¶å€™ä½¿ç”¨fine tuningè¿˜æ˜¯feature extractionæ–¹æ³•ã€‚å¦‚æœ<code>feature_extract = False</code>ï¼Œæ•´ä¸ªæ¨¡å‹éƒ½ä¼šè¢«åŒæ—¶æ›´æ–°ã€‚å¦‚æœ<code>feature_extract = True</code>ï¼Œåªæœ‰æ¨¡å‹çš„æœ€åä¸€å±‚è¢«æ›´æ–°ã€‚</li></ul><p>In [36]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># Top level data directory. Here we assume the format of the directory conforms </span><br><span class="line">#   to the ImageFolder structure</span><br><span class="line">data_dir = &quot;./hymenoptera_data&quot;</span><br><span class="line"># Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]</span><br><span class="line">model_name = &quot;resnet&quot;</span><br><span class="line"># Number of classes in the dataset</span><br><span class="line">num_classes = 2</span><br><span class="line"># Batch size for training (change depending on how much memory you have)</span><br><span class="line">batch_size = 32</span><br><span class="line"># Number of epochs to train for </span><br><span class="line">num_epochs = 15</span><br><span class="line"># Flag for feature extracting. When False, we finetune the whole model, </span><br><span class="line">#   when True we only update the reshaped layer params</span><br><span class="line">feature_extract = True</span><br></pre></td></tr></table></figure><p>In [120]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_model</span><span class="params">(model, dataloaders, criterion, optimizer, num_epochs=<span class="number">5</span>)</span>:</span></span><br><span class="line">    since = time.time()</span><br><span class="line">    val_acc_history = []</span><br><span class="line">    best_model_wts = copy.deepcopy(model.state_dict())</span><br><span class="line">    best_acc = <span class="number">0.</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">        print(<span class="string">"Epoch &#123;&#125;/&#123;&#125;"</span>.format(epoch, num_epochs<span class="number">-1</span>))</span><br><span class="line">        print(<span class="string">"-"</span>*<span class="number">10</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> phase <span class="keyword">in</span> [<span class="string">"train"</span>, <span class="string">"val"</span>]:</span><br><span class="line">            running_loss = <span class="number">0.</span></span><br><span class="line">            running_corrects = <span class="number">0.</span></span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">"train"</span>:</span><br><span class="line">                model.train()</span><br><span class="line">            <span class="keyword">else</span>: </span><br><span class="line">                model.eval()</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> inputs, labels <span class="keyword">in</span> dataloaders[phase]:</span><br><span class="line">                inputs = inputs.to(device)</span><br><span class="line">                labels = labels.to(device)</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">with</span> torch.autograd.set_grad_enabled(phase==<span class="string">"train"</span>):</span><br><span class="line">                    outputs = model(inputs)</span><br><span class="line">                    loss = criterion(outputs, labels)</span><br><span class="line">                    </span><br><span class="line">                _, preds = torch.max(outputs, <span class="number">1</span>)</span><br><span class="line">                <span class="keyword">if</span> phase == <span class="string">"train"</span>:</span><br><span class="line">                    optimizer.zero_grad()</span><br><span class="line">                    loss.backward()</span><br><span class="line">                    optimizer.step()</span><br><span class="line">                    </span><br><span class="line">                running_loss += loss.item() * inputs.size(<span class="number">0</span>)</span><br><span class="line">                running_corrects += torch.sum(preds.view(<span class="number">-1</span>) == labels.view(<span class="number">-1</span>)).item()</span><br><span class="line">            </span><br><span class="line">            epoch_loss = running_loss / len(dataloaders[phase].dataset)</span><br><span class="line">            epoch_acc = running_corrects / len(dataloaders[phase].dataset)</span><br><span class="line">       </span><br><span class="line">            print(<span class="string">"&#123;&#125; Loss: &#123;&#125; Acc: &#123;&#125;"</span>.format(phase, epoch_loss, epoch_acc))</span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">"val"</span> <span class="keyword">and</span> epoch_acc &gt; best_acc:</span><br><span class="line">                best_acc = epoch_acc</span><br><span class="line">                best_model_wts = copy.deepcopy(model.state_dict())</span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">"val"</span>:</span><br><span class="line">                val_acc_history.append(epoch_acc)</span><br><span class="line">            </span><br><span class="line">        print()</span><br><span class="line">    </span><br><span class="line">    time_elapsed = time.time() - since</span><br><span class="line">    print(<span class="string">"Training compete in &#123;&#125;m &#123;&#125;s"</span>.format(time_elapsed // <span class="number">60</span>, time_elapsed % <span class="number">60</span>))</span><br><span class="line">    print(<span class="string">"Best val Acc: &#123;&#125;"</span>.format(best_acc))</span><br><span class="line">    </span><br><span class="line">    model.load_state_dict(best_model_wts)</span><br><span class="line">    <span class="keyword">return</span> model, val_acc_history</span><br></pre></td></tr></table></figure><p>In [121]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># it = iter(dataloaders_dict[&quot;train&quot;])</span><br><span class="line"># inputs, labels = next(it)</span><br><span class="line"># for inputs, labels in dataloaders_dict[&quot;train&quot;]:</span><br><span class="line">#     print(labels.size())</span><br></pre></td></tr></table></figure><p>In [122]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">len(dataloaders_dict[&quot;train&quot;].dataset.imgs)</span><br></pre></td></tr></table></figure><p>Out[122]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">244</span><br></pre></td></tr></table></figure><p>In [123]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">len(dataloaders_dict[&quot;train&quot;].dataset)</span><br></pre></td></tr></table></figure><p>Out[123]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">244</span><br></pre></td></tr></table></figure><p>In [124]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def set_parameter_requires_grad(model, feature_extracting):</span><br><span class="line">    if feature_extracting:</span><br><span class="line">        for param in model.parameters():</span><br><span class="line">            param.requires_grad = False</span><br></pre></td></tr></table></figure><p>In [125]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_model</span><span class="params">(model_name, num_classes, feature_extract, use_pretrained=True)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> model_name == <span class="string">"resnet"</span>:</span><br><span class="line">        model_ft = models.resnet18(pretrained=use_pretrained)</span><br><span class="line">        set_parameter_requires_grad(model_ft, feature_extract)</span><br><span class="line">        num_ftrs = model_ft.fc.in_features</span><br><span class="line">        model_ft.fc = nn.Linear(num_ftrs, num_classes)</span><br><span class="line">        input_size = <span class="number">224</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> model_ft, input_size</span><br><span class="line">model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=<span class="literal">True</span>)</span><br><span class="line">print(model_ft)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line">ResNet(</span><br><span class="line">  (conv1): Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=(<span class="number">7</span>, <span class="number">7</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), padding=(<span class="number">3</span>, <span class="number">3</span>), bias=<span class="literal">False</span>)</span><br><span class="line">  (bn1): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">  (relu): ReLU(inplace)</span><br><span class="line">  (maxpool): MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">  (layer1): Sequential(</span><br><span class="line">    (<span class="number">0</span>): BasicBlock(</span><br><span class="line">      (conv1): Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">      (bn1): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      (relu): ReLU(inplace)</span><br><span class="line">      (conv2): Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">      (bn2): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">    )</span><br><span class="line">    (<span class="number">1</span>): BasicBlock(</span><br><span class="line">      (conv1): Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">      (bn1): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      (relu): ReLU(inplace)</span><br><span class="line">      (conv2): Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">      (bn2): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (layer2): Sequential(</span><br><span class="line">    (<span class="number">0</span>): BasicBlock(</span><br><span class="line">      (conv1): Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">      (bn1): BatchNorm2d(<span class="number">128</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      (relu): ReLU(inplace)</span><br><span class="line">      (conv2): Conv2d(<span class="number">128</span>, <span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">      (bn2): BatchNorm2d(<span class="number">128</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      (downsample): Sequential(</span><br><span class="line">        (<span class="number">0</span>): Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), bias=<span class="literal">False</span>)</span><br><span class="line">        (<span class="number">1</span>): BatchNorm2d(<span class="number">128</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (<span class="number">1</span>): BasicBlock(</span><br><span class="line">      (conv1): Conv2d(<span class="number">128</span>, <span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">      (bn1): BatchNorm2d(<span class="number">128</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      (relu): ReLU(inplace)</span><br><span class="line">      (conv2): Conv2d(<span class="number">128</span>, <span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">      (bn2): BatchNorm2d(<span class="number">128</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (layer3): Sequential(</span><br><span class="line">    (<span class="number">0</span>): BasicBlock(</span><br><span class="line">      (conv1): Conv2d(<span class="number">128</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">      (bn1): BatchNorm2d(<span class="number">256</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      (relu): ReLU(inplace)</span><br><span class="line">      (conv2): Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">      (bn2): BatchNorm2d(<span class="number">256</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      (downsample): Sequential(</span><br><span class="line">        (<span class="number">0</span>): Conv2d(<span class="number">128</span>, <span class="number">256</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), bias=<span class="literal">False</span>)</span><br><span class="line">        (<span class="number">1</span>): BatchNorm2d(<span class="number">256</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (<span class="number">1</span>): BasicBlock(</span><br><span class="line">      (conv1): Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">      (bn1): BatchNorm2d(<span class="number">256</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      (relu): ReLU(inplace)</span><br><span class="line">      (conv2): Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">      (bn2): BatchNorm2d(<span class="number">256</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (layer4): Sequential(</span><br><span class="line">    (<span class="number">0</span>): BasicBlock(</span><br><span class="line">      (conv1): Conv2d(<span class="number">256</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">      (bn1): BatchNorm2d(<span class="number">512</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      (relu): ReLU(inplace)</span><br><span class="line">      (conv2): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">      (bn2): BatchNorm2d(<span class="number">512</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      (downsample): Sequential(</span><br><span class="line">        (<span class="number">0</span>): Conv2d(<span class="number">256</span>, <span class="number">512</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), bias=<span class="literal">False</span>)</span><br><span class="line">        (<span class="number">1</span>): BatchNorm2d(<span class="number">512</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (<span class="number">1</span>): BasicBlock(</span><br><span class="line">      (conv1): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">      (bn1): BatchNorm2d(<span class="number">512</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      (relu): ReLU(inplace)</span><br><span class="line">      (conv2): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">      (bn2): BatchNorm2d(<span class="number">512</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (avgpool): AvgPool2d(kernel_size=<span class="number">7</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line">  (fc): Linear(in_features=<span class="number">512</span>, out_features=<span class="number">2</span>, bias=<span class="literal">True</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="è¯»å…¥æ•°æ®"><a href="#è¯»å…¥æ•°æ®" class="headerlink" title="è¯»å…¥æ•°æ®"></a>è¯»å…¥æ•°æ®</h2><p>ç°åœ¨æˆ‘ä»¬çŸ¥é“äº†æ¨¡å‹è¾“å…¥çš„sizeï¼Œæˆ‘ä»¬å°±å¯ä»¥æŠŠæ•°æ®é¢„å¤„ç†æˆç›¸åº”çš„æ ¼å¼ã€‚</p><p>In [126]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">data_transforms = &#123;</span><br><span class="line">    <span class="string">"train"</span>: transforms.Compose([</span><br><span class="line">        transforms.RandomResizedCrop(input_size),</span><br><span class="line">        transforms.RandomHorizontalFlip(),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">    ]),</span><br><span class="line">    <span class="string">"val"</span>: transforms.Compose([</span><br><span class="line">        transforms.Resize(input_size),</span><br><span class="line">        transforms.CenterCrop(input_size),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">    ]),</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Initializing Datasets and Dataloaders..."</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create training and validation datasets</span></span><br><span class="line">image_datasets = &#123;x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">'train'</span>, <span class="string">'val'</span>]&#125;</span><br><span class="line"><span class="comment"># Create training and validation dataloaders</span></span><br><span class="line">dataloaders_dict = &#123;x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=<span class="literal">True</span>, num_workers=<span class="number">4</span>) <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">'train'</span>, <span class="string">'val'</span>]&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Detect if we have a GPU available</span></span><br><span class="line">device = torch.device(<span class="string">"cuda:0"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Initializing Datasets and Dataloaders...</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>In [127]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Send the model to GPU</span></span><br><span class="line">model_ft = model_ft.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Gather the parameters to be optimized/updated in this run. If we are</span></span><br><span class="line"><span class="comment">#  finetuning we will be updating all parameters. However, if we are </span></span><br><span class="line"><span class="comment">#  doing feature extract method, we will only update the parameters</span></span><br><span class="line"><span class="comment">#  that we have just initialized, i.e. the parameters with requires_grad</span></span><br><span class="line"><span class="comment">#  is True.</span></span><br><span class="line">params_to_update = model_ft.parameters()</span><br><span class="line">print(<span class="string">"Params to learn:"</span>)</span><br><span class="line"><span class="keyword">if</span> feature_extract:</span><br><span class="line">    params_to_update = []</span><br><span class="line">    <span class="keyword">for</span> name,param <span class="keyword">in</span> model_ft.named_parameters():</span><br><span class="line">        <span class="keyword">if</span> param.requires_grad == <span class="literal">True</span>:</span><br><span class="line">            params_to_update.append(param)</span><br><span class="line">            print(<span class="string">"\t"</span>,name)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">for</span> name,param <span class="keyword">in</span> model_ft.named_parameters():</span><br><span class="line">        <span class="keyword">if</span> param.requires_grad == <span class="literal">True</span>:</span><br><span class="line">            print(<span class="string">"\t"</span>,name)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Observe that all parameters are being optimized</span></span><br><span class="line">optimizer_ft = optim.SGD(params_to_update, lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Params to learn:</span><br><span class="line"> fc.weight</span><br><span class="line"> fc.bias</span><br></pre></td></tr></table></figure><p>In [133]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Setup the loss fxn</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train and evaluate</span></span><br><span class="line">model_ft, ohist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">Epoch 0/14</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.2623850886450439 Acc: 0.8975409836065574</span><br><span class="line">val Loss: 0.22199168762350394 Acc: 0.9215686274509803</span><br><span class="line"></span><br><span class="line">Epoch 1/14</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.20775875546893136 Acc: 0.9262295081967213</span><br><span class="line">val Loss: 0.21329789413930544 Acc: 0.9215686274509803</span><br><span class="line"></span><br><span class="line">Epoch 2/14</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.24463887243974405 Acc: 0.9098360655737705</span><br><span class="line">val Loss: 0.2308054333613589 Acc: 0.9215686274509803</span><br><span class="line"></span><br><span class="line">Epoch 3/14</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.2108444703406975 Acc: 0.930327868852459</span><br><span class="line">val Loss: 0.20637644174831365 Acc: 0.954248366013072</span><br><span class="line"></span><br><span class="line">Epoch 4/14</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.22102872954040279 Acc: 0.9221311475409836</span><br><span class="line">val Loss: 0.19902625017695957 Acc: 0.9281045751633987</span><br><span class="line"></span><br><span class="line">Epoch 5/14</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.22044393127081824 Acc: 0.9221311475409836</span><br><span class="line">val Loss: 0.2212505256818011 Acc: 0.9281045751633987</span><br><span class="line"></span><br><span class="line">Epoch 6/14</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.1636357441788814 Acc: 0.9467213114754098</span><br><span class="line">val Loss: 0.1969745449380937 Acc: 0.934640522875817</span><br><span class="line"></span><br><span class="line">Epoch 7/14</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.1707800094221459 Acc: 0.9385245901639344</span><br><span class="line">val Loss: 0.20569930824578977 Acc: 0.934640522875817</span><br><span class="line"></span><br><span class="line">Epoch 8/14</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.18224841185280535 Acc: 0.9344262295081968</span><br><span class="line">val Loss: 0.192565394480244 Acc: 0.9411764705882353</span><br><span class="line"></span><br><span class="line">Epoch 9/14</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.17762072372143387 Acc: 0.9385245901639344</span><br><span class="line">val Loss: 0.19549715163466197 Acc: 0.9411764705882353</span><br><span class="line"></span><br><span class="line">Epoch 10/14</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.19314993575948183 Acc: 0.9180327868852459</span><br><span class="line">val Loss: 0.2000840900380627 Acc: 0.934640522875817</span><br><span class="line"></span><br><span class="line">Epoch 11/14</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.21551114418467537 Acc: 0.9057377049180327</span><br><span class="line">val Loss: 0.18960770005299374 Acc: 0.934640522875817</span><br><span class="line"></span><br><span class="line">Epoch 12/14</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.1847396502729322 Acc: 0.9426229508196722</span><br><span class="line">val Loss: 0.1871058808432685 Acc: 0.9411764705882353</span><br><span class="line"></span><br><span class="line">Epoch 13/14</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.17342406132670699 Acc: 0.9508196721311475</span><br><span class="line">val Loss: 0.20636656588199093 Acc: 0.9215686274509803</span><br><span class="line"></span><br><span class="line">Epoch 14/14</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.16013679030488748 Acc: 0.9508196721311475</span><br><span class="line">val Loss: 0.18491691759988374 Acc: 0.9411764705882353</span><br><span class="line"></span><br><span class="line">Training compete in 0.0m 14.700076580047607s</span><br><span class="line">Best val Acc: 0.954248366013072</span><br></pre></td></tr></table></figure><p>In [130]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Initialize the non-pretrained version of the model used for this run</span></span><br><span class="line">scratch_model,_ = initialize_model(model_name, num_classes, feature_extract=<span class="literal">False</span>, use_pretrained=<span class="literal">False</span>)</span><br><span class="line">scratch_model = scratch_model.to(device)</span><br><span class="line">scratch_optimizer = optim.SGD(scratch_model.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line">scratch_criterion = nn.CrossEntropyLoss()</span><br><span class="line">_,scratch_hist = train_model(scratch_model, dataloaders_dict, scratch_criterion, scratch_optimizer, num_epochs=num_epochs)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">Epoch 0/14</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.7185551504619786 Acc: 0.4426229508196721</span><br><span class="line">val Loss: 0.6956208067781785 Acc: 0.45751633986928103</span><br><span class="line"></span><br><span class="line">Epoch 1/14</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.6852761008700387 Acc: 0.5778688524590164</span><br><span class="line">val Loss: 0.6626271987273022 Acc: 0.6601307189542484</span><br><span class="line"></span><br><span class="line">Epoch 2/14</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.6603062289660094 Acc: 0.5942622950819673</span><br><span class="line">val Loss: 0.6489538297154545 Acc: 0.5816993464052288</span><br><span class="line"></span><br><span class="line">Epoch 3/14</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.6203305486772881 Acc: 0.639344262295082</span><br><span class="line">val Loss: 0.6013184107986151 Acc: 0.673202614379085</span><br><span class="line"></span><br><span class="line">Epoch 4/14</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.5989709232674271 Acc: 0.6680327868852459</span><br><span class="line">val Loss: 0.5929347966231552 Acc: 0.6993464052287581</span><br><span class="line"></span><br><span class="line">Epoch 5/14</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.5821619336722327 Acc: 0.6557377049180327</span><br><span class="line">val Loss: 0.5804777059679717 Acc: 0.6928104575163399</span><br><span class="line"></span><br><span class="line">Epoch 6/14</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.6114685896967278 Acc: 0.6270491803278688</span><br><span class="line">val Loss: 0.5674225290616354 Acc: 0.7189542483660131</span><br><span class="line"></span><br><span class="line">Epoch 7/14</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.5681056575696977 Acc: 0.6680327868852459</span><br><span class="line">val Loss: 0.5602688086188696 Acc: 0.7189542483660131</span><br><span class="line"></span><br><span class="line">Epoch 8/14</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.5701596453541615 Acc: 0.7090163934426229</span><br><span class="line">val Loss: 0.5554519264526616 Acc: 0.7450980392156863</span><br><span class="line"></span><br><span class="line">Epoch 9/14</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.5476810380083615 Acc: 0.7254098360655737</span><br><span class="line">val Loss: 0.5805927063125411 Acc: 0.7189542483660131</span><br><span class="line"></span><br><span class="line">Epoch 10/14</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.5508710468401674 Acc: 0.6926229508196722</span><br><span class="line">val Loss: 0.5859468777974447 Acc: 0.7058823529411765</span><br><span class="line"></span><br><span class="line">Epoch 11/14</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.5344281519045595 Acc: 0.7172131147540983</span><br><span class="line">val Loss: 0.5640550851821899 Acc: 0.7058823529411765</span><br><span class="line"></span><br><span class="line">Epoch 12/14</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.5125471890949812 Acc: 0.7295081967213115</span><br><span class="line">val Loss: 0.5665123891207128 Acc: 0.7058823529411765</span><br><span class="line"></span><br><span class="line">Epoch 13/14</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.496260079204059 Acc: 0.7254098360655737</span><br><span class="line">val Loss: 0.5820710787586137 Acc: 0.7058823529411765</span><br><span class="line"></span><br><span class="line">Epoch 14/14</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.49067981907578767 Acc: 0.7704918032786885</span><br><span class="line">val Loss: 0.5722863315756804 Acc: 0.7058823529411765</span><br><span class="line"></span><br><span class="line">Training compete in 0.0m 18.418847799301147s</span><br><span class="line">Best val Acc: 0.7450980392156863</span><br></pre></td></tr></table></figure><p>In [134]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Plot the training curves of validation accuracy vs. number </span></span><br><span class="line"><span class="comment">#  of training epochs for the transfer learning method and</span></span><br><span class="line"><span class="comment">#  the model trained from scratch</span></span><br><span class="line"><span class="comment"># ohist = []</span></span><br><span class="line"><span class="comment"># shist = []</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ohist = [h.cpu().numpy() for h in ohist]</span></span><br><span class="line"><span class="comment"># shist = [h.cpu().numpy() for h in scratch_hist]</span></span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">"Validation Accuracy vs. Number of Training Epochs"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Training Epochs"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Validation Accuracy"</span>)</span><br><span class="line">plt.plot(range(<span class="number">1</span>,num_epochs+<span class="number">1</span>),ohist,label=<span class="string">"Pretrained"</span>)</span><br><span class="line">plt.plot(range(<span class="number">1</span>,num_epochs+<span class="number">1</span>),scratch_hist,label=<span class="string">"Scratch"</span>)</span><br><span class="line">plt.ylim((<span class="number">0</span>,<span class="number">1.</span>))</span><br><span class="line">plt.xticks(np.arange(<span class="number">1</span>, num_epochs+<span class="number">1</span>, <span class="number">1.0</span>))</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ä¸˜å‰å°”çš„äººç‰©ä¼ è®°charçº§åˆ«çš„æ–‡æœ¬ç”Ÿæˆä»£ç æ³¨é‡Š</title>
      <link href="/2019/11/08/%E4%B8%98%E5%90%89%E5%B0%94%E7%9A%84%E4%BA%BA%E7%89%A9%E4%BC%A0%E8%AE%B0char%E7%BA%A7%E5%88%AB%E7%9A%84%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E4%BB%A3%E7%A0%81%E6%B3%A8%E9%87%8A/"/>
      <url>/2019/11/08/%E4%B8%98%E5%90%89%E5%B0%94%E7%9A%84%E4%BA%BA%E7%89%A9%E4%BC%A0%E8%AE%B0char%E7%BA%A7%E5%88%AB%E7%9A%84%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E4%BB%A3%E7%A0%81%E6%B3%A8%E9%87%8A/</url>
      
        <content type="html"><![CDATA[<h1 id="è¯»å–æ•°æ®"><a href="#è¯»å–æ•°æ®" class="headerlink" title="è¯»å–æ•°æ®"></a>è¯»å–æ•°æ®</h1><p>ä¸¾ä¸ªå°å°çš„ä¾‹å­ï¼Œæ¥çœ‹çœ‹LSTMæ˜¯æ€ä¹ˆç©çš„</p><p>æˆ‘ä»¬è¿™é‡Œç”¨æ¸©æ–¯é¡¿ä¸˜å‰å°”çš„äººç‰©ä¼ è®°ä½œä¸ºæˆ‘ä»¬çš„å­¦ä¹ è¯­æ–™ã€‚</p><p>ç¬¬ä¸€æ­¥ï¼Œä¸€æ ·ï¼Œå…ˆå¯¼å…¥å„ç§åº“</p><p>å…³äºLSTMçš„è¯¦ç»†åŸç†å…ˆçœ‹åšå®¢ï¼š<a href="https://www.julyedu.com/question/big/kp_id/26/ques_id/1851" target="_blank" rel="noopener">å¦‚ä½•ä»RNNèµ·æ­¥ï¼Œä¸€æ­¥ä¸€æ­¥é€šä¿—ç†è§£LSTM</a></p><p>In [68]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dropout</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> LSTM</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ModelCheckpoint</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br></pre></td></tr></table></figure><p>In [69]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">raw_text = open(<span class="string">'./input/Winston_Churchil.txt'</span>).read()</span><br><span class="line"><span class="comment"># .read() è¯»å…¥æ•´ä¸ªæ–‡ä»¶ä¸ºä¸€ä¸ªå­—ç¬¦ä¸²</span></span><br><span class="line">raw_text = raw_text.lower() <span class="comment"># å°å†™</span></span><br><span class="line">print(raw_text[:<span class="number">100</span>]) <span class="comment">#æ‰“å°å‰100ä¸ªå­—ç¬¦</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ï»¿project gutenbergâ€™s real soldiers of fortune, by richard harding davis</span><br><span class="line"></span><br><span class="line">this ebook <span class="keyword">is</span> <span class="keyword">for</span> the use o</span><br></pre></td></tr></table></figure><p>æ—¢ç„¶æˆ‘ä»¬æ˜¯ä»¥æ¯ä¸ªå­—æ¯ä¸ºå±‚çº§ï¼Œå­—æ¯æ€»å…±æ‰26ä¸ªï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥å¾ˆæ–¹ä¾¿çš„ç”¨One-Hotæ¥ç¼–ç å‡ºæ‰€æœ‰çš„å­—æ¯ï¼ˆå½“ç„¶ï¼Œå¯èƒ½è¿˜æœ‰äº›æ ‡ç‚¹ç¬¦å·å’Œå…¶ä»–noiseï¼‰</p><p>In [70]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">chars = sorted(list(set(raw_text))) </span><br><span class="line"><span class="comment"># è¿™é‡Œå»é‡ä¸æ˜¯å•è¯å»é‡ï¼Œæ˜¯å­—æ¯å»é‡ï¼Œå»é‡ååªæœ‰è‹±æ–‡å­—æ¯å’Œæ ‡ç‚¹ç¬¦å·ç­‰å­—ç¬¦</span></span><br><span class="line">print(len(raw_text))</span><br><span class="line">print(len(chars))</span><br><span class="line">char_to_int = dict((c, i) <span class="keyword">for</span> i, c <span class="keyword">in</span> enumerate(chars)) </span><br><span class="line"><span class="comment"># å»é‡åçš„å­—ç¬¦æ’åºå¥½åï¼Œxi</span></span><br><span class="line">int_to_char = dict((i, c) <span class="keyword">for</span> i, c <span class="keyword">in</span> enumerate(chars))</span><br><span class="line">print(char_to_int)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">276830</span><br><span class="line">61</span><br><span class="line">&#123;&apos;\n&apos;: 0, &apos; &apos;: 1, &apos;!&apos;: 2, &apos;#&apos;: 3, &apos;$&apos;: 4, &apos;%&apos;: 5, &apos;(&apos;: 6, &apos;)&apos;: 7, &apos;*&apos;: 8, &apos;,&apos;: 9, &apos;-&apos;: 10, &apos;.&apos;: 11, &apos;/&apos;: 12, &apos;0&apos;: 13, &apos;1&apos;: 14, &apos;2&apos;: 15, &apos;3&apos;: 16, &apos;4&apos;: 17, &apos;5&apos;: 18, &apos;6&apos;: 19, &apos;7&apos;: 20, &apos;8&apos;: 21, &apos;9&apos;: 22, &apos;:&apos;: 23, &apos;;&apos;: 24, &apos;?&apos;: 25, &apos;@&apos;: 26, &apos;[&apos;: 27, &apos;]&apos;: 28, &apos;_&apos;: 29, &apos;a&apos;: 30, &apos;b&apos;: 31, &apos;c&apos;: 32, &apos;d&apos;: 33, &apos;e&apos;: 34, &apos;f&apos;: 35, &apos;g&apos;: 36, &apos;h&apos;: 37, &apos;i&apos;: 38, &apos;j&apos;: 39, &apos;k&apos;: 40, &apos;l&apos;: 41, &apos;m&apos;: 42, &apos;n&apos;: 43, &apos;o&apos;: 44, &apos;p&apos;: 45, &apos;q&apos;: 46, &apos;r&apos;: 47, &apos;s&apos;: 48, &apos;t&apos;: 49, &apos;u&apos;: 50, &apos;v&apos;: 51, &apos;w&apos;: 52, &apos;x&apos;: 53, &apos;y&apos;: 54, &apos;z&apos;: 55, &apos;â€˜&apos;: 56, &apos;â€™&apos;: 57, &apos;â€œ&apos;: 58, &apos;â€&apos;: 59, &apos;\ufeff&apos;: 60&#125;</span><br></pre></td></tr></table></figure><h1 id="æ„é€ è®­ç»ƒé›†"><a href="#æ„é€ è®­ç»ƒé›†" class="headerlink" title="æ„é€ è®­ç»ƒé›†"></a>æ„é€ è®­ç»ƒé›†</h1><p>æˆ‘ä»¬è¿™é‡Œç®€å•çš„æ–‡æœ¬é¢„æµ‹å°±æ˜¯ï¼Œç»™äº†å‰ç½®çš„å­—æ¯ä»¥åï¼Œä¸‹ä¸€ä¸ªå­—æ¯æ˜¯è°ï¼Ÿ<br>æˆ‘ä»¬éœ€è¦æŠŠæˆ‘ä»¬çš„raw textå˜æˆå¯ä»¥ç”¨æ¥è®­ç»ƒçš„x,y:</p><p>x æ˜¯å‰ç½®å­—æ¯ä»¬ y æ˜¯åä¸€ä¸ªå­—æ¯</p><p>In [71]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">seq_length = <span class="number">100</span> </span><br><span class="line"><span class="comment"># è¾“å…¥çš„å­—ç¬¦çš„é•¿åº¦ï¼Œä¸€ä¸ªå­—ç¬¦å¯¹åº”ä¸€ä¸ªç¥ç»å…ƒï¼Œæ€»å…±100ä¸ªç¥ç»å…ƒ</span></span><br><span class="line"><span class="comment"># è¾“å…¥æ˜¯100ä¸ªå­—ç¬¦ï¼Œè¾“å‡ºæ˜¯é¢„æµ‹çš„ä¸€ä¸ªå­—ç¬¦</span></span><br><span class="line"></span><br><span class="line">x = []</span><br><span class="line">y = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, len(raw_text) - seq_length): <span class="comment"># æ¯æ¬¡å¾ªç¯éƒ½æ»‘åŠ¨ä¸€ä¸ªå­—ç¬¦è·ç¦»</span></span><br><span class="line">    given = raw_text[i:i + seq_length] <span class="comment"># ä»é›¶å…ˆå–å‰100ä¸ªå­—ç¬¦ä½œä¸ºè¾“å…¥</span></span><br><span class="line">    predict = raw_text[i + seq_length] <span class="comment"># yæ˜¯åä¸€ä¸ªå­—ç¬¦</span></span><br><span class="line">    x.append([char_to_int[char] <span class="keyword">for</span> char <span class="keyword">in</span> given]) <span class="comment"># æŠŠå­—ç¬¦è½¬åŒ–ä¸ºå‘é‡</span></span><br><span class="line">    y.append(char_to_int[predict]) <span class="comment"># # æŠŠå­—ç¬¦è½¬åŒ–ä¸ºå‘é‡</span></span><br></pre></td></tr></table></figure><p>In [72]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(x[:<span class="number">3</span>]) </span><br><span class="line">print(y[:<span class="number">3</span>])</span><br><span class="line">print(set(y)) <span class="comment"># è¿™é‡Œæ³¨æ„ä¸‹ï¼Œ'\ufeff': 60è¿™ä¸ªå­—ç¬¦æ˜¯æ–‡æœ¬çš„é¦–å­—ç¬¦ï¼Œåªæœ‰è¿™ä¹ˆä¸€ä¸ªï¼Œyæ˜¯å–ä¸åˆ°çš„ï¼Œæ‰€ä»¥yå€¼çš„å¯èƒ½åªæœ‰60ç§</span></span><br><span class="line">print(len(set(y)))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[[60, 45, 47, 44, 39, 34, 32, 49, 1, 36, 50, 49, 34, 43, 31, 34, 47, 36, 57, 48, 1, 47, 34, 30, 41, 1, 48, 44, 41, 33, 38, 34, 47, 48, 1, 44, 35, 1, 35, 44, 47, 49, 50, 43, 34, 9, 1, 31, 54, 1, 47, 38, 32, 37, 30, 47, 33, 1, 37, 30, 47, 33, 38, 43, 36, 1, 33, 30, 51, 38, 48, 0, 0, 49, 37, 38, 48, 1, 34, 31, 44, 44, 40, 1, 38, 48, 1, 35, 44, 47, 1, 49, 37, 34, 1, 50, 48, 34, 1, 44], [45, 47, 44, 39, 34, 32, 49, 1, 36, 50, 49, 34, 43, 31, 34, 47, 36, 57, 48, 1, 47, 34, 30, 41, 1, 48, 44, 41, 33, 38, 34, 47, 48, 1, 44, 35, 1, 35, 44, 47, 49, 50, 43, 34, 9, 1, 31, 54, 1, 47, 38, 32, 37, 30, 47, 33, 1, 37, 30, 47, 33, 38, 43, 36, 1, 33, 30, 51, 38, 48, 0, 0, 49, 37, 38, 48, 1, 34, 31, 44, 44, 40, 1, 38, 48, 1, 35, 44, 47, 1, 49, 37, 34, 1, 50, 48, 34, 1, 44, 35], [47, 44, 39, 34, 32, 49, 1, 36, 50, 49, 34, 43, 31, 34, 47, 36, 57, 48, 1, 47, 34, 30, 41, 1, 48, 44, 41, 33, 38, 34, 47, 48, 1, 44, 35, 1, 35, 44, 47, 49, 50, 43, 34, 9, 1, 31, 54, 1, 47, 38, 32, 37, 30, 47, 33, 1, 37, 30, 47, 33, 38, 43, 36, 1, 33, 30, 51, 38, 48, 0, 0, 49, 37, 38, 48, 1, 34, 31, 44, 44, 40, 1, 38, 48, 1, 35, 44, 47, 1, 49, 37, 34, 1, 50, 48, 34, 1, 44, 35, 1]]</span><br><span class="line">[35, 1, 30]</span><br><span class="line">&#123;0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59&#125;</span><br><span class="line">60</span><br></pre></td></tr></table></figure><p>æ­¤åˆ»ï¼Œæ¥¼ä¸Šè¿™äº›è¡¨è¾¾æ–¹å¼ï¼Œç±»ä¼¼å°±æ˜¯ä¸€ä¸ªè¯è¢‹ï¼Œæˆ–è€…è¯´ indexã€‚</p><p>æ¥ä¸‹æ¥æˆ‘ä»¬åšä¸¤ä»¶äº‹ï¼š</p><p>1.æˆ‘ä»¬å·²ç»æœ‰äº†ä¸€ä¸ªinputçš„æ•°å­—è¡¨è¾¾ï¼ˆindexï¼‰ï¼Œæˆ‘ä»¬è¦æŠŠå®ƒå˜æˆLSTMéœ€è¦çš„æ•°ç»„æ ¼å¼ï¼š [æ ·æœ¬æ•°ï¼Œæ—¶é—´æ­¥ä¼ï¼Œç‰¹å¾]</p><p>2.å¯¹äºoutputï¼Œæˆ‘ä»¬åœ¨Word2Vecé‡Œå­¦è¿‡ï¼Œç”¨one-hotåšoutputçš„é¢„æµ‹å¯ä»¥ç»™æˆ‘ä»¬æ›´å¥½çš„æ•ˆæœï¼Œç›¸å¯¹äºç›´æ¥é¢„æµ‹ä¸€ä¸ªå‡†ç¡®çš„yæ•°å€¼çš„è¯ã€‚</p><p>In [73]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">n_patterns = len(x) <span class="comment"># æ ·æœ¬æ•°é‡</span></span><br><span class="line">n_vocab = len(chars) <span class="comment"># </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># æŠŠxå˜æˆLSTMéœ€è¦çš„æ ·å­</span></span><br><span class="line">x = numpy.reshape(x, (n_patterns, seq_length, <span class="number">1</span>))</span><br><span class="line"><span class="comment"># n_patterns æ ·æœ¬çš„æ•°é‡</span></span><br><span class="line"><span class="comment"># seq_length æ¯ä¸ªæ ·æœ¬æ¯æ¬¡è®­ç»ƒ100ä¸ªå­—ç¬¦</span></span><br><span class="line"><span class="comment"># 1 ä»£è¡¨æˆ‘ä»¬çš„ä¸€ä¸ªå­—ç¬¦çš„ç»´åº¦æ˜¯1ç»´ï¼Œè¿™é‡Œ1ç»´æ˜¯ç‰¹æ®Šæƒ…å†µï¼Œå¦‚æœæˆ‘ä»¬çš„è¾“å…¥ä¸æ˜¯ä¸€ä¸ªå­—ç¬¦ï¼Œ</span></span><br><span class="line"><span class="comment">#æ˜¯ä¸€ä¸ªå•è¯çš„è¯ï¼Œå•è¯æ˜¯å¯ä»¥embeddingæˆ100ç»´å‘é‡ï¼Œé‚£è¿™é‡Œå°±æ˜¯100.</span></span><br><span class="line"></span><br><span class="line">x = x / float(n_vocab) <span class="comment"># ç®€å•normalåˆ°0-1ä¹‹é—´ï¼Œå½’ä¸€åŒ–ï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸</span></span><br><span class="line">y = np_utils.to_categorical(y) </span><br><span class="line"><span class="comment"># yå€¼æ€»å…±å–å€¼61ç§ï¼Œç›´æ¥åšä¸ªonehotç¼–ç </span></span><br><span class="line"><span class="comment"># å¯¹ç±»åˆ«è¿›è¡Œonehotç¼–ç ä¸€ä¸ªå¾ˆé‡è¦çš„åŸå› åœ¨äºè®¡ç®—lossæ—¶çš„é—®é¢˜ã€‚lossä¸€èˆ¬ç”¨è·ç¦»æ¥è¡¨ç¤ºï¼Œ</span></span><br><span class="line"><span class="comment"># å¦‚æœç”¨1~5æ¥è¡¨ç¤ºï¼Œé‚£ä¹ˆ1å’Œ2çš„è·ç¦»æ˜¯1ï¼Œè€Œ1å’Œ5çš„è·ç¦»æ˜¯4ï¼Œä½†æ˜¯æŒ‰é“ç†1å’Œ2ã€1å’Œ5çš„è·ç¦»åº”è¯¥ä¸€æ ·ã€‚</span></span><br><span class="line"><span class="comment"># å¦‚æœç”¨one hotç¼–ç è¡¨ç¤ºï¼Œé‚£ä¹ˆ1å’Œ2çš„è·ç¦»è·Ÿ1å’Œ5çš„è·ç¦»æ—¶ä¸€æ ·çš„ã€‚</span></span><br><span class="line"></span><br><span class="line">print(x[<span class="number">10</span>][:<span class="number">10</span>]) <span class="comment"># ç¬¬10ä¸ªæ ·æœ¬çš„å‰10ä¸ªå­—ç¬¦å‘é‡</span></span><br><span class="line">print(y[<span class="number">10</span>])</span><br><span class="line">print(y.shape) <span class="comment">#</span></span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[[0.81967213]</span><br><span class="line"> [0.80327869]</span><br><span class="line"> [0.55737705]</span><br><span class="line"> [0.70491803]</span><br><span class="line"> [0.50819672]</span><br><span class="line"> [0.55737705]</span><br><span class="line"> [0.7704918 ]</span><br><span class="line"> [0.59016393]</span><br><span class="line"> [0.93442623]</span><br><span class="line"> [0.78688525]]</span><br><span class="line">[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.</span><br><span class="line"> 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.</span><br><span class="line"> 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]</span><br><span class="line">(276730, 60)</span><br></pre></td></tr></table></figure><h1 id="æ„å»ºå’Œè®­ç»ƒæ¨¡å‹"><a href="#æ„å»ºå’Œè®­ç»ƒæ¨¡å‹" class="headerlink" title="æ„å»ºå’Œè®­ç»ƒæ¨¡å‹"></a>æ„å»ºå’Œè®­ç»ƒæ¨¡å‹</h1><p>In [74]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line"><span class="comment"># Sequential()ï¼šåºè´¯æ¨¡å‹æ˜¯å¤šä¸ªç½‘ç»œå±‚çš„çº¿æ€§å †å ï¼Œå¯ä»¥é€šè¿‡.add()ä¸€ä¸ªä¸€ä¸ªæ·»åŠ å±‚</span></span><br><span class="line">model.add(LSTM(<span class="number">256</span>, input_shape=(x.shape[<span class="number">1</span>], x.shape[<span class="number">2</span>])))</span><br><span class="line"><span class="comment"># 256æ˜¯LSTMçš„éšè—å±‚çš„ç»´åº¦ã€‚</span></span><br><span class="line"><span class="comment"># input_shapeï¼Œä¸éœ€è¦è€ƒè™‘æ ·æœ¬æ•°é‡ï¼Œå¯¹æ¨¡å‹æœ¬èº«ç»“æ„æ²¡æœ‰æ„ä¹‰</span></span><br><span class="line">model.add(Dropout(<span class="number">0.2</span>)) <span class="comment"># å»æ‰20%çš„ç¥ç»å…ƒ</span></span><br><span class="line">model.add(Dense(y.shape[<span class="number">1</span>], activation=<span class="string">'softmax'</span>)) </span><br><span class="line"><span class="comment"># y.shape[1] = 60ï¼Œ'softmax'è½¬åŒ–ä¸ºæ¦‚ç‡ï¼Œæ¦‚ç‡å’Œä¸º1</span></span><br><span class="line">model.compile(loss=<span class="string">'categorical_crossentropy'</span>, optimizer=<span class="string">'adam'</span>)</span><br><span class="line"><span class="comment"># å¤šåˆ†ç±»äº¤å‰ç†µæŸå¤±ï¼Œadamä¼˜åŒ–å™¨</span></span><br></pre></td></tr></table></figure><p>In [75]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.fit(x, y, nb_epoch=<span class="number">1</span>, batch_size=<span class="number">1024</span>)</span><br><span class="line"><span class="comment"># è¿™é‡Œæœ¬åœ°è·‘çš„å¤ªæ…¢äº†ï¼Œnb_epochè®¾ç½®ä¸º1äº†</span></span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/Users/yyg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.</span><br><span class="line">  &quot;&quot;&quot;Entry point for launching an IPython kernel.</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Epoch 1/1</span><br><span class="line">276730/276730 [==============================] - 1152s 4ms/step - loss: 3.0591</span><br></pre></td></tr></table></figure><p>Out[75]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;keras.callbacks.History at 0xb27cb07f0&gt;</span><br></pre></td></tr></table></figure><h2 id="é¢„æµ‹æ¨¡å‹"><a href="#é¢„æµ‹æ¨¡å‹" class="headerlink" title="é¢„æµ‹æ¨¡å‹"></a>é¢„æµ‹æ¨¡å‹</h2><p>In [95]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_next</span><span class="params">(input_array)</span>:</span></span><br><span class="line">    x = numpy.reshape(input_array, (<span class="number">1</span>, seq_length, <span class="number">1</span>))</span><br><span class="line">    <span class="comment"># åŒä¸Šï¼Œåªæœ‰ä¸€ä¸ªæ ·æœ¬ï¼Œreshapeæˆlstméœ€è¦çš„ç»´åº¦ã€‚</span></span><br><span class="line">    x = x / float(n_vocab) <span class="comment"># å½’ä¸€åŒ–</span></span><br><span class="line">    y = model.predict(x) <span class="comment"># yæ˜¯60ç»´çš„å‘é‡</span></span><br><span class="line">    <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">string_to_index</span><span class="params">(raw_input)</span>:</span></span><br><span class="line">    res = [] </span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> raw_input[(len(raw_input)-seq_length):]:</span><br><span class="line"><span class="comment"># è¿™æ­¥ä¸€ä¸ªé—®é¢˜æ˜¯len(raw_input)ä¸€å®šè¦å¤§äºseq_lengthï¼š100,ä¸ç„¶ä¼šæŠ¥é”™</span></span><br><span class="line">        res.append(char_to_int[c]) <span class="comment"># å¾—åˆ°è¾“å…¥å¥å­ä¸­å100ä¸ªå­—ç¬¦çš„å‘é‡è¡¨ç¤º</span></span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">y_to_char</span><span class="params">(y)</span>:</span> </span><br><span class="line">    largest_index = y.argmax() <span class="comment"># å–å‡ºæ¦‚ç‡æœ€å¤§çš„å€¼å¯¹åº”çš„ç´¢å¼•</span></span><br><span class="line">    c = int_to_char[largest_index] <span class="comment"># æ ¹æ®ç´¢å¼•å¾—åˆ°å¯¹åº”çš„å­—ç¬¦</span></span><br><span class="line">    <span class="keyword">return</span> c</span><br></pre></td></tr></table></figure><p>In [96]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_article</span><span class="params">(init, rounds=<span class="number">200</span>)</span>:</span> </span><br><span class="line">    <span class="comment"># rounds=200 ä»£è¡¨é¢„æµ‹ç”Ÿæˆ200ä¸ªæ–°çš„å­—ç¬¦</span></span><br><span class="line">    <span class="comment"># initæ˜¯è¾“å…¥çš„å­—ç¬¦ä¸²</span></span><br><span class="line">    in_string = init.lower() <span class="comment"># è·Ÿä¸Šé¢ä¸€æ ·çš„é¢„å¤„ç†æ­¥éª¤</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(rounds): <span class="comment"># æ¯æ¬¡æ¨¡å‹é¢„æµ‹ä¸€ä¸ªå­—ç¬¦</span></span><br><span class="line">        n = y_to_char(predict_next(string_to_index(in_string)))</span><br><span class="line">        <span class="comment"># næ˜¯é¢„æµ‹çš„æ–°çš„å­—ç¬¦</span></span><br><span class="line">        in_string += n <span class="comment"># æŠŠæ–°çš„å­—ç¬¦æ‹¼æ¥ï¼Œé‡æ–°ä½œä¸ºæ–°çš„è¾“å…¥</span></span><br><span class="line">    <span class="keyword">return</span> in_string</span><br></pre></td></tr></table></figure><p>In [97]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">init = <span class="string">'His object in coming to New York was to engage officers for that service. He came at an opportune moment'</span></span><br><span class="line">article = generate_article(init)</span><br><span class="line">print(article) <span class="comment"># è¿™é‡Œä¸Šé¢åªæ˜¯è¿­ä»£äº†ä¸€æ¬¡ï¼Œå¯¼è‡´åé¢æ‰€æœ‰çš„é¢„æµ‹éƒ½æ˜¯ç©ºæ ¼</span></span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">his object in coming to new york was to engage officers for that service. he came at an opportune moment</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LSTM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ç”¨æœ´ç´ è´å¶æ–¯å®Œæˆè¯­ç§æ£€æµ‹</title>
      <link href="/2019/11/08/%E7%94%A8%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%8C%E6%88%90%E8%AF%AD%E7%A7%8D%E6%A3%80%E6%B5%8B/"/>
      <url>/2019/11/08/%E7%94%A8%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%8C%E6%88%90%E8%AF%AD%E7%A7%8D%E6%A3%80%E6%B5%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="ç”¨æœ´ç´ è´å¶æ–¯å®Œæˆè¯­ç§æ£€æµ‹"><a href="#ç”¨æœ´ç´ è´å¶æ–¯å®Œæˆè¯­ç§æ£€æµ‹" class="headerlink" title="ç”¨æœ´ç´ è´å¶æ–¯å®Œæˆè¯­ç§æ£€æµ‹"></a>ç”¨æœ´ç´ è´å¶æ–¯å®Œæˆè¯­ç§æ£€æµ‹</h1><p>æˆ‘ä»¬è¯•è¯•ç”¨æœ´ç´ è´å¶æ–¯å®Œæˆä¸€ä¸ªè¯­ç§æ£€æµ‹çš„åˆ†ç±»å™¨ï¼Œè¯´èµ·æ¥ï¼Œç”¨æœ´ç´ è´å¶æ–¯å®Œæˆè¿™ä¸ªä»»åŠ¡ï¼Œå…¶å®å‡†ç¡®åº¦è¿˜ä¸é”™ã€‚</p><p><img src="data:image/png;base64,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" alt="image.png"></p><h2 id="æŸ¥çœ‹æ•°æ®ï¼Œå¹¶åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†"><a href="#æŸ¥çœ‹æ•°æ®ï¼Œå¹¶åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†" class="headerlink" title="æŸ¥çœ‹æ•°æ®ï¼Œå¹¶åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†"></a>æŸ¥çœ‹æ•°æ®ï¼Œå¹¶åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†</h2><p>In [87]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">in_f = open(<span class="string">'data.csv'</span>)</span><br><span class="line">lines = in_f.readlines() <span class="comment"># ä¸€æ¬¡è¯»å–æ•´ä¸ªæ–‡ä»¶ï¼Œæ¯è¡Œçš„å†…å®¹æ”¾åœ¨ä¸€ä¸ªå­—ç¬¦ä¸²å˜é‡ä¸­ä½œä¸ºåˆ—è¡¨çš„ä¸€ä¸ªå…ƒç´ ã€‚</span></span><br><span class="line">in_f.close()</span><br><span class="line">dataset = [(line.strip()[:<span class="number">-3</span>], line.strip()[<span class="number">-2</span>:]) <span class="keyword">for</span> line <span class="keyword">in</span> lines]</span><br><span class="line"><span class="comment"># æŠŠå¥å­å’Œè¯­è¨€åˆ†å¼€ï¼Œè¿™é‡Œ.strip()æŠŠ\nå»æ‰äº†ã€‚</span></span><br><span class="line">print(lines[<span class="number">0</span>]) <span class="comment"># æ‰“å°ç¬¬ä¸€ä¸ªå¥å­</span></span><br><span class="line">print(dataset[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1 december wereld aids dag voorlichting in zuidafrika over bieten taboes en optimisme,nl</span><br><span class="line"></span><br><span class="line">(&apos;1 december wereld aids dag voorlichting in zuidafrika over bieten taboes en optimisme&apos;, &apos;nl&apos;)</span><br></pre></td></tr></table></figure><p>In [88]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">x, y = zip(*dataset) <span class="comment"># è§£å‹ç¼©</span></span><br><span class="line">x, y = list(x),list(y) </span><br><span class="line">print(x[<span class="number">0</span>],y[<span class="number">0</span>])</span><br><span class="line">print(<span class="string">"-----"</span>*<span class="number">10</span>)</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># é»˜è®¤0.25çš„æ¯”ä¾‹</span></span><br><span class="line"></span><br><span class="line">print(len(x_train),x_train[<span class="number">0</span>],y_train[<span class="number">0</span>])</span><br><span class="line">print(len(x_test),x_test[<span class="number">0</span>],y_test[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1 december wereld aids dag voorlichting in zuidafrika over bieten taboes en optimisme nl</span><br><span class="line">--------------------------------------------------</span><br><span class="line">6799 io non ho ipad ma mi sa che Ã¨ fatta un po meglio sfrutta meglio la superficie it</span><br><span class="line">2267 ook jullie bedankt voor jullie steun nl</span><br></pre></td></tr></table></figure><h2 id="æ•°æ®å»ç‡¥ï¼Œè®¾ç½®æ­£åˆ™åŒ–è§„åˆ™"><a href="#æ•°æ®å»ç‡¥ï¼Œè®¾ç½®æ­£åˆ™åŒ–è§„åˆ™" class="headerlink" title="æ•°æ®å»ç‡¥ï¼Œè®¾ç½®æ­£åˆ™åŒ–è§„åˆ™"></a>æ•°æ®å»ç‡¥ï¼Œè®¾ç½®æ­£åˆ™åŒ–è§„åˆ™</h2><p>In [89]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="comment">#å› ä¸ºæ˜¯twitterçš„æ•°æ®ï¼Œæœ‰æ—¶å€™ä¼šæœ‰ä¸€äº›@ # httpç­‰å­—ç¬¦ã€‚</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">remove_noise</span><span class="params">(document)</span>:</span></span><br><span class="line">    noise_pattern = re.compile(<span class="string">"|"</span>.join([<span class="string">"http\S+"</span>, <span class="string">"\@\w+"</span>, <span class="string">"\#\w+"</span>]))</span><br><span class="line">    <span class="comment"># å…³äºæ­£åˆ™è¡¨è¾¾å¼çš„ä½¿ç”¨æ–¹æ³•ï¼Œçœ‹ç¬¬ä¸€èŠ‚è¯¾</span></span><br><span class="line">    </span><br><span class="line">    clean_text = re.sub(noise_pattern, <span class="string">""</span>, document)</span><br><span class="line">    <span class="comment"># ä½¿ç”¨ç©ºç™½""æ›¿æ¢documentä¸­æ¯ä¸€ä¸ªåŒ¹é…noise_patternè§„åˆ™çš„å­ä¸²ã€‚</span></span><br><span class="line">    <span class="keyword">return</span> clean_text.strip()</span><br><span class="line"></span><br><span class="line"><span class="comment">#ä¸¾ä¾‹</span></span><br><span class="line">remove_noise(<span class="string">"Trump images are now more popular than cat gifs. @trump a #trends http://www.trumptrends.html"</span>)</span><br><span class="line"><span class="comment"># http\S+ åŒ¹é…çš„æ˜¯http://www.trumptrends.html</span></span><br><span class="line"><span class="comment"># \@\w+ åŒ¹é…çš„æ˜¯@trump</span></span><br><span class="line"><span class="comment"># \#\w+ åŒ¹é…çš„æ˜¯#trends</span></span><br></pre></td></tr></table></figure><p>Out[89]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&apos;Trump images are now more popular than cat gifs.  a&apos;</span><br></pre></td></tr></table></figure><h2 id="ç»Ÿè®¡è¯é¢‘ï¼Œå¹¶é€‰å–1000ä¸ªç‰¹å¾ä½œä¸ºè¾“å…¥çš„ç‰¹å¾ç»´åº¦"><a href="#ç»Ÿè®¡è¯é¢‘ï¼Œå¹¶é€‰å–1000ä¸ªç‰¹å¾ä½œä¸ºè¾“å…¥çš„ç‰¹å¾ç»´åº¦" class="headerlink" title="ç»Ÿè®¡è¯é¢‘ï¼Œå¹¶é€‰å–1000ä¸ªç‰¹å¾ä½œä¸ºè¾“å…¥çš„ç‰¹å¾ç»´åº¦"></a>ç»Ÿè®¡è¯é¢‘ï¼Œå¹¶é€‰å–1000ä¸ªç‰¹å¾ä½œä¸ºè¾“å…¥çš„ç‰¹å¾ç»´åº¦</h2><p>In [94]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"><span class="comment"># å…³äºCountVectorizerå‚æ•°å¯ä»¥çœ‹è¿™ä¸ªï¼šhttps://blog.csdn.net/weixin_38278334/article/details/82320307</span></span><br><span class="line"></span><br><span class="line">vec = CountVectorizer(</span><br><span class="line">    lowercase=<span class="literal">True</span>,     <span class="comment"># å°†æ‰€æœ‰å­—ç¬¦å˜æˆå°å†™</span></span><br><span class="line">    analyzer=<span class="string">'char_wb'</span>, <span class="comment"># æŒ‰ngram_rangeï¼š1ï½2ä¸ªå­—ç¬¦åˆ’åˆ†ç‰¹å¾</span></span><br><span class="line">    ngram_range=(<span class="number">1</span>,<span class="number">2</span>),  <span class="comment"># è€ƒè™‘ä¸¤ä¸ªå•è¯çš„çš„å…³è”é¡ºåº</span></span><br><span class="line">    max_features=<span class="number">1000</span>,  <span class="comment"># é€‰å–å‡ºç°æ¬¡æ•°æœ€å¤šçš„1000ä¸ªç‰¹å¾</span></span><br><span class="line">    preprocessor=remove_noise  <span class="comment"># è°ƒç”¨å‰é¢å»ç‡¥çš„å‡½æ•°ï¼Œè¿™é‡Œæ˜¯è¯´è®¡æ•°å‰éœ€è¦å…ˆåšè¿™ä¸€æ­¥</span></span><br><span class="line">)</span><br><span class="line">vec.fit(x_train)</span><br><span class="line">print(vec.transform(x_train).toarray()) <span class="comment"># è®­ç»ƒé›†</span></span><br><span class="line">print(vec.transform(x_train).toarray().shape) <span class="comment"># è®­ç»ƒé›†ç»´åº¦</span></span><br><span class="line">vec.get_feature_names()[:<span class="number">50</span>] <span class="comment"># çœ‹ä¸‹é€‰å–çš„1000ä¸ªç‰¹å¾å‰100ä¸ªé•¿å•¥æ ·ï¼Œå¯ä»¥çœ‹åˆ°æŒ‰1ï½2ä¸ªå­—ç¬¦ä¸ç­‰åˆ’åˆ†ç‰¹å¾ã€‚</span></span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[[34  0  0 ...  0  0  0]</span><br><span class="line"> [22  0  0 ...  0  0  0]</span><br><span class="line"> [18  0  0 ...  0  0  0]</span><br><span class="line"> ...</span><br><span class="line"> [32  0  0 ...  0  0  0]</span><br><span class="line"> [18  0  0 ...  0  0  0]</span><br><span class="line"> [ 8  0  0 ...  0  0  0]]</span><br><span class="line">(6799, 1000)</span><br></pre></td></tr></table></figure><p>Out[94]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">[&apos; &apos;,</span><br><span class="line"> &apos; 0&apos;,</span><br><span class="line"> &apos; 1&apos;,</span><br><span class="line"> &apos; 2&apos;,</span><br><span class="line"> &apos; 3&apos;,</span><br><span class="line"> &apos; 4&apos;,</span><br><span class="line"> &apos; 5&apos;,</span><br><span class="line"> &apos; 6&apos;,</span><br><span class="line"> &apos; 7&apos;,</span><br><span class="line"> &apos; 8&apos;,</span><br><span class="line"> &apos; 9&apos;,</span><br><span class="line"> &apos; a&apos;,</span><br><span class="line"> &apos; b&apos;,</span><br><span class="line"> &apos; c&apos;,</span><br><span class="line"> &apos; d&apos;,</span><br><span class="line"> &apos; e&apos;,</span><br><span class="line"> &apos; f&apos;,</span><br><span class="line"> &apos; g&apos;,</span><br><span class="line"> &apos; h&apos;,</span><br><span class="line"> &apos; i&apos;,</span><br><span class="line"> &apos; j&apos;,</span><br><span class="line"> &apos; k&apos;,</span><br><span class="line"> &apos; l&apos;,</span><br><span class="line"> &apos; m&apos;,</span><br><span class="line"> &apos; n&apos;,</span><br><span class="line"> &apos; o&apos;,</span><br><span class="line"> &apos; p&apos;,</span><br><span class="line"> &apos; q&apos;,</span><br><span class="line"> &apos; r&apos;,</span><br><span class="line"> &apos; s&apos;,</span><br><span class="line"> &apos; t&apos;,</span><br><span class="line"> &apos; u&apos;,</span><br><span class="line"> &apos; v&apos;,</span><br><span class="line"> &apos; w&apos;,</span><br><span class="line"> &apos; x&apos;,</span><br><span class="line"> &apos; y&apos;,</span><br><span class="line"> &apos; z&apos;,</span><br><span class="line"> &apos; Ã¤&apos;,</span><br><span class="line"> &apos; Ã¨&apos;,</span><br><span class="line"> &apos; Ã©&apos;,</span><br><span class="line"> &apos; Ãª&apos;,</span><br><span class="line"> &apos; Ãº&apos;,</span><br><span class="line"> &apos; Ã¼&apos;,</span><br><span class="line"> &apos;0&apos;,</span><br><span class="line"> &apos;0 &apos;,</span><br><span class="line"> &apos;00&apos;,</span><br><span class="line"> &apos;01&apos;,</span><br><span class="line"> &apos;02&apos;,</span><br><span class="line"> &apos;04&apos;,</span><br><span class="line"> &apos;05&apos;]</span><br></pre></td></tr></table></figure><h2 id="è®­ç»ƒåŠé¢„æµ‹"><a href="#è®­ç»ƒåŠé¢„æµ‹" class="headerlink" title="è®­ç»ƒåŠé¢„æµ‹"></a>è®­ç»ƒåŠé¢„æµ‹</h2><p>In [91]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</span><br><span class="line">classifier = MultinomialNB()</span><br><span class="line">classifier.fit(vec.transform(x_train), y_train)</span><br><span class="line"><span class="comment">#classifier.fit(vec.transform(x_train).toarray(), y_train) ä¹Ÿå¯ä»¥</span></span><br><span class="line">print(classifier.score(vec.transform(x_test), y_test))</span><br><span class="line"><span class="comment"># æ‰“å°å‡†ç¡®ç‡</span></span><br><span class="line">print(classifier.predict(vec.transform([<span class="string">'This is an English sentence'</span>])))</span><br><span class="line"><span class="comment"># æµ‹è¯•ä¸‹</span></span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">0.9770621967357741</span><br><span class="line">[&apos;en&apos;]</span><br></pre></td></tr></table></figure><h2 id="é‡æ–°å°è£…ä¸‹"><a href="#é‡æ–°å°è£…ä¸‹" class="headerlink" title="é‡æ–°å°è£…ä¸‹"></a>é‡æ–°å°è£…ä¸‹</h2><p>In [92]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LanguageDetector</span><span class="params">()</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, classifier=MultinomialNB<span class="params">()</span>)</span>:</span></span><br><span class="line">        self.classifier = classifier</span><br><span class="line">        self.vectorizer = CountVectorizer(ngram_range=(<span class="number">1</span>,<span class="number">2</span>), max_features=<span class="number">1000</span>, preprocessor=self._remove_noise)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_remove_noise</span><span class="params">(self, document)</span>:</span></span><br><span class="line">        noise_pattern = re.compile(<span class="string">"|"</span>.join([<span class="string">"http\S+"</span>, <span class="string">"\@\w+"</span>, <span class="string">"\#\w+"</span>]))</span><br><span class="line">        clean_text = re.sub(noise_pattern, <span class="string">""</span>, document)</span><br><span class="line">        <span class="keyword">return</span> clean_text</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">features</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.vectorizer.transform(X)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y)</span>:</span></span><br><span class="line">        self.vectorizer.fit(X)</span><br><span class="line">        self.classifier.fit(self.features(X), y)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.classifier.predict(self.features([x]))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">score</span><span class="params">(self, X, y)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.classifier.score(self.features(X), y)</span><br></pre></td></tr></table></figure><p>In [93]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">in_f = open(<span class="string">'data.csv'</span>)</span><br><span class="line">lines = in_f.readlines()</span><br><span class="line">in_f.close()</span><br><span class="line">dataset = [(line.strip()[:<span class="number">-3</span>], line.strip()[<span class="number">-2</span>:]) <span class="keyword">for</span> line <span class="keyword">in</span> lines]</span><br><span class="line">x, y = zip(*dataset)</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">language_detector = LanguageDetector()</span><br><span class="line">language_detector.fit(x_train, y_train)</span><br><span class="line">print(language_detector.predict(<span class="string">'This is an English sentence'</span>))</span><br><span class="line">print(language_detector.score(x_test, y_test))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[&apos;en&apos;]</span><br><span class="line">0.9770621967357741</span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æœ´ç´ è´å¶æ–¯ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>æ·±åº¦å­¦ä¹ é€ŸæŸ¥è¡¨</title>
      <link href="/2019/09/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%80%9F%E6%9F%A5%E8%A1%A8/"/>
      <url>/2019/09/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%80%9F%E6%9F%A5%E8%A1%A8/</url>
      
        <content type="html"><![CDATA[<p>è¯·å‚è€ƒ</p><ul><li><a href="https://github.com/fengdu78/deeplearning_ai_books" target="_blank" rel="noopener">å´æ©è¾¾è€å¸ˆçš„æ·±åº¦å­¦ä¹ è¯¾ç¨‹ç¬”è®°åŠèµ„æº</a></li><li><a href="https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-deep-learning" target="_blank" rel="noopener">CS229æ·±åº¦å­¦ä¹ é€ŸæŸ¥è¡¨</a></li><li><a href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks" target="_blank" rel="noopener">CS230æ·±åº¦å­¦ä¹ é€ŸæŸ¥è¡¨</a></li></ul><h2 id="æ·±åº¦å­¦ä¹ å„ç§æ¨¡å‹ä¸çŸ¥è¯†é€ŸæŸ¥è¡¨"><a href="#æ·±åº¦å­¦ä¹ å„ç§æ¨¡å‹ä¸çŸ¥è¯†é€ŸæŸ¥è¡¨" class="headerlink" title="æ·±åº¦å­¦ä¹ å„ç§æ¨¡å‹ä¸çŸ¥è¯†é€ŸæŸ¥è¡¨"></a>æ·±åº¦å­¦ä¹ å„ç§æ¨¡å‹ä¸çŸ¥è¯†é€ŸæŸ¥è¡¨</h2><p><img src="/blog_picture/dl-0001.jpg" alt="avatar"><br><img src="/blog_picture/dl-0002.jpg" alt="avatar"><br><img src="/blog_picture/dl-0003.jpg" alt="avatar"><br><img src="/blog_picture/dl-0004.jpg" alt="avatar"><br><img src="/blog_picture/dl-0005.jpg" alt="avatar"><br><img src="/blog_picture/dl-0006.jpg" alt="avatar"><br><img src="/blog_picture/dl-0007.jpg" alt="avatar"><br><img src="/blog_picture/dl-0008.jpg" alt="avatar"><br><img src="/blog_picture/dl-0009.jpg" alt="avatar"><br><img src="/blog_picture/dl-0010.jpg" alt="avatar"><br><img src="/blog_picture/dl-0011.jpg" alt="avatar"><br><img src="/blog_picture/dl-0012.jpg" alt="avatar"><br><img src="/blog_picture/dl-0013.jpg" alt="avatar"></p>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ·±åº¦å­¦ä¹ é€ŸæŸ¥è¡¨ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>æ¨¡å‹è°ƒä¼˜</title>
      <link href="/2019/09/01/%E6%A8%A1%E5%9E%8B%E8%B0%83%E4%BC%98/"/>
      <url>/2019/09/01/%E6%A8%A1%E5%9E%8B%E8%B0%83%E4%BC%98/</url>
      
        <content type="html"><![CDATA[<p>å‚è€ƒé˜…è¯»ææ–™ï¼š</p><ul><li><a href="https://www.zhihu.com/question/34470160" target="_blank" rel="noopener">æœºå™¨å­¦ä¹ å„ç§ç®—æ³•æ€ä¹ˆè°ƒå‚?</a></li><li><a href="https://blog.csdn.net/mozhizun/article/details/60966354" target="_blank" rel="noopener">æœºå™¨å­¦ä¹ æ¨¡å‹åº”ç”¨ä»¥åŠæ¨¡å‹ä¼˜åŒ–çš„ä¸€äº›æ€è·¯</a></li><li><a href="https://blog.csdn.net/mozhizun/article/details/71438821" target="_blank" rel="noopener">æœºå™¨å­¦ä¹ æ¨¡å‹ä¼˜åŒ–ä¸­å¸¸è§é—®é¢˜å’Œè§£å†³æ€è·¯</a></li><li><a href="https://blog.csdn.net/bitcarmanlee/article/details/71753056" target="_blank" rel="noopener">æœºå™¨å­¦ä¹ ä¸­æ¨¡å‹ä¼˜åŒ–ä¸å¾—ä¸æ€è€ƒçš„å‡ ä¸ªé—®é¢˜</a></li><li><a href="https://www.jianshu.com/p/9fe84a7a5ba8" target="_blank" rel="noopener">æœºå™¨å­¦ä¹ ä¸­æ¨¡å‹ä¼˜åŒ–çš„ä¸¤ä¸ªé—®é¢˜</a></li></ul><h2 id="æ¨¡å‹é€‰æ‹©ä¸è°ƒä¼˜"><a href="#æ¨¡å‹é€‰æ‹©ä¸è°ƒä¼˜" class="headerlink" title="æ¨¡å‹é€‰æ‹©ä¸è°ƒä¼˜"></a>æ¨¡å‹é€‰æ‹©ä¸è°ƒä¼˜</h2><h3 id="ä¸åŒæ¨¡å‹çš„é€‰æ‹©"><a href="#ä¸åŒæ¨¡å‹çš„é€‰æ‹©" class="headerlink" title="ä¸åŒæ¨¡å‹çš„é€‰æ‹©"></a>ä¸åŒæ¨¡å‹çš„é€‰æ‹©</h3><p><img src="/blog_picture/model_tuning1.png" alt="avatar"></p><h3 id="æ¨¡å‹è¶…å‚æ•°çš„é€‰æ‹©"><a href="#æ¨¡å‹è¶…å‚æ•°çš„é€‰æ‹©" class="headerlink" title="æ¨¡å‹è¶…å‚æ•°çš„é€‰æ‹©"></a>æ¨¡å‹è¶…å‚æ•°çš„é€‰æ‹©</h3><p><img src="/blog_picture/model_tuning2.png" alt="avatar"></p><h3 id="è¯„ä¼°æ–¹æ³•-è¶…å‚æ•°äº§å‡ºæ–¹æ³•"><a href="#è¯„ä¼°æ–¹æ³•-è¶…å‚æ•°äº§å‡ºæ–¹æ³•" class="headerlink" title="è¯„ä¼°æ–¹æ³•+è¶…å‚æ•°äº§å‡ºæ–¹æ³•"></a>è¯„ä¼°æ–¹æ³•+è¶…å‚æ•°äº§å‡ºæ–¹æ³•</h3><p><img src="/blog_picture/model_tuning4.png" alt="avatar"><br><img src="/blog_picture/model_tuning5.png" alt="avatar"><br><img src="/blog_picture/model_tuning6.png" alt="avatar"></p><h3 id="æ¨¡å‹çŠ¶æ€"><a href="#æ¨¡å‹çŠ¶æ€" class="headerlink" title="æ¨¡å‹çŠ¶æ€"></a>æ¨¡å‹çŠ¶æ€</h3><p><img src="/blog_picture/model_tuning3.png" alt="avatar"><br><img src="/blog_picture/model_tuning7.png" alt="avatar"><br><img src="/blog_picture/model_tuning8.png" alt="avatar"><br><img src="/blog_picture/model_tuning9.png" alt="avatar"></p>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ¨¡å‹è°ƒä¼˜ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>é›†æˆå­¦ä¹ ä¸boostingæ¨¡å‹</title>
      <link href="/2019/09/01/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E4%B8%8Eboosting%E6%A8%A1%E5%9E%8B/"/>
      <url>/2019/09/01/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E4%B8%8Eboosting%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="æœºå™¨å­¦ä¹ ä¸­çš„é›†æˆå­¦ä¹ "><a href="#æœºå™¨å­¦ä¹ ä¸­çš„é›†æˆå­¦ä¹ " class="headerlink" title="æœºå™¨å­¦ä¹ ä¸­çš„é›†æˆå­¦ä¹ "></a>æœºå™¨å­¦ä¹ ä¸­çš„é›†æˆå­¦ä¹ </h2><p>é¡¾åæ€ä¹‰ï¼Œé›†æˆå­¦ä¹ ï¼ˆensemble learningï¼‰æŒ‡çš„æ˜¯å°†å¤šä¸ªå­¦ä¹ å™¨è¿›è¡Œæœ‰æ•ˆåœ°ç»“åˆï¼Œç»„å»ºä¸€ä¸ªâ€œå­¦ä¹ å™¨å§”å‘˜ä¼šâ€ï¼Œå…¶ä¸­æ¯ä¸ªå­¦ä¹ å™¨æ‹…ä»»å§”å‘˜ä¼šæˆå‘˜å¹¶è¡Œä½¿æŠ•ç¥¨è¡¨å†³æƒï¼Œä½¿å¾—å§”å‘˜ä¼šæœ€åçš„å†³å®šæ›´èƒ½å¤Ÿå››æ–¹é€ ç¦æ™®åº¦ä¼—ç”Ÿ<del>â€¦</del>ï¼Œå³å…¶æ³›åŒ–æ€§èƒ½è¦èƒ½ä¼˜äºå…¶ä¸­ä»»ä½•ä¸€ä¸ªå­¦ä¹ å™¨ã€‚</p><h3 id="ä¸ªä½“ä¸é›†æˆ"><a href="#ä¸ªä½“ä¸é›†æˆ" class="headerlink" title="ä¸ªä½“ä¸é›†æˆ"></a>ä¸ªä½“ä¸é›†æˆ</h3><p>é›†æˆå­¦ä¹ çš„åŸºæœ¬ç»“æ„ä¸ºï¼šå…ˆäº§ç”Ÿä¸€ç»„ä¸ªä½“å­¦ä¹ å™¨ï¼Œå†ä½¿ç”¨æŸç§ç­–ç•¥å°†å®ƒä»¬ç»“åˆåœ¨ä¸€èµ·ã€‚é›†æˆæ¨¡å‹å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc84d0c15683.png" alt="1.png"></p><p>åœ¨ä¸Šå›¾çš„é›†æˆæ¨¡å‹ä¸­ï¼Œè‹¥ä¸ªä½“å­¦ä¹ å™¨éƒ½å±äºåŒä¸€ç±»åˆ«ï¼Œä¾‹å¦‚éƒ½æ˜¯å†³ç­–æ ‘æˆ–éƒ½æ˜¯ç¥ç»ç½‘ç»œï¼Œåˆ™ç§°è¯¥é›†æˆä¸ºåŒè´¨çš„ï¼ˆhomogeneousï¼‰;è‹¥ä¸ªä½“å­¦ä¹ å™¨åŒ…å«å¤šç§ç±»å‹çš„å­¦ä¹ ç®—æ³•ï¼Œä¾‹å¦‚æ—¢æœ‰å†³ç­–æ ‘åˆæœ‰ç¥ç»ç½‘ç»œï¼Œåˆ™ç§°è¯¥é›†æˆä¸ºå¼‚è´¨çš„ï¼ˆheterogenousï¼‰ã€‚</p><blockquote><p><strong>åŒè´¨é›†æˆ</strong>ï¼šä¸ªä½“å­¦ä¹ å™¨ç§°ä¸ºâ€œåŸºå­¦ä¹ å™¨â€ï¼ˆbase learnerï¼‰ï¼Œå¯¹åº”çš„å­¦ä¹ ç®—æ³•ä¸ºâ€œåŸºå­¦ä¹ ç®—æ³•â€ï¼ˆbase learning algorithmï¼‰ã€‚</p></blockquote><blockquote><p><strong>å¼‚è´¨é›†æˆ</strong>ï¼šä¸ªä½“å­¦ä¹ å™¨ç§°ä¸ºâ€œç»„ä»¶å­¦ä¹ å™¨â€ï¼ˆcomponent learnerï¼‰æˆ–ç›´ç§°ä¸ºâ€œä¸ªä½“å­¦ä¹ å™¨â€ã€‚</p></blockquote><p>ä¸Šé¢æˆ‘ä»¬å·²ç»æåˆ°è¦è®©é›†æˆèµ·æ¥çš„æ³›åŒ–æ€§èƒ½æ¯”å•ä¸ªå­¦ä¹ å™¨éƒ½è¦å¥½ï¼Œè™½è¯´å›¢ç»“åŠ›é‡å¤§ä½†ä¹Ÿæœ‰æœ¨æ¡¶çŸ­æ¿ç†è®ºè°ƒçš®æ£è›‹ï¼Œé‚£å¦‚ä½•åšåˆ°å‘¢ï¼Ÿè¿™å°±å¼•å‡ºäº†é›†æˆå­¦ä¹ çš„ä¸¤ä¸ªé‡è¦æ¦‚å¿µï¼š<strong>å‡†ç¡®æ€§</strong>å’Œ<strong>å¤šæ ·æ€§</strong>ï¼ˆdiversityï¼‰ã€‚å‡†ç¡®æ€§æŒ‡çš„æ˜¯ä¸ªä½“å­¦ä¹ å™¨ä¸èƒ½å¤ªå·®ï¼Œè¦æœ‰ä¸€å®šçš„å‡†ç¡®åº¦ï¼›å¤šæ ·æ€§åˆ™æ˜¯ä¸ªä½“å­¦ä¹ å™¨ä¹‹é—´çš„è¾“å‡ºè¦å…·æœ‰å·®å¼‚æ€§ã€‚é€šè¿‡ä¸‹é¢çš„è¿™ä¸‰ä¸ªä¾‹å­å¯ä»¥å¾ˆå®¹æ˜“çœ‹å‡ºè¿™ä¸€ç‚¹ï¼Œå‡†ç¡®åº¦è¾ƒé«˜ï¼Œå·®å¼‚åº¦ä¹Ÿè¾ƒé«˜ï¼Œå¯ä»¥è¾ƒå¥½åœ°æå‡é›†æˆæ€§èƒ½ã€‚</p><p><img src="https://i.loli.net/2018/10/18/5bc84d0d23e13.png" alt="2.png"></p><p>ç°åœ¨è€ƒè™‘äºŒåˆ†ç±»çš„ç®€å•æƒ…å½¢ï¼Œå‡è®¾åŸºåˆ†ç±»å™¨ä¹‹é—´ç›¸äº’ç‹¬ç«‹ï¼ˆèƒ½æä¾›è¾ƒé«˜çš„å·®å¼‚åº¦ï¼‰ï¼Œä¸”é”™è¯¯ç‡ç›¸ç­‰ä¸º Îµï¼Œåˆ™å¯ä»¥å°†é›†æˆå™¨çš„é¢„æµ‹çœ‹åšä¸€ä¸ªä¼¯åŠªåˆ©å®éªŒï¼Œæ˜“çŸ¥å½“æ‰€æœ‰åŸºåˆ†ç±»å™¨ä¸­ä¸è¶³ä¸€åŠé¢„æµ‹æ­£ç¡®çš„æƒ…å†µä¸‹ï¼Œé›†æˆå™¨é¢„æµ‹é”™è¯¯ï¼Œæ‰€ä»¥é›†æˆå™¨çš„é”™è¯¯ç‡å¯ä»¥è®¡ç®—ä¸ºï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc84d0cce0bb.png" alt="3.png"></p><p>æ­¤æ—¶ï¼Œé›†æˆå™¨é”™è¯¯ç‡éšç€åŸºåˆ†ç±»å™¨çš„ä¸ªæ•°çš„å¢åŠ å‘ˆæŒ‡æ•°ä¸‹é™ï¼Œä½†å‰ææ˜¯åŸºåˆ†ç±»å™¨ä¹‹é—´ç›¸äº’ç‹¬ç«‹ï¼Œåœ¨å®é™…æƒ…å½¢ä¸­æ˜¾ç„¶æ˜¯ä¸å¯èƒ½çš„ï¼Œå‡è®¾è®­ç»ƒæœ‰Aå’ŒBä¸¤ä¸ªåˆ†ç±»å™¨ï¼Œå¯¹äºæŸä¸ªæµ‹è¯•æ ·æœ¬ï¼Œæ˜¾ç„¶æ»¡è¶³ï¼šPï¼ˆA=1 | B=1ï¼‰&gt; Pï¼ˆA=1ï¼‰ï¼Œå› ä¸ºAå’ŒBä¸ºäº†è§£å†³ç›¸åŒçš„é—®é¢˜è€Œè®­ç»ƒï¼Œå› æ­¤åœ¨é¢„æµ‹æ–°æ ·æœ¬æ—¶å­˜åœ¨ç€å¾ˆå¤§çš„è”ç³»ã€‚å› æ­¤ï¼Œ<strong>ä¸ªä½“å­¦ä¹ å™¨çš„â€œå‡†ç¡®æ€§â€å’Œâ€œå·®å¼‚æ€§â€æœ¬èº«å°±æ˜¯ä¸€å¯¹çŸ›ç›¾çš„å˜é‡</strong>ï¼Œå‡†ç¡®æ€§é«˜æ„å‘³ç€ç‰ºç‰²å¤šæ ·æ€§ï¼Œæ‰€ä»¥äº§ç”Ÿâ€œ<strong>å¥½è€Œä¸åŒ</strong>â€çš„ä¸ªä½“å­¦ä¹ å™¨æ­£æ˜¯é›†æˆå­¦ä¹ ç ”ç©¶çš„æ ¸å¿ƒã€‚ç°é˜¶æ®µæœ‰ä¸‰ç§ä¸»æµçš„é›†æˆå­¦ä¹ æ–¹æ³•ï¼šBoostingã€Baggingä»¥åŠéšæœºæ£®æ—ï¼ˆRandom Forestï¼‰ï¼Œæ¥ä¸‹æ¥å°†è¿›è¡Œé€ä¸€ä»‹ç»ã€‚</p><h3 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h3><p>Boostingæ˜¯ä¸€ç§ä¸²è¡Œçš„å·¥ä½œæœºåˆ¶ï¼Œå³ä¸ªä½“å­¦ä¹ å™¨çš„è®­ç»ƒå­˜åœ¨ä¾èµ–å…³ç³»ï¼Œå¿…é¡»ä¸€æ­¥ä¸€æ­¥åºåˆ—åŒ–è¿›è¡Œã€‚å…¶åŸºæœ¬æ€æƒ³æ˜¯ï¼šå¢åŠ å‰ä¸€ä¸ªåŸºå­¦ä¹ å™¨åœ¨è®­ç»ƒè®­ç»ƒè¿‡ç¨‹ä¸­é¢„æµ‹é”™è¯¯æ ·æœ¬çš„æƒé‡ï¼Œä½¿å¾—åç»­åŸºå­¦ä¹ å™¨æ›´åŠ å…³æ³¨è¿™äº›æ‰“æ ‡é”™è¯¯çš„è®­ç»ƒæ ·æœ¬ï¼Œå°½å¯èƒ½çº æ­£è¿™äº›é”™è¯¯ï¼Œä¸€ç›´å‘ä¸‹ä¸²è¡Œç›´è‡³äº§ç”Ÿéœ€è¦çš„Tä¸ªåŸºå­¦ä¹ å™¨ï¼ŒBoostingæœ€ç»ˆå¯¹è¿™Tä¸ªå­¦ä¹ å™¨è¿›è¡ŒåŠ æƒç»“åˆï¼Œäº§ç”Ÿå­¦ä¹ å™¨å§”å‘˜ä¼šã€‚</p><p>Boostingæ—ç®—æ³•æœ€è‘—åã€ä½¿ç”¨æœ€ä¸ºå¹¿æ³›çš„å°±æ˜¯AdaBoostï¼Œå› æ­¤ä¸‹é¢ä¸»è¦æ˜¯å¯¹AdaBoostç®—æ³•è¿›è¡Œä»‹ç»ã€‚AdaBoostä½¿ç”¨çš„æ˜¯<strong>æŒ‡æ•°æŸå¤±å‡½æ•°</strong>ï¼Œå› æ­¤AdaBoostçš„æƒå€¼ä¸æ ·æœ¬åˆ†å¸ƒçš„æ›´æ–°éƒ½æ˜¯å›´ç»•ç€æœ€å°åŒ–æŒ‡æ•°æŸå¤±å‡½æ•°è¿›è¡Œçš„ã€‚çœ‹åˆ°è¿™é‡Œå›æƒ³ä¸€ä¸‹ä¹‹å‰çš„æœºå™¨å­¦ä¹ ç®—æ³•ï¼Œ<strong>ä¸éš¾å‘ç°æœºå™¨å­¦ä¹ çš„å¤§éƒ¨åˆ†å¸¦å‚æ¨¡å‹åªæ˜¯æ”¹å˜äº†æœ€ä¼˜åŒ–ç›®æ ‡ä¸­çš„æŸå¤±å‡½æ•°</strong>ï¼šå¦‚æœæ˜¯Square lossï¼Œé‚£å°±æ˜¯æœ€å°äºŒä¹˜äº†ï¼›å¦‚æœæ˜¯Hinge Lossï¼Œé‚£å°±æ˜¯è‘—åçš„SVMäº†ï¼›å¦‚æœæ˜¯log-Lossï¼Œé‚£å°±æ˜¯Logistic Regressionäº†ã€‚</p><p>å®šä¹‰åŸºå­¦ä¹ å™¨çš„é›†æˆä¸ºåŠ æƒç»“åˆï¼Œåˆ™æœ‰ï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc84d0ca2ca5.png" alt="4.png"></p><p>AdaBoostç®—æ³•çš„æŒ‡æ•°æŸå¤±å‡½æ•°å®šä¹‰ä¸ºï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc84d0d10461.png" alt="5.png"></p><p>å…·ä½“è¯´æ¥ï¼Œæ•´ä¸ªAdaboost è¿­ä»£ç®—æ³•åˆ†ä¸º3æ­¥ï¼š</p><ul><li>åˆå§‹åŒ–è®­ç»ƒæ•°æ®çš„æƒå€¼åˆ†å¸ƒã€‚å¦‚æœæœ‰Nä¸ªæ ·æœ¬ï¼Œåˆ™æ¯ä¸€ä¸ªè®­ç»ƒæ ·æœ¬æœ€å¼€å§‹æ—¶éƒ½è¢«èµ‹äºˆç›¸åŒçš„æƒå€¼ï¼š1/Nã€‚</li><li>è®­ç»ƒå¼±åˆ†ç±»å™¨ã€‚å…·ä½“è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¦‚æœæŸä¸ªæ ·æœ¬ç‚¹å·²ç»è¢«å‡†ç¡®åœ°åˆ†ç±»ï¼Œé‚£ä¹ˆåœ¨æ„é€ ä¸‹ä¸€ä¸ªè®­ç»ƒé›†ä¸­ï¼Œå®ƒçš„æƒå€¼å°±è¢«é™ä½ï¼›ç›¸åï¼Œå¦‚æœæŸä¸ªæ ·æœ¬ç‚¹æ²¡æœ‰è¢«å‡†ç¡®åœ°åˆ†ç±»ï¼Œé‚£ä¹ˆå®ƒçš„æƒå€¼å°±å¾—åˆ°æé«˜ã€‚ç„¶åï¼Œæƒå€¼æ›´æ–°è¿‡çš„æ ·æœ¬é›†è¢«ç”¨äºè®­ç»ƒä¸‹ä¸€ä¸ªåˆ†ç±»å™¨ï¼Œæ•´ä¸ªè®­ç»ƒè¿‡ç¨‹å¦‚æ­¤è¿­ä»£åœ°è¿›è¡Œä¸‹å»ã€‚</li><li>å°†å„ä¸ªè®­ç»ƒå¾—åˆ°çš„å¼±åˆ†ç±»å™¨ç»„åˆæˆå¼ºåˆ†ç±»å™¨ã€‚å„ä¸ªå¼±åˆ†ç±»å™¨çš„è®­ç»ƒè¿‡ç¨‹ç»“æŸåï¼ŒåŠ å¤§åˆ†ç±»è¯¯å·®ç‡å°çš„å¼±åˆ†ç±»å™¨çš„æƒé‡ï¼Œä½¿å…¶åœ¨æœ€ç»ˆçš„åˆ†ç±»å‡½æ•°ä¸­èµ·ç€è¾ƒå¤§çš„å†³å®šä½œç”¨ï¼Œè€Œé™ä½åˆ†ç±»è¯¯å·®ç‡å¤§çš„å¼±åˆ†ç±»å™¨çš„æƒé‡ï¼Œä½¿å…¶åœ¨æœ€ç»ˆçš„åˆ†ç±»å‡½æ•°ä¸­èµ·ç€è¾ƒå°çš„å†³å®šä½œç”¨ã€‚</li></ul><p>æ•´ä¸ªAdaBoostçš„ç®—æ³•æµç¨‹å¦‚ä¸‹æ‰€ç¤ºï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc84d0d7c057.png" alt="6.png"></p><p>å¯ä»¥çœ‹å‡ºï¼š<strong>AdaBoostçš„æ ¸å¿ƒæ­¥éª¤å°±æ˜¯è®¡ç®—åŸºå­¦ä¹ å™¨æƒé‡å’Œæ ·æœ¬æƒé‡åˆ†å¸ƒ</strong>ï¼Œé‚£ä¸ºä½•æ˜¯ä¸Šè¿°çš„è®¡ç®—å…¬å¼å‘¢ï¼Ÿè¿™å°±æ¶‰åŠåˆ°äº†æˆ‘ä»¬ä¹‹å‰ä¸ºä»€ä¹ˆè¯´å¤§éƒ¨åˆ†å¸¦å‚æœºå™¨å­¦ä¹ ç®—æ³•åªæ˜¯æ”¹å˜äº†æŸå¤±å‡½æ•°ï¼Œå°±æ˜¯å› ä¸º<strong>å¤§éƒ¨åˆ†æ¨¡å‹çš„å‚æ•°éƒ½æ˜¯é€šè¿‡æœ€ä¼˜åŒ–æŸå¤±å‡½æ•°ï¼ˆå¯èƒ½è¿˜åŠ ä¸ªè§„åˆ™é¡¹ï¼‰è€Œè®¡ç®—ï¼ˆæ¢¯åº¦ä¸‹é™ï¼Œåæ ‡ä¸‹é™ç­‰ï¼‰å¾—åˆ°</strong>ï¼Œè¿™é‡Œæ­£æ˜¯é€šè¿‡æœ€ä¼˜åŒ–æŒ‡æ•°æŸå¤±å‡½æ•°ä»è€Œå¾—åˆ°è¿™ä¸¤ä¸ªå‚æ•°çš„è®¡ç®—å…¬å¼ï¼Œå…·ä½“çš„æ¨å¯¼è¿‡ç¨‹æ­¤å¤„ä¸è¿›è¡Œå±•å¼€ã€‚</p><p>Boostingç®—æ³•è¦æ±‚åŸºå­¦ä¹ å™¨èƒ½å¯¹ç‰¹å®šåˆ†å¸ƒçš„æ•°æ®è¿›è¡Œå­¦ä¹ ï¼Œå³æ¯æ¬¡éƒ½æ›´æ–°æ ·æœ¬åˆ†å¸ƒæƒé‡ï¼Œè¿™é‡Œä¹¦ä¸Šæåˆ°äº†ä¸¤ç§æ–¹æ³•ï¼šâ€œé‡èµ‹æƒæ³•â€ï¼ˆre-weightingï¼‰å’Œâ€œé‡é‡‡æ ·æ³•â€ï¼ˆre-samplingï¼‰ï¼Œä¹¦ä¸Šçš„è§£é‡Šæœ‰äº›æ™¦æ¶©ï¼Œè¿™é‡Œè¿›è¡Œå±•å¼€ä¸€ä¸‹ï¼š</p><blockquote><p><strong>é‡èµ‹æƒæ³•</strong> : å¯¹æ¯ä¸ªæ ·æœ¬é™„åŠ ä¸€ä¸ªæƒé‡ï¼Œè¿™æ—¶æ¶‰åŠåˆ°æ ·æœ¬å±æ€§ä¸æ ‡ç­¾çš„è®¡ç®—ï¼Œéƒ½éœ€è¦ä¹˜ä¸Šä¸€ä¸ªæƒå€¼ã€‚<br><strong>é‡é‡‡æ ·æ³•</strong> : å¯¹äºä¸€äº›æ— æ³•æ¥å—å¸¦æƒæ ·æœ¬çš„åŠå­¦ä¹ ç®—æ³•ï¼Œé€‚åˆç”¨â€œé‡é‡‡æ ·æ³•â€è¿›è¡Œå¤„ç†ã€‚æ–¹æ³•å¤§è‡´è¿‡ç¨‹æ˜¯ï¼Œæ ¹æ®å„ä¸ªæ ·æœ¬çš„æƒé‡ï¼Œå¯¹è®­ç»ƒæ•°æ®è¿›è¡Œé‡é‡‡æ ·ï¼Œåˆå§‹æ—¶æ ·æœ¬æƒé‡ä¸€æ ·ï¼Œæ¯ä¸ªæ ·æœ¬è¢«é‡‡æ ·åˆ°çš„æ¦‚ç‡ä¸€è‡´ï¼Œæ¯æ¬¡ä»Nä¸ªåŸå§‹çš„è®­ç»ƒæ ·æœ¬ä¸­æŒ‰ç…§æƒé‡æœ‰æ”¾å›é‡‡æ ·Nä¸ªæ ·æœ¬ä½œä¸ºè®­ç»ƒé›†ï¼Œç„¶åè®¡ç®—è®­ç»ƒé›†é”™è¯¯ç‡ï¼Œç„¶åè°ƒæ•´æƒé‡ï¼Œé‡å¤é‡‡æ ·ï¼Œé›†æˆå¤šä¸ªåŸºå­¦ä¹ å™¨ã€‚</p></blockquote><p>ä»åå·®-æ–¹å·®åˆ†è§£æ¥çœ‹ï¼šBoostingç®—æ³•ä¸»è¦å…³æ³¨äºé™ä½åå·®ï¼Œæ¯è½®çš„è¿­ä»£éƒ½å…³æ³¨äºè®­ç»ƒè¿‡ç¨‹ä¸­é¢„æµ‹é”™è¯¯çš„æ ·æœ¬ï¼Œå°†å¼±å­¦ä¹ æå‡ä¸ºå¼ºå­¦ä¹ å™¨ã€‚ä»AdaBoostçš„ç®—æ³•æµç¨‹æ¥çœ‹ï¼Œæ ‡å‡†çš„AdaBooståªé€‚ç”¨äºäºŒåˆ†ç±»é—®é¢˜ã€‚åœ¨æ­¤ï¼Œå½“é€‰ä¸ºæ•°æ®æŒ–æ˜åå¤§ç®—æ³•ä¹‹ä¸€çš„AdaBoostä»‹ç»åˆ°è¿™é‡Œï¼Œèƒ½å¤Ÿå½“é€‰æ­£æ˜¯è¯´æ˜è¿™ä¸ªç®—æ³•ååˆ†å©€å¨œå¤šå§¿ï¼ŒèƒŒåçš„æ•°å­¦è¯æ˜å’Œæ¨å¯¼å……åˆ†è¯æ˜äº†è¿™ä¸€ç‚¹ï¼Œé™äºç¯‡å¹…ä¸å†ç»§ç»­å±•å¼€ã€‚</p><h3 id="Baggingä¸Random-Forest"><a href="#Baggingä¸Random-Forest" class="headerlink" title="Baggingä¸Random Forest"></a>Baggingä¸Random Forest</h3><p>ç›¸æ¯”ä¹‹ä¸‹ï¼ŒBaggingä¸éšæœºæ£®æ—ç®—æ³•å°±ç®€æ´äº†è®¸å¤šï¼Œä¸Šé¢å·²ç»æåˆ°äº§ç”Ÿâ€œå¥½è€Œä¸åŒâ€çš„ä¸ªä½“å­¦ä¹ å™¨æ˜¯é›†æˆå­¦ä¹ ç ”ç©¶çš„æ ¸å¿ƒï¼Œå³åœ¨ä¿è¯åŸºå­¦ä¹ å™¨å‡†ç¡®æ€§çš„åŒæ—¶å¢åŠ åŸºå­¦ä¹ å™¨ä¹‹é—´çš„å¤šæ ·æ€§ã€‚è€Œè¿™ä¸¤ç§ç®—æ³•çš„åŸºæœ¬æ€ï¼ˆtaoï¼‰æƒ³ï¼ˆluï¼‰éƒ½æ˜¯é€šè¿‡â€œè‡ªåŠ©é‡‡æ ·â€çš„æ–¹æ³•æ¥å¢åŠ å¤šæ ·æ€§ã€‚</p><h4 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h4><p>Baggingæ˜¯ä¸€ç§å¹¶è¡Œå¼çš„é›†æˆå­¦ä¹ æ–¹æ³•ï¼Œå³åŸºå­¦ä¹ å™¨çš„è®­ç»ƒä¹‹é—´æ²¡æœ‰å‰åé¡ºåºå¯ä»¥åŒæ—¶è¿›è¡Œï¼ŒBaggingä½¿ç”¨â€œæœ‰æ”¾å›â€é‡‡æ ·çš„æ–¹å¼é€‰å–è®­ç»ƒé›†ï¼Œå¯¹äºåŒ…å«mä¸ªæ ·æœ¬çš„è®­ç»ƒé›†ï¼Œè¿›è¡Œmæ¬¡æœ‰æ”¾å›çš„éšæœºé‡‡æ ·æ“ä½œï¼Œä»è€Œå¾—åˆ°mä¸ªæ ·æœ¬çš„é‡‡æ ·é›†ï¼Œè¿™æ ·è®­ç»ƒé›†ä¸­æœ‰æ¥è¿‘36.8%çš„æ ·æœ¬æ²¡æœ‰è¢«é‡‡åˆ°ã€‚æŒ‰ç…§ç›¸åŒçš„æ–¹å¼é‡å¤è¿›è¡Œï¼Œæˆ‘ä»¬å°±å¯ä»¥é‡‡é›†åˆ°Tä¸ªåŒ…å«mä¸ªæ ·æœ¬çš„æ•°æ®é›†ï¼Œä»è€Œè®­ç»ƒå‡ºTä¸ªåŸºå­¦ä¹ å™¨ï¼Œæœ€ç»ˆå¯¹è¿™Tä¸ªåŸºå­¦ä¹ å™¨çš„è¾“å‡ºè¿›è¡Œç»“åˆã€‚</p><p><img src="https://i.loli.net/2018/10/18/5bc84d0ce62fc.png" alt="7.png"></p><p>Baggingç®—æ³•çš„æµç¨‹å¦‚ä¸‹æ‰€ç¤ºï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc84d0d0e761.png" alt="8.png"></p><p>å¯ä»¥çœ‹å‡ºBaggingä¸»è¦é€šè¿‡<strong>æ ·æœ¬çš„æ‰°åŠ¨</strong>æ¥å¢åŠ åŸºå­¦ä¹ å™¨ä¹‹é—´çš„å¤šæ ·æ€§ï¼Œå› æ­¤Baggingçš„åŸºå­¦ä¹ å™¨åº”ä¸ºé‚£äº›å¯¹è®­ç»ƒé›†ååˆ†æ•æ„Ÿçš„ä¸ç¨³å®šå­¦ä¹ ç®—æ³•ï¼Œä¾‹å¦‚ï¼šç¥ç»ç½‘ç»œä¸å†³ç­–æ ‘ç­‰ã€‚ä»åå·®-æ–¹å·®åˆ†è§£æ¥çœ‹ï¼ŒBaggingç®—æ³•ä¸»è¦å…³æ³¨äºé™ä½æ–¹å·®ï¼Œå³é€šè¿‡å¤šæ¬¡é‡å¤è®­ç»ƒæé«˜ç¨³å®šæ€§ã€‚ä¸åŒäºAdaBoostçš„æ˜¯ï¼ŒBaggingå¯ä»¥ååˆ†ç®€å•åœ°ç§»æ¤åˆ°å¤šåˆ†ç±»ã€å›å½’ç­‰é—®é¢˜ã€‚æ€»çš„è¯´èµ·æ¥åˆ™æ˜¯ï¼š<strong>AdaBoostå…³æ³¨äºé™ä½åå·®ï¼Œè€ŒBaggingå…³æ³¨äºé™ä½æ–¹å·®ã€‚</strong></p><h4 id="éšæœºæ£®æ—"><a href="#éšæœºæ£®æ—" class="headerlink" title="éšæœºæ£®æ—"></a>éšæœºæ£®æ—</h4><p>éšæœºæ£®æ—ï¼ˆRandom Forestï¼‰æ˜¯Baggingçš„ä¸€ä¸ªæ‹“å±•ä½“ï¼Œå®ƒçš„åŸºå­¦ä¹ å™¨å›ºå®šä¸ºå†³ç­–æ ‘ï¼Œå¤šæ£µæ ‘ä¹Ÿå°±ç»„æˆäº†æ£®æ—ï¼Œè€Œâ€œéšæœºâ€åˆ™åœ¨äºé€‰æ‹©åˆ’åˆ†å±æ€§çš„éšæœºï¼Œéšæœºæ£®æ—åœ¨è®­ç»ƒåŸºå­¦ä¹ å™¨æ—¶ï¼Œä¹Ÿé‡‡ç”¨æœ‰æ”¾å›é‡‡æ ·çš„æ–¹å¼æ·»åŠ æ ·æœ¬æ‰°åŠ¨ï¼ŒåŒæ—¶å®ƒè¿˜å¼•å…¥äº†ä¸€ç§<strong>å±æ€§æ‰°åŠ¨</strong>ï¼Œå³åœ¨åŸºå†³ç­–æ ‘çš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œåœ¨é€‰æ‹©åˆ’åˆ†å±æ€§æ—¶ï¼ŒRFå…ˆä»å€™é€‰å±æ€§é›†ä¸­éšæœºæŒ‘é€‰å‡ºä¸€ä¸ªåŒ…å«Kä¸ªå±æ€§çš„å­é›†ï¼Œå†ä»è¿™ä¸ªå­é›†ä¸­é€‰æ‹©æœ€ä¼˜åˆ’åˆ†å±æ€§ï¼Œä¸€èˆ¬æ¨èK=log2ï¼ˆdï¼‰ã€‚</p><p>è¿™æ ·éšæœºæ£®æ—ä¸­åŸºå­¦ä¹ å™¨çš„å¤šæ ·æ€§ä¸ä»…æ¥è‡ªæ ·æœ¬æ‰°åŠ¨ï¼Œè¿˜æ¥è‡ªå±æ€§æ‰°åŠ¨ï¼Œä»è€Œè¿›ä¸€æ­¥æå‡äº†åŸºå­¦ä¹ å™¨ä¹‹é—´çš„å·®å¼‚åº¦ã€‚ç›¸æ¯”å†³ç­–æ ‘çš„Baggingé›†æˆï¼Œéšæœºæ£®æ—çš„èµ·å§‹æ€§èƒ½è¾ƒå·®ï¼ˆç”±äºå±æ€§æ‰°åŠ¨ï¼ŒåŸºå†³ç­–æ ‘çš„å‡†ç¡®åº¦æœ‰æ‰€ä¸‹é™ï¼‰ï¼Œä½†éšç€åŸºå­¦ä¹ å™¨æ•°ç›®çš„å¢å¤šï¼Œéšæœºæ£®æ—å¾€å¾€ä¼šæ”¶æ•›åˆ°æ›´ä½çš„æ³›åŒ–è¯¯å·®ã€‚åŒæ—¶ä¸åŒäºBaggingä¸­å†³ç­–æ ‘ä»æ‰€æœ‰å±æ€§é›†ä¸­é€‰æ‹©æœ€ä¼˜åˆ’åˆ†å±æ€§ï¼Œéšæœºæ£®æ—åªåœ¨å±æ€§é›†çš„ä¸€ä¸ªå­é›†ä¸­é€‰æ‹©åˆ’åˆ†å±æ€§ï¼Œå› æ­¤è®­ç»ƒæ•ˆç‡æ›´é«˜ã€‚<br><img src="../img/random-forest.png" alt><br><img src="https://i.loli.net/2018/10/18/5bc84d0d7a4fd.png" alt="9.png"></p><h3 id="ç»“åˆç­–ç•¥"><a href="#ç»“åˆç­–ç•¥" class="headerlink" title="ç»“åˆç­–ç•¥"></a>ç»“åˆç­–ç•¥</h3><p>ç»“åˆç­–ç•¥æŒ‡çš„æ˜¯åœ¨è®­ç»ƒå¥½åŸºå­¦ä¹ å™¨åï¼Œå¦‚ä½•å°†è¿™äº›åŸºå­¦ä¹ å™¨çš„è¾“å‡ºç»“åˆèµ·æ¥äº§ç”Ÿé›†æˆæ¨¡å‹çš„æœ€ç»ˆè¾“å‡ºï¼Œä¸‹é¢å°†ä»‹ç»ä¸€äº›å¸¸ç”¨çš„ç»“åˆç­–ç•¥ï¼š</p><h4 id="å¹³å‡æ³•ï¼ˆå›å½’é—®é¢˜ï¼‰"><a href="#å¹³å‡æ³•ï¼ˆå›å½’é—®é¢˜ï¼‰" class="headerlink" title="å¹³å‡æ³•ï¼ˆå›å½’é—®é¢˜ï¼‰"></a>å¹³å‡æ³•ï¼ˆå›å½’é—®é¢˜ï¼‰</h4><p><img src="https://i.loli.net/2018/10/18/5bc84d0d07983.png" alt="10.png"></p><p><img src="https://i.loli.net/2018/10/18/5bc84de1b74ff.png" alt="11.png"></p><p>æ˜“çŸ¥ç®€å•å¹³å‡æ³•æ˜¯åŠ æƒå¹³å‡æ³•çš„ä¸€ç§ç‰¹ä¾‹ï¼ŒåŠ æƒå¹³å‡æ³•å¯ä»¥è®¤ä¸ºæ˜¯é›†æˆå­¦ä¹ ç ”ç©¶çš„åŸºæœ¬å‡ºå‘ç‚¹ã€‚ç”±äºå„ä¸ªåŸºå­¦ä¹ å™¨çš„æƒå€¼åœ¨è®­ç»ƒä¸­å¾—å‡ºï¼Œ<strong>ä¸€èˆ¬è€Œè¨€ï¼Œåœ¨ä¸ªä½“å­¦ä¹ å™¨æ€§èƒ½ç›¸å·®è¾ƒå¤§æ—¶å®œä½¿ç”¨åŠ æƒå¹³å‡æ³•ï¼Œåœ¨ä¸ªä½“å­¦ä¹ å™¨æ€§èƒ½ç›¸å·®è¾ƒå°æ—¶å®œä½¿ç”¨ç®€å•å¹³å‡æ³•</strong>ã€‚</p><h4 id="æŠ•ç¥¨æ³•ï¼ˆåˆ†ç±»é—®é¢˜ï¼‰"><a href="#æŠ•ç¥¨æ³•ï¼ˆåˆ†ç±»é—®é¢˜ï¼‰" class="headerlink" title="æŠ•ç¥¨æ³•ï¼ˆåˆ†ç±»é—®é¢˜ï¼‰"></a>æŠ•ç¥¨æ³•ï¼ˆåˆ†ç±»é—®é¢˜ï¼‰</h4><p><img src="https://i.loli.net/2018/10/18/5bc84de2629c4.png" alt="12.png"></p><p><img src="https://i.loli.net/2018/10/18/5bc84de25a74b.png" alt="13.png"></p><p><img src="https://i.loli.net/2018/10/18/5bc84de1bacc4.png" alt="14.png"></p><p>ç»å¯¹å¤šæ•°æŠ•ç¥¨æ³•ï¼ˆmajority votingï¼‰æä¾›äº†æ‹’ç»é€‰é¡¹ï¼Œè¿™åœ¨å¯é æ€§è¦æ±‚å¾ˆé«˜çš„å­¦ä¹ ä»»åŠ¡ä¸­æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„æœºåˆ¶ã€‚åŒæ—¶ï¼Œå¯¹äºåˆ†ç±»ä»»åŠ¡ï¼Œå„ä¸ªåŸºå­¦ä¹ å™¨çš„è¾“å‡ºå€¼æœ‰ä¸¤ç§ç±»å‹ï¼Œåˆ†åˆ«ä¸ºç±»æ ‡è®°å’Œç±»æ¦‚ç‡ã€‚</p><p><img src="https://i.loli.net/2018/10/18/5bc84de2768c1.png" alt="15.png"></p><p>ä¸€äº›åœ¨äº§ç”Ÿç±»åˆ«æ ‡è®°çš„åŒæ—¶ä¹Ÿç”Ÿæˆç½®ä¿¡åº¦çš„å­¦ä¹ å™¨ï¼Œç½®ä¿¡åº¦å¯è½¬åŒ–ä¸ºç±»æ¦‚ç‡ä½¿ç”¨ï¼Œ<strong>ä¸€èˆ¬åŸºäºç±»æ¦‚ç‡è¿›è¡Œç»“åˆå¾€å¾€æ¯”åŸºäºç±»æ ‡è®°è¿›è¡Œç»“åˆçš„æ•ˆæœæ›´å¥½</strong>ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯å¯¹äºå¼‚è´¨é›†æˆï¼Œå…¶ç±»æ¦‚ç‡ä¸èƒ½ç›´æ¥è¿›è¡Œæ¯”è¾ƒï¼Œæ­¤æ—¶éœ€è¦å°†ç±»æ¦‚ç‡è½¬åŒ–ä¸ºç±»æ ‡è®°è¾“å‡ºï¼Œç„¶åå†æŠ•ç¥¨ã€‚</p><h4 id="å­¦ä¹ æ³•"><a href="#å­¦ä¹ æ³•" class="headerlink" title="å­¦ä¹ æ³•"></a>å­¦ä¹ æ³•</h4><p>å­¦ä¹ æ³•æ˜¯ä¸€ç§æ›´é«˜çº§çš„ç»“åˆç­–ç•¥ï¼Œå³å­¦ä¹ å‡ºä¸€ç§â€œæŠ•ç¥¨â€çš„å­¦ä¹ å™¨ï¼ŒStackingæ˜¯å­¦ä¹ æ³•çš„å…¸å‹ä»£è¡¨ã€‚Stackingçš„åŸºæœ¬æ€æƒ³æ˜¯ï¼šé¦–å…ˆè®­ç»ƒå‡ºTä¸ªåŸºå­¦ä¹ å™¨ï¼Œå¯¹äºä¸€ä¸ªæ ·æœ¬å®ƒä»¬ä¼šäº§ç”ŸTä¸ªè¾“å‡ºï¼Œå°†è¿™Tä¸ªåŸºå­¦ä¹ å™¨çš„è¾“å‡ºä¸è¯¥æ ·æœ¬çš„çœŸå®æ ‡è®°ä½œä¸ºæ–°çš„æ ·æœ¬ï¼Œmä¸ªæ ·æœ¬å°±ä¼šäº§ç”Ÿä¸€ä¸ªm<em>Tçš„æ ·æœ¬é›†ï¼Œæ¥è®­ç»ƒä¸€ä¸ªæ–°çš„â€œæŠ•ç¥¨â€å­¦ä¹ å™¨ã€‚æŠ•ç¥¨å­¦ä¹ å™¨çš„è¾“å…¥å±æ€§ä¸å­¦ä¹ ç®—æ³•å¯¹Stackingé›†æˆçš„æ³›åŒ–æ€§èƒ½æœ‰å¾ˆå¤§çš„å½±å“ï¼Œä¹¦ä¸­å·²ç»æåˆ°ï¼š*</em>æŠ•ç¥¨å­¦ä¹ å™¨é‡‡ç”¨ç±»æ¦‚ç‡ä½œä¸ºè¾“å…¥å±æ€§ï¼Œé€‰ç”¨å¤šå“åº”çº¿æ€§å›å½’ï¼ˆMLRï¼‰ä¸€èˆ¬ä¼šäº§ç”Ÿè¾ƒå¥½çš„æ•ˆæœ**ã€‚</p><p><img src="https://i.loli.net/2018/10/18/5bc84de25cbaf.png" alt="16.png"></p><h4 id="å¤šæ ·æ€§ï¼ˆdiversityï¼‰"><a href="#å¤šæ ·æ€§ï¼ˆdiversityï¼‰" class="headerlink" title="å¤šæ ·æ€§ï¼ˆdiversityï¼‰"></a>å¤šæ ·æ€§ï¼ˆdiversityï¼‰</h4><p>åœ¨é›†æˆå­¦ä¹ ä¸­ï¼ŒåŸºå­¦ä¹ å™¨ä¹‹é—´çš„å¤šæ ·æ€§æ˜¯å½±å“é›†æˆå™¨æ³›åŒ–æ€§èƒ½çš„é‡è¦å› ç´ ã€‚å› æ­¤å¢åŠ å¤šæ ·æ€§å¯¹äºé›†æˆå­¦ä¹ ç ”ç©¶ååˆ†é‡è¦ï¼Œä¸€èˆ¬çš„æ€è·¯æ˜¯åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­å¼•å…¥éšæœºæ€§ï¼Œå¸¸è§çš„åšæ³•ä¸»è¦æ˜¯å¯¹æ•°æ®æ ·æœ¬ã€è¾“å…¥å±æ€§ã€è¾“å‡ºè¡¨ç¤ºã€ç®—æ³•å‚æ•°è¿›è¡Œæ‰°åŠ¨ã€‚</p><blockquote><p><strong>æ•°æ®æ ·æœ¬æ‰°åŠ¨</strong>ï¼Œå³åˆ©ç”¨å…·æœ‰å·®å¼‚çš„æ•°æ®é›†æ¥è®­ç»ƒä¸åŒçš„åŸºå­¦ä¹ å™¨ã€‚ä¾‹å¦‚ï¼šæœ‰æ”¾å›è‡ªåŠ©é‡‡æ ·æ³•ï¼Œä½†æ­¤ç±»åšæ³•åªå¯¹é‚£äº›ä¸ç¨³å®šå­¦ä¹ ç®—æ³•ååˆ†æœ‰æ•ˆï¼Œä¾‹å¦‚ï¼šå†³ç­–æ ‘å’Œç¥ç»ç½‘ç»œç­‰ï¼Œè®­ç»ƒé›†çš„ç¨å¾®æ”¹å˜èƒ½å¯¼è‡´å­¦ä¹ å™¨çš„æ˜¾è‘—å˜åŠ¨ã€‚<br><strong>è¾“å…¥å±æ€§æ‰°åŠ¨</strong>ï¼Œå³éšæœºé€‰å–åŸç©ºé—´çš„ä¸€ä¸ªå­ç©ºé—´æ¥è®­ç»ƒåŸºå­¦ä¹ å™¨ã€‚ä¾‹å¦‚ï¼šéšæœºæ£®æ—ï¼Œä»åˆå§‹å±æ€§é›†ä¸­æŠ½å–å­é›†ï¼Œå†åŸºäºæ¯ä¸ªå­é›†æ¥è®­ç»ƒåŸºå­¦ä¹ å™¨ã€‚ä½†è‹¥è®­ç»ƒé›†åªåŒ…å«å°‘é‡å±æ€§ï¼Œåˆ™ä¸å®œä½¿ç”¨å±æ€§æ‰°åŠ¨ã€‚<br><strong>è¾“å‡ºè¡¨ç¤ºæ‰°åŠ¨</strong>ï¼Œæ­¤ç±»åšæ³•å¯å¯¹è®­ç»ƒæ ·æœ¬çš„ç±»æ ‡ç¨ä½œå˜åŠ¨ï¼Œæˆ–å¯¹åŸºå­¦ä¹ å™¨çš„è¾“å‡ºè¿›è¡Œè½¬åŒ–ã€‚<br><strong>ç®—æ³•å‚æ•°æ‰°åŠ¨</strong>ï¼Œé€šè¿‡éšæœºè®¾ç½®ä¸åŒçš„å‚æ•°ï¼Œä¾‹å¦‚ï¼šç¥ç»ç½‘ç»œä¸­ï¼Œéšæœºåˆå§‹åŒ–æƒé‡ä¸éšæœºè®¾ç½®éšå«å±‚èŠ‚ç‚¹æ•°ã€‚</p></blockquote><h2 id="æœºå™¨å­¦ä¹ ä¸­çš„Boostingæ¨¡å‹ï¼šGBDT-vs-Xgboost-vs-LightGBM"><a href="#æœºå™¨å­¦ä¹ ä¸­çš„Boostingæ¨¡å‹ï¼šGBDT-vs-Xgboost-vs-LightGBM" class="headerlink" title="æœºå™¨å­¦ä¹ ä¸­çš„Boostingæ¨¡å‹ï¼šGBDT vs Xgboost vs LightGBM"></a>æœºå™¨å­¦ä¹ ä¸­çš„Boostingæ¨¡å‹ï¼šGBDT vs Xgboost vs LightGBM</h2><p>è§èµ„æ–™<strong>GBDT_wepon.pdf</strong></p>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹  </tag>
            
            <tag> é›†æˆå­¦ä¹  </tag>
            
            <tag> boosting </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>èšç±»ä¸é™ç»´</title>
      <link href="/2019/09/01/%E8%81%9A%E7%B1%BB%E4%B8%8E%E9%99%8D%E7%BB%B4/"/>
      <url>/2019/09/01/%E8%81%9A%E7%B1%BB%E4%B8%8E%E9%99%8D%E7%BB%B4/</url>
      
        <content type="html"><![CDATA[<h2 id="æœºå™¨å­¦ä¹ ä¸­çš„èšç±»ç®—æ³•"><a href="#æœºå™¨å­¦ä¹ ä¸­çš„èšç±»ç®—æ³•" class="headerlink" title="æœºå™¨å­¦ä¹ ä¸­çš„èšç±»ç®—æ³•"></a>æœºå™¨å­¦ä¹ ä¸­çš„èšç±»ç®—æ³•</h2><p>èšç±»æ˜¯ä¸€ç§ç»å…¸çš„<strong>æ— ç›‘ç£å­¦ä¹ </strong>æ–¹æ³•ï¼Œ<strong>æ— ç›‘ç£å­¦ä¹ çš„ç›®æ ‡æ˜¯é€šè¿‡å¯¹æ— æ ‡è®°è®­ç»ƒæ ·æœ¬çš„å­¦ä¹ ï¼Œå‘æ˜å’Œæ­ç¤ºæ•°æ®é›†æœ¬èº«æ½œåœ¨çš„ç»“æ„ä¸è§„å¾‹</strong>ï¼Œå³ä¸ä¾èµ–äºè®­ç»ƒæ•°æ®é›†çš„ç±»æ ‡è®°ä¿¡æ¯ã€‚èšç±»åˆ™æ˜¯è¯•å›¾å°†æ•°æ®é›†çš„æ ·æœ¬åˆ’åˆ†ä¸ºè‹¥å¹²ä¸ªäº’ä¸ç›¸äº¤çš„ç±»ç°‡ï¼Œä»è€Œæ¯ä¸ªç°‡å¯¹åº”ä¸€ä¸ªæ½œåœ¨çš„ç±»åˆ«ã€‚</p><p>èšç±»ç›´è§‚ä¸Šæ¥è¯´æ˜¯å°†ç›¸ä¼¼çš„æ ·æœ¬èšåœ¨ä¸€èµ·ï¼Œä»è€Œå½¢æˆä¸€ä¸ª<strong>ç±»ç°‡ï¼ˆclusterï¼‰</strong>ã€‚é‚£é¦–å…ˆçš„é—®é¢˜æ˜¯å¦‚ä½•æ¥<strong>åº¦é‡ç›¸ä¼¼æ€§</strong>ï¼ˆsimilarity measureï¼‰å‘¢ï¼Ÿè¿™ä¾¿æ˜¯<strong>è·ç¦»åº¦é‡</strong>ï¼Œåœ¨ç”Ÿæ´»ä¸­æˆ‘ä»¬è¯´å·®åˆ«å°åˆ™ç›¸ä¼¼ï¼Œå¯¹åº”åˆ°å¤šç»´æ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬å¯ä»¥å¯¹åº”äºé«˜ç»´ç©ºé—´ä¸­çš„ä¸€ä¸ªæ•°æ®ç‚¹ï¼Œè‹¥å®ƒä»¬çš„è·ç¦»ç›¸è¿‘ï¼Œæˆ‘ä»¬ä¾¿å¯ä»¥ç§°å®ƒä»¬ç›¸ä¼¼ã€‚é‚£æ¥ç€å¦‚ä½•æ¥è¯„ä»·èšç±»ç»“æœçš„å¥½åå‘¢ï¼Ÿè¿™ä¾¿æ˜¯<strong>æ€§èƒ½åº¦é‡</strong>ï¼Œæ€§èƒ½åº¦é‡ä¸ºè¯„ä»·èšç±»ç»“æœçš„å¥½åæä¾›äº†ä¸€ç³»åˆ—æœ‰æ•ˆæ€§æŒ‡æ ‡ã€‚</p><h3 id="è·ç¦»åº¦é‡"><a href="#è·ç¦»åº¦é‡" class="headerlink" title="è·ç¦»åº¦é‡"></a>è·ç¦»åº¦é‡</h3><p>è°ˆåŠè·ç¦»åº¦é‡ï¼Œæœ€ç†Ÿæ‚‰çš„è«è¿‡äºæ¬§å¼è·ç¦»äº†ï¼Œä»å¹´å¤´ä¸€ç›´ç”¨åˆ°å¹´å°¾çš„è·ç¦»è®¡ç®—å…¬å¼ï¼šå³å¯¹åº”å±æ€§ä¹‹é—´ç›¸å‡çš„å¹³æ–¹å’Œå†å¼€æ ¹å·ã€‚åº¦é‡è·ç¦»è¿˜æœ‰å…¶å®ƒçš„å¾ˆå¤šç»å…¸æ–¹æ³•ï¼Œé€šå¸¸å®ƒä»¬éœ€è¦æ»¡è¶³ä¸€äº›åŸºæœ¬æ€§è´¨ï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc84ed4c0390.png" alt="1.png"></p><p>æœ€å¸¸ç”¨çš„è·ç¦»åº¦é‡æ–¹æ³•æ˜¯<strong>â€œé—µå¯å¤«æ–¯åŸºè·ç¦»â€ï¼ˆMinkowski distance)</strong>ï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc84ed49e31f.png" alt="2.png"></p><p>å½“p=1æ—¶ï¼Œé—µå¯å¤«æ–¯åŸºè·ç¦»å³<strong>æ›¼å“ˆé¡¿è·ç¦»ï¼ˆManhattan distanceï¼‰</strong>ï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc84ed49c31f.png" alt="3.png"></p><p>å½“p=2æ—¶ï¼Œé—µå¯å¤«æ–¯åŸºè·ç¦»å³<strong>æ¬§æ°è·ç¦»ï¼ˆEuclidean distanceï¼‰</strong>ï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc84ed497613.png" alt="4.png"></p><p>æˆ‘ä»¬çŸ¥é“å±æ€§åˆ†ä¸ºä¸¤ç§ï¼š<strong>è¿ç»­å±æ€§</strong>å’Œ<strong>ç¦»æ•£å±æ€§</strong>ï¼ˆæœ‰é™ä¸ªå–å€¼ï¼‰ã€‚å¯¹äºè¿ç»­å€¼çš„å±æ€§ï¼Œä¸€èˆ¬éƒ½å¯ä»¥è¢«å­¦ä¹ å™¨æ‰€ç”¨ï¼Œæœ‰æ—¶ä¼šæ ¹æ®å…·ä½“çš„æƒ…å½¢ä½œç›¸åº”çš„é¢„å¤„ç†ï¼Œä¾‹å¦‚ï¼šå½’ä¸€åŒ–ç­‰ï¼›è€Œå¯¹äºç¦»æ•£å€¼çš„å±æ€§ï¼Œéœ€è¦ä½œä¸‹é¢è¿›ä¸€æ­¥çš„å¤„ç†ï¼š</p><blockquote><p>è‹¥å±æ€§å€¼ä¹‹é—´<strong>å­˜åœ¨åºå…³ç³»</strong>ï¼Œåˆ™å¯ä»¥å°†å…¶è½¬åŒ–ä¸ºè¿ç»­å€¼ï¼Œä¾‹å¦‚ï¼šèº«é«˜å±æ€§â€œé«˜â€â€œä¸­ç­‰â€â€œçŸ®â€ï¼Œå¯è½¬åŒ–ä¸º{1, 0.5, 0}ã€‚<br>è‹¥å±æ€§å€¼ä¹‹é—´<strong>ä¸å­˜åœ¨åºå…³ç³»</strong>ï¼Œåˆ™é€šå¸¸å°†å…¶è½¬åŒ–ä¸ºå‘é‡çš„å½¢å¼ï¼Œä¾‹å¦‚ï¼šæ€§åˆ«å±æ€§â€œç”·â€â€œå¥³â€ï¼Œå¯è½¬åŒ–ä¸º{ï¼ˆ1,0ï¼‰ï¼Œï¼ˆ0,1ï¼‰}ã€‚</p></blockquote><p>åœ¨è¿›è¡Œè·ç¦»åº¦é‡æ—¶ï¼Œæ˜“çŸ¥<strong>è¿ç»­å±æ€§å’Œå­˜åœ¨åºå…³ç³»çš„ç¦»æ•£å±æ€§éƒ½å¯ä»¥ç›´æ¥å‚ä¸è®¡ç®—</strong>ï¼Œå› ä¸ºå®ƒä»¬éƒ½å¯ä»¥åæ˜ ä¸€ç§ç¨‹åº¦ï¼Œæˆ‘ä»¬ç§°å…¶ä¸ºâ€œ<strong>æœ‰åºå±æ€§</strong>â€ï¼›è€Œå¯¹äºä¸å­˜åœ¨åºå…³ç³»çš„ç¦»æ•£å±æ€§ï¼Œæˆ‘ä»¬ç§°å…¶ä¸ºï¼šâ€œ<strong>æ— åºå±æ€§</strong>â€ï¼Œæ˜¾ç„¶æ— åºå±æ€§å†ä½¿ç”¨é—µå¯å¤«æ–¯åŸºè·ç¦»å°±è¡Œä¸é€šäº†ã€‚</p><p><strong>å¯¹äºæ— åºå±æ€§ï¼Œæˆ‘ä»¬ä¸€èˆ¬é‡‡ç”¨VDMè¿›è¡Œè·ç¦»çš„è®¡ç®—</strong>ï¼Œä¾‹å¦‚ï¼šå¯¹äºç¦»æ•£å±æ€§çš„ä¸¤ä¸ªå–å€¼aå’Œbï¼Œå®šä¹‰ï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc84ed4e9560.png" alt="5.png"></p><p>äºæ˜¯ï¼Œåœ¨è®¡ç®—ä¸¤ä¸ªæ ·æœ¬ä¹‹é—´çš„è·ç¦»æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥å°†é—µå¯å¤«æ–¯åŸºè·ç¦»å’ŒVDMæ··åˆåœ¨ä¸€èµ·è¿›è¡Œè®¡ç®—ï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc84ed507bc7.png" alt="6.png"></p><p>è‹¥æˆ‘ä»¬å®šä¹‰çš„è·ç¦»è®¡ç®—æ–¹æ³•æ˜¯ç”¨æ¥åº¦é‡ç›¸ä¼¼æ€§ï¼Œä¾‹å¦‚ä¸‹é¢å°†è¦è®¨è®ºçš„èšç±»é—®é¢˜ï¼Œå³è·ç¦»è¶Šå°ï¼Œç›¸ä¼¼æ€§è¶Šå¤§ï¼Œåä¹‹è·ç¦»è¶Šå¤§ï¼Œç›¸ä¼¼æ€§è¶Šå°ã€‚è¿™æ—¶è·ç¦»çš„åº¦é‡æ–¹æ³•å¹¶ä¸ä¸€å®šéœ€è¦æ»¡è¶³å‰é¢æ‰€è¯´çš„å››ä¸ªåŸºæœ¬æ€§è´¨ï¼Œè¿™æ ·çš„æ–¹æ³•ç§°ä¸ºï¼š<strong>éåº¦é‡è·ç¦»ï¼ˆnon-metric distanceï¼‰</strong>ã€‚</p><h3 id="æ€§èƒ½åº¦é‡"><a href="#æ€§èƒ½åº¦é‡" class="headerlink" title="æ€§èƒ½åº¦é‡"></a>æ€§èƒ½åº¦é‡</h3><p>ç”±äºèšç±»ç®—æ³•ä¸ä¾èµ–äºæ ·æœ¬çš„çœŸå®ç±»æ ‡ï¼Œå°±ä¸èƒ½åƒç›‘ç£å­¦ä¹ çš„åˆ†ç±»é‚£èˆ¬ï¼Œé€šè¿‡è®¡ç®—åˆ†å¯¹åˆ†é”™ï¼ˆå³ç²¾ç¡®åº¦æˆ–é”™è¯¯ç‡ï¼‰æ¥è¯„ä»·å­¦ä¹ å™¨çš„å¥½åæˆ–ä½œä¸ºå­¦ä¹ è¿‡ç¨‹ä¸­çš„ä¼˜åŒ–ç›®æ ‡ã€‚ä¸€èˆ¬èšç±»æœ‰ä¸¤ç±»æ€§èƒ½åº¦é‡æŒ‡æ ‡ï¼š<strong>å¤–éƒ¨æŒ‡æ ‡</strong>å’Œ<strong>å†…éƒ¨æŒ‡æ ‡</strong>ã€‚</p><h4 id="å¤–éƒ¨æŒ‡æ ‡"><a href="#å¤–éƒ¨æŒ‡æ ‡" class="headerlink" title="å¤–éƒ¨æŒ‡æ ‡"></a>å¤–éƒ¨æŒ‡æ ‡</h4><p>å³å°†èšç±»ç»“æœä¸æŸä¸ªå‚è€ƒæ¨¡å‹çš„ç»“æœè¿›è¡Œæ¯”è¾ƒï¼Œ<strong>ä»¥å‚è€ƒæ¨¡å‹çš„è¾“å‡ºä½œä¸ºæ ‡å‡†ï¼Œæ¥è¯„ä»·èšç±»å¥½å</strong>ã€‚å‡è®¾èšç±»ç»™å‡ºçš„ç»“æœä¸ºÎ»ï¼Œå‚è€ƒæ¨¡å‹ç»™å‡ºçš„ç»“æœæ˜¯Î»*ï¼Œåˆ™æˆ‘ä»¬å°†æ ·æœ¬è¿›è¡Œä¸¤ä¸¤é…å¯¹ï¼Œå®šä¹‰ï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc84ed59160e.png" alt="7.png"></p><p>æ˜¾ç„¶aå’Œbä»£è¡¨ç€èšç±»ç»“æœå¥½åçš„æ­£èƒ½é‡ï¼Œbå’Œcåˆ™è¡¨ç¤ºå‚è€ƒç»“æœå’Œèšç±»ç»“æœç›¸çŸ›ç›¾ï¼ŒåŸºäºè¿™å››ä¸ªå€¼å¯ä»¥å¯¼å‡ºä»¥ä¸‹å¸¸ç”¨çš„å¤–éƒ¨è¯„ä»·æŒ‡æ ‡ï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc84ed587438.png" alt="8.png"></p><h4 id="å†…éƒ¨æŒ‡æ ‡"><a href="#å†…éƒ¨æŒ‡æ ‡" class="headerlink" title="å†…éƒ¨æŒ‡æ ‡"></a>å†…éƒ¨æŒ‡æ ‡</h4><p>å†…éƒ¨æŒ‡æ ‡å³ä¸ä¾èµ–ä»»ä½•å¤–éƒ¨æ¨¡å‹ï¼Œç›´æ¥å¯¹èšç±»çš„ç»“æœè¿›è¡Œè¯„ä¼°ï¼Œèšç±»çš„ç›®çš„æ˜¯æƒ³å°†é‚£äº›ç›¸ä¼¼çš„æ ·æœ¬å°½å¯èƒ½èšåœ¨ä¸€èµ·ï¼Œä¸ç›¸ä¼¼çš„æ ·æœ¬å°½å¯èƒ½åˆ†å¼€ï¼Œç›´è§‚æ¥è¯´ï¼š<strong>ç°‡å†…é«˜å†…èšç´§ç´§æŠ±å›¢ï¼Œç°‡é—´ä½è€¦åˆè€æ­»ä¸ç›¸å¾€æ¥</strong>ã€‚å®šä¹‰ï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc84ed581852.png" alt="9.png"></p><p>åŸºäºä¸Šé¢çš„å››ä¸ªè·ç¦»ï¼Œå¯ä»¥å¯¼å‡ºä¸‹é¢è¿™äº›å¸¸ç”¨çš„å†…éƒ¨è¯„ä»·æŒ‡æ ‡ï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc84ed582854.png" alt="10.png"></p><h3 id="åŸå‹èšç±»"><a href="#åŸå‹èšç±»" class="headerlink" title="åŸå‹èšç±»"></a>åŸå‹èšç±»</h3><p>åŸå‹èšç±»å³â€œ<strong>åŸºäºåŸå‹çš„èšç±»</strong>â€ï¼ˆprototype-based clusteringï¼‰ï¼ŒåŸå‹è¡¨ç¤ºæ¨¡æ¿çš„æ„æ€ï¼Œå°±æ˜¯é€šè¿‡å‚è€ƒä¸€ä¸ªæ¨¡æ¿å‘é‡æˆ–æ¨¡æ¿åˆ†å¸ƒçš„æ–¹å¼æ¥å®Œæˆèšç±»çš„è¿‡ç¨‹ï¼Œå¸¸è§çš„K-Meansä¾¿æ˜¯åŸºäºç°‡ä¸­å¿ƒæ¥å®ç°èšç±»ï¼Œæ··åˆé«˜æ–¯èšç±»åˆ™æ˜¯åŸºäºç°‡åˆ†å¸ƒæ¥å®ç°èšç±»ã€‚</p><h4 id="K-Means"><a href="#K-Means" class="headerlink" title="K-Means"></a>K-Means</h4><p>K-Meansçš„æ€æƒ³ååˆ†ç®€å•ï¼Œ<strong>é¦–å…ˆéšæœºæŒ‡å®šç±»ä¸­å¿ƒï¼Œæ ¹æ®æ ·æœ¬ä¸ç±»ä¸­å¿ƒçš„è¿œè¿‘åˆ’åˆ†ç±»ç°‡ï¼Œæ¥ç€é‡æ–°è®¡ç®—ç±»ä¸­å¿ƒï¼Œè¿­ä»£ç›´è‡³æ”¶æ•›</strong>ã€‚ä½†æ˜¯å…¶ä¸­è¿­ä»£çš„è¿‡ç¨‹å¹¶ä¸æ˜¯ä¸»è§‚åœ°æƒ³è±¡å¾—å‡ºï¼Œäº‹å®ä¸Šï¼Œè‹¥å°†æ ·æœ¬çš„ç±»åˆ«çœ‹åšä¸ºâ€œéšå˜é‡â€ï¼ˆlatent variableï¼‰ï¼Œç±»ä¸­å¿ƒçœ‹ä½œæ ·æœ¬çš„åˆ†å¸ƒå‚æ•°ï¼Œè¿™ä¸€è¿‡ç¨‹æ­£æ˜¯é€šè¿‡<strong>EMç®—æ³•</strong>çš„ä¸¤æ­¥èµ°ç­–ç•¥è€Œè®¡ç®—å‡ºï¼Œå…¶æ ¹æœ¬çš„ç›®çš„æ˜¯ä¸ºäº†æœ€å°åŒ–å¹³æ–¹è¯¯å·®å‡½æ•°Eï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc84fb82b5d3.png" alt="11.png"></p><p>K-Meansçš„ç®—æ³•æµç¨‹å¦‚ä¸‹æ‰€ç¤ºï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc84fb9c0817.png" alt="12.png"></p><p><img src="../img/K-Means.png" alt></p><h4 id="é«˜æ–¯æ··åˆèšç±»"><a href="#é«˜æ–¯æ··åˆèšç±»" class="headerlink" title="é«˜æ–¯æ··åˆèšç±»"></a>é«˜æ–¯æ··åˆèšç±»</h4><p>ç°åœ¨å¯ä»¥çœ‹å‡ºK-Meansä¸LVQéƒ½è¯•å›¾ä»¥ç±»ä¸­å¿ƒä½œä¸ºåŸå‹æŒ‡å¯¼èšç±»ï¼Œé«˜æ–¯æ··åˆèšç±»åˆ™é‡‡ç”¨é«˜æ–¯åˆ†å¸ƒæ¥æè¿°åŸå‹ã€‚ç°å‡è®¾<strong>æ¯ä¸ªç±»ç°‡ä¸­çš„æ ·æœ¬éƒ½æœä»ä¸€ä¸ªå¤šç»´é«˜æ–¯åˆ†å¸ƒï¼Œé‚£ä¹ˆç©ºé—´ä¸­çš„æ ·æœ¬å¯ä»¥çœ‹ä½œç”±kä¸ªå¤šç»´é«˜æ–¯åˆ†å¸ƒæ··åˆè€Œæˆ</strong>ã€‚</p><p>å¯¹äºå¤šç»´é«˜æ–¯åˆ†å¸ƒï¼Œå…¶æ¦‚ç‡å¯†åº¦å‡½æ•°å¦‚ä¸‹æ‰€ç¤ºï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc84fb870d98.png" alt="14.png"></p><p>å…¶ä¸­uè¡¨ç¤ºå‡å€¼å‘é‡ï¼Œâˆ‘è¡¨ç¤ºåæ–¹å·®çŸ©é˜µï¼Œå¯ä»¥çœ‹å‡ºä¸€ä¸ªå¤šç»´é«˜æ–¯åˆ†å¸ƒå®Œå…¨ç”±è¿™ä¸¤ä¸ªå‚æ•°æ‰€ç¡®å®šã€‚æ¥ç€å®šä¹‰é«˜æ–¯æ··åˆåˆ†å¸ƒä¸ºï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc84fb876794.png" alt="15.png"></p><p>Î±ç§°ä¸ºæ··åˆç³»æ•°ï¼Œè¿™æ ·ç©ºé—´ä¸­æ ·æœ¬çš„é‡‡é›†è¿‡ç¨‹åˆ™å¯ä»¥æŠ½è±¡ä¸ºï¼š<strong>ï¼ˆ1ï¼‰å…ˆé€‰æ‹©ä¸€ä¸ªç±»ç°‡ï¼ˆé«˜æ–¯åˆ†å¸ƒï¼‰ï¼Œï¼ˆ2ï¼‰å†æ ¹æ®å¯¹åº”é«˜æ–¯åˆ†å¸ƒçš„å¯†åº¦å‡½æ•°è¿›è¡Œé‡‡æ ·</strong>ï¼Œè¿™æ—¶å€™è´å¶æ–¯å…¬å¼åˆèƒ½å¤§å±•èº«æ‰‹äº†ï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc84fb9191d9.png" alt="16.png"></p><p>æ­¤æ—¶åªéœ€è¦é€‰æ‹©PMæœ€å¤§æ—¶çš„ç±»ç°‡å¹¶å°†è¯¥æ ·æœ¬åˆ’åˆ†åˆ°å…¶ä¸­ï¼Œçœ‹åˆ°è¿™é‡Œå¾ˆå®¹æ˜“å‘ç°ï¼šè¿™å’Œé‚£ä¸ªä¼ è¯´ä¸­çš„è´å¶æ–¯åˆ†ç±»ä¸æ˜¯ç¥ä¼¼å—ï¼Œéƒ½æ˜¯é€šè¿‡è´å¶æ–¯å…¬å¼å±•å¼€ï¼Œç„¶åè®¡ç®—ç±»å…ˆéªŒæ¦‚ç‡å’Œç±»æ¡ä»¶æ¦‚ç‡ã€‚ä½†é—æ†¾çš„æ˜¯ï¼š<strong>è¿™é‡Œæ²¡æœ‰çœŸå®ç±»æ ‡ä¿¡æ¯ï¼Œå¯¹äºç±»æ¡ä»¶æ¦‚ç‡ï¼Œå¹¶ä¸èƒ½åƒè´å¶æ–¯åˆ†ç±»é‚£æ ·é€šè¿‡æœ€å¤§ä¼¼ç„¶æ³•ç¾å¥½åœ°è®¡ç®—å‡ºæ¥</strong>ï¼Œå› ä¸ºè¿™é‡Œçš„æ ·æœ¬å¯èƒ½å±äºæ‰€æœ‰çš„ç±»ç°‡ï¼Œè¿™é‡Œçš„ä¼¼ç„¶å‡½æ•°å˜ä¸ºï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc84fb871d4a.png" alt="17.png"></p><p>å¯ä»¥çœ‹å‡ºï¼šç®€å•çš„æœ€å¤§ä¼¼ç„¶æ³•æ ¹æœ¬æ— æ³•æ±‚å‡ºæ‰€æœ‰çš„å‚æ•°ï¼Œè¿™æ ·PMä¹Ÿå°±æ²¡æ³•è®¡ç®—ã€‚<strong>è¿™é‡Œå°±è¦å¬å”¤å‡ºä¹‹å‰çš„EMå¤§æ³•ï¼Œé¦–å…ˆå¯¹é«˜æ–¯åˆ†å¸ƒçš„å‚æ•°åŠæ··åˆç³»æ•°è¿›è¡Œéšæœºåˆå§‹åŒ–ï¼Œè®¡ç®—å‡ºå„ä¸ªPMï¼ˆå³Î³jiï¼Œç¬¬iä¸ªæ ·æœ¬å±äºjç±»ï¼‰ï¼Œå†æœ€å¤§åŒ–ä¼¼ç„¶å‡½æ•°ï¼ˆå³LLï¼ˆDï¼‰åˆ†åˆ«å¯¹Î±ã€uå’Œâˆ‘æ±‚åå¯¼ ï¼‰ï¼Œå¯¹å‚æ•°è¿›è¡Œè¿­ä»£æ›´æ–°</strong>ã€‚</p><p><img src="https://i.loli.net/2018/10/18/5bc84fb8a6f32.png" alt="18.png"></p><p>é«˜æ–¯æ··åˆèšç±»çš„ç®—æ³•æµç¨‹å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc84fb9c4fa4.png" alt="19.png"></p><h4 id="å¯†åº¦èšç±»"><a href="#å¯†åº¦èšç±»" class="headerlink" title="å¯†åº¦èšç±»"></a>å¯†åº¦èšç±»</h4><p>å¯†åº¦èšç±»åˆ™æ˜¯åŸºäºå¯†åº¦çš„èšç±»ï¼Œå®ƒä»æ ·æœ¬åˆ†å¸ƒçš„è§’åº¦æ¥è€ƒå¯Ÿæ ·æœ¬ä¹‹é—´çš„å¯è¿æ¥æ€§ï¼Œå¹¶åŸºäºå¯è¿æ¥æ€§ï¼ˆå¯†åº¦å¯è¾¾ï¼‰ä¸æ–­æ‹“å±•ç–†åŸŸï¼ˆç±»ç°‡ï¼‰ã€‚å…¶ä¸­æœ€è‘—åçš„ä¾¿æ˜¯<strong>DBSCAN</strong>ç®—æ³•ï¼Œé¦–å…ˆå®šä¹‰ä»¥ä¸‹æ¦‚å¿µï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc84fb9bd69c.png" alt="20.png"></p><p><img src="https://i.loli.net/2018/10/18/5bc8509f8d619.png" alt="21.png"></p><p>ç®€å•æ¥ç†è§£DBSCANä¾¿æ˜¯ï¼š<strong>æ‰¾å‡ºä¸€ä¸ªæ ¸å¿ƒå¯¹è±¡æ‰€æœ‰å¯†åº¦å¯è¾¾çš„æ ·æœ¬é›†åˆå½¢æˆç°‡</strong>ã€‚é¦–å…ˆä»æ•°æ®é›†ä¸­ä»»é€‰ä¸€ä¸ªæ ¸å¿ƒå¯¹è±¡Aï¼Œæ‰¾å‡ºæ‰€æœ‰Aå¯†åº¦å¯è¾¾çš„æ ·æœ¬é›†åˆï¼Œå°†è¿™äº›æ ·æœ¬å½¢æˆä¸€ä¸ªå¯†åº¦ç›¸è¿çš„ç±»ç°‡ï¼Œç›´åˆ°æ‰€æœ‰çš„æ ¸å¿ƒå¯¹è±¡éƒ½éå†å®Œã€‚DBSCANç®—æ³•çš„æµç¨‹å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc8509feb587.png" alt="22.png"></p><h4 id="å±‚æ¬¡èšç±»"><a href="#å±‚æ¬¡èšç±»" class="headerlink" title="å±‚æ¬¡èšç±»"></a>å±‚æ¬¡èšç±»</h4><p>å±‚æ¬¡èšç±»æ˜¯ä¸€ç§åŸºäºæ ‘å½¢ç»“æ„çš„èšç±»æ–¹æ³•ï¼Œå¸¸ç”¨çš„æ˜¯<strong>è‡ªåº•å‘ä¸Š</strong>çš„ç»“åˆç­–ç•¥ï¼ˆ<strong>AGNESç®—æ³•</strong>ï¼‰ã€‚å‡è®¾æœ‰Nä¸ªå¾…èšç±»çš„æ ·æœ¬ï¼Œå…¶åŸºæœ¬æ­¥éª¤æ˜¯ï¼š</p><ul><li>1.åˆå§‹åŒ–â€“&gt;æŠŠæ¯ä¸ªæ ·æœ¬å½’ä¸ºä¸€ç±»ï¼Œè®¡ç®—æ¯ä¸¤ä¸ªç±»ä¹‹é—´çš„è·ç¦»ï¼Œä¹Ÿå°±æ˜¯æ ·æœ¬ä¸æ ·æœ¬ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼›</li><li>2.å¯»æ‰¾å„ä¸ªç±»ä¹‹é—´æœ€è¿‘çš„ä¸¤ä¸ªç±»ï¼ŒæŠŠä»–ä»¬å½’ä¸ºä¸€ç±»ï¼ˆè¿™æ ·ç±»çš„æ€»æ•°å°±å°‘äº†ä¸€ä¸ªï¼‰ï¼›</li><li>3.é‡æ–°è®¡ç®—æ–°ç”Ÿæˆçš„è¿™ä¸ª<strong>ç±»ä¸å„ä¸ªæ—§ç±»ä¹‹é—´çš„ç›¸ä¼¼åº¦</strong>ï¼›</li><li>4.é‡å¤2å’Œ3ç›´åˆ°æ‰€æœ‰æ ·æœ¬ç‚¹éƒ½å½’ä¸ºä¸€ç±»ï¼Œç»“æŸã€‚</li></ul><p>å¯ä»¥çœ‹å‡ºå…¶ä¸­æœ€å…³é”®çš„ä¸€æ­¥å°±æ˜¯<strong>è®¡ç®—ä¸¤ä¸ªç±»ç°‡çš„ç›¸ä¼¼åº¦</strong>ï¼Œè¿™é‡Œæœ‰å¤šç§åº¦é‡æ–¹æ³•ï¼š</p><pre><code>* å•é“¾æ¥ï¼ˆsingle-linkageï¼‰:å–ç±»é—´æœ€å°è·ç¦»ã€‚</code></pre><p><img src="https://i.loli.net/2018/10/18/5bc8509ebb022.png" alt="23.png"></p><pre><code>* å…¨é“¾æ¥ï¼ˆcomplete-linkageï¼‰:å–ç±»é—´æœ€å¤§è·ç¦»</code></pre><p><img src="https://i.loli.net/2018/10/18/5bc8509eb2b30.png" alt="24.png"></p><pre><code>* å‡é“¾æ¥ï¼ˆaverage-linkageï¼‰:å–ç±»é—´ä¸¤ä¸¤çš„å¹³å‡è·ç¦»</code></pre><p><img src="https://i.loli.net/2018/10/18/5bc8509f089a7.png" alt="25.png"></p><p>å¾ˆå®¹æ˜“çœ‹å‡ºï¼š<strong>å•é“¾æ¥çš„åŒ…å®¹æ€§æå¼ºï¼Œç¨å¾®æœ‰ç‚¹æš§æ˜§å°±å½“åšæ˜¯è‡ªå·±äººäº†ï¼Œå…¨é“¾æ¥åˆ™æ˜¯åšæŒåˆ°åº•ï¼Œåªè¦å­˜åœ¨ç¼ºç‚¹å°±åšå†³ä¸åˆå¹¶ï¼Œå‡è¿æ¥åˆ™æ˜¯ä»å…¨å±€å‡ºå‘é¡¾å…¨å¤§å±€</strong>ã€‚å±‚æ¬¡èšç±»æ³•çš„ç®—æ³•æµç¨‹å¦‚ä¸‹æ‰€ç¤ºï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc8509f9d4a0.png" alt="26.png"><br><img src="/blog_picture/clustering.png" alt="avatar"></p><h2 id="æœºå™¨å­¦ä¹ ä¸­çš„PCAé™ç»´"><a href="#æœºå™¨å­¦ä¹ ä¸­çš„PCAé™ç»´" class="headerlink" title="æœºå™¨å­¦ä¹ ä¸­çš„PCAé™ç»´"></a>æœºå™¨å­¦ä¹ ä¸­çš„PCAé™ç»´</h2><p>èµ„æ–™from<a href="http://blog.codinglabs.org/articles/pca-tutorial.html" target="_blank" rel="noopener">PCAçš„æ•°å­¦åŸç†</a></p><p><img src="/blog_picture/PCA_.jpg" alt="avatar"></p>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹  </tag>
            
            <tag> èšç±» </tag>
            
            <tag> é™ç»´ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>è´å¶æ–¯åˆ†ç±»å™¨</title>
      <link href="/2019/09/01/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/"/>
      <url>/2019/09/01/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<p>å‚è€ƒé˜…è¯»ææ–™ï¼š</p><ul><li><a href="https://blog.csdn.net/han_xiaoyang/article/details/50616559" target="_blank" rel="noopener">NLPç³»åˆ—(2)_ç”¨æœ´ç´ è´å¶æ–¯è¿›è¡Œæ–‡æœ¬åˆ†ç±»(ä¸Š)</a></li><li><a href="https://blog.csdn.net/han_xiaoyang/article/details/50629587" target="_blank" rel="noopener">NLPç³»åˆ—(3)_ç”¨æœ´ç´ è´å¶æ–¯è¿›è¡Œæ–‡æœ¬åˆ†ç±»(ä¸‹)</a></li></ul><p>æœ´ç´ è´å¶æ–¯</p><ul><li>è´å¶æ–¯å…¬å¼ + æ¡ä»¶ç‹¬ç«‹å‡è®¾</li><li>å¹³æ»‘ç®—æ³•</li></ul><h2 id="æœºå™¨å­¦ä¹ ä¸­çš„è´å¶æ–¯åˆ†ç±»å™¨"><a href="#æœºå™¨å­¦ä¹ ä¸­çš„è´å¶æ–¯åˆ†ç±»å™¨" class="headerlink" title="æœºå™¨å­¦ä¹ ä¸­çš„è´å¶æ–¯åˆ†ç±»å™¨"></a>æœºå™¨å­¦ä¹ ä¸­çš„è´å¶æ–¯åˆ†ç±»å™¨</h2><p>è´å¶æ–¯åˆ†ç±»å™¨æ˜¯ä¸€ç§æ¦‚ç‡æ¡†æ¶ä¸‹çš„ç»Ÿè®¡å­¦ä¹ åˆ†ç±»å™¨ï¼Œå¯¹åˆ†ç±»ä»»åŠ¡è€Œè¨€ï¼Œå‡è®¾åœ¨ç›¸å…³æ¦‚ç‡éƒ½å·²çŸ¥çš„æƒ…å†µä¸‹ï¼Œè´å¶æ–¯åˆ†ç±»å™¨è€ƒè™‘å¦‚ä½•åŸºäºè¿™äº›æ¦‚ç‡ä¸ºæ ·æœ¬åˆ¤å®šæœ€ä¼˜çš„ç±»æ ‡ã€‚åœ¨å¼€å§‹ä»‹ç»è´å¶æ–¯å†³ç­–è®ºä¹‹å‰ï¼Œæˆ‘ä»¬é¦–å…ˆæ¥å›é¡¾ä¸‹æ¦‚ç‡è®ºå§”å‘˜ä¼šå¸¸å§”â€“è´å¶æ–¯å…¬å¼ã€‚</p><p><img src="https://i.loli.net/2018/10/18/5bc83fd7a2575.png" alt="1.png"></p><h3 id="è´å¶æ–¯å†³ç­–è®º"><a href="#è´å¶æ–¯å†³ç­–è®º" class="headerlink" title="è´å¶æ–¯å†³ç­–è®º"></a>è´å¶æ–¯å†³ç­–è®º</h3><p>è‹¥å°†ä¸Šè¿°å®šä¹‰ä¸­æ ·æœ¬ç©ºé—´çš„åˆ’åˆ†Biçœ‹åšä¸ºç±»æ ‡ï¼ŒAçœ‹åšä¸ºä¸€ä¸ªæ–°çš„æ ·æœ¬ï¼Œåˆ™å¾ˆå®¹æ˜“å°†æ¡ä»¶æ¦‚ç‡ç†è§£ä¸ºæ ·æœ¬Aæ˜¯ç±»åˆ«Biçš„æ¦‚ç‡ã€‚åœ¨æœºå™¨å­¦ä¹ è®­ç»ƒæ¨¡å‹çš„è¿‡ç¨‹ä¸­ï¼Œå¾€å¾€æˆ‘ä»¬éƒ½è¯•å›¾å»ä¼˜åŒ–ä¸€ä¸ªé£é™©å‡½æ•°ï¼Œå› æ­¤åœ¨æ¦‚ç‡æ¡†æ¶ä¸‹æˆ‘ä»¬ä¹Ÿå¯ä»¥ä¸ºè´å¶æ–¯å®šä¹‰â€œ<strong>æ¡ä»¶é£é™©</strong>â€ï¼ˆconditional riskï¼‰ã€‚</p><p><img src="https://i.loli.net/2018/10/18/5bc83fd15db94.png" alt="2.png"></p><p>æˆ‘ä»¬çš„ä»»åŠ¡å°±æ˜¯å¯»æ‰¾ä¸€ä¸ªåˆ¤å®šå‡†åˆ™æœ€å°åŒ–æ‰€æœ‰æ ·æœ¬çš„æ¡ä»¶é£é™©æ€»å’Œï¼Œå› æ­¤å°±æœ‰äº†<strong>è´å¶æ–¯åˆ¤å®šå‡†åˆ™</strong>ï¼ˆBayes decision ruleï¼‰:ä¸ºæœ€å°åŒ–æ€»ä½“é£é™©ï¼Œåªéœ€åœ¨æ¯ä¸ªæ ·æœ¬ä¸Šé€‰æ‹©é‚£ä¸ªä½¿å¾—æ¡ä»¶é£é™©æœ€å°çš„ç±»æ ‡ã€‚</p><p><img src="https://i.loli.net/2018/10/18/5bc83fd308600.png" alt="3.png"></p><p>è‹¥æŸå¤±å‡½æ•°Î»å–0-1æŸå¤±ï¼Œåˆ™æœ‰ï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc83fd37c502.png" alt="4.png"></p><p>å³å¯¹äºæ¯ä¸ªæ ·æœ¬xï¼Œé€‰æ‹©å…¶åéªŒæ¦‚ç‡Pï¼ˆc | xï¼‰æœ€å¤§æ‰€å¯¹åº”çš„ç±»æ ‡ï¼Œèƒ½ä½¿å¾—æ€»ä½“é£é™©å‡½æ•°æœ€å°ï¼Œä»è€Œå°†åŸé—®é¢˜è½¬åŒ–ä¸ºä¼°è®¡åéªŒæ¦‚ç‡Pï¼ˆc | xï¼‰ã€‚ä¸€èˆ¬è¿™é‡Œæœ‰ä¸¤ç§ç­–ç•¥æ¥å¯¹åéªŒæ¦‚ç‡è¿›è¡Œä¼°è®¡ï¼š</p><pre><code>* åˆ¤åˆ«å¼æ¨¡å‹ï¼šç›´æ¥å¯¹ Pï¼ˆc | xï¼‰è¿›è¡Œå»ºæ¨¡æ±‚è§£ã€‚ä¾‹æˆ‘ä»¬å‰é¢æ‰€ä»‹ç»çš„å†³ç­–æ ‘ã€ç¥ç»ç½‘ç»œã€SVMéƒ½æ˜¯å±äºåˆ¤åˆ«å¼æ¨¡å‹ã€‚* ç”Ÿæˆå¼æ¨¡å‹ï¼šé€šè¿‡å…ˆå¯¹è”åˆåˆ†å¸ƒPï¼ˆx,cï¼‰å»ºæ¨¡ï¼Œä»è€Œè¿›ä¸€æ­¥æ±‚è§£ Pï¼ˆc | xï¼‰ã€‚</code></pre><p>è´å¶æ–¯åˆ†ç±»å™¨å°±å±äºç”Ÿæˆå¼æ¨¡å‹ï¼ŒåŸºäºè´å¶æ–¯å…¬å¼å¯¹åéªŒæ¦‚ç‡Pï¼ˆc | xï¼‰ è¿›è¡Œä¸€é¡¹ç¥å¥‡çš„å˜æ¢ï¼Œå·´æ‹‰æ‹‰èƒ½é‡â€¦. Pï¼ˆc | xï¼‰å˜èº«ï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc83fd501ad3.png" alt="5.png"></p><p>å¯¹äºç»™å®šçš„æ ·æœ¬xï¼ŒPï¼ˆxï¼‰ä¸ç±»æ ‡æ— å…³ï¼ŒPï¼ˆcï¼‰ç§°ä¸ºç±»å…ˆéªŒæ¦‚ç‡ï¼Œpï¼ˆx | c ï¼‰ç§°ä¸ºç±»æ¡ä»¶æ¦‚ç‡ã€‚è¿™æ—¶ä¼°è®¡åéªŒæ¦‚ç‡Pï¼ˆc | xï¼‰å°±å˜æˆä¸ºä¼°è®¡ç±»å…ˆéªŒæ¦‚ç‡å’Œç±»æ¡ä»¶æ¦‚ç‡çš„é—®é¢˜ã€‚å¯¹äºå…ˆéªŒæ¦‚ç‡å’ŒåéªŒæ¦‚ç‡ï¼Œåœ¨çœ‹è¿™ç« ä¹‹å‰ä¹Ÿæ˜¯æ¨¡ç³Šäº†æˆ‘å¥½ä¹…ï¼Œè¿™é‡Œæ™®åŠä¸€ä¸‹å®ƒä»¬çš„åŸºæœ¬æ¦‚å¿µã€‚</p><pre><code>* å…ˆéªŒæ¦‚ç‡ï¼š æ ¹æ®ä»¥å¾€ç»éªŒå’Œåˆ†æå¾—åˆ°çš„æ¦‚ç‡ã€‚* åéªŒæ¦‚ç‡ï¼šåéªŒæ¦‚ç‡æ˜¯åŸºäºæ–°çš„ä¿¡æ¯ï¼Œä¿®æ­£åŸæ¥çš„å…ˆéªŒæ¦‚ç‡åæ‰€è·å¾—çš„æ›´æ¥è¿‘å®é™…æƒ…å†µçš„æ¦‚ç‡ä¼°è®¡ã€‚</code></pre><p>å®é™…ä¸Šå…ˆéªŒæ¦‚ç‡å°±æ˜¯åœ¨æ²¡æœ‰ä»»ä½•ç»“æœå‡ºæ¥çš„æƒ…å†µä¸‹ä¼°è®¡çš„æ¦‚ç‡ï¼Œè€ŒåéªŒæ¦‚ç‡åˆ™æ˜¯åœ¨æœ‰ä¸€å®šä¾æ®åçš„é‡æ–°ä¼°è®¡ï¼Œç›´è§‚æ„ä¹‰ä¸ŠåéªŒæ¦‚ç‡å°±æ˜¯æ¡ä»¶æ¦‚ç‡ã€‚ä¸‹é¢ç›´æ¥ä¸ŠWikiä¸Šçš„ä¸€ä¸ªä¾‹å­ï¼Œç®€å•ç²—æš´å¿«é€Ÿå®Œäº‹â€¦</p><p><img src="https://i.loli.net/2018/10/18/5bc83fd799610.png" alt="6.png"></p><p>å›å½’æ­£é¢˜ï¼Œå¯¹äºç±»å…ˆéªŒæ¦‚ç‡Pï¼ˆcï¼‰ï¼Œpï¼ˆcï¼‰å°±æ˜¯æ ·æœ¬ç©ºé—´ä¸­å„ç±»æ ·æœ¬æ‰€å çš„æ¯”ä¾‹ï¼Œæ ¹æ®å¤§æ•°å®šç†ï¼ˆå½“æ ·æœ¬è¶³å¤Ÿå¤šæ—¶ï¼Œé¢‘ç‡è¶‹äºç¨³å®šç­‰äºå…¶æ¦‚ç‡ï¼‰ï¼Œè¿™æ ·å½“è®­ç»ƒæ ·æœ¬å……è¶³æ—¶ï¼Œp(c)å¯ä»¥ä½¿ç”¨å„ç±»å‡ºç°çš„é¢‘ç‡æ¥ä»£æ›¿ã€‚å› æ­¤åªå‰©ä¸‹ç±»æ¡ä»¶æ¦‚ç‡pï¼ˆx | c ï¼‰ï¼Œå®ƒè¡¨è¾¾çš„æ„æ€æ˜¯åœ¨ç±»åˆ«cä¸­å‡ºç°xçš„æ¦‚ç‡ï¼Œå®ƒæ¶‰åŠåˆ°å±æ€§çš„è”åˆæ¦‚ç‡é—®é¢˜ï¼Œè‹¥åªæœ‰ä¸€ä¸ªç¦»æ•£å±æ€§è¿˜å¥½ï¼Œå½“å±æ€§å¤šæ—¶é‡‡ç”¨é¢‘ç‡ä¼°è®¡èµ·æ¥å°±ååˆ†å›°éš¾ï¼Œå› æ­¤è¿™é‡Œä¸€èˆ¬é‡‡ç”¨æå¤§ä¼¼ç„¶æ³•è¿›è¡Œä¼°è®¡ã€‚</p><h3 id="æå¤§ä¼¼ç„¶æ³•"><a href="#æå¤§ä¼¼ç„¶æ³•" class="headerlink" title="æå¤§ä¼¼ç„¶æ³•"></a>æå¤§ä¼¼ç„¶æ³•</h3><p>æå¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆMaximum Likelihood Estimationï¼Œç®€ç§°MLEï¼‰ï¼Œæ˜¯ä¸€ç§æ ¹æ®æ•°æ®é‡‡æ ·æ¥ä¼°è®¡æ¦‚ç‡åˆ†å¸ƒçš„ç»å…¸æ–¹æ³•ã€‚å¸¸ç”¨çš„ç­–ç•¥æ˜¯å…ˆå‡å®šæ€»ä½“å…·æœ‰æŸç§ç¡®å®šçš„æ¦‚ç‡åˆ†å¸ƒï¼Œå†åŸºäºè®­ç»ƒæ ·æœ¬å¯¹æ¦‚ç‡åˆ†å¸ƒçš„å‚æ•°è¿›è¡Œä¼°è®¡ã€‚è¿ç”¨åˆ°ç±»æ¡ä»¶æ¦‚ç‡pï¼ˆx | c ï¼‰ä¸­ï¼Œå‡è®¾pï¼ˆx | c ï¼‰æœä»ä¸€ä¸ªå‚æ•°ä¸ºÎ¸çš„åˆ†å¸ƒï¼Œé—®é¢˜å°±å˜ä¸ºæ ¹æ®å·²çŸ¥çš„è®­ç»ƒæ ·æœ¬æ¥ä¼°è®¡Î¸ã€‚æå¤§ä¼¼ç„¶æ³•çš„æ ¸å¿ƒæ€æƒ³å°±æ˜¯ï¼šä¼°è®¡å‡ºçš„å‚æ•°ä½¿å¾—å·²çŸ¥æ ·æœ¬å‡ºç°çš„æ¦‚ç‡æœ€å¤§ï¼Œå³ä½¿å¾—è®­ç»ƒæ•°æ®çš„ä¼¼ç„¶æœ€å¤§ã€‚</p><p><img src="https://i.loli.net/2018/10/18/5bc83fd70fb73.png" alt="7.png"></p><p>æ‰€ä»¥ï¼Œè´å¶æ–¯åˆ†ç±»å™¨çš„è®­ç»ƒè¿‡ç¨‹å°±æ˜¯å‚æ•°ä¼°è®¡ã€‚æ€»ç»“æœ€å¤§ä¼¼ç„¶æ³•ä¼°è®¡å‚æ•°çš„è¿‡ç¨‹ï¼Œä¸€èˆ¬åˆ†ä¸ºä»¥ä¸‹å››ä¸ªæ­¥éª¤ï¼š</p><pre><code>* 1.å†™å‡ºä¼¼ç„¶å‡½æ•°ï¼›* 2.å¯¹ä¼¼ç„¶å‡½æ•°å–å¯¹æ•°ï¼Œå¹¶æ•´ç†ï¼›* 3.æ±‚å¯¼æ•°ï¼Œä»¤åå¯¼æ•°ä¸º0ï¼Œå¾—åˆ°ä¼¼ç„¶æ–¹ç¨‹ç»„ï¼›* 4.è§£ä¼¼ç„¶æ–¹ç¨‹ç»„ï¼Œå¾—åˆ°æ‰€æœ‰å‚æ•°å³ä¸ºæ‰€æ±‚ã€‚</code></pre><p>ä¾‹å¦‚ï¼šå‡è®¾æ ·æœ¬å±æ€§éƒ½æ˜¯è¿ç»­å€¼ï¼Œpï¼ˆx | c ï¼‰æœä»ä¸€ä¸ªå¤šç»´é«˜æ–¯åˆ†å¸ƒï¼Œåˆ™é€šè¿‡MLEè®¡ç®—å‡ºçš„å‚æ•°åˆšå¥½åˆ†åˆ«ä¸ºï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc83fd705729.png" alt="8.png"></p><p>ä¸Šè¿°ç»“æœçœ‹èµ·æ¥ååˆ†åˆä¹å®é™…ï¼Œä½†æ˜¯é‡‡ç”¨æœ€å¤§ä¼¼ç„¶æ³•ä¼°è®¡å‚æ•°çš„æ•ˆæœå¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äºä½œå‡ºçš„å‡è®¾æ˜¯å¦åˆç†ï¼Œæ˜¯å¦ç¬¦åˆæ½œåœ¨çš„çœŸå®æ•°æ®åˆ†å¸ƒã€‚è¿™å°±éœ€è¦å¤§é‡çš„ç»éªŒçŸ¥è¯†ï¼Œæç»Ÿè®¡è¶Šæ¥è¶Šå€¼é’±ä¹Ÿæ˜¯è¿™ä¸ªé“ç†ï¼Œå¤§ç‰›ä»¬ææŒ‡ä¸€ç®—æ¯”æˆ‘ä»¬æ¬ç –å‡ å¤©æ›´æœ‰æ•ˆæœã€‚</p><h3 id="æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨"><a href="#æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨" class="headerlink" title="æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨"></a>æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨</h3><p>ä¸éš¾çœ‹å‡ºï¼šåŸå§‹çš„è´å¶æ–¯åˆ†ç±»å™¨æœ€å¤§çš„é—®é¢˜åœ¨äºè”åˆæ¦‚ç‡å¯†åº¦å‡½æ•°çš„ä¼°è®¡ï¼Œé¦–å…ˆéœ€è¦æ ¹æ®ç»éªŒæ¥å‡è®¾è”åˆæ¦‚ç‡åˆ†å¸ƒï¼Œå…¶æ¬¡å½“å±æ€§å¾ˆå¤šæ—¶ï¼Œè®­ç»ƒæ ·æœ¬å¾€å¾€è¦†ç›–ä¸å¤Ÿï¼Œå‚æ•°çš„ä¼°è®¡ä¼šå‡ºç°å¾ˆå¤§çš„åå·®ã€‚ä¸ºäº†é¿å…è¿™ä¸ªé—®é¢˜ï¼Œæœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ï¼ˆnaive Bayes classifierï¼‰é‡‡ç”¨äº†â€œå±æ€§æ¡ä»¶ç‹¬ç«‹æ€§å‡è®¾â€ï¼Œå³æ ·æœ¬æ•°æ®çš„æ‰€æœ‰å±æ€§ä¹‹é—´ç›¸äº’ç‹¬ç«‹ã€‚è¿™æ ·ç±»æ¡ä»¶æ¦‚ç‡pï¼ˆx | c ï¼‰å¯ä»¥æ”¹å†™ä¸ºï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc83fd55e102.png" alt="9.png"></p><p>è¿™æ ·ï¼Œä¸ºæ¯ä¸ªæ ·æœ¬ä¼°è®¡ç±»æ¡ä»¶æ¦‚ç‡å˜æˆä¸ºæ¯ä¸ªæ ·æœ¬çš„æ¯ä¸ªå±æ€§ä¼°è®¡ç±»æ¡ä»¶æ¦‚ç‡ã€‚</p><p><img src="https://i.loli.net/2018/10/18/5bc83fd6678cd.png" alt="10.png"></p><p>ç›¸æ¯”åŸå§‹è´å¶æ–¯åˆ†ç±»å™¨ï¼Œæœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨åŸºäºå•ä¸ªçš„å±æ€§è®¡ç®—ç±»æ¡ä»¶æ¦‚ç‡æ›´åŠ å®¹æ˜“æ“ä½œï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼šè‹¥æŸä¸ªå±æ€§å€¼åœ¨è®­ç»ƒé›†ä¸­å’ŒæŸä¸ªç±»åˆ«æ²¡æœ‰ä¸€èµ·å‡ºç°è¿‡ï¼Œè¿™æ ·ä¼šæŠ¹æ‰å…¶å®ƒçš„å±æ€§ä¿¡æ¯ï¼Œå› ä¸ºè¯¥æ ·æœ¬çš„ç±»æ¡ä»¶æ¦‚ç‡è¢«è®¡ç®—ä¸º0ã€‚å› æ­¤åœ¨ä¼°è®¡æ¦‚ç‡å€¼æ—¶ï¼Œå¸¸å¸¸ç”¨è¿›è¡Œå¹³æ»‘ï¼ˆsmoothingï¼‰å¤„ç†ï¼Œæ‹‰æ™®æ‹‰æ–¯ä¿®æ­£ï¼ˆLaplacian correctionï¼‰å°±æ˜¯å…¶ä¸­çš„ä¸€ç§ç»å…¸æ–¹æ³•ï¼Œå…·ä½“è®¡ç®—æ–¹æ³•å¦‚ä¸‹ï¼š</p><p><img src="https://i.loli.net/2018/10/18/5bc83fe54aaed.png" alt="11.png"></p><p>å½“è®­ç»ƒé›†è¶Šå¤§æ—¶ï¼Œæ‹‰æ™®æ‹‰æ–¯ä¿®æ­£å¼•å…¥çš„å½±å“è¶Šæ¥è¶Šå°ã€‚å¯¹äºè´å¶æ–¯åˆ†ç±»å™¨ï¼Œæ¨¡å‹çš„è®­ç»ƒå°±æ˜¯å‚æ•°ä¼°è®¡ï¼Œå› æ­¤å¯ä»¥äº‹å…ˆå°†æ‰€æœ‰çš„æ¦‚ç‡å‚¨å­˜å¥½ï¼Œå½“æœ‰æ–°æ ·æœ¬éœ€è¦åˆ¤å®šæ—¶ï¼Œç›´æ¥æŸ¥è¡¨è®¡ç®—å³å¯ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹  </tag>
            
            <tag> è´å¶æ–¯åˆ†ç±»å™¨ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>å†³ç­–æ ‘ä¸éšæœºæ£®æ—</title>
      <link href="/2019/09/01/%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/"/>
      <url>/2019/09/01/%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/</url>
      
        <content type="html"><![CDATA[<h2 id="æœºå™¨å­¦ä¹ ä¸­çš„å†³ç­–æ ‘æ¨¡å‹"><a href="#æœºå™¨å­¦ä¹ ä¸­çš„å†³ç­–æ ‘æ¨¡å‹" class="headerlink" title="æœºå™¨å­¦ä¹ ä¸­çš„å†³ç­–æ ‘æ¨¡å‹"></a>æœºå™¨å­¦ä¹ ä¸­çš„å†³ç­–æ ‘æ¨¡å‹</h2><ul><li>â‘  æ ‘æ¨¡å‹ä¸ç”¨åšscaling</li><li>â‘¡ æ ‘æ¨¡å‹ä¸å¤ªéœ€è¦åšç¦»æ•£åŒ–</li><li>â‘¢ ç”¨Xgboostç­‰å·¥å…·åº“ï¼Œæ˜¯ä¸éœ€è¦åšç¼ºå¤±å€¼å¡«å……</li><li>â‘£ æ ‘æ¨¡å‹æ˜¯éçº¿æ€§æ¨¡å‹ï¼Œæœ‰éçº¿æ€§çš„è¡¨è¾¾èƒ½åŠ›</li></ul><h3 id="å†³ç­–æ ‘åŸºæœ¬æ¦‚å¿µ"><a href="#å†³ç­–æ ‘åŸºæœ¬æ¦‚å¿µ" class="headerlink" title="å†³ç­–æ ‘åŸºæœ¬æ¦‚å¿µ"></a>å†³ç­–æ ‘åŸºæœ¬æ¦‚å¿µ</h3><ul><li>å†³ç­–æ—¶æ˜¯ä¸€ç§æ ‘å½¢ç»“æ„ï¼Œå…¶ä¸­æ¯ä¸ªå†…éƒ¨èŠ‚ç‚¹è¡¨ç¤ºåœ¨ä¸€ä¸ªå±æ€§ä¸Šçš„æµ‹è¯•ï¼Œæ¯ä¸ªåˆ†æ”¯ä»£è¡¨ä¸€ä¸ªæµ‹è¯•è¾“å‡ºï¼Œæ¯ä¸ªå¶èŠ‚ç‚¹ä»£è¡¨ä¸€ç§ç±»åˆ«</li><li>å†³ç­–æ ‘å­¦ä¹ æ˜¯ä»¥å®ä¾‹ä¸ºåŸºç¡€çš„å½’çº³å­¦ä¹ </li><li>å†³ç­–æ ‘å­¦ä¹ é‡‡ç”¨çš„æ˜¯è‡ªé¡¶å‘ä¸‹çš„å½’çº³æ–¹æ³•ï¼Œå…¶åŸºæœ¬æ€æƒ³æ˜¯ä»¥ä¿¡æ¯ç†µä¸ºåº¦é‡æ„é€ ä¸€æ£µç†µå€¼ä¸‹é™æœ€å¿«çš„æ ‘ï¼Œåˆ°å¶å­èŠ‚ç‚¹å¤„çš„ç†µå€¼ä¸º0ï¼Œæ­¤æ—¶æ¯ä¸ªå¶å­èŠ‚ç‚¹ä¸­çš„å®ä¾‹éƒ½å±äºåŒä¸€ç±»ã€‚</li></ul><p>é¡¾åæ€ä¹‰ï¼Œå†³ç­–æ ‘æ˜¯åŸºäºæ ‘ç»“æ„æ¥è¿›è¡Œå†³ç­–çš„ï¼Œï¼Œåœ¨ç½‘ä¸Šçœ‹åˆ°ä¸€ä¸ªä¾‹å­ååˆ†æœ‰è¶£ï¼Œæ”¾åœ¨è¿™é‡Œæ­£å¥½åˆé€‚ã€‚ç°æƒ³è±¡ä¸€ä½æ‰æ€¥çš„æ¯äº²æƒ³è¦ç»™è‡ªå·±çš„å¥³å¨ƒä»‹ç»ä¸€ä¸ªç”·æœ‹å‹ï¼Œäºæ˜¯æœ‰äº†ä¸‹é¢çš„å¯¹è¯ï¼š</p><hr><pre><code>å¥³å„¿ï¼šå¤šå¤§å¹´çºªäº†ï¼Ÿæ¯äº²ï¼š26ã€‚å¥³å„¿ï¼šé•¿çš„å¸…ä¸å¸…ï¼Ÿæ¯äº²ï¼šæŒºå¸…çš„ã€‚å¥³å„¿ï¼šæ”¶å…¥é«˜ä¸ï¼Ÿæ¯äº²ï¼šä¸ç®—å¾ˆé«˜ï¼Œä¸­ç­‰æƒ…å†µã€‚å¥³å„¿ï¼šæ˜¯å…¬åŠ¡å‘˜ä¸ï¼Ÿæ¯äº²ï¼šæ˜¯ï¼Œåœ¨ç¨åŠ¡å±€ä¸Šç­å‘¢ã€‚å¥³å„¿ï¼šé‚£å¥½ï¼Œæˆ‘å»è§è§ã€‚</code></pre><hr><p>è¿™ä¸ªå¥³å­©çš„æŒ‘å‰”è¿‡ç¨‹å°±æ˜¯ä¸€ä¸ªå…¸å‹çš„å†³ç­–æ ‘ï¼Œå³ç›¸å½“äºé€šè¿‡å¹´é¾„ã€é•¿ç›¸ã€æ”¶å…¥å’Œæ˜¯å¦å…¬åŠ¡å‘˜å°†ç”·ç«¥é‹åˆ†ä¸ºä¸¤ä¸ªç±»åˆ«ï¼šè§å’Œä¸è§ã€‚å‡è®¾è¿™ä¸ªå¥³å­©å¯¹ç”·äººçš„è¦æ±‚æ˜¯ï¼š30å²ä»¥ä¸‹ã€é•¿ç›¸ä¸­ç­‰ä»¥ä¸Šå¹¶ä¸”æ˜¯é«˜æ”¶å…¥è€…æˆ–ä¸­ç­‰ä»¥ä¸Šæ”¶å…¥çš„å…¬åŠ¡å‘˜ï¼Œé‚£ä¹ˆä½¿ç”¨ä¸‹å›¾å°±èƒ½å¾ˆå¥½åœ°è¡¨ç¤ºå¥³å­©çš„å†³ç­–é€»è¾‘ï¼ˆå³ä¸€é¢—å†³ç­–æ ‘ï¼‰ã€‚</p><p><img src="https://i.loli.net/2018/10/17/5bc728ec84a77.png" alt="1.png"></p><p>åœ¨ä¸Šå›¾çš„å†³ç­–æ ‘ä¸­ï¼Œå†³ç­–è¿‡ç¨‹çš„æ¯ä¸€æ¬¡åˆ¤å®šéƒ½æ˜¯å¯¹æŸä¸€å±æ€§çš„â€œæµ‹è¯•â€ï¼Œå†³ç­–æœ€ç»ˆç»“è®ºåˆ™å¯¹åº”æœ€ç»ˆçš„åˆ¤å®šç»“æœã€‚ä¸€èˆ¬ä¸€é¢—å†³ç­–æ ‘åŒ…å«ï¼šä¸€ä¸ªæ ¹èŠ‚ç‚¹ã€è‹¥å¹²ä¸ªå†…éƒ¨èŠ‚ç‚¹å’Œè‹¥å¹²ä¸ªå¶å­èŠ‚ç‚¹ï¼Œæ˜“çŸ¥ï¼š</p><pre><code>* æ¯ä¸ªéå¶èŠ‚ç‚¹è¡¨ç¤ºä¸€ä¸ªç‰¹å¾å±æ€§æµ‹è¯•ã€‚* æ¯ä¸ªåˆ†æ”¯ä»£è¡¨è¿™ä¸ªç‰¹å¾å±æ€§åœ¨æŸä¸ªå€¼åŸŸä¸Šçš„è¾“å‡ºã€‚* æ¯ä¸ªå¶å­èŠ‚ç‚¹å­˜æ”¾ä¸€ä¸ªç±»åˆ«ã€‚* æ¯ä¸ªèŠ‚ç‚¹åŒ…å«çš„æ ·æœ¬é›†åˆé€šè¿‡å±æ€§æµ‹è¯•è¢«åˆ’åˆ†åˆ°å­èŠ‚ç‚¹ä¸­ï¼Œæ ¹èŠ‚ç‚¹åŒ…å«æ ·æœ¬å…¨é›†ã€‚</code></pre><h3 id="å†³ç­–æ ‘çš„æ„é€ "><a href="#å†³ç­–æ ‘çš„æ„é€ " class="headerlink" title="å†³ç­–æ ‘çš„æ„é€ "></a>å†³ç­–æ ‘çš„æ„é€ </h3><p>å†³ç­–æ ‘çš„æ„é€ æ˜¯ä¸€ä¸ªé€’å½’çš„è¿‡ç¨‹ï¼Œæœ‰ä¸‰ç§æƒ…å½¢ä¼šå¯¼è‡´é€’å½’è¿”å›ï¼š(1) å½“å‰ç»“ç‚¹åŒ…å«çš„æ ·æœ¬å…¨å±äºåŒä¸€ç±»åˆ«ï¼Œè¿™æ—¶ç›´æ¥å°†è¯¥èŠ‚ç‚¹æ ‡è®°ä¸ºå¶èŠ‚ç‚¹ï¼Œå¹¶è®¾ä¸ºç›¸åº”çš„ç±»åˆ«ï¼›(2) å½“å‰å±æ€§é›†ä¸ºç©ºï¼Œæˆ–æ˜¯æ‰€æœ‰æ ·æœ¬åœ¨æ‰€æœ‰å±æ€§ä¸Šå–å€¼ç›¸åŒï¼Œæ— æ³•åˆ’åˆ†ï¼Œè¿™æ—¶å°†è¯¥èŠ‚ç‚¹æ ‡è®°ä¸ºå¶èŠ‚ç‚¹ï¼Œå¹¶å°†å…¶ç±»åˆ«è®¾ä¸ºè¯¥èŠ‚ç‚¹æ‰€å«æ ·æœ¬æœ€å¤šçš„ç±»åˆ«ï¼›(3) å½“å‰ç»“ç‚¹åŒ…å«çš„æ ·æœ¬é›†åˆä¸ºç©ºï¼Œä¸èƒ½åˆ’åˆ†ï¼Œè¿™æ—¶ä¹Ÿå°†è¯¥èŠ‚ç‚¹æ ‡è®°ä¸ºå¶èŠ‚ç‚¹ï¼Œå¹¶å°†å…¶ç±»åˆ«è®¾ä¸ºçˆ¶èŠ‚ç‚¹ä¸­æ‰€å«æ ·æœ¬æœ€å¤šçš„ç±»åˆ«ã€‚ç®—æ³•çš„åŸºæœ¬æµç¨‹å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc728ecc27fe.png" alt="2.png"></p><p>å¯ä»¥çœ‹å‡ºï¼šå†³ç­–æ ‘å­¦ä¹ çš„å…³é”®åœ¨äºå¦‚ä½•é€‰æ‹©åˆ’åˆ†å±æ€§ï¼Œä¸åŒçš„åˆ’åˆ†å±æ€§å¾—å‡ºä¸åŒçš„åˆ†æ”¯ç»“æ„ï¼Œä»è€Œå½±å“æ•´é¢—å†³ç­–æ ‘çš„æ€§èƒ½ã€‚å±æ€§åˆ’åˆ†çš„ç›®æ ‡æ˜¯è®©å„ä¸ªåˆ’åˆ†å‡ºæ¥çš„å­èŠ‚ç‚¹å°½å¯èƒ½åœ°â€œçº¯â€ï¼Œå³å±äºåŒä¸€ç±»åˆ«ã€‚å› æ­¤ä¸‹é¢ä¾¿æ˜¯ä»‹ç»é‡åŒ–çº¯åº¦çš„å…·ä½“æ–¹æ³•ï¼Œå†³ç­–æ ‘æœ€å¸¸ç”¨çš„ç®—æ³•æœ‰ä¸‰ç§ï¼šID3ï¼ŒC4.5å’ŒCARTã€‚##</p><h4 id="å†³ç­–æ ‘å­¦ä¹ ç®—æ³•çš„ç‰¹ç‚¹"><a href="#å†³ç­–æ ‘å­¦ä¹ ç®—æ³•çš„ç‰¹ç‚¹" class="headerlink" title="å†³ç­–æ ‘å­¦ä¹ ç®—æ³•çš„ç‰¹ç‚¹"></a>å†³ç­–æ ‘å­¦ä¹ ç®—æ³•çš„ç‰¹ç‚¹</h4><p>å†³ç­–æ ‘å­¦ä¹ ç®—æ³•æœ€å¤§çš„ä¼˜ç‚¹æ˜¯ï¼Œå®ƒå¯ä»¥è‡ªå­¦ä¹ ã€‚åœ¨å­¦ä¹ çš„è¿‡ç¨‹ä¸­ï¼Œä¸éœ€è¦ä½¿ç”¨è€…äº†è§£è¿‡å¤šèƒŒæ™¯çŸ¥è¯†ï¼Œåªéœ€è¦å¯¹è®­ç»ƒå®ä¾‹è¿›è¡Œè¾ƒå¥½çš„æ ‡æ³¨ï¼Œå°±èƒ½è¿›è¡Œå­¦ä¹ ã€‚æ˜¾ç„¶ï¼Œå±äºæœ‰ç›‘ç£å­¦ä¹ ã€‚ä»ä¸€ç±»æ— åºã€æ— è§„åˆ™çš„äº‹ç‰©ä¸­æ¨ç†å‡ºå†³ç­–æ ‘è¡¨ç¤ºåˆ†ç±»çš„è§„åˆ™ã€‚</p><h4 id="ID3ç®—æ³•"><a href="#ID3ç®—æ³•" class="headerlink" title="ID3ç®—æ³•"></a>ID3ç®—æ³•</h4><p>ID3ç®—æ³•ä½¿ç”¨ä¿¡æ¯å¢ç›Šä¸ºå‡†åˆ™æ¥é€‰æ‹©åˆ’åˆ†å±æ€§ï¼Œâ€œä¿¡æ¯ç†µâ€(information entropy)æ˜¯åº¦é‡æ ·æœ¬ç»“åˆçº¯åº¦çš„å¸¸ç”¨æŒ‡æ ‡ï¼Œå‡å®šå½“å‰æ ·æœ¬é›†åˆDä¸­ç¬¬kç±»æ ·æœ¬æ‰€å æ¯”ä¾‹ä¸ºpkï¼Œåˆ™æ ·æœ¬é›†åˆDçš„ä¿¡æ¯ç†µå®šä¹‰ä¸ºï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc728ec515a5.png" alt="3.png"></p><p>å‡å®šé€šè¿‡å±æ€§åˆ’åˆ†æ ·æœ¬é›†Dï¼Œäº§ç”Ÿäº†Vä¸ªåˆ†æ”¯èŠ‚ç‚¹ï¼Œvè¡¨ç¤ºå…¶ä¸­ç¬¬vä¸ªåˆ†æ”¯èŠ‚ç‚¹ï¼Œæ˜“çŸ¥ï¼šåˆ†æ”¯èŠ‚ç‚¹åŒ…å«çš„æ ·æœ¬æ•°è¶Šå¤šï¼Œè¡¨ç¤ºè¯¥åˆ†æ”¯èŠ‚ç‚¹çš„å½±å“åŠ›è¶Šå¤§ã€‚æ•…å¯ä»¥è®¡ç®—å‡ºåˆ’åˆ†åç›¸æ¯”åŸå§‹æ•°æ®é›†Dè·å¾—çš„â€œä¿¡æ¯å¢ç›Šâ€ï¼ˆinformation gainï¼‰ã€‚</p><p><img src="https://i.loli.net/2018/10/17/5bc728ec3e067.png" alt="4.png"></p><p>Ent(D)åˆ’åˆ†å‰çš„ä¿¡æ¯å¢ç›Š -åˆ’åˆ†åçš„ä¿¡æ¯å¢ç›Š</p><p>DV/Dè¡¨ç¤ºç¬¬Vä¸ªåˆ†æ”¯çš„æƒé‡ï¼Œæ ·æœ¬è¶Šå¤šè¶Šé‡è¦</p><p>ä¿¡æ¯å¢ç›Šè¶Šå¤§ï¼Œè¡¨ç¤ºä½¿ç”¨è¯¥å±æ€§åˆ’åˆ†æ ·æœ¬é›†Dçš„æ•ˆæœè¶Šå¥½ï¼Œå› æ­¤ID3ç®—æ³•åœ¨é€’å½’è¿‡ç¨‹ä¸­ï¼Œæ¯æ¬¡é€‰æ‹©æœ€å¤§ä¿¡æ¯å¢ç›Šçš„å±æ€§ä½œä¸ºå½“å‰çš„åˆ’åˆ†å±æ€§ã€‚</p><h4 id="C4-5ç®—æ³•"><a href="#C4-5ç®—æ³•" class="headerlink" title="C4.5ç®—æ³•"></a>C4.5ç®—æ³•</h4><p>ID3ç®—æ³•å­˜åœ¨ä¸€ä¸ªé—®é¢˜ï¼Œå°±æ˜¯åå‘äºå–å€¼æ•°ç›®è¾ƒå¤šçš„å±æ€§ï¼Œä¾‹å¦‚ï¼šå¦‚æœå­˜åœ¨ä¸€ä¸ªå”¯ä¸€æ ‡è¯†ï¼Œè¿™æ ·æ ·æœ¬é›†Då°†ä¼šè¢«åˆ’åˆ†ä¸º|D|ä¸ªåˆ†æ”¯ï¼Œæ¯ä¸ªåˆ†æ”¯åªæœ‰ä¸€ä¸ªæ ·æœ¬ï¼Œè¿™æ ·åˆ’åˆ†åçš„ä¿¡æ¯ç†µä¸ºé›¶ï¼Œååˆ†çº¯å‡€ï¼Œä½†æ˜¯å¯¹åˆ†ç±»æ¯«æ— ç”¨å¤„ã€‚å› æ­¤C4.5ç®—æ³•ä½¿ç”¨äº†â€œå¢ç›Šç‡â€ï¼ˆgain ratioï¼‰æ¥é€‰æ‹©åˆ’åˆ†å±æ€§ï¼Œæ¥é¿å…è¿™ä¸ªé—®é¢˜å¸¦æ¥çš„å›°æ‰°ã€‚é¦–å…ˆä½¿ç”¨ID3ç®—æ³•è®¡ç®—å‡ºä¿¡æ¯å¢ç›Šé«˜äºå¹³å‡æ°´å¹³çš„å€™é€‰å±æ€§ï¼Œæ¥ç€C4.5è®¡ç®—è¿™äº›å€™é€‰å±æ€§çš„å¢ç›Šç‡ï¼Œå¢ç›Šç‡å®šä¹‰ä¸ºï¼š</p><p>å¯å‘å¼ï¼šå…ˆä»å€™é€‰åˆ’åˆ†å±æ€§ä¸­æ‰¾å‡ºä¿¡æ¯å¢ç›Šé«˜äºå¹³å‡æ°´å¹³çš„ï¼Œå†ä»ä¸­é€‰å–å¢ç›Šç‡æœ€é«˜çš„</p><p><img src="https://i.loli.net/2018/10/17/5bc728ec69647.png" alt="5.png"></p><h4 id="CARTç®—æ³•"><a href="#CARTç®—æ³•" class="headerlink" title="CARTç®—æ³•"></a>CARTç®—æ³•</h4><p>CARTå†³ç­–æ ‘ä½¿ç”¨â€œåŸºå°¼æŒ‡æ•°â€ï¼ˆGini indexï¼‰æ¥é€‰æ‹©åˆ’åˆ†å±æ€§ï¼ŒåŸºå°¼æŒ‡æ•°åæ˜ çš„æ˜¯ä»æ ·æœ¬é›†Dä¸­éšæœºæŠ½å–ä¸¤ä¸ªæ ·æœ¬ï¼Œå…¶ç±»åˆ«æ ‡è®°ä¸ä¸€è‡´çš„æ¦‚ç‡ï¼Œå› æ­¤Gini(D)è¶Šå°è¶Šå¥½ï¼Œæ•°æ®é›†Dçš„çº¯åº¦è¶Šé«˜ã€‚åŸºå°¼æŒ‡æ•°å®šä¹‰å¦‚ä¸‹ï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc728ec5a2ff.png" alt="6.png"></p><p>è¿›è€Œï¼Œä½¿ç”¨å±æ€§Î±åˆ’åˆ†åçš„åŸºå°¼æŒ‡æ•°ä¸ºï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc728ec62eaf.png" alt="7.png"></p><p>äºŒåˆ†ç±»è§†è§’çœ‹CART</p><ul><li>æ¯ä¸€ä¸ªäº§ç”Ÿåˆ†æ”¯çš„è¿‡ç¨‹æ˜¯ä¸€ä¸ªäºŒåˆ†ç±»è¿‡ç¨‹</li><li>è¿™ä¸ªè¿‡ç¨‹å«ä½œâ€œå†³ç­–æ ‘æ¡©â€</li><li>ä¸€æ£µCARTæ˜¯ç”±è®¸å¤šå†³ç­–æ ‘æ¡©æ‹¼æ¥èµ·æ¥çš„</li><li>å†³ç­–æ ‘æ¡©æ˜¯åªæœ‰ä¸€å±‚çš„å†³ç­–æ ‘</li></ul><h4 id="ä¸‰ç§ä¸åŒçš„å†³ç­–æ ‘"><a href="#ä¸‰ç§ä¸åŒçš„å†³ç­–æ ‘" class="headerlink" title="ä¸‰ç§ä¸åŒçš„å†³ç­–æ ‘"></a>ä¸‰ç§ä¸åŒçš„å†³ç­–æ ‘</h4><ul><li>ID3:å–å€¼å¤šçš„å±æ€§ï¼Œæ›´å®¹æ˜“ä½¿æ•°æ®æ›´çº¯ï¼Œå…¶ä¿¡æ¯å¢ç›Šæ›´å¤§ï¼›è®­ç»ƒå¾—åˆ°çš„æ˜¯ä¸€æ£µåºå¤§ä¸”æ·±åº¦æµ…çš„æ ‘ï¼šä¸åˆç†</li><li>C4.5:é‡‡ç”¨ä¿¡æ¯å¢ç›Šç‡æ›¿ä»£ä¿¡æ¯å¢ç›Š</li><li>CARTï¼šä»¥åŸºå°¼ç³»æ•°æ›¿ä»£ç†µï¼›æœ€å°åŒ–ä¸çº¯åº¦ï¼Œè€Œä¸æ˜¯æœ€å¤§åŒ–ä¿¡æ¯å¢ç›Š</li></ul><h4 id="å‰ªæå¤„ç†"><a href="#å‰ªæå¤„ç†" class="headerlink" title="å‰ªæå¤„ç†"></a>å‰ªæå¤„ç†</h4><p>ä»å†³ç­–æ ‘çš„æ„é€ æµç¨‹ä¸­æˆ‘ä»¬å¯ä»¥ç›´è§‚åœ°çœ‹å‡ºï¼šä¸ç®¡æ€ä¹ˆæ ·çš„è®­ç»ƒé›†ï¼Œå†³ç­–æ ‘æ€»æ˜¯èƒ½å¾ˆå¥½åœ°å°†å„ä¸ªç±»åˆ«åˆ†ç¦»å¼€æ¥ï¼Œè¿™æ—¶å°±ä¼šé‡åˆ°ä¹‹å‰æåˆ°è¿‡çš„é—®é¢˜ï¼šè¿‡æ‹Ÿåˆï¼ˆoverfittingï¼‰ï¼Œå³å¤ªä¾èµ–äºè®­ç»ƒæ ·æœ¬ã€‚å‰ªæï¼ˆpruningï¼‰åˆ™æ˜¯å†³ç­–æ ‘ç®—æ³•å¯¹ä»˜è¿‡æ‹Ÿåˆçš„ä¸»è¦æ‰‹æ®µï¼Œå‰ªæçš„ç­–ç•¥æœ‰ä¸¤ç§å¦‚ä¸‹ï¼š</p><pre><code>* é¢„å‰ªæï¼ˆprepruningï¼‰ï¼šåœ¨æ„é€ çš„è¿‡ç¨‹ä¸­å…ˆè¯„ä¼°ï¼Œå†è€ƒè™‘æ˜¯å¦åˆ†æ”¯ã€‚* åå‰ªæï¼ˆpost-pruningï¼‰ï¼šåœ¨æ„é€ å¥½ä¸€é¢—å®Œæ•´çš„å†³ç­–æ ‘åï¼Œè‡ªåº•å‘ä¸Šï¼Œè¯„ä¼°åˆ†æ”¯çš„å¿…è¦æ€§ã€‚</code></pre><p>è¯„ä¼°æŒ‡çš„æ˜¯æ€§èƒ½åº¦é‡ï¼Œå³å†³ç­–æ ‘çš„æ³›åŒ–æ€§èƒ½ã€‚ä¹‹å‰æåˆ°ï¼šå¯ä»¥ä½¿ç”¨æµ‹è¯•é›†ä½œä¸ºå­¦ä¹ å™¨æ³›åŒ–æ€§èƒ½çš„è¿‘ä¼¼ï¼Œå› æ­¤å¯ä»¥å°†æ•°æ®é›†åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚é¢„å‰ªæè¡¨ç¤ºåœ¨æ„é€ æ•°çš„è¿‡ç¨‹ä¸­ï¼Œå¯¹ä¸€ä¸ªèŠ‚ç‚¹è€ƒè™‘æ˜¯å¦åˆ†æ”¯æ—¶ï¼Œé¦–å…ˆè®¡ç®—å†³ç­–æ ‘ä¸åˆ†æ”¯æ—¶åœ¨æµ‹è¯•é›†ä¸Šçš„æ€§èƒ½ï¼Œå†è®¡ç®—åˆ†æ”¯ä¹‹åçš„æ€§èƒ½ï¼Œè‹¥åˆ†æ”¯å¯¹æ€§èƒ½æ²¡æœ‰æå‡ï¼Œåˆ™é€‰æ‹©ä¸åˆ†æ”¯ï¼ˆå³å‰ªæï¼‰ã€‚åå‰ªæåˆ™è¡¨ç¤ºåœ¨æ„é€ å¥½ä¸€é¢—å®Œæ•´çš„å†³ç­–æ ‘åï¼Œä»æœ€ä¸‹é¢çš„èŠ‚ç‚¹å¼€å§‹ï¼Œè€ƒè™‘è¯¥èŠ‚ç‚¹åˆ†æ”¯å¯¹æ¨¡å‹çš„æ€§èƒ½æ˜¯å¦æœ‰æå‡ï¼Œè‹¥æ— åˆ™å‰ªæï¼Œå³å°†è¯¥èŠ‚ç‚¹æ ‡è®°ä¸ºå¶å­èŠ‚ç‚¹ï¼Œç±»åˆ«æ ‡è®°ä¸ºå…¶åŒ…å«æ ·æœ¬æœ€å¤šçš„ç±»åˆ«ã€‚</p><p><img src="https://i.loli.net/2018/10/17/5bc728ec80d34.png" alt="8.png"></p><p><img src="https://i.loli.net/2018/10/17/5bc728ec9e330.png" alt="9.png"></p><p><img src="https://i.loli.net/2018/10/17/5bc728ec9d497.png" alt="10.png"></p><p>ä¸Šå›¾åˆ†åˆ«è¡¨ç¤ºä¸å‰ªæå¤„ç†çš„å†³ç­–æ ‘ã€é¢„å‰ªæå†³ç­–æ ‘å’Œåå‰ªæå†³ç­–æ ‘ã€‚é¢„å‰ªæå¤„ç†ä½¿å¾—å†³ç­–æ ‘çš„å¾ˆå¤šåˆ†æ”¯è¢«å‰ªæ‰ï¼Œå› æ­¤å¤§å¤§é™ä½äº†è®­ç»ƒæ—¶é—´å¼€é”€ï¼ŒåŒæ—¶é™ä½äº†è¿‡æ‹Ÿåˆçš„é£é™©ï¼Œä½†å¦ä¸€æ–¹é¢ç”±äºå‰ªæåŒæ—¶å‰ªæ‰äº†å½“å‰èŠ‚ç‚¹åç»­å­èŠ‚ç‚¹çš„åˆ†æ”¯ï¼Œå› æ­¤é¢„å‰ªæâ€œè´ªå¿ƒâ€çš„æœ¬è´¨é˜»æ­¢äº†åˆ†æ”¯çš„å±•å¼€ï¼Œåœ¨ä¸€å®šç¨‹åº¦ä¸Šå¸¦æ¥äº†æ¬ æ‹Ÿåˆçš„é£é™©ã€‚è€Œåå‰ªæåˆ™é€šå¸¸ä¿ç•™äº†æ›´å¤šçš„åˆ†æ”¯ï¼Œå› æ­¤é‡‡ç”¨åå‰ªæç­–ç•¥çš„å†³ç­–æ ‘æ€§èƒ½å¾€å¾€ä¼˜äºé¢„å‰ªæï¼Œä½†å…¶è‡ªåº•å‘ä¸Šéå†äº†æ‰€æœ‰èŠ‚ç‚¹ï¼Œå¹¶è®¡ç®—æ€§èƒ½ï¼Œè®­ç»ƒæ—¶é—´å¼€é”€ç›¸æ¯”é¢„å‰ªæå¤§å¤§æå‡ã€‚</p><h4 id="è¿ç»­å€¼ä¸ç¼ºå¤±å€¼å¤„ç†"><a href="#è¿ç»­å€¼ä¸ç¼ºå¤±å€¼å¤„ç†" class="headerlink" title="è¿ç»­å€¼ä¸ç¼ºå¤±å€¼å¤„ç†"></a>è¿ç»­å€¼ä¸ç¼ºå¤±å€¼å¤„ç†</h4><p>å¯¹äºè¿ç»­å€¼çš„å±æ€§ï¼Œè‹¥æ¯ä¸ªå–å€¼ä½œä¸ºä¸€ä¸ªåˆ†æ”¯åˆ™æ˜¾å¾—ä¸å¯è¡Œï¼Œå› æ­¤éœ€è¦è¿›è¡Œç¦»æ•£åŒ–å¤„ç†ï¼Œå¸¸ç”¨çš„æ–¹æ³•ä¸ºäºŒåˆ†æ³•ï¼ŒåŸºæœ¬æ€æƒ³ä¸ºï¼šç»™å®šæ ·æœ¬é›†Dä¸è¿ç»­å±æ€§Î±ï¼ŒäºŒåˆ†æ³•è¯•å›¾æ‰¾åˆ°ä¸€ä¸ªåˆ’åˆ†ç‚¹tå°†æ ·æœ¬é›†Dåœ¨å±æ€§Î±ä¸Šåˆ†ä¸ºâ‰¤tä¸ï¼tã€‚</p><pre><code>* é¦–å…ˆå°†Î±çš„æ‰€æœ‰å–å€¼æŒ‰å‡åºæ’åˆ—ï¼Œæ‰€æœ‰ç›¸é‚»å±æ€§çš„å‡å€¼ä½œä¸ºå€™é€‰åˆ’åˆ†ç‚¹ï¼ˆn-1ä¸ªï¼Œnä¸ºÎ±æ‰€æœ‰çš„å–å€¼æ•°ç›®ï¼‰ã€‚* è®¡ç®—æ¯ä¸€ä¸ªåˆ’åˆ†ç‚¹åˆ’åˆ†é›†åˆDï¼ˆå³åˆ’åˆ†ä¸ºä¸¤ä¸ªåˆ†æ”¯ï¼‰åçš„ä¿¡æ¯å¢ç›Šã€‚* é€‰æ‹©æœ€å¤§ä¿¡æ¯å¢ç›Šçš„åˆ’åˆ†ç‚¹ä½œä¸ºæœ€ä¼˜åˆ’åˆ†ç‚¹ã€‚</code></pre><p><img src="https://i.loli.net/2018/10/17/5bc72a0968fad.png" alt="11.png"></p><p>ç°å®ä¸­å¸¸ä¼šé‡åˆ°ä¸å®Œæ•´çš„æ ·æœ¬ï¼Œå³æŸäº›å±æ€§å€¼ç¼ºå¤±ã€‚æœ‰æ—¶è‹¥ç®€å•é‡‡å–å‰”é™¤ï¼Œåˆ™ä¼šé€ æˆå¤§é‡çš„ä¿¡æ¯æµªè´¹ï¼Œå› æ­¤åœ¨å±æ€§å€¼ç¼ºå¤±çš„æƒ…å†µä¸‹éœ€è¦è§£å†³ä¸¤ä¸ªé—®é¢˜ï¼šï¼ˆ1ï¼‰å¦‚ä½•é€‰æ‹©åˆ’åˆ†å±æ€§ã€‚ï¼ˆ2ï¼‰ç»™å®šåˆ’åˆ†å±æ€§ï¼Œè‹¥æŸæ ·æœ¬åœ¨è¯¥å±æ€§ä¸Šç¼ºå¤±å€¼ï¼Œå¦‚ä½•åˆ’åˆ†åˆ°å…·ä½“çš„åˆ†æ”¯ä¸Šã€‚å‡å®šä¸ºæ ·æœ¬é›†ä¸­çš„æ¯ä¸€ä¸ªæ ·æœ¬éƒ½èµ‹äºˆä¸€ä¸ªæƒé‡ï¼Œæ ¹èŠ‚ç‚¹ä¸­çš„æƒé‡åˆå§‹åŒ–ä¸º1ï¼Œåˆ™å®šä¹‰ï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc72a098f3be.png" alt="12.png"></p><p>å¯¹äºï¼ˆ1ï¼‰ï¼šé€šè¿‡åœ¨æ ·æœ¬é›†Dä¸­é€‰å–åœ¨å±æ€§Î±ä¸Šæ²¡æœ‰ç¼ºå¤±å€¼çš„æ ·æœ¬å­é›†ï¼Œè®¡ç®—åœ¨è¯¥æ ·æœ¬å­é›†ä¸Šçš„ä¿¡æ¯å¢ç›Šï¼Œæœ€ç»ˆçš„ä¿¡æ¯å¢ç›Šç­‰äºè¯¥æ ·æœ¬å­é›†åˆ’åˆ†åä¿¡æ¯å¢ç›Šä¹˜ä»¥æ ·æœ¬å­é›†å æ ·æœ¬é›†çš„æ¯”é‡ã€‚å³ï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc72a096ccc3.png" alt="13.png"></p><p>å¯¹äºï¼ˆ2ï¼‰ï¼šè‹¥è¯¥æ ·æœ¬å­é›†åœ¨å±æ€§Î±ä¸Šçš„å€¼ç¼ºå¤±ï¼Œåˆ™å°†è¯¥æ ·æœ¬ä»¥ä¸åŒçš„æƒé‡ï¼ˆå³æ¯ä¸ªåˆ†æ”¯æ‰€å«æ ·æœ¬æ¯”ä¾‹ï¼‰åˆ’å…¥åˆ°æ‰€æœ‰åˆ†æ”¯èŠ‚ç‚¹ä¸­ã€‚è¯¥æ ·æœ¬åœ¨åˆ†æ”¯èŠ‚ç‚¹ä¸­çš„æƒé‡å˜ä¸ºï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc72a093ed3c.png" alt="14.png"></p><h4 id="Bootstraping"><a href="#Bootstraping" class="headerlink" title="Bootstraping"></a>Bootstraping</h4><p>ç§°ä¸ºè‡ªåŠ©æ³•ï¼Œå®ƒæ˜¯ä¸€ç§æœ‰æ”¾å›çš„æŠ½æ ·æ–¹æ³•</p><p>####Baggingçš„ç­–ç•¥</p><ul><li>bootstrap aggregation</li><li>ä»æ ·æœ¬é›†ä¸­é‡é‡‡æ ·(æœ‰é‡å¤çš„)é€‰å‡ºnä¸ªæ ·æœ¬</li><li>åœ¨æ‰€æœ‰å±æ€§ä¸Šï¼Œå¯¹è¿™nä¸ªæ ·æœ¬å»ºç«‹åˆ†ç±»å™¨(ID3ã€C4.5ã€CARTã€SVMã€Logisticå›å½’ç­‰)</li><li>é‡å¤ä»¥ä¸Šä¸¤æ­¥mæ¬¡ï¼Œå³è·å¾—äº†mä¸ªåˆ†ç±»å™¨</li><li>å°†æ•°æ®æ”¾åœ¨è¿™mä¸ªåˆ†ç±»å™¨ä¸Šï¼Œæœ€åæ ¹æ®è¿™mä¸ªåˆ†ç±»å™¨çš„æŠ•ç¥¨ç»“æœï¼Œå†³å®šæ•°æ®å±äºå“ªä¸€ç±»</li></ul><h4 id="OOBæ•°æ®"><a href="#OOBæ•°æ®" class="headerlink" title="OOBæ•°æ®"></a>OOBæ•°æ®</h4><p>å¯ä»¥å‘ç°ï¼ŒBootstrapæ¯æ¬¡çº¦æœ‰36.79%çš„æ ·æœ¬ä¸ä¼šå‡ºç°åœ¨Bootstrapæ‰€é‡‡é›†çš„æ ·æœ¬é›†åˆä¸­ï¼Œå°†æœªå‚ä¸æ¨¡å‹è®­ç»ƒçš„æ•°æ®ç§°ä¸ºè¢‹å¤–æ•°æ®(out of bag)ã€‚å®ƒå¯ä»¥ç”¨äºå–ä»£æµ‹è¯•é›†ç”¨äºè¯¯å·®ä¼°è®¡ã€‚å¾—åˆ°çš„æ¨¡å‹å‚æ•°æ˜¯æ— åä¼°è®¡ã€‚</p><h4 id="éšæœºæ£®æ—"><a href="#éšæœºæ£®æ—" class="headerlink" title="éšæœºæ£®æ—"></a>éšæœºæ£®æ—</h4><p>éšæœºæ£®æ—åœ¨baggingåŸºç¡€ä¸Šåšäº†ä¿®æ”¹</p><ul><li>ä»æ ·æœ¬é›†ä¸­ç”¨bootstrapé‡‡æ ·é€‰å‡ºnä¸ªæ ·æœ¬</li><li>ä»æ‰€æœ‰å±æ€§ä¸­éšæœºé€‰æ‹©kä¸ªå±æ€§ï¼Œé€‰æ‹©æœ€ä½³åˆ†å‰²å±æ€§ä½œä¸ºèŠ‚ç‚¹å»ºç«‹CARTå†³ç­–æ ‘</li><li>é‡å¤ä»¥ä¸Šä¸¤æ­¥mæ¬¡ï¼Œå³å»ºç«‹mè¯¾CARTå†³ç­–æ ‘</li><li>è¿™mä¸ªCARTå½¢æˆéšæœºæ£®æ—ï¼Œé€šè¿‡æŠ•ç¥¨è¡¨å†³ç»“æœï¼Œå†³å®šæ•°æ®å±äºå“ªä¸€ç±»</li></ul><h4 id="éšæœºæ£®æ—-baggingå’Œå†³ç­–æ ‘çš„å…³ç³»"><a href="#éšæœºæ£®æ—-baggingå’Œå†³ç­–æ ‘çš„å…³ç³»" class="headerlink" title="éšæœºæ£®æ—/baggingå’Œå†³ç­–æ ‘çš„å…³ç³»"></a>éšæœºæ£®æ—/baggingå’Œå†³ç­–æ ‘çš„å…³ç³»</h4><ul><li>å½“ç„¶å¯ä»¥ä½¿ç”¨å†³ç­–æ ‘ä½œä¸ºåŸºæœ¬åˆ†ç±»å™¨</li><li>ä½†ä¹Ÿå¯ä»¥ä½¿ç”¨SVMã€Logisticså›å½’ç­‰å…¶ä»–åˆ†ç±»ï¼Œä¹ æƒ¯ä¸Šï¼Œè¿™äº›åˆ†ç±»å™¨ç»„æˆçš„â€œæ€»åˆ†ç±»å™¨â€ï¼Œä»ç„¶å«åšéšæœºæ£®æ—</li></ul>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹  </tag>
            
            <tag> å†³ç­–æ ‘ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>æœºå™¨å­¦ä¹ é€»è¾‘å›å½’ä¸softmax</title>
      <link href="/2019/08/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%B8%8Esoftmax/"/>
      <url>/2019/08/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%B8%8Esoftmax/</url>
      
        <content type="html"><![CDATA[<h1 id="æœºå™¨å­¦ä¹ é€»è¾‘å›å½’ä¸softmax"><a href="#æœºå™¨å­¦ä¹ é€»è¾‘å›å½’ä¸softmax" class="headerlink" title="æœºå™¨å­¦ä¹ é€»è¾‘å›å½’ä¸softmax"></a>æœºå™¨å­¦ä¹ é€»è¾‘å›å½’ä¸softmax</h1><h2 id="æœºå™¨å­¦ä¹ ä¸­çš„çº¿æ€§æ¨¡å‹"><a href="#æœºå™¨å­¦ä¹ ä¸­çš„çº¿æ€§æ¨¡å‹" class="headerlink" title="æœºå™¨å­¦ä¹ ä¸­çš„çº¿æ€§æ¨¡å‹"></a>æœºå™¨å­¦ä¹ ä¸­çš„çº¿æ€§æ¨¡å‹</h2><p>è°ˆåŠçº¿æ€§æ¨¡å‹ï¼Œå…¶å®æˆ‘ä»¬å¾ˆæ—©å°±å·²ç»ä¸å®ƒæ‰“è¿‡äº¤é“ï¼Œè¿˜è®°å¾—é«˜ä¸­æ•°å­¦å¿…ä¿®3è¯¾æœ¬ä¸­é‚£ä¸ªé¡½çš®çš„â€œæœ€å°äºŒä¹˜æ³•â€å—ï¼Ÿè¿™å°±æ˜¯çº¿æ€§æ¨¡å‹çš„ç»å…¸ç®—æ³•ä¹‹ä¸€ï¼šæ ¹æ®ç»™å®šçš„ï¼ˆxï¼Œyï¼‰ç‚¹å¯¹ï¼Œæ±‚å‡ºä¸€æ¡ä¸è¿™äº›ç‚¹æ‹Ÿåˆæ•ˆæœæœ€å¥½çš„ç›´çº¿y=ax+bï¼Œä¹‹å‰æˆ‘ä»¬åˆ©ç”¨ä¸‹é¢çš„å…¬å¼ä¾¿å¯ä»¥è®¡ç®—å‡ºæ‹Ÿåˆç›´çº¿çš„ç³»æ•°a,bï¼ˆ3.1ä¸­ç»™å‡ºäº†å…·ä½“çš„è®¡ç®—è¿‡ç¨‹ï¼‰ï¼Œä»è€Œå¯¹äºä¸€ä¸ªæ–°çš„xï¼Œå¯ä»¥é¢„æµ‹å®ƒæ‰€å¯¹åº”çš„yå€¼ã€‚å‰é¢æˆ‘ä»¬æåˆ°ï¼šåœ¨æœºå™¨å­¦ä¹ çš„æœ¯è¯­ä¸­ï¼Œå½“é¢„æµ‹å€¼ä¸ºè¿ç»­å€¼æ—¶ï¼Œç§°ä¸ºâ€œå›å½’é—®é¢˜â€ï¼Œç¦»æ•£å€¼æ—¶ä¸ºâ€œåˆ†ç±»é—®é¢˜â€ã€‚æœ¬ç¯‡å…ˆä»çº¿æ€§å›å½’ä»»åŠ¡å¼€å§‹ï¼Œæ¥ç€è®¨è®ºåˆ†ç±»å’Œå¤šåˆ†ç±»é—®é¢˜ã€‚</p><p><img src="https://i.loli.net/2018/10/17/5bc722b068e48.png" alt="1.png"></p><h3 id="çº¿æ€§å›å½’"><a href="#çº¿æ€§å›å½’" class="headerlink" title="çº¿æ€§å›å½’"></a>çº¿æ€§å›å½’</h3><p>çº¿æ€§å›å½’é—®é¢˜å°±æ˜¯è¯•å›¾å­¦åˆ°ä¸€ä¸ªçº¿æ€§æ¨¡å‹å°½å¯èƒ½å‡†ç¡®åœ°é¢„æµ‹æ–°æ ·æœ¬çš„è¾“å‡ºå€¼ï¼Œä¾‹å¦‚ï¼šé€šè¿‡å†å¹´çš„äººå£æ•°æ®é¢„æµ‹2017å¹´äººå£æ•°é‡ã€‚åœ¨è¿™ç±»é—®é¢˜ä¸­ï¼Œå¾€å¾€æˆ‘ä»¬ä¼šå…ˆå¾—åˆ°ä¸€ç³»åˆ—çš„æœ‰æ ‡è®°æ•°æ®ï¼Œä¾‹å¦‚ï¼š2000â€“&gt;13äº¿â€¦2016â€“&gt;15äº¿ï¼Œè¿™æ—¶è¾“å…¥çš„å±æ€§åªæœ‰ä¸€ä¸ªï¼Œå³å¹´ä»½ï¼›ä¹Ÿæœ‰è¾“å…¥å¤šå±æ€§çš„æƒ…å½¢ï¼Œå‡è®¾æˆ‘ä»¬é¢„æµ‹ä¸€ä¸ªäººçš„æ”¶å…¥ï¼Œè¿™æ—¶è¾“å…¥çš„å±æ€§å€¼å°±ä¸æ­¢ä¸€ä¸ªäº†ï¼Œä¾‹å¦‚ï¼šï¼ˆå­¦å†ï¼Œå¹´é¾„ï¼Œæ€§åˆ«ï¼Œé¢œå€¼ï¼Œèº«é«˜ï¼Œä½“é‡ï¼‰â€“&gt;15kã€‚</p><p>æœ‰æ—¶è¿™äº›è¾“å…¥çš„å±æ€§å€¼å¹¶ä¸èƒ½ç›´æ¥è¢«æˆ‘ä»¬çš„å­¦ä¹ æ¨¡å‹æ‰€ç”¨ï¼Œéœ€è¦è¿›è¡Œç›¸åº”çš„å¤„ç†ï¼Œå¯¹äºè¿ç»­å€¼çš„å±æ€§ï¼Œä¸€èˆ¬éƒ½å¯ä»¥è¢«å­¦ä¹ å™¨æ‰€ç”¨ï¼Œæœ‰æ—¶ä¼šæ ¹æ®å…·ä½“çš„æƒ…å½¢ä½œç›¸åº”çš„é¢„å¤„ç†ï¼Œä¾‹å¦‚ï¼šå½’ä¸€åŒ–ç­‰ï¼›å¯¹äºç¦»æ•£å€¼çš„å±æ€§ï¼Œå¯ä½œä¸‹é¢çš„å¤„ç†ï¼š</p><ul><li><p>è‹¥å±æ€§å€¼ä¹‹é—´å­˜åœ¨â€œåºå…³ç³»â€ï¼Œåˆ™å¯ä»¥å°†å…¶è½¬åŒ–ä¸ºè¿ç»­å€¼ï¼Œä¾‹å¦‚ï¼šèº«é«˜å±æ€§åˆ†ä¸ºâ€œé«˜â€â€œä¸­ç­‰â€â€œçŸ®â€ï¼Œå¯è½¬åŒ–ä¸ºæ•°å€¼ï¼š{1ï¼Œ 0.5ï¼Œ 0}ã€‚</p></li><li><p>è‹¥å±æ€§å€¼ä¹‹é—´ä¸å­˜åœ¨â€œåºå…³ç³»â€ï¼Œåˆ™é€šå¸¸å°†å…¶è½¬åŒ–ä¸ºå‘é‡çš„å½¢å¼ï¼Œä¾‹å¦‚ï¼šæ€§åˆ«å±æ€§åˆ†ä¸ºâ€œç”·â€â€œå¥³â€ï¼Œå¯è½¬åŒ–ä¸ºäºŒç»´å‘é‡ï¼š{ï¼ˆ1ï¼Œ0ï¼‰ï¼Œï¼ˆ0ï¼Œ1ï¼‰}ã€‚</p></li></ul><p>ï¼ˆ1ï¼‰å½“è¾“å…¥å±æ€§åªæœ‰ä¸€ä¸ªçš„æ—¶å€™ï¼Œå°±æ˜¯æœ€ç®€å•çš„æƒ…å½¢ï¼Œä¹Ÿå°±æ˜¯æˆ‘ä»¬é«˜ä¸­æ—¶æœ€ç†Ÿæ‚‰çš„â€œæœ€å°äºŒä¹˜æ³•â€ï¼ˆEuclidean distanceï¼‰ï¼Œé¦–å…ˆè®¡ç®—å‡ºæ¯ä¸ªæ ·æœ¬é¢„æµ‹å€¼ä¸çœŸå®å€¼ä¹‹é—´çš„è¯¯å·®å¹¶æ±‚å’Œï¼Œé€šè¿‡æœ€å°åŒ–å‡æ–¹è¯¯å·®MSEï¼Œä½¿ç”¨æ±‚åå¯¼ç­‰äºé›¶çš„æ–¹æ³•è®¡ç®—å‡ºæ‹Ÿåˆç›´çº¿y=wx+bçš„ä¸¤ä¸ªå‚æ•°wå’Œbï¼Œè®¡ç®—è¿‡ç¨‹å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc722b0ccec4.png" alt="2.png"></p><p>ï¼ˆ2ï¼‰å½“è¾“å…¥å±æ€§æœ‰å¤šä¸ªçš„æ—¶å€™ï¼Œä¾‹å¦‚å¯¹äºä¸€ä¸ªæ ·æœ¬æœ‰dä¸ªå±æ€§{ï¼ˆx1,x2â€¦xdï¼‰,y}ï¼Œåˆ™y=wx+béœ€è¦å†™æˆï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc72567b8bcd.png" alt="0.png"></p><p>é€šå¸¸å¯¹äºå¤šå…ƒé—®é¢˜ï¼Œå¸¸å¸¸ä½¿ç”¨çŸ©é˜µçš„å½¢å¼æ¥è¡¨ç¤ºæ•°æ®ã€‚åœ¨æœ¬é—®é¢˜ä¸­ï¼Œå°†å…·æœ‰mä¸ªæ ·æœ¬çš„æ•°æ®é›†è¡¨ç¤ºæˆçŸ©é˜µXï¼Œå°†ç³»æ•°wä¸båˆå¹¶æˆä¸€ä¸ªåˆ—å‘é‡ï¼Œè¿™æ ·æ¯ä¸ªæ ·æœ¬çš„é¢„æµ‹å€¼ä»¥åŠæ‰€æœ‰æ ·æœ¬çš„å‡æ–¹è¯¯å·®æœ€å°åŒ–å°±å¯ä»¥å†™æˆä¸‹é¢çš„å½¢å¼ï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc722b0ad8f7.png" alt="3.png"></p><p><img src="https://i.loli.net/2018/10/17/5bc722b0af652.png" alt="4.png"></p><p><img src="https://i.loli.net/2018/10/17/5bc722b090543.png" alt="5.png"></p><p><img src="/blog_picture/line04.jpg" alt="avatar"></p><p><img src="/blog_picture/line05.jpg" alt="avatar"></p><p><img src="/blog_picture/line06.jpg" alt="avatar"></p><p><img src="/blog_picture/line07.jpg" alt="avatar"></p><h3 id="æœ€å°äºŒä¹˜æ³•"><a href="#æœ€å°äºŒä¹˜æ³•" class="headerlink" title="æœ€å°äºŒä¹˜æ³•"></a>æœ€å°äºŒä¹˜æ³•</h3><p>åŒæ ·åœ°ï¼Œæˆ‘ä»¬ä½¿ç”¨æœ€å°äºŒä¹˜æ³•å¯¹wå’Œbè¿›è¡Œä¼°è®¡ï¼Œä»¤å‡æ–¹è¯¯å·®çš„æ±‚å¯¼ç­‰äº0ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå½“ä¸€ä¸ªçŸ©é˜µçš„è¡Œåˆ—å¼ä¸ç­‰äº0æ—¶ï¼Œæˆ‘ä»¬æ‰å¯èƒ½å¯¹å…¶æ±‚é€†ï¼Œå› æ­¤å¯¹äºä¸‹å¼ï¼Œæˆ‘ä»¬éœ€è¦è€ƒè™‘çŸ©é˜µï¼ˆXçš„è½¬ç½®*Xï¼‰çš„è¡Œåˆ—å¼æ˜¯å¦ä¸º0ï¼Œè‹¥ä¸ä¸º0ï¼Œåˆ™å¯ä»¥æ±‚å‡ºå…¶è§£ï¼Œè‹¥ä¸º0ï¼Œåˆ™éœ€è¦ä½¿ç”¨å…¶å®ƒçš„æ–¹æ³•è¿›è¡Œè®¡ç®—ï¼Œä¹¦ä¸­æåˆ°äº†å¼•å…¥æ­£åˆ™åŒ–ï¼Œæ­¤å¤„ä¸è¿›è¡Œæ·±å…¥ã€‚</p><p><img src="https://i.loli.net/2018/10/17/5bc722b0cde33.png" alt="6.png"></p><p>ç„¶è€Œç°å®ä»»åŠ¡ä¸­å½“ç‰¹å¾æ•°é‡å¤§äºæ ·æœ¬æ•°æ—¶ï¼ŒXTXä¸æ»¡ç§©ï¼Œæ­¤æ—¶Î¸æœ‰å¤šä¸ªè§£ï¼›è€Œä¸”å½“æ•°æ®é‡å¤§æ—¶ï¼Œæ±‚çŸ©é˜µçš„é€†éå¸¸è€—æ—¶ï¼›å¯¹äºä¸å¯é€†çŸ©é˜µï¼ˆç‰¹å¾ä¹‹é—´ä¸ç›¸äº’ç‹¬ç«‹ï¼‰ï¼Œè¿™ç§æ­£è§„æ–¹ç¨‹æ–¹æ³•æ˜¯ä¸èƒ½ç”¨çš„ã€‚æ‰€ä»¥ï¼Œè¿˜å¯ä»¥é‡‡ç”¨æ¢¯åº¦ä¸‹é™æ³•ï¼Œåˆ©ç”¨è¿­ä»£çš„æ–¹å¼æ±‚è§£Î¸ã€‚</p><h3 id="æ¢¯åº¦ä¸‹é™æ³•"><a href="#æ¢¯åº¦ä¸‹é™æ³•" class="headerlink" title="æ¢¯åº¦ä¸‹é™æ³•"></a>æ¢¯åº¦ä¸‹é™æ³•</h3><p>æ¢¯åº¦ä¸‹é™æ³•æ˜¯æŒ‰ä¸‹é¢çš„æµç¨‹è¿›è¡Œçš„ï¼š<br>1ï¼‰é¦–å…ˆå¯¹Î¸èµ‹å€¼ï¼Œè¿™ä¸ªå€¼å¯ä»¥æ˜¯éšæœºçš„ï¼Œä¹Ÿå¯ä»¥è®©Î¸æ˜¯ä¸€ä¸ªå…¨é›¶çš„å‘é‡ã€‚<br>2ï¼‰æ”¹å˜Î¸çš„å€¼ï¼Œä½¿å¾—Î¸æŒ‰æ¢¯åº¦ä¸‹é™çš„æ–¹å‘è¿›è¡Œå‡å°‘ã€‚</p><p><img src="/blog_picture/line01.jpg" alt="avatar"></p><p>å¯¹äºåªæœ‰ä¸¤ç»´å±æ€§çš„æ ·æœ¬ï¼ŒJ(Î¸)å³J(Î¸0,Î¸1)çš„ç­‰é«˜çº¿å›¾</p><p><img src="/blog_picture/line02.jpg" alt="avatar"></p><p><img src="/blog_picture/line03.jpg" alt="avatar"></p><p>è¿­ä»£æ›´æ–°çš„æ–¹å¼æœ‰å¤šç§</p><ul><li>æ‰¹é‡æ¢¯åº¦ä¸‹é™ï¼ˆbatch gradient descentï¼‰ï¼Œä¹Ÿå°±æ˜¯æ˜¯æ¢¯åº¦ä¸‹é™æ³•æœ€åŸå§‹çš„å½¢å¼ï¼Œå¯¹å…¨éƒ¨çš„è®­ç»ƒæ•°æ®æ±‚å¾—è¯¯å·®åå†å¯¹Î¸<br>è¿›è¡Œæ›´æ–°ï¼Œä¼˜ç‚¹æ˜¯æ¯æ­¥éƒ½è¶‹å‘å…¨å±€æœ€ä¼˜è§£ï¼›ç¼ºç‚¹æ˜¯å¯¹äºå¤§é‡æ•°æ®ï¼Œç”±äºæ¯æ­¥è¦è®¡ç®—æ•´ä½“æ•°æ®ï¼Œè®­ç»ƒè¿‡ç¨‹æ…¢ï¼›</li><li>éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆstochastic gradient descentï¼‰ï¼Œæ¯ä¸€æ­¥éšæœºé€‰æ‹©ä¸€ä¸ªæ ·æœ¬å¯¹Î¸<br>è¿›è¡Œæ›´æ–°ï¼Œä¼˜ç‚¹æ˜¯è®­ç»ƒé€Ÿåº¦å¿«ï¼›ç¼ºç‚¹æ˜¯æ¯æ¬¡çš„å‰è¿›æ–¹å‘ä¸å¥½ç¡®å®šï¼Œå®¹æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ï¼›</li><li>å¾®å‹æ‰¹é‡æ¢¯åº¦ä¸‹é™ï¼ˆmini-batch gradient descentï¼‰ï¼Œæ¯æ­¥é€‰æ‹©ä¸€å°æ‰¹æ•°æ®è¿›è¡Œæ‰¹é‡æ¢¯åº¦ä¸‹é™æ›´æ–°Î¸<br>ï¼Œå±äºæ‰¹é‡æ¢¯åº¦ä¸‹é™å’Œéšæœºæ¢¯åº¦ä¸‹é™çš„ä¸€ç§æŠ˜ä¸­ï¼Œéå¸¸é€‚åˆå¹¶è¡Œå¤„ç†ã€‚</li></ul><p>å¦ä¸€æ–¹é¢ï¼Œæœ‰æ—¶åƒä¸Šé¢è¿™ç§åŸå§‹çš„çº¿æ€§å›å½’å¯èƒ½å¹¶ä¸èƒ½æ»¡è¶³éœ€æ±‚ï¼Œä¾‹å¦‚ï¼šyå€¼å¹¶ä¸æ˜¯çº¿æ€§å˜åŒ–ï¼Œè€Œæ˜¯åœ¨æŒ‡æ•°å°ºåº¦ä¸Šå˜åŒ–ã€‚è¿™æ—¶æˆ‘ä»¬å¯ä»¥é‡‡ç”¨çº¿æ€§æ¨¡å‹æ¥é€¼è¿‘yçš„è¡ç”Ÿç‰©ï¼Œä¾‹å¦‚lnyï¼Œè¿™æ—¶è¡ç”Ÿçš„çº¿æ€§æ¨¡å‹å¦‚ä¸‹æ‰€ç¤ºï¼Œå®é™…ä¸Šå°±æ˜¯ç›¸å½“äºå°†æŒ‡æ•°æ›²çº¿æŠ•å½±åœ¨ä¸€æ¡ç›´çº¿ä¸Šï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc722b103cbf.png" alt="7.png"></p><p>æ›´ä¸€èˆ¬åœ°ï¼Œè€ƒè™‘æ‰€æœ‰yçš„è¡ç”Ÿç‰©çš„æƒ…å½¢ï¼Œå°±å¾—åˆ°äº†â€œå¹¿ä¹‰çš„çº¿æ€§æ¨¡å‹â€ï¼ˆgeneralized linear modelï¼‰ï¼Œå…¶ä¸­ï¼Œgï¼ˆ*ï¼‰ç§°ä¸ºè”ç³»å‡½æ•°ï¼ˆlink functionï¼‰ã€‚</p><p><img src="https://i.loli.net/2018/10/17/5bc722b0a2841.png" alt="8.png"></p><h3 id="å¯¹æ•°å‡ ç‡å›å½’"><a href="#å¯¹æ•°å‡ ç‡å›å½’" class="headerlink" title="å¯¹æ•°å‡ ç‡å›å½’"></a>å¯¹æ•°å‡ ç‡å›å½’</h3><p>å›å½’å°±æ˜¯é€šè¿‡è¾“å…¥çš„å±æ€§å€¼å¾—åˆ°ä¸€ä¸ªé¢„æµ‹å€¼ï¼Œåˆ©ç”¨ä¸Šè¿°å¹¿ä¹‰çº¿æ€§æ¨¡å‹çš„ç‰¹å¾ï¼Œæ˜¯å¦å¯ä»¥é€šè¿‡ä¸€ä¸ªè”ç³»å‡½æ•°ï¼Œå°†é¢„æµ‹å€¼è½¬åŒ–ä¸ºç¦»æ•£å€¼ä»è€Œè¿›è¡Œåˆ†ç±»å‘¢ï¼Ÿçº¿æ€§å‡ ç‡å›å½’æ­£æ˜¯ç ”ç©¶è¿™æ ·çš„é—®é¢˜ã€‚å¯¹æ•°å‡ ç‡å¼•å…¥äº†ä¸€ä¸ªå¯¹æ•°å‡ ç‡å‡½æ•°ï¼ˆlogistic functionï¼‰,å°†é¢„æµ‹å€¼æŠ•å½±åˆ°0-1ä¹‹é—´ï¼Œä»è€Œå°†çº¿æ€§å›å½’é—®é¢˜è½¬åŒ–ä¸ºäºŒåˆ†ç±»é—®é¢˜ã€‚</p><p><img src="https://i.loli.net/2018/10/17/5bc722b0c7748.png" alt="9.png"></p><p><img src="https://i.loli.net/2018/10/17/5bc722b0a655d.png" alt="10.png"></p><p>è‹¥å°†yçœ‹åšæ ·æœ¬ä¸ºæ­£ä¾‹çš„æ¦‚ç‡ï¼Œï¼ˆ1-yï¼‰çœ‹åšæ ·æœ¬ä¸ºåä¾‹çš„æ¦‚ç‡ï¼Œåˆ™ä¸Šå¼å®é™…ä¸Šä½¿ç”¨çº¿æ€§å›å½’æ¨¡å‹çš„é¢„æµ‹ç»“æœå™¨é€¼è¿‘çœŸå®æ ‡è®°çš„å¯¹æ•°å‡ ç‡ã€‚å› æ­¤è¿™ä¸ªæ¨¡å‹ç§°ä¸ºâ€œå¯¹æ•°å‡ ç‡å›å½’â€ï¼ˆlogistic regressionï¼‰ï¼Œä¹Ÿæœ‰ä¸€äº›ä¹¦ç±ç§°ä¹‹ä¸ºâ€œé€»è¾‘å›å½’â€ã€‚ä¸‹é¢ä½¿ç”¨æœ€å¤§ä¼¼ç„¶ä¼°è®¡çš„æ–¹æ³•æ¥è®¡ç®—å‡ºwå’Œbä¸¤ä¸ªå‚æ•°çš„å–å€¼ï¼Œä¸‹é¢åªåˆ—å‡ºæ±‚è§£çš„æ€è·¯ï¼Œä¸åˆ—å‡ºå…·ä½“çš„è®¡ç®—è¿‡ç¨‹ã€‚</p><p><img src="https://i.loli.net/2018/10/17/5bc723b824f0c.png" alt="11.png"></p><p><img src="https://i.loli.net/2018/10/17/5bc723b817961.png" alt="12.png"></p><h3 id="çº¿æ€§åˆ¤åˆ«åˆ†æ"><a href="#çº¿æ€§åˆ¤åˆ«åˆ†æ" class="headerlink" title="çº¿æ€§åˆ¤åˆ«åˆ†æ"></a>çº¿æ€§åˆ¤åˆ«åˆ†æ</h3><p>çº¿æ€§åˆ¤åˆ«åˆ†æï¼ˆLinear Discriminant Analysisï¼Œç®€ç§°LDAï¼‰,å…¶åŸºæœ¬æ€æƒ³æ˜¯ï¼šå°†è®­ç»ƒæ ·æœ¬æŠ•å½±åˆ°ä¸€æ¡ç›´çº¿ä¸Šï¼Œä½¿å¾—åŒç±»çš„æ ·ä¾‹å°½å¯èƒ½è¿‘ï¼Œä¸åŒç±»çš„æ ·ä¾‹å°½å¯èƒ½è¿œã€‚å¦‚å›¾æ‰€ç¤ºï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc723b863ebb.png" alt="13.png"><img src="https://i.loli.net/2018/10/17/5bc723b85bfa9.png" alt="14.png"></p><p>æƒ³è®©åŒç±»æ ·æœ¬ç‚¹çš„æŠ•å½±ç‚¹å°½å¯èƒ½æ¥è¿‘ï¼Œä¸åŒç±»æ ·æœ¬ç‚¹æŠ•å½±ä¹‹é—´å°½å¯èƒ½è¿œï¼Œå³ï¼šè®©å„ç±»çš„åæ–¹å·®ä¹‹å’Œå°½å¯èƒ½å°ï¼Œä¸ç”¨ç±»ä¹‹é—´ä¸­å¿ƒçš„è·ç¦»å°½å¯èƒ½å¤§ã€‚åŸºäºè¿™æ ·çš„è€ƒè™‘ï¼ŒLDAå®šä¹‰äº†ä¸¤ä¸ªæ•£åº¦çŸ©é˜µã€‚</p><ul><li>ç±»å†…æ•£åº¦çŸ©é˜µï¼ˆwithin-class scatter matrixï¼‰</li></ul><p><img src="https://i.loli.net/2018/10/17/5bc723b8156e1.png" alt="15.png"></p><ul><li>ç±»é—´æ•£åº¦çŸ©é˜µ(between-class scaltter matrix)</li></ul><p><img src="https://i.loli.net/2018/10/17/5bc723b7e9db3.png" alt="16.png"></p><p>å› æ­¤å¾—åˆ°äº†LDAçš„æœ€å¤§åŒ–ç›®æ ‡ï¼šâ€œå¹¿ä¹‰ç‘åˆ©å•†â€ï¼ˆgeneralized Rayleigh quotientï¼‰ã€‚</p><p><img src="https://i.loli.net/2018/10/17/5bc723b7e8a61.png" alt="17.png"></p><p>ä»è€Œåˆ†ç±»é—®é¢˜è½¬åŒ–ä¸ºæœ€ä¼˜åŒ–æ±‚è§£wçš„é—®é¢˜ï¼Œå½“æ±‚è§£å‡ºwåï¼Œå¯¹æ–°çš„æ ·æœ¬è¿›è¡Œåˆ†ç±»æ—¶ï¼Œåªéœ€å°†è¯¥æ ·æœ¬ç‚¹æŠ•å½±åˆ°è¿™æ¡ç›´çº¿ä¸Šï¼Œæ ¹æ®ä¸å„ä¸ªç±»åˆ«çš„ä¸­å¿ƒå€¼è¿›è¡Œæ¯”è¾ƒï¼Œä»è€Œåˆ¤å®šå‡ºæ–°æ ·æœ¬ä¸å“ªä¸ªç±»åˆ«è·ç¦»æœ€è¿‘ã€‚æ±‚è§£wçš„æ–¹æ³•å¦‚ä¸‹æ‰€ç¤ºï¼Œä½¿ç”¨çš„æ–¹æ³•ä¸ºÎ»ä¹˜å­ã€‚</p><p><img src="https://i.loli.net/2018/10/17/5bc723b83d5e0.png" alt="18.png"></p><p>è‹¥å°†wçœ‹åšä¸€ä¸ªæŠ•å½±çŸ©é˜µï¼Œç±»ä¼¼PCAçš„æ€æƒ³ï¼Œåˆ™LDAå¯å°†æ ·æœ¬æŠ•å½±åˆ°N-1ç»´ç©ºé—´ï¼ˆNä¸ºç±»ç°‡æ•°ï¼‰ï¼ŒæŠ•å½±çš„è¿‡ç¨‹ä½¿ç”¨äº†ç±»åˆ«ä¿¡æ¯ï¼ˆæ ‡è®°ä¿¡æ¯ï¼‰ï¼Œå› æ­¤LDAä¹Ÿå¸¸è¢«è§†ä¸ºä¸€ç§ç»å…¸çš„ç›‘ç£é™ç»´æŠ€æœ¯ã€‚    </p><h3 id="å›å½’ä¸æ¬ -è¿‡æ‹Ÿåˆ"><a href="#å›å½’ä¸æ¬ -è¿‡æ‹Ÿåˆ" class="headerlink" title="å›å½’ä¸æ¬ /è¿‡æ‹Ÿåˆ"></a>å›å½’ä¸æ¬ /è¿‡æ‹Ÿåˆ</h3><p><img src="/blog_picture/line08.jpg" alt="avatar">    </p><h3 id="çº¿æ€§å›å½’ä¸æ­£åˆ™åŒ–"><a href="#çº¿æ€§å›å½’ä¸æ­£åˆ™åŒ–" class="headerlink" title="çº¿æ€§å›å½’ä¸æ­£åˆ™åŒ–"></a>çº¿æ€§å›å½’ä¸æ­£åˆ™åŒ–</h3><p><img src="/blog_picture/line09.jpg" alt="avatar">     </p><h3 id="å¤šåˆ†ç±»å­¦ä¹ "><a href="#å¤šåˆ†ç±»å­¦ä¹ " class="headerlink" title="å¤šåˆ†ç±»å­¦ä¹ "></a>å¤šåˆ†ç±»å­¦ä¹ </h3><p>ç°å®ä¸­æˆ‘ä»¬ç»å¸¸é‡åˆ°ä¸åªä¸¤ä¸ªç±»åˆ«çš„åˆ†ç±»é—®é¢˜ï¼Œå³å¤šåˆ†ç±»é—®é¢˜ï¼Œåœ¨è¿™ç§æƒ…å½¢ä¸‹ï¼Œæˆ‘ä»¬å¸¸å¸¸è¿ç”¨â€œæ‹†åˆ†â€çš„ç­–ç•¥ï¼Œé€šè¿‡å¤šä¸ªäºŒåˆ†ç±»å­¦ä¹ å™¨æ¥è§£å†³å¤šåˆ†ç±»é—®é¢˜ï¼Œå³å°†å¤šåˆ†ç±»é—®é¢˜æ‹†è§£ä¸ºå¤šä¸ªäºŒåˆ†ç±»é—®é¢˜ï¼Œè®­ç»ƒå‡ºå¤šä¸ªäºŒåˆ†ç±»å­¦ä¹ å™¨ï¼Œæœ€åå°†å¤šä¸ªåˆ†ç±»ç»“æœè¿›è¡Œé›†æˆå¾—å‡ºç»“è®ºã€‚æœ€ä¸ºç»å…¸çš„æ‹†åˆ†ç­–ç•¥æœ‰ä¸‰ç§ï¼šâ€œä¸€å¯¹ä¸€â€ï¼ˆOvOï¼‰ã€â€œä¸€å¯¹å…¶ä½™â€ï¼ˆOvRï¼‰å’Œâ€œå¤šå¯¹å¤šâ€ï¼ˆMvMï¼‰ï¼Œæ ¸å¿ƒæ€æƒ³ä¸ç¤ºæ„å›¾å¦‚ä¸‹æ‰€ç¤ºã€‚</p><ul><li><p>OvOï¼šç»™å®šæ•°æ®é›†Dï¼Œå‡å®šå…¶ä¸­æœ‰Nä¸ªçœŸå®ç±»åˆ«ï¼Œå°†è¿™Nä¸ªç±»åˆ«è¿›è¡Œä¸¤ä¸¤é…å¯¹ï¼ˆä¸€ä¸ªæ­£ç±»/ä¸€ä¸ªåç±»ï¼‰ï¼Œä»è€Œäº§ç”ŸNï¼ˆN-1ï¼‰/2ä¸ªäºŒåˆ†ç±»å­¦ä¹ å™¨ï¼Œåœ¨æµ‹è¯•é˜¶æ®µï¼Œå°†æ–°æ ·æœ¬æ”¾å…¥æ‰€æœ‰çš„äºŒåˆ†ç±»å­¦ä¹ å™¨ä¸­æµ‹è¯•ï¼Œå¾—å‡ºNï¼ˆN-1ï¼‰ä¸ªç»“æœï¼Œæœ€ç»ˆé€šè¿‡æŠ•ç¥¨äº§ç”Ÿæœ€ç»ˆçš„åˆ†ç±»ç»“æœã€‚</p></li><li><p>OvMï¼šç»™å®šæ•°æ®é›†Dï¼Œå‡å®šå…¶ä¸­æœ‰Nä¸ªçœŸå®ç±»åˆ«ï¼Œæ¯æ¬¡å–å‡ºä¸€ä¸ªç±»ä½œä¸ºæ­£ç±»ï¼Œå‰©ä½™çš„æ‰€æœ‰ç±»åˆ«ä½œä¸ºä¸€ä¸ªæ–°çš„åç±»ï¼Œä»è€Œäº§ç”ŸNä¸ªäºŒåˆ†ç±»å­¦ä¹ å™¨ï¼Œåœ¨æµ‹è¯•é˜¶æ®µï¼Œå¾—å‡ºNä¸ªç»“æœï¼Œè‹¥ä»…æœ‰ä¸€ä¸ªå­¦ä¹ å™¨é¢„æµ‹ä¸ºæ­£ç±»ï¼Œåˆ™å¯¹åº”çš„ç±»æ ‡ä½œä¸ºæœ€ç»ˆåˆ†ç±»ç»“æœã€‚</p></li><li><p>MvMï¼šç»™å®šæ•°æ®é›†Dï¼Œå‡å®šå…¶ä¸­æœ‰Nä¸ªçœŸå®ç±»åˆ«ï¼Œæ¯æ¬¡å–è‹¥å¹²ä¸ªç±»ä½œä¸ºæ­£ç±»ï¼Œè‹¥å¹²ä¸ªç±»ä½œä¸ºåç±»ï¼ˆé€šè¿‡ECOCç ç»™å‡ºï¼Œç¼–ç ï¼‰ï¼Œè‹¥è¿›è¡Œäº†Mæ¬¡åˆ’åˆ†ï¼Œåˆ™ç”Ÿæˆäº†Mä¸ªäºŒåˆ†ç±»å­¦ä¹ å™¨ï¼Œåœ¨æµ‹è¯•é˜¶æ®µï¼ˆè§£ç ï¼‰ï¼Œå¾—å‡ºMä¸ªç»“æœç»„æˆä¸€ä¸ªæ–°çš„ç ï¼Œæœ€ç»ˆé€šè¿‡è®¡ç®—æµ·æ˜/æ¬§å¼è·ç¦»é€‰æ‹©è·ç¦»æœ€å°çš„ç±»åˆ«ä½œä¸ºæœ€ç»ˆåˆ†ç±»ç»“æœã€‚</p></li></ul><p><img src="https://i.loli.net/2018/10/17/5bc723b862bfb.png" alt="19.png"></p><p><img src="https://i.loli.net/2018/10/17/5bc723b8300d5.png" alt="20.png"></p><h3 id="ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜"><a href="#ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜" class="headerlink" title="ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜"></a>ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜</h3><p>ç±»åˆ«ä¸å¹³è¡¡ï¼ˆclass-imbanlanceï¼‰å°±æ˜¯æŒ‡åˆ†ç±»é—®é¢˜ä¸­ä¸åŒç±»åˆ«çš„è®­ç»ƒæ ·æœ¬ç›¸å·®æ‚¬æ®Šçš„æƒ…å†µï¼Œä¾‹å¦‚æ­£ä¾‹æœ‰900ä¸ªï¼Œè€Œåä¾‹åªæœ‰100ä¸ªï¼Œè¿™ä¸ªæ—¶å€™æˆ‘ä»¬å°±éœ€è¦è¿›è¡Œç›¸åº”çš„å¤„ç†æ¥å¹³è¡¡è¿™ä¸ªé—®é¢˜ã€‚å¸¸è§çš„åšæ³•æœ‰ä¸‰ç§ï¼š</p><ol><li>åœ¨è®­ç»ƒæ ·æœ¬è¾ƒå¤šçš„ç±»åˆ«ä¸­è¿›è¡Œâ€œæ¬ é‡‡æ ·â€ï¼ˆundersamplingï¼‰,æ¯”å¦‚ä»æ­£ä¾‹ä¸­é‡‡å‡º100ä¸ªï¼Œå¸¸è§çš„ç®—æ³•æœ‰ï¼šEasyEnsembleã€‚</li><li>åœ¨è®­ç»ƒæ ·æœ¬è¾ƒå°‘çš„ç±»åˆ«ä¸­è¿›è¡Œâ€œè¿‡é‡‡æ ·â€ï¼ˆoversamplingï¼‰,ä¾‹å¦‚é€šè¿‡å¯¹åä¾‹ä¸­çš„æ•°æ®è¿›è¡Œæ’å€¼ï¼Œæ¥äº§ç”Ÿé¢å¤–çš„åä¾‹ï¼Œå¸¸è§çš„ç®—æ³•æœ‰SMOTEã€‚</li><li>ç›´æ¥åŸºäºåŸæ•°æ®é›†è¿›è¡Œå­¦ä¹ ï¼Œå¯¹é¢„æµ‹å€¼è¿›è¡Œâ€œå†ç¼©æ”¾â€å¤„ç†ã€‚å…¶ä¸­å†ç¼©æ”¾ä¹Ÿæ˜¯ä»£ä»·æ•æ„Ÿå­¦ä¹ çš„åŸºç¡€ã€‚<img src="https://i.loli.net/2018/10/17/5bc726fe87ae2.png" alt="21.png"></li></ol><h3 id="LRåº”ç”¨ç»éªŒ"><a href="#LRåº”ç”¨ç»éªŒ" class="headerlink" title="LRåº”ç”¨ç»éªŒ"></a>LRåº”ç”¨ç»éªŒ</h3><p>LRå®ç°ç®€å•é«˜æ•ˆæ˜“è§£é‡Šï¼Œè®¡ç®—é€Ÿåº¦å¿«ï¼Œæ˜“å¹¶è¡Œï¼Œåœ¨å¤§è§„æ¨¡æ•°æ®æƒ…å†µä¸‹éå¸¸é€‚ç”¨ï¼Œæ›´é€‚åˆäºåº”å¯¹æ•°å€¼å‹å’Œæ ‡ç§°å‹æ•°æ®ï¼Œä¸»è¦é€‚åˆè§£å†³çº¿æ€§å¯åˆ†çš„é—®é¢˜ï¼Œä½†å®¹æ˜“æ¬ æ‹Ÿåˆï¼Œå¤§å¤šæ•°æƒ…å†µä¸‹éœ€è¦æ‰‹åŠ¨è¿›è¡Œç‰¹å¾å·¥ç¨‹ï¼Œæ„å»ºç»„åˆç‰¹å¾ï¼Œåˆ†ç±»ç²¾åº¦ä¸é«˜ã€‚</p><p>LRç›´æ¥å¯¹åˆ†ç±»å¯èƒ½æ€§è¿›è¡Œå»ºæ¨¡ï¼Œæ— éœ€äº‹å…ˆå‡è®¾æ•°æ®åˆ†å¸ƒï¼Œè¿™æ ·å°±é¿å…äº†å‡è®¾åˆ†å¸ƒä¸å‡†ç¡®æ‰€å¸¦æ¥çš„é—®é¢˜<br>LRèƒ½ä»¥æ¦‚ç‡çš„å½¢å¼è¾“å‡ºï¼Œè€ŒéçŸ¥è¯†0ï¼Œ1åˆ¤å®šï¼Œå¯¹è®¸å¤šåˆ©ç”¨æ¦‚ç‡è¾…åŠ©å†³ç­–çš„ä»»åŠ¡å¾ˆæœ‰ç”¨<br>å¯¹ç‡å‡½æ•°ä»»æ„é˜¶å¯å¯¼ï¼Œå…·æœ‰å¾ˆå¥½çš„æ•°å­¦æ€§è´¨ï¼Œè®¸å¤šç°æœ‰çš„æ•°å€¼ä¼˜åŒ–ç®—æ³•éƒ½å¯ä»¥ç”¨æ¥æ±‚æœ€ä¼˜è§£ï¼Œè®­ç»ƒé€Ÿåº¦å¿«<br>é€‚ç”¨æƒ…æ™¯ï¼šLRæ˜¯å¾ˆå¤šåˆ†ç±»ç®—æ³•çš„åŸºç¡€ç»„ä»¶ï¼Œå®ƒçš„å¥½å¤„æ˜¯è¾“å‡ºå€¼è‡ªç„¶åœ°è½åœ¨0åˆ°1ä¹‹é—´ï¼Œå¹¶ä¸”æœ‰æ¦‚ç‡æ„ä¹‰ã€‚å› ä¸ºå®ƒæœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªçº¿æ€§çš„åˆ†ç±»å™¨ï¼Œæ‰€ä»¥å¤„ç†ä¸å¥½ç‰¹å¾ä¹‹é—´ç›¸å…³çš„æƒ…å†µã€‚è™½ç„¶æ•ˆæœä¸€èˆ¬ï¼Œå´èƒœåœ¨æ¨¡å‹æ¸…æ™°ï¼ŒèƒŒåçš„æ¦‚ç‡å­¦ç»å¾—ä½æ¨æ•²ã€‚å®ƒæ‹Ÿåˆå‡ºæ¥çš„å‚æ•°å°±ä»£è¡¨äº†æ¯ä¸€ä¸ªç‰¹å¾(feature)å¯¹ç»“æœçš„å½±å“ã€‚ä¹Ÿæ˜¯ä¸€ä¸ªç†è§£æ•°æ®çš„å¥½å·¥å…·ã€‚</p><p>åº”ç”¨ä¸Šï¼š </p><ul><li>CTRé¢„ä¼°ï¼Œæ¨èç³»ç»Ÿçš„learning to rankï¼Œå„ç§åˆ†ç±»åœºæ™¯ </li><li>æŸæœç´¢å¼•æ“å‚çš„å¹¿å‘ŠCTRé¢„ä¼°åŸºçº¿ç‰ˆæ˜¯LR </li><li>æŸç”µå•†æœç´¢æ’åºåŸºçº¿ç‰ˆæ˜¯LR </li><li>æŸæ–°é—»appæ’åºåŸºçº¿ç‰ˆæ˜¯LR</li></ul><p>å¤§è§„æ¨¡å·¥ä¸šå®æ—¶æ•°æ®ï¼Œéœ€è¦å¯è§£é‡Šæ€§çš„é‡‘èæ•°æ®ï¼Œéœ€è¦å¿«é€Ÿéƒ¨ç½²ä½è€—æ—¶æ•°æ®<br>LRå°±æ˜¯ç®€å•ï¼Œå¯è§£é‡Šï¼Œé€Ÿåº¦å¿«ï¼Œæ¶ˆè€—èµ„æºå°‘ï¼Œåˆ†å¸ƒå¼æ€§èƒ½å¥½</p><p>ADMM-LR:ç”¨ADMMæ±‚è§£LogisticRegressionçš„ä¼˜åŒ–æ–¹æ³•ç§°ä½œADMM_LRã€‚ADMMç®—æ³•æ˜¯ä¸€ç§æ±‚è§£çº¦æŸé—®é¢˜çš„æœ€ä¼˜åŒ–æ–¹æ³•ï¼Œå®ƒé€‚ç”¨å¹¿æ³›ã€‚ç›¸æ¯”äºSGDï¼ŒADMMåœ¨ç²¾åº¦è¦æ±‚ä¸é«˜çš„æƒ…å†µä¸‹ï¼Œåœ¨å°‘æ•°è¿­ä»£è½®æ•°æ—¶å°±è¾¾åˆ°ä¸€ä¸ªåˆç†çš„ç²¾åº¦ï¼Œä½†æ˜¯æ”¶æ•›åˆ°å¾ˆç²¾ç¡®çš„è§£åˆ™éœ€è¦å¾ˆå¤šæ¬¡è¿­ä»£ã€‚</p><p><img src="/blog_picture/line10.jpg" alt="avatar">   </p><p><img src="/blog_picture/line11.jpg" alt="avatar">   </p><p><img src="/blog_picture/line12.jpg" alt="avatar">   </p><h2 id="LRå¤šåˆ†ç±»æ¨å¹¿-Softmaxå›å½’"><a href="#LRå¤šåˆ†ç±»æ¨å¹¿-Softmaxå›å½’" class="headerlink" title="LRå¤šåˆ†ç±»æ¨å¹¿ - Softmaxå›å½’"></a>LRå¤šåˆ†ç±»æ¨å¹¿ - Softmaxå›å½’</h2><p>LRæ˜¯ä¸€ä¸ªä¼ ç»Ÿçš„äºŒåˆ†ç±»æ¨¡å‹ï¼Œå®ƒä¹Ÿå¯ä»¥ç”¨äºå¤šåˆ†ç±»ä»»åŠ¡ï¼Œå…¶åŸºæœ¬æ€æƒ³æ˜¯ï¼šå°†å¤šåˆ†ç±»ä»»åŠ¡æ‹†åˆ†æˆè‹¥å¹²ä¸ªäºŒåˆ†ç±»ä»»åŠ¡ï¼Œç„¶åå¯¹æ¯ä¸ªäºŒåˆ†ç±»ä»»åŠ¡è®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œæœ€åå°†å¤šä¸ªæ¨¡å‹çš„ç»“æœè¿›è¡Œé›†æˆä»¥è·å¾—æœ€ç»ˆçš„åˆ†ç±»ç»“æœã€‚ä¸€èˆ¬æ¥è¯´ï¼Œå¯ä»¥é‡‡å–çš„æ‹†åˆ†ç­–ç•¥æœ‰ï¼š</p><h3 id="one-vs-oneç­–ç•¥"><a href="#one-vs-oneç­–ç•¥" class="headerlink" title="one vs oneç­–ç•¥"></a>one vs oneç­–ç•¥</h3><p>ã€€ã€€å‡è®¾æˆ‘ä»¬æœ‰Nä¸ªç±»åˆ«ï¼Œè¯¥ç­–ç•¥åŸºæœ¬æ€æƒ³å°±æ˜¯ä¸åŒç±»åˆ«ä¸¤ä¸¤ä¹‹é—´è®­ç»ƒä¸€ä¸ªåˆ†ç±»å™¨ï¼Œè¿™æ—¶æˆ‘ä»¬ä¸€å…±ä¼šè®­ç»ƒå‡º<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171104175530607-1392543504.png" alt="img">ç§ä¸åŒçš„åˆ†ç±»å™¨ã€‚åœ¨é¢„æµ‹æ—¶ï¼Œæˆ‘ä»¬å°†æ ·æœ¬æäº¤ç»™æ‰€æœ‰çš„åˆ†ç±»å™¨ï¼Œä¸€å…±ä¼šè·å¾—N(N-1)ä¸ªç»“æœï¼Œæœ€ç»ˆç»“æœé€šè¿‡<strong>æŠ•ç¥¨</strong>äº§ç”Ÿã€‚</p><h3 id="one-vs-allç­–ç•¥"><a href="#one-vs-allç­–ç•¥" class="headerlink" title="one vs allç­–ç•¥"></a>one vs allç­–ç•¥</h3><p>ã€€ã€€è¯¥ç­–ç•¥åŸºæœ¬æ€æƒ³å°±æ˜¯å°†ç¬¬iç§ç±»å‹çš„æ‰€æœ‰æ ·æœ¬ä½œä¸ºæ­£ä¾‹ï¼Œå°†å‰©ä¸‹çš„æ‰€æœ‰æ ·æœ¬ä½œä¸ºè´Ÿä¾‹ï¼Œè¿›è¡Œè®­ç»ƒå¾—åˆ°ä¸€ä¸ªåˆ†ç±»å™¨ã€‚è¿™æ ·æˆ‘ä»¬å°±ä¸€å…±å¯ä»¥å¾—åˆ°Nä¸ªåˆ†ç±»å™¨ã€‚åœ¨é¢„æµ‹æ—¶ï¼Œæˆ‘ä»¬å°†æ ·æœ¬æäº¤ç»™æ‰€æœ‰çš„åˆ†ç±»å™¨ï¼Œä¸€å…±ä¼šè·å¾—Nä¸ªç»“æœï¼Œæˆ‘ä»¬<strong>é€‰æ‹©å…¶ä¸­æ¦‚ç‡å€¼æœ€å¤§</strong>çš„é‚£ä¸ªä½œä¸ºæœ€ç»ˆåˆ†ç±»ç»“æœã€‚ <img src="https://images2017.cnblogs.com/blog/1251096/201710/1251096-20171021171313943-1199609768.png" alt="img"></p><h2 id="softmaxå›å½’"><a href="#softmaxå›å½’" class="headerlink" title="softmaxå›å½’"></a>softmaxå›å½’</h2><p>ã€€ã€€softmaxæ˜¯LRåœ¨å¤šåˆ†ç±»çš„æ¨å¹¿ã€‚ä¸LRä¸€æ ·ï¼ŒåŒå±äºå¹¿ä¹‰çº¿æ€§æ¨¡å‹ã€‚ä»€ä¹ˆæ˜¯Softmaxå‡½æ•°ï¼Ÿå‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªæ•°ç»„Aï¼Œ<img src="https://images2017.cnblogs.com/blog/1251096/201710/1251096-20171021164616881-992414484.png" alt="img">è¡¨ç¤ºçš„æ˜¯æ•°ç»„Aä¸­çš„ç¬¬iä¸ªå…ƒç´ ï¼Œé‚£ä¹ˆè¿™ä¸ªå…ƒç´ çš„Softmaxå€¼å°±æ˜¯</p><p>ã€€ã€€ã€€ã€€ã€€ã€€ã€€ã€€ã€€ã€€ã€€ã€€<img src="https://images2017.cnblogs.com/blog/1251096/201710/1251096-20171021165228865-866731732.png" alt="img"></p><p>ä¹Ÿå°±æ˜¯è¯´ï¼Œæ˜¯è¯¥å…ƒç´ çš„æŒ‡æ•°ï¼Œä¸æ‰€æœ‰å…ƒç´ æŒ‡æ•°å’Œçš„æ¯”å€¼ã€‚é‚£ä¹ˆ softmaxå›å½’æ¨¡å‹çš„å‡è®¾å‡½æ•°åˆæ˜¯æ€ä¹ˆæ ·çš„å‘¢ï¼Ÿ</p><p>ã€€ã€€ã€€ã€€ã€€ã€€ã€€ã€€ã€€ã€€<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171105100956795-1587348606.png" alt="img"></p><p>ç”±ä¸Šå¼å¾ˆæ˜æ˜¾å¯ä»¥å¾—å‡ºï¼Œå‡è®¾å‡½æ•°çš„åˆ†æ¯å…¶å®å°±æ˜¯å¯¹æ¦‚ç‡åˆ†å¸ƒè¿›è¡Œäº†å½’ä¸€åŒ–ï¼Œä½¿å¾—æ‰€æœ‰ç±»åˆ«çš„æ¦‚ç‡ä¹‹å’Œä¸º1ï¼›ä¹Ÿå¯ä»¥çœ‹å‡ºLRå…¶å®å°±æ˜¯K=2æ—¶çš„Softmaxã€‚åœ¨å‚æ•°è·å¾—ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥é‡‡ç”¨one vs allç­–ç•¥è·å¾—Kä¸ªä¸åŒçš„è®­ç»ƒæ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œè¿›è€Œé’ˆå¯¹æ¯ä¸€ç±»åˆ«éƒ½ä¼šå¾—åˆ°ä¸€ç»„å‚æ•°å‘é‡<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171105102153701-629755133.png" alt="img">ã€‚å½“æµ‹è¯•æ ·æœ¬ç‰¹å¾å‘é‡<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171105102416560-1451219507.png" alt="img">è¾“å…¥æ—¶ï¼Œæˆ‘ä»¬å…ˆç”¨å‡è®¾å‡½æ•°é’ˆå¯¹æ¯ä¸€ä¸ªç±»åˆ«<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171105102622045-1005416234.png" alt="img">ä¼°ç®—å‡ºæ¦‚ç‡å€¼<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171105102706623-369597312.png" alt="img">ã€‚å› æ­¤æˆ‘ä»¬çš„å‡è®¾å‡½æ•°å°†è¦è¾“å‡ºä¸€ä¸ªKç»´çš„å‘é‡ï¼ˆå‘é‡å…ƒç´ å’Œä¸º1ï¼‰æ¥è¡¨ç¤ºKä¸ªç±»åˆ«çš„ä¼°è®¡æ¦‚ç‡ï¼Œæˆ‘ä»¬é€‰æ‹©å…¶ä¸­å¾—åˆ†æœ€å¤§çš„ç±»åˆ«ä½œä¸ºè¯¥è¾“å…¥çš„é¢„æµ‹ç±»åˆ«ã€‚Softmaxçœ‹èµ·æ¥å’Œone vs all çš„LRå¾ˆåƒï¼Œå®ƒä»¬æœ€å¤§çš„ä¸åŒåœ¨ä¸Softmaxå¾—åˆ°çš„Kä¸ªç±»åˆ«çš„å¾—åˆ†å’Œä¸º1ï¼Œè€Œone vs allçš„LRå¹¶ä¸æ˜¯ã€‚</p><h3 id="softmaxçš„ä»£ä»·å‡½æ•°"><a href="#softmaxçš„ä»£ä»·å‡½æ•°" class="headerlink" title="softmaxçš„ä»£ä»·å‡½æ•°"></a>softmaxçš„ä»£ä»·å‡½æ•°</h3><p>ã€€ã€€ç±»ä¼¼äºLRï¼Œå…¶ä¼¼ç„¶å‡½æ•°æˆ‘ä»¬é‡‡ç”¨å¯¹æ•°ä¼¼ç„¶ï¼Œæ•…ï¼š</p><p>ã€€ã€€ã€€ã€€<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171105113747779-692061991.png" alt="img"></p><p>åŠ å…¥<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171104162333248-539020480.png" alt="img">æ­£åˆ™é¡¹çš„æŸå¤±å‡½æ•°ä¸ºï¼š</p><p>ã€€ã€€ã€€ã€€<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171105114132232-517057992.png" alt="img"></p><p>æ­¤å¤„çš„<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171105110553560-1026190635.png" alt="img">ä¸ºç¬¦å·å‡½æ•°ã€‚å¯¹äºå…¶å‚æ•°çš„æ±‚è§£è¿‡ç¨‹ï¼Œæˆ‘ä»¬ä¾ç„¶é‡‡ç”¨æ¢¯åº¦ä¸‹é™æ³•ã€‚</p><h3 id="softmaxçš„æ¢¯åº¦çš„æ±‚è§£"><a href="#softmaxçš„æ¢¯åº¦çš„æ±‚è§£" class="headerlink" title="softmaxçš„æ¢¯åº¦çš„æ±‚è§£"></a>softmaxçš„æ¢¯åº¦çš„æ±‚è§£</h3><p>ã€€ã€€æ­£åˆ™åŒ–é¡¹çš„æ±‚å¯¼å¾ˆç®€å•ï¼Œå°±ç­‰äº<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171105120226607-495282914.png" alt="img">ï¼Œä¸‹é¢æˆ‘ä»¬ä¸»è¦è®¨è®ºæ²¡æœ‰åŠ æ­£åˆ™é¡¹çš„æŸå¤±å‡½æ•°çš„æ¢¯åº¦æ±‚è§£ï¼Œå³</p><p>ã€€ã€€ã€€ã€€ã€€ã€€<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171105113747779-692061991.png" alt="img"></p><p>çš„å¯¼æ•°ï¼ˆæ¢¯åº¦ï¼‰ã€‚ä¸ºäº†ä½¿å¾—æ±‚è§£è¿‡ç¨‹çœ‹èµ·æ¥ç®€ä¾¿ã€æ˜“äºç†è§£ï¼Œæˆ‘ä»¬ä»…ä»…åªå¯¹äºä¸€ä¸ªæ ·æœ¬ï¼ˆx,yï¼‰æƒ…å†µï¼ˆSGDï¼‰è¿›è¡Œè®¨è®ºï¼Œ</p><p>ã€€ã€€ã€€ã€€<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171105161912482-1607069737.png" alt="img"></p><p>æ­¤æ—¶ï¼Œæˆ‘ä»¬ä»¤</p><p>ã€€ã€€ã€€ã€€<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171105162625888-1575402902.png" alt="img"></p><p>å¯ä»¥å¾—åˆ°</p><p>ã€€ã€€ã€€ã€€<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171105163457810-492161690.png" alt="img"></p><p>æ•…ï¼š</p><p><img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171105170233232-810575386.png" alt="img"></p><p>æ‰€ä»¥ï¼Œæ­£åˆ™åŒ–ä¹‹åçš„æŸå¤±å‡½æ•°çš„æ¢¯åº¦ä¸º</p><p>ã€€ã€€ã€€ã€€<img src="https://images2017.cnblogs.com/blog/1251096/201711/1251096-20171105171748341-1281292385.png" alt="img"></p><p>ç„¶åé€šè¿‡æ¢¯åº¦ä¸‹é™æ³•æœ€å°åŒ– <img src="http://ufldl.stanford.edu/wiki/images/math/c/e/0/ce027336c1cb3c0cd461406c81369ebf.png" alt="\textstyle J(\theta)">ï¼Œæˆ‘ä»¬å°±èƒ½å®ç°ä¸€ä¸ªå¯ç”¨çš„ softmax å›å½’æ¨¡å‹äº†ã€‚</p><h3 id="å¤šåˆ†ç±»LRä¸Softmaxå›å½’"><a href="#å¤šåˆ†ç±»LRä¸Softmaxå›å½’" class="headerlink" title="å¤šåˆ†ç±»LRä¸Softmaxå›å½’"></a>å¤šåˆ†ç±»LRä¸Softmaxå›å½’</h3><p>ã€€ã€€æœ‰äº†å¤šåˆ†ç±»çš„å¤„ç†æ–¹æ³•ï¼Œé‚£ä¹ˆæˆ‘ä»¬ä»€ä¹ˆæ—¶å€™è¯¥ç”¨å¤šåˆ†ç±»LRï¼Ÿä»€ä¹ˆæ—¶å€™è¦ç”¨softmaxå‘¢ï¼Ÿ</p><p>æ€»çš„æ¥è¯´ï¼Œè‹¥å¾…åˆ†ç±»çš„<strong>ç±»åˆ«äº’æ–¥</strong>ï¼Œæˆ‘ä»¬å°±ä½¿ç”¨Softmaxæ–¹æ³•ï¼›è‹¥å¾…åˆ†ç±»çš„<strong>ç±»åˆ«æœ‰ç›¸äº¤</strong>ï¼Œæˆ‘ä»¬åˆ™è¦é€‰ç”¨å¤šåˆ†ç±»LRï¼Œç„¶åæŠ•ç¥¨è¡¨å†³ã€‚</p><h2 id="Softmaxåˆ†ç±»å™¨"><a href="#Softmaxåˆ†ç±»å™¨" class="headerlink" title="Softmaxåˆ†ç±»å™¨"></a>Softmaxåˆ†ç±»å™¨</h2><p>SVMæ˜¯æœ€å¸¸ç”¨çš„ä¸¤ä¸ªåˆ†ç±»å™¨ä¹‹ä¸€ï¼Œè€Œå¦ä¸€ä¸ªå°±æ˜¯<strong>Softmaxåˆ†ç±»å™¨ï¼Œ</strong>å®ƒçš„æŸå¤±å‡½æ•°ä¸SVMçš„æŸå¤±å‡½æ•°ä¸åŒã€‚å¯¹äºå­¦ä¹ è¿‡äºŒå…ƒé€»è¾‘å›å½’åˆ†ç±»å™¨çš„è¯»è€…æ¥è¯´ï¼ŒSoftmaxåˆ†ç±»å™¨å°±å¯ä»¥ç†è§£ä¸ºé€»è¾‘å›å½’åˆ†ç±»å™¨é¢å¯¹å¤šä¸ªåˆ†ç±»çš„ä¸€èˆ¬åŒ–å½’çº³ã€‚SVMå°†è¾“å‡º<img src="https://www.zhihu.com/equation?tex=f%28x_i%2CW%29" alt="[å…¬å¼]">ä½œä¸ºæ¯ä¸ªåˆ†ç±»çš„è¯„åˆ†ï¼ˆå› ä¸ºæ— å®šæ ‡ï¼Œæ‰€ä»¥éš¾ä»¥ç›´æ¥è§£é‡Šï¼‰ã€‚ä¸SVMä¸åŒï¼ŒSoftmaxçš„è¾“å‡ºï¼ˆå½’ä¸€åŒ–çš„åˆ†ç±»æ¦‚ç‡ï¼‰æ›´åŠ ç›´è§‚ï¼Œå¹¶ä¸”ä»æ¦‚ç‡ä¸Šå¯ä»¥è§£é‡Šï¼Œè¿™ä¸€ç‚¹åæ–‡ä¼šè®¨è®ºã€‚åœ¨Softmaxåˆ†ç±»å™¨ä¸­ï¼Œå‡½æ•°æ˜ å°„<img src="https://www.zhihu.com/equation?tex=f%28x_i%3BW%29%3DWx_i" alt="[å…¬å¼]">ä¿æŒä¸å˜ï¼Œä½†å°†è¿™äº›è¯„åˆ†å€¼è§†ä¸ºæ¯ä¸ªåˆ†ç±»çš„æœªå½’ä¸€åŒ–çš„å¯¹æ•°æ¦‚ç‡ï¼Œå¹¶ä¸”å°†<em>æŠ˜å¶æŸå¤±ï¼ˆhinge lossï¼‰</em>æ›¿æ¢ä¸º<strong>äº¤å‰ç†µæŸå¤±</strong>ï¼ˆ<strong>cross-entropy lossï¼‰</strong>ã€‚å…¬å¼å¦‚ä¸‹ï¼š</p><p><img src="https://www.zhihu.com/equation?tex=%5Cdisplaystyle+Li%3D-log%28%5Cfrac%7Be%5E%7Bf_%7By_i%7D%7D%7D%7B%5Csum_je%5E%7Bf_j%7D%7D%29" alt="[å…¬å¼]"> æˆ–ç­‰ä»·çš„ <img src="https://www.zhihu.com/equation?tex=L_i%3D-f_%7By_i%7D%2Blog%28%5Csum_je%5E%7Bf_j%7D%29" alt="[å…¬å¼]"></p><p>åœ¨ä¸Šå¼ä¸­ï¼Œä½¿ç”¨<img src="https://www.zhihu.com/equation?tex=f_j" alt="[å…¬å¼]">æ¥è¡¨ç¤ºåˆ†ç±»è¯„åˆ†å‘é‡<img src="https://www.zhihu.com/equation?tex=f" alt="[å…¬å¼]">ä¸­çš„ç¬¬jä¸ªå…ƒç´ ã€‚å’Œä¹‹å‰ä¸€æ ·ï¼Œæ•´ä¸ªæ•°æ®é›†çš„æŸå¤±å€¼æ˜¯æ•°æ®é›†ä¸­æ‰€æœ‰æ ·æœ¬æ•°æ®çš„æŸå¤±å€¼<img src="https://www.zhihu.com/equation?tex=L_i" alt="[å…¬å¼]">çš„å‡å€¼ä¸æ­£åˆ™åŒ–æŸå¤±<img src="https://www.zhihu.com/equation?tex=R%28W%29" alt="[å…¬å¼]">ä¹‹å’Œã€‚å…¶ä¸­å‡½æ•°<img src="https://www.zhihu.com/equation?tex=f_j%28z%29%3D%5Cfrac%7Be%5E%7Bz_j%7D%7D%7B%5Csum_ke%5E%7Bz_k%7D%7D" alt="[å…¬å¼]">è¢«ç§°ä½œ<strong>softmax å‡½æ•°</strong>ï¼šå…¶è¾“å…¥å€¼æ˜¯ä¸€ä¸ªå‘é‡ï¼Œå‘é‡ä¸­å…ƒç´ ä¸ºä»»æ„å®æ•°çš„è¯„åˆ†å€¼ï¼ˆ<img src="https://www.zhihu.com/equation?tex=z" alt="[å…¬å¼]">ä¸­çš„ï¼‰ï¼Œå‡½æ•°å¯¹å…¶è¿›è¡Œå‹ç¼©ï¼Œè¾“å‡ºä¸€ä¸ªå‘é‡ï¼Œå…¶ä¸­æ¯ä¸ªå…ƒç´ å€¼åœ¨0åˆ°1ä¹‹é—´ï¼Œä¸”æ‰€æœ‰å…ƒç´ ä¹‹å’Œä¸º1ã€‚æ‰€ä»¥ï¼ŒåŒ…å«softmaxå‡½æ•°çš„å®Œæ•´äº¤å‰ç†µæŸå¤±çœ‹èµ·å”¬äººï¼Œå®é™…ä¸Šè¿˜æ˜¯æ¯”è¾ƒå®¹æ˜“ç†è§£çš„ã€‚</p><p><strong>ä¿¡æ¯ç†è®ºè§†è§’</strong>ï¼šåœ¨â€œçœŸå®â€åˆ†å¸ƒ<img src="https://www.zhihu.com/equation?tex=p" alt="[å…¬å¼]">å’Œä¼°è®¡åˆ†å¸ƒ<img src="https://www.zhihu.com/equation?tex=q" alt="[å…¬å¼]">ä¹‹é—´çš„<em>äº¤å‰ç†µ</em>å®šä¹‰å¦‚ä¸‹ï¼š</p><p><img src="https://www.zhihu.com/equation?tex=%5Cdisplaystyle+H%28p%2Cq%29%3D-%5Csum_xp%28x%29+logq%28x%29" alt="[å…¬å¼]"></p><p><strong>*è¯‘è€…æ³¨</strong>ï¼šKullback-Leiblerå·®å¼‚ï¼ˆKullback-Leibler Divergenceï¼‰ä¹Ÿå«åšç›¸å¯¹ç†µï¼ˆRelative Entropyï¼‰ï¼Œå®ƒè¡¡é‡çš„æ˜¯ç›¸åŒäº‹ä»¶ç©ºé—´é‡Œçš„ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒçš„å·®å¼‚æƒ…å†µã€‚*</p><p><strong>æ¦‚ç‡è®ºè§£é‡Š</strong>ï¼šå…ˆçœ‹ä¸‹é¢çš„å…¬å¼ï¼š</p><p><img src="https://www.zhihu.com/equation?tex=P%28y_i%7Cx_i%2CW%29%3D%5Cfrac%7Be%5E%7Bf_%7By_i%7D%7D%7D%7B%5Csum_je%5E%7Bf_j%7D%7D" alt="[å…¬å¼]"></p><p><strong>å®æ“äº‹é¡¹ï¼šæ•°å€¼ç¨³å®šã€‚</strong>ç¼–ç¨‹å®ç°softmaxå‡½æ•°è®¡ç®—çš„æ—¶å€™ï¼Œä¸­é—´é¡¹<img src="https://www.zhihu.com/equation?tex=e%5E%7Bf_%7By_i%7D%7D" alt="[å…¬å¼]">å’Œ<img src="https://www.zhihu.com/equation?tex=%5Csum_j+e%5E%7Bf_j%7D" alt="[å…¬å¼]">å› ä¸ºå­˜åœ¨æŒ‡æ•°å‡½æ•°ï¼Œæ‰€ä»¥æ•°å€¼å¯èƒ½éå¸¸å¤§ã€‚é™¤ä»¥å¤§æ•°å€¼å¯èƒ½å¯¼è‡´æ•°å€¼è®¡ç®—çš„ä¸ç¨³å®šï¼Œæ‰€ä»¥å­¦ä¼šä½¿ç”¨å½’ä¸€åŒ–æŠ€å·§éå¸¸é‡è¦ã€‚å¦‚æœåœ¨åˆ†å¼çš„åˆ†å­å’Œåˆ†æ¯éƒ½ä¹˜ä»¥ä¸€ä¸ªå¸¸æ•°<img src="https://www.zhihu.com/equation?tex=C" alt="[å…¬å¼]">ï¼Œå¹¶æŠŠå®ƒå˜æ¢åˆ°æ±‚å’Œä¹‹ä¸­ï¼Œå°±èƒ½å¾—åˆ°ä¸€ä¸ªä»æ•°å­¦ä¸Šç­‰ä»·çš„å…¬å¼ï¼š</p><p><img src="https://www.zhihu.com/equation?tex=%5Cfrac%7Be%5E%7Bf_%7By_i%7D%7D%7D%7B%5Csum_je%5E%7Bf_j%7D%7D%3D%5Cfrac%7BCe%5E%7Bf_%7By_i%7D%7D%7D%7BC%5Csum_je%5E%7Bf_j%7D%7D%3D%5Cfrac%7Be%5E%7Bf_%7By_i%7D%2BlogC%7D%7D%7B%5Csum_je%5E%7Bf_j%2BlogC%7D%7D" alt="[å…¬å¼]"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">f = np.array([<span class="number">123</span>, <span class="number">456</span>, <span class="number">789</span>]) <span class="comment"># ä¾‹å­ä¸­æœ‰3ä¸ªåˆ†ç±»ï¼Œæ¯ä¸ªè¯„åˆ†çš„æ•°å€¼éƒ½å¾ˆå¤§</span></span><br><span class="line">p = np.exp(f) / np.sum(np.exp(f)) <span class="comment"># ä¸å¦™ï¼šæ•°å€¼é—®é¢˜ï¼Œå¯èƒ½å¯¼è‡´æ•°å€¼çˆ†ç‚¸</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># é‚£ä¹ˆå°†fä¸­çš„å€¼å¹³ç§»åˆ°æœ€å¤§å€¼ä¸º0ï¼š</span></span><br><span class="line">f -= np.max(f) <span class="comment"># f becomes [-666, -333, 0]</span></span><br><span class="line">p = np.exp(f) / np.sum(np.exp(f)) <span class="comment"># ç°åœ¨OKäº†ï¼Œå°†ç»™å‡ºæ­£ç¡®ç»“æœ</span></span><br></pre></td></tr></table></figure><p><strong>è®©äººè¿·æƒ‘çš„å‘½åè§„åˆ™</strong>ï¼šç²¾ç¡®åœ°è¯´ï¼ŒSVMåˆ†ç±»å™¨ä½¿ç”¨çš„æ˜¯<em>æŠ˜å¶æŸå¤±ï¼ˆhinge lossï¼‰</em>ï¼Œæœ‰æ—¶å€™åˆè¢«ç§°ä¸º<em>æœ€å¤§è¾¹ç•ŒæŸå¤±ï¼ˆmax-margin lossï¼‰</em>ã€‚Softmaxåˆ†ç±»å™¨ä½¿ç”¨çš„æ˜¯<em>äº¤å‰ç†µæŸå¤±ï¼ˆcorss-entropy lossï¼‰</em>ã€‚Softmaxåˆ†ç±»å™¨çš„å‘½åæ˜¯ä»<em>softmaxå‡½æ•°</em>é‚£é‡Œå¾—æ¥çš„ï¼Œsoftmaxå‡½æ•°å°†åŸå§‹åˆ†ç±»è¯„åˆ†å˜æˆæ­£çš„å½’ä¸€åŒ–æ•°å€¼ï¼Œæ‰€æœ‰æ•°å€¼å’Œä¸º1ï¼Œè¿™æ ·å¤„ç†åäº¤å‰ç†µæŸå¤±æ‰èƒ½åº”ç”¨ã€‚æ³¨æ„ä»æŠ€æœ¯ä¸Šè¯´â€œsoftmaxæŸå¤±ï¼ˆsoftmax lossï¼‰â€æ˜¯æ²¡æœ‰æ„ä¹‰çš„ï¼Œå› ä¸ºsoftmaxåªæ˜¯ä¸€ä¸ªå‹ç¼©æ•°å€¼çš„å‡½æ•°ã€‚ä½†æ˜¯åœ¨è¿™ä¸ªè¯´æ³•å¸¸å¸¸è¢«ç”¨æ¥åšç®€ç§°ã€‚</p><h2 id="SVMå’ŒSoftmaxçš„æ¯”è¾ƒ"><a href="#SVMå’ŒSoftmaxçš„æ¯”è¾ƒ" class="headerlink" title="SVMå’ŒSoftmaxçš„æ¯”è¾ƒ"></a>SVMå’ŒSoftmaxçš„æ¯”è¾ƒ</h2><p>ä¸‹å›¾æœ‰åŠ©äºåŒºåˆ†è¿™ Softmaxå’ŒSVMè¿™ä¸¤ç§åˆ†ç±»å™¨ï¼š</p><p>â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”</p><p><img src="https://pic1.zhimg.com/80/a90ce9e0ff533f3efee4747305382064_hd.png" alt="img"></p><p>é’ˆå¯¹ä¸€ä¸ªæ•°æ®ç‚¹ï¼ŒSVMå’ŒSoftmaxåˆ†ç±»å™¨çš„ä¸åŒå¤„ç†æ–¹å¼çš„ä¾‹å­ã€‚ä¸¤ä¸ªåˆ†ç±»å™¨éƒ½è®¡ç®—äº†åŒæ ·çš„åˆ†å€¼å‘é‡<strong>f</strong>ï¼ˆæœ¬èŠ‚ä¸­æ˜¯é€šè¿‡çŸ©é˜µä¹˜æ¥å®ç°ï¼‰ã€‚ä¸åŒä¹‹å¤„åœ¨äºå¯¹<strong>f</strong>ä¸­åˆ†å€¼çš„è§£é‡Šï¼šSVMåˆ†ç±»å™¨å°†å®ƒä»¬çœ‹åšæ˜¯åˆ†ç±»è¯„åˆ†ï¼Œå®ƒçš„æŸå¤±å‡½æ•°é¼“åŠ±æ­£ç¡®çš„åˆ†ç±»ï¼ˆæœ¬ä¾‹ä¸­æ˜¯è“è‰²çš„ç±»åˆ«2ï¼‰çš„åˆ†å€¼æ¯”å…¶ä»–åˆ†ç±»çš„åˆ†å€¼é«˜å‡ºè‡³å°‘ä¸€ä¸ªè¾¹ç•Œå€¼ã€‚Softmaxåˆ†ç±»å™¨å°†è¿™äº›æ•°å€¼çœ‹åšæ˜¯æ¯ä¸ªåˆ†ç±»æ²¡æœ‰å½’ä¸€åŒ–çš„<strong>å¯¹æ•°æ¦‚ç‡</strong>ï¼Œé¼“åŠ±æ­£ç¡®åˆ†ç±»çš„å½’ä¸€åŒ–çš„å¯¹æ•°æ¦‚ç‡å˜é«˜ï¼Œå…¶ä½™çš„å˜ä½ã€‚SVMçš„æœ€ç»ˆçš„æŸå¤±å€¼æ˜¯1.58ï¼ŒSoftmaxçš„æœ€ç»ˆçš„æŸå¤±å€¼æ˜¯0.452ï¼Œä½†è¦æ³¨æ„è¿™ä¸¤ä¸ªæ•°å€¼æ²¡æœ‰å¯æ¯”æ€§ã€‚åªåœ¨ç»™å®šåŒæ ·æ•°æ®ï¼Œåœ¨åŒæ ·çš„åˆ†ç±»å™¨çš„æŸå¤±å€¼è®¡ç®—ä¸­ï¼Œå®ƒä»¬æ‰æœ‰æ„ä¹‰ã€‚</p><p>â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”</p><p><strong>Softmaxåˆ†ç±»å™¨ä¸ºæ¯ä¸ªåˆ†ç±»æä¾›äº†â€œå¯èƒ½æ€§â€</strong>ï¼šSVMçš„è®¡ç®—æ˜¯æ— æ ‡å®šçš„ï¼Œè€Œä¸”éš¾ä»¥é’ˆå¯¹æ‰€æœ‰åˆ†ç±»çš„è¯„åˆ†å€¼ç»™å‡ºç›´è§‚è§£é‡Šã€‚Softmaxåˆ†ç±»å™¨åˆ™ä¸åŒï¼Œå®ƒå…è®¸æˆ‘ä»¬è®¡ç®—å‡ºå¯¹äºæ‰€æœ‰åˆ†ç±»æ ‡ç­¾çš„å¯èƒ½æ€§ã€‚ä¸¾ä¸ªä¾‹å­ï¼Œé’ˆå¯¹ç»™å‡ºçš„å›¾åƒï¼ŒSVMåˆ†ç±»å™¨å¯èƒ½ç»™ä½ çš„æ˜¯ä¸€ä¸ª[12.5, 0.6, -23.0]å¯¹åº”åˆ†ç±»â€œçŒ«â€ï¼Œâ€œç‹—â€ï¼Œâ€œèˆ¹â€ã€‚è€Œsoftmaxåˆ†ç±»å™¨å¯ä»¥è®¡ç®—å‡ºè¿™ä¸‰ä¸ªæ ‡ç­¾çš„â€å¯èƒ½æ€§â€œæ˜¯[0.9, 0.09, 0.01]ï¼Œè¿™å°±è®©ä½ èƒ½çœ‹å‡ºå¯¹äºä¸åŒåˆ†ç±»å‡†ç¡®æ€§çš„æŠŠæ¡ã€‚ä¸ºä»€ä¹ˆæˆ‘ä»¬è¦åœ¨â€å¯èƒ½æ€§â€œä¸Šé¢æ‰“å¼•å·å‘¢ï¼Ÿè¿™æ˜¯å› ä¸ºå¯èƒ½æ€§åˆ†å¸ƒçš„é›†ä¸­æˆ–ç¦»æ•£ç¨‹åº¦æ˜¯ç”±æ­£åˆ™åŒ–å‚æ•°Î»ç›´æ¥å†³å®šçš„ï¼ŒÎ»æ˜¯ä½ èƒ½ç›´æ¥æ§åˆ¶çš„ä¸€ä¸ªè¾“å…¥å‚æ•°ã€‚ä¸¾ä¸ªä¾‹å­ï¼Œå‡è®¾3ä¸ªåˆ†ç±»çš„åŸå§‹åˆ†æ•°æ˜¯[1, -2, 0]ï¼Œé‚£ä¹ˆsoftmaxå‡½æ•°å°±ä¼šè®¡ç®—ï¼š</p><p><img src="https://www.zhihu.com/equation?tex=%5B1%2C-2%2C0%5D%5Cto%5Be%5E1%2Ce%5E%7B-2%7D%2Ce%5E0%5D%3D%5B2.71%2C0.14%2C1%5D%5Cto%5B0.7%2C0.04%2C0.26%5D" alt="[å…¬å¼]"></p><p>ç°åœ¨ï¼Œå¦‚æœæ­£åˆ™åŒ–å‚æ•°Î»æ›´å¤§ï¼Œé‚£ä¹ˆæƒé‡Wå°±ä¼šè¢«æƒ©ç½šçš„æ›´å¤šï¼Œç„¶åä»–çš„æƒé‡æ•°å€¼å°±ä¼šæ›´å°ã€‚è¿™æ ·ç®—å‡ºæ¥çš„åˆ†æ•°ä¹Ÿä¼šæ›´å°ï¼Œå‡è®¾å°äº†ä¸€åŠå§[0.5, -1, 0]ï¼Œé‚£ä¹ˆsoftmaxå‡½æ•°çš„è®¡ç®—å°±æ˜¯ï¼š</p><p><img src="https://www.zhihu.com/equation?tex=%5B0.5%2C-1%2C0%5D%5Cto%5Be%5E%7B0.5%7D%2Ce%5E%7B-1%7D%2Ce%5E0%5D%3D%5B1.65%2C0.73%2C1%5D%5Cto%5B0.55%2C0.12%2C0.33%5D" alt="[å…¬å¼]"></p><p>ç°åœ¨çœ‹èµ·æ¥ï¼Œæ¦‚ç‡çš„åˆ†å¸ƒå°±æ›´åŠ åˆ†æ•£äº†ã€‚è¿˜æœ‰ï¼Œéšç€æ­£åˆ™åŒ–å‚æ•°Î»ä¸æ–­å¢å¼ºï¼Œæƒé‡æ•°å€¼ä¼šè¶Šæ¥è¶Šå°ï¼Œæœ€åè¾“å‡ºçš„æ¦‚ç‡ä¼šæ¥è¿‘äºå‡åŒ€åˆ†å¸ƒã€‚è¿™å°±æ˜¯è¯´ï¼Œsoftmaxåˆ†ç±»å™¨ç®—å‡ºæ¥çš„æ¦‚ç‡æœ€å¥½æ˜¯çœ‹æˆä¸€ç§å¯¹äºåˆ†ç±»æ­£ç¡®æ€§çš„è‡ªä¿¡ã€‚å’ŒSVMä¸€æ ·ï¼Œæ•°å­—é—´ç›¸äº’æ¯”è¾ƒå¾—å‡ºçš„å¤§å°é¡ºåºæ˜¯å¯ä»¥è§£é‡Šçš„ï¼Œä½†å…¶ç»å¯¹å€¼åˆ™éš¾ä»¥ç›´è§‚è§£é‡Š<strong>ã€‚</strong></p><p><strong>åœ¨å®é™…ä½¿ç”¨ä¸­ï¼ŒSVMå’ŒSoftmaxç»å¸¸æ˜¯ç›¸ä¼¼çš„</strong>ï¼šé€šå¸¸è¯´æ¥ï¼Œä¸¤ç§åˆ†ç±»å™¨çš„è¡¨ç°å·®åˆ«å¾ˆå°ï¼Œä¸åŒçš„äººå¯¹äºå“ªä¸ªåˆ†ç±»å™¨æ›´å¥½æœ‰ä¸åŒçš„çœ‹æ³•ã€‚ç›¸å¯¹äºSoftmaxåˆ†ç±»å™¨ï¼ŒSVMæ›´åŠ â€œå±€éƒ¨ç›®æ ‡åŒ–ï¼ˆlocal objectiveï¼‰â€ï¼Œè¿™æ—¢å¯ä»¥çœ‹åšæ˜¯ä¸€ä¸ªç‰¹æ€§ï¼Œä¹Ÿå¯ä»¥çœ‹åšæ˜¯ä¸€ä¸ªåŠ£åŠ¿ã€‚è€ƒè™‘ä¸€ä¸ªè¯„åˆ†æ˜¯[10, -2, 3]çš„æ•°æ®ï¼Œå…¶ä¸­ç¬¬ä¸€ä¸ªåˆ†ç±»æ˜¯æ­£ç¡®çš„ã€‚é‚£ä¹ˆä¸€ä¸ªSVMï¼ˆ<img src="https://www.zhihu.com/equation?tex=%5CDelta+%3D1" alt="[å…¬å¼]">ï¼‰ä¼šçœ‹åˆ°æ­£ç¡®åˆ†ç±»ç›¸è¾ƒäºä¸æ­£ç¡®åˆ†ç±»ï¼Œå·²ç»å¾—åˆ°äº†æ¯”è¾¹ç•Œå€¼è¿˜è¦é«˜çš„åˆ†æ•°ï¼Œå®ƒå°±ä¼šè®¤ä¸ºæŸå¤±å€¼æ˜¯0ã€‚SVMå¯¹äºæ•°å­—ä¸ªä½“çš„ç»†èŠ‚æ˜¯ä¸å…³å¿ƒçš„ï¼šå¦‚æœåˆ†æ•°æ˜¯[10, -100, -100]æˆ–è€…[10, 9, 9]ï¼Œå¯¹äºSVMæ¥è¯´æ²¡è®¾ä¹ˆä¸åŒï¼Œåªè¦æ»¡è¶³è¶…è¿‡è¾¹ç•Œå€¼ç­‰äº1ï¼Œé‚£ä¹ˆæŸå¤±å€¼å°±ç­‰äº0ã€‚</p><p>å¯¹äºsoftmaxåˆ†ç±»å™¨ï¼Œæƒ…å†µåˆ™ä¸åŒã€‚å¯¹äº[10, 9, 9]æ¥è¯´ï¼Œè®¡ç®—å‡ºçš„æŸå¤±å€¼å°±è¿œè¿œé«˜äº[10, -100, -100]çš„ã€‚æ¢å¥è¯æ¥è¯´ï¼Œsoftmaxåˆ†ç±»å™¨å¯¹äºåˆ†æ•°æ˜¯æ°¸è¿œä¸ä¼šæ»¡æ„çš„ï¼šæ­£ç¡®åˆ†ç±»æ€»èƒ½å¾—åˆ°æ›´é«˜çš„å¯èƒ½æ€§ï¼Œé”™è¯¯åˆ†ç±»æ€»èƒ½å¾—åˆ°æ›´ä½çš„å¯èƒ½æ€§ï¼ŒæŸå¤±å€¼æ€»æ˜¯èƒ½å¤Ÿæ›´å°ã€‚ä½†æ˜¯ï¼ŒSVMåªè¦è¾¹ç•Œå€¼è¢«æ»¡è¶³äº†å°±æ»¡æ„äº†ï¼Œä¸ä¼šè¶…è¿‡é™åˆ¶å»ç»†å¾®åœ°æ“ä½œå…·ä½“åˆ†æ•°ã€‚è¿™å¯ä»¥è¢«çœ‹åšæ˜¯SVMçš„ä¸€ç§ç‰¹æ€§ã€‚ä¸¾ä¾‹è¯´æ¥ï¼Œä¸€ä¸ªæ±½è½¦çš„åˆ†ç±»å™¨åº”è¯¥æŠŠä»–çš„å¤§é‡ç²¾åŠ›æ”¾åœ¨å¦‚ä½•åˆ†è¾¨å°è½¿è½¦å’Œå¤§å¡è½¦ä¸Šï¼Œè€Œä¸åº”è¯¥çº ç»“äºå¦‚ä½•ä¸é’è›™è¿›è¡ŒåŒºåˆ†ï¼Œå› ä¸ºåŒºåˆ†é’è›™å¾—åˆ°çš„è¯„åˆ†å·²ç»è¶³å¤Ÿä½äº†ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹  </tag>
            
            <tag> LR </tag>
            
            <tag> softmax </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>æ–‡æœ¬åˆ†ç±»é—®é¢˜</title>
      <link href="/2019/08/24/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/"/>
      <url>/2019/08/24/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h1 id="æ–‡æœ¬åˆ†ç±»é—®é¢˜"><a href="#æ–‡æœ¬åˆ†ç±»é—®é¢˜" class="headerlink" title="æ–‡æœ¬åˆ†ç±»é—®é¢˜"></a>æ–‡æœ¬åˆ†ç±»é—®é¢˜</h1><p>ä¸‹é¢æˆ‘ä»¬æ¥çœ‹ä¸€ä¸ªæ–‡æœ¬åˆ†ç±»é—®é¢˜ï¼Œç»å…¸çš„æ–°é—»ä¸»é¢˜åˆ†ç±»ï¼Œç”¨æœ´ç´ è´å¶æ–¯æ€ä¹ˆåšã€‚</p><p>In [193]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line">seg_list = jieba.cut(<span class="string">"ä»–æ¥åˆ°ä¸œæµ·è¯†åˆ«åŒº"</span>,cut_all=<span class="literal">False</span>)</span><br><span class="line">print(<span class="string">"/"</span> .join(seg_list) )</span><br><span class="line">jieba.add_word(<span class="string">'ä¸œæµ·è¯†åˆ«åŒº'</span>)</span><br><span class="line">seg_list = jieba.cut(<span class="string">"ä»–æ¥åˆ°ä¸œæµ·è¯†åˆ«åŒº"</span>,cut_all=<span class="literal">False</span>)</span><br><span class="line">print(<span class="string">"/ "</span> .join(seg_list) )</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ä»–/æ¥åˆ°/ä¸œæµ·/è¯†åˆ«åŒº</span><br><span class="line">ä»–/ æ¥åˆ°/ ä¸œæµ·è¯†åˆ«åŒº</span><br></pre></td></tr></table></figure><p>In [175]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding: utf-8</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> jieba  <span class="comment">#å¤„ç†ä¸­æ–‡</span></span><br><span class="line"><span class="keyword">import</span> nltk  <span class="comment">#å¤„ç†è‹±æ–‡</span></span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pylab <span class="keyword">as</span> pl</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> nltk</span><br></pre></td></tr></table></figure><h2 id="æ–‡æœ¬å¤„ç†Â¶"><a href="#æ–‡æœ¬å¤„ç†Â¶" class="headerlink" title="æ–‡æœ¬å¤„ç†Â¶"></a>æ–‡æœ¬å¤„ç†<a href="file:///Users/mmy/Downloads/æœ´ç´ è´å¶æ–¯æ–°é—»åˆ†ç±».html#æ–‡æœ¬å¤„ç†" target="_blank" rel="noopener">Â¶</a></h2><p>1ã€æŠŠè®­ç»ƒæ ·æœ¬åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†</p><p>2ã€ç»Ÿè®¡äº†è¯é¢‘ï¼ŒæŒ‰è¯é¢‘é™åºç”Ÿæˆè¯è¢‹</p><p>In [137]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æ–‡æœ¬å¤„ç†ï¼Œä¹Ÿå°±æ˜¯æ ·æœ¬ç”Ÿæˆè¿‡ç¨‹</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">text_processing</span><span class="params">(folder_path, test_size=<span class="number">0.2</span>)</span>:</span></span><br><span class="line">    folder_list = os.listdir(folder_path)</span><br><span class="line">    <span class="comment"># os.listdir æ–¹æ³•ç”¨äºè¿”å›è·¯å¾„ä¸‹åŒ…å«çš„æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹çš„åå­—çš„åˆ—è¡¨</span></span><br><span class="line">    <span class="comment"># folder_list = ['C000008', 'C000014', 'C000013', 'C000022', 'C000023', 'C000024', 'C000010', 'C000020', 'C000016']</span></span><br><span class="line">    </span><br><span class="line">    data_list = []</span><br><span class="line">    class_list = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># éå†æ–‡ä»¶å¤¹ï¼Œæ¯ä¸ªæ–‡ä»¶å¤¹é‡Œæ˜¯ä¸€ä¸ªæ–°é—»çš„ç±»åˆ«</span></span><br><span class="line">    <span class="keyword">for</span> folder <span class="keyword">in</span> folder_list:</span><br><span class="line">        new_folder_path = os.path.join(folder_path, folder)</span><br><span class="line">        <span class="comment"># os.path.joinå°±æ˜¯æŠŠä¸¤ä¸ªè·¯å¾„æ‹¼æ¥</span></span><br><span class="line">        <span class="comment"># new_folder_path = ./Database/SogouC/Sample/C000008</span></span><br><span class="line">        </span><br><span class="line">        files = os.listdir(new_folder_path)</span><br><span class="line">        <span class="comment"># è¯»å–new_folder_pathè·¯å¾„ä¸‹çš„æ–‡ä»¶å</span></span><br><span class="line">        <span class="comment"># ['15.txt', '14.txt', '16.txt', '17.txt', '13.txt', '12.txt', '10.txt', '11.txt', '19.txt', '18.txt']</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># è¯»å–æ–‡ä»¶</span></span><br><span class="line">        j = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> file <span class="keyword">in</span> files:</span><br><span class="line">            <span class="keyword">if</span> j &gt; <span class="number">100</span>: </span><br><span class="line">            <span class="comment"># æ€•å†…å­˜çˆ†æ‰ï¼Œåªå–100ä¸ªæ ·æœ¬æ–‡ä»¶ï¼Œä½ å¯ä»¥æ³¨é‡Šæ‰å–å®Œï¼Œ</span></span><br><span class="line">            <span class="comment"># è¿™é‡Œæ¯ä¸ªç±»åˆ«ä¸‹åªæœ‰10ä¸ªæ ·æœ¬ï¼Œæ²¡äº‹</span></span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">with</span> open(os.path.join(new_folder_path, file), <span class="string">'r'</span>) <span class="keyword">as</span> fp:</span><br><span class="line">                raw = fp.read()</span><br><span class="line">                <span class="comment"># read() è¿”å›å€¼ä¸ºstrï¼Œæ¯æ¬¡è¯»å–æ•´ä¸ªæ–‡ä»¶ï¼Œå°†æ–‡ä»¶æ‰€æœ‰å†…å®¹æ”¾åˆ°ä¸€ä¸ªå­—ç¬¦ä¸²å˜é‡ä¸­</span></span><br><span class="line">                <span class="comment"># readline() è¿”å›å€¼ä¸ºstrï¼Œæ¯æ¬¡åªè¯»å–ä¸€è¡Œ,æ¯è¡Œçš„å†…å®¹æ”¾åœ¨ä¸€ä¸ªå­—ç¬¦ä¸²å˜é‡ä¸­</span></span><br><span class="line">                <span class="comment"># readlines() è¿”å›å€¼ä¸ºlistï¼Œä¸€æ¬¡è¯»å–æ•´ä¸ªæ–‡ä»¶ï¼Œæ¯è¡Œçš„å†…å®¹æ”¾åœ¨ä¸€ä¸ªå­—ç¬¦ä¸²å˜é‡ä¸­ä½œä¸ºåˆ—è¡¨çš„ä¸€ä¸ªå…ƒç´ ã€‚</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">## æ˜¯çš„ï¼Œéšå¤„å¯è§çš„jiebaä¸­æ–‡åˆ†è¯</span></span><br><span class="line">            jieba.enable_parallel(<span class="number">4</span>) <span class="comment"># å¼€å¯å¹¶è¡Œåˆ†è¯æ¨¡å¼ï¼Œå‚æ•°ä¸ºå¹¶è¡Œè¿›ç¨‹æ•°ï¼Œä¸æ”¯æŒwindows</span></span><br><span class="line">            word_cut = jieba.cut(raw, cut_all=<span class="literal">False</span>) <span class="comment"># ç²¾ç¡®æ¨¡å¼ï¼Œè¿”å›çš„ç»“æ„æ˜¯ä¸€ä¸ªå¯è¿­ä»£çš„genertor</span></span><br><span class="line">            word_list = list(word_cut) <span class="comment"># genertorè½¬åŒ–ä¸ºlistï¼Œæ¯ä¸ªè¯unicodeæ ¼å¼</span></span><br><span class="line">            jieba.disable_parallel() <span class="comment"># å…³é—­å¹¶è¡Œåˆ†è¯æ¨¡å¼</span></span><br><span class="line">            </span><br><span class="line">            data_list.append(word_list) <span class="comment">#è®­ç»ƒé›†list</span></span><br><span class="line">            <span class="comment">#class_list.append(folder.decode('utf-8')) #ç±»åˆ«,str.decodeä¼šæŠ¥é”™</span></span><br><span class="line">            class_list.append(folder) <span class="comment">#è®­ç»ƒé›†çš„æ ‡ç­¾ç±»åˆ«</span></span><br><span class="line">            j += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line">    <span class="comment">## ä¸‹é¢æ‰‹åŠ¨ç²—æš´åœ°åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†</span></span><br><span class="line">    data_class_list = zip(data_list, class_list) <span class="comment"># zip å‡½æ•°è¿”å›ä¸€ä¸ªzipå¯¹è±¡</span></span><br><span class="line">    data_class_list = list(data_class_list) <span class="comment"># éœ€è¦ç”¨listè½¬æ¢æˆåˆ—è¡¨</span></span><br><span class="line">    </span><br><span class="line">    random.shuffle(data_class_list) <span class="comment"># shuffleéšæœºæ‰“ä¹±æ ·æœ¬</span></span><br><span class="line">    index = int(len(data_class_list)*test_size)+<span class="number">1</span></span><br><span class="line">    train_list = data_class_list[index:]</span><br><span class="line">    test_list = data_class_list[:index]</span><br><span class="line">    </span><br><span class="line">    train_data_list, train_class_list = zip(*train_list) </span><br><span class="line">    <span class="comment"># è§£å‹ç¼©,æ–‡æœ¬å’Œç±»åˆ«åˆ†å¼€è¿”å›çš„æ˜¯å…ƒç»„æ ¼å¼ï¼Œå¯ä»¥åœ¨ç”¨listè½¬æ¢</span></span><br><span class="line">    test_data_list, test_class_list = zip(*test_list) </span><br><span class="line">    <span class="comment">#ä»¥ä¸Šåˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†å…¶å®å¯ä»¥ç”¨sklearnè‡ªå¸¦çš„éƒ¨åˆ†åš</span></span><br><span class="line">    <span class="comment">#train_data_list, test_data_list, train_class_list, test_class_list = \</span></span><br><span class="line">    <span class="comment">#sklearn.model_selection.train_test_split(data_list, class_list, test_size=test_size) </span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">   </span><br><span class="line">    <span class="comment"># ç»Ÿè®¡è¯é¢‘æ”¾å…¥all_words_dict</span></span><br><span class="line">    all_words_dict = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> word_list <span class="keyword">in</span> train_data_list:</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> word_list:</span><br><span class="line">            <span class="comment">#if all_words_dict.has_key(word):å·²åˆ é™¤æ­¤æ–¹æ³•</span></span><br><span class="line">            <span class="keyword">if</span> word <span class="keyword">in</span> all_words_dict:</span><br><span class="line">                all_words_dict[word] += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                all_words_dict[word] = <span class="number">1</span></span><br><span class="line">    <span class="comment"># all_words_dict=&#123;'\n': 1257, '\u3000': 1986, 'æœ‰': 175, 'æ±Ÿæ¹–': 1,.....&#125;</span></span><br><span class="line">    <span class="comment"># åŒæ ·ä»¥ä¸Šæœ‰ç°æˆçš„ç»Ÿè®¡è¯é¢‘çš„APIå¯ä»¥è°ƒç”¨</span></span><br><span class="line">    <span class="comment"># from collections import Counter </span></span><br><span class="line">    <span class="comment"># Counter(train_data_list)</span></span><br><span class="line"></span><br><span class="line">    all_words_tuple_list = sorted(all_words_dict.items(), key=<span class="keyword">lambda</span> f:f[<span class="number">1</span>], reverse=<span class="literal">True</span>) </span><br><span class="line">    <span class="comment"># å†…å»ºå‡½æ•°sortedç¬¬ä¸€ä¸ªå‚æ•°éœ€ä¸ºlistï¼Œall_words_dict.items()è½¬åŒ–ä¸ºåˆ—è¡¨ï¼Œé”®å’Œå€¼ä¸ºå…ƒç»„</span></span><br><span class="line">    <span class="comment"># keyå‡½æ•°ä»£è¡¨æŒ‰å…ƒç»„çš„çš„è¯é¢‘æ’åºï¼Œå¹¶é™åºè¿”å›ç»“æœ</span></span><br><span class="line">    <span class="comment"># all_words_tuple_list = [('ï¼Œ', 3424), ('çš„', 2527), ('\u3000', 1734), ('ã€‚', 1482),.....]</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#all_words_list = list(zip(*all_words_tuple_list)[0]) æŠ¥é”™ï¼Œéœ€è¦ä¿®æ”¹</span></span><br><span class="line">    all_words_list,_ = zip(*all_words_tuple_list) <span class="comment"># è§£å‹ç¼©</span></span><br><span class="line">    all_words_list = list(all_words_list)</span><br><span class="line">    <span class="comment"># all_words_list = ['ï¼Œ', 'çš„', '\u3000', 'ã€‚', '\n', 'åœ¨', ' ', 'ã€', 'äº†', 'â€œ',.....]</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> all_words_list, train_data_list, test_data_list, train_class_list, test_class_list</span><br></pre></td></tr></table></figure><p>In [138]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> (<span class="string">"start"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## æ–‡æœ¬é¢„å¤„ç†</span></span><br><span class="line">folder_path = <span class="string">'./Database/SogouC/Sample'</span></span><br><span class="line">all_words_list, train_data_list, test_data_list, train_class_list, test_class_list = \</span><br><span class="line">text_processing(folder_path, test_size=<span class="number">0.2</span>)</span><br><span class="line">print(len(all_words_list)) <span class="comment"># 9748ä¸ªä¸é‡å¤å•è¯</span></span><br><span class="line">print(all_words_list[:<span class="number">100</span>])</span><br><span class="line">print(len(train_data_list)) <span class="comment"># 71ä¸ªè®­ç»ƒé›†æ ·æœ¬</span></span><br><span class="line">print(len(test_data_list))  <span class="comment"># 19ä¸ªæµ‹è¯•é›†æ ·æœ¬</span></span><br><span class="line">print(len(train_class_list))  <span class="comment"># 71ä¸ªè®­ç»ƒé›†æ ‡ç­¾</span></span><br><span class="line">print(len(test_class_list))  <span class="comment"># 19ä¸ªæµ‹è¯•é›†æ ‡ç­¾</span></span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">start</span><br><span class="line">9481</span><br><span class="line">[&apos;ï¼Œ&apos;, &apos;çš„&apos;, &apos;\u3000&apos;, &apos;ã€‚&apos;, &apos;\n&apos;, &apos; &apos;, &apos;;&apos;, &apos;&amp;&apos;, &apos;nbsp&apos;, &apos;ã€&apos;, &apos;åœ¨&apos;, &apos;äº†&apos;, &apos;â€œ&apos;, &apos;æ˜¯&apos;, &apos;â€&apos;, &apos;\x00&apos;, &apos;ï¼š&apos;, &apos;å’Œ&apos;, &apos;ä¸­å›½&apos;, &apos;æœ‰&apos;, &apos;ä¹Ÿ&apos;, &apos;æˆ‘&apos;, &apos;å¯¹&apos;, &apos;å°±&apos;, &apos;å°†&apos;, &apos;â€”&apos;, &apos;ä¸Š&apos;, &apos;è¿™&apos;, &apos;æ¸¸å®¢&apos;, &apos;éƒ½&apos;, &apos;æ—…æ¸¸&apos;, &apos;ä¸­&apos;, &apos;ä¸&apos;, &apos;ä¸º&apos;, &apos;è¦&apos;, &apos;ä¸&apos;, &apos;å¹´&apos;, &apos;ç­‰&apos;, &apos;è€Œ&apos;, &apos;ï¼›&apos;, &apos;å¯ä»¥&apos;, &apos;æœˆ&apos;, &apos;ï¼ˆ&apos;, &apos;ï¼‰&apos;, &apos;å¯¼å¼¹&apos;, &apos;å¤§é™†&apos;, &apos;ä¸€ä¸ª&apos;, &apos;ä»&apos;, &apos;äºº&apos;, &apos;3&apos;, &apos;åˆ°&apos;, &apos;ä½†&apos;, &apos;ä½ &apos;, &apos;å…¬å¸&apos;, &apos;è¯´&apos;, &apos;ç«ç‚®&apos;, &apos;æ—¥&apos;, &apos;(&apos;, &apos;)&apos;, &apos;ä»–&apos;, &apos;è€ƒç”Ÿ&apos;, &apos;å°å†›&apos;, &apos;è®¤ä¸º&apos;, &apos;åŒ—äº¬&apos;, &apos;æ—¶&apos;, &apos;å¤š&apos;, &apos;è¿˜&apos;, &apos;ä¸ª&apos;, &apos;1&apos;, &apos;.&apos;, &apos;èƒ½&apos;, &apos;ã€Š&apos;, &apos;ã€‹&apos;, &apos;å·²ç»&apos;, &apos;è§£æ”¾å†›&apos;, &apos;ä¸€ç§&apos;, &apos;ä¼š&apos;, &apos;æ—¶é—´&apos;, &apos;è‡ªå·±&apos;, &apos;æ¥&apos;, &apos;æ–°&apos;, &apos;å„ç§&apos;, &apos;å¤§&apos;, &apos;ï¼&apos;, &apos;5&apos;, &apos;è¿›è¡Œ&apos;, &apos;å¸‚åœº&apos;, &apos;ä¸»è¦&apos;, &apos;æˆ‘ä»¬&apos;, &apos;ä»¥&apos;, &apos;å&apos;, &apos;ç¾å›½&apos;, &apos;äº”ä¸€&apos;, &apos;è®©&apos;, &apos;æ”¯ä»˜&apos;, &apos;é»„é‡‘å‘¨&apos;, &apos;å¢é•¿&apos;, &apos;å¹¶&apos;, &apos;æˆä¸º&apos;, &apos;æœ€&apos;]</span><br><span class="line">71</span><br><span class="line">19</span><br><span class="line">71</span><br><span class="line">19</span><br></pre></td></tr></table></figure><h2 id="åœç”¨è¯æ–‡ä»¶å»é‡"><a href="#åœç”¨è¯æ–‡ä»¶å»é‡" class="headerlink" title="åœç”¨è¯æ–‡ä»¶å»é‡"></a>åœç”¨è¯æ–‡ä»¶å»é‡</h2><p>è¿™ä¸ªåœç”¨è¯æ–‡ä»¶ä¸æ˜¯å¾ˆå®˜æ–¹ï¼Œæ‰€ä»¥éœ€è¦æ¸…æ´—ä¸‹</p><p>In [140]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ç²—æš´çš„è¯å»é‡</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_word_set</span><span class="params">(words_file)</span>:</span></span><br><span class="line">    words_set = set() <span class="comment"># é›†åˆæ ¼å¼</span></span><br><span class="line">    <span class="keyword">with</span> open(words_file, <span class="string">'r'</span>) <span class="keyword">as</span> fp:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> fp.readlines(): <span class="comment"># å¾ªç¯å–å‡ºæ¯ä¸€è¡Œ</span></span><br><span class="line">            word = line.strip()</span><br><span class="line">            <span class="comment"># line.strip() å½“()ä¸ºç©ºæ—¶ï¼Œé»˜è®¤åˆ é™¤ç©ºç™½ç¬¦ï¼ˆåŒ…æ‹¬'\n','\r','\t',' ')</span></span><br><span class="line">            <span class="keyword">if</span> len(word)&gt;<span class="number">0</span> <span class="keyword">and</span> word <span class="keyword">not</span> <span class="keyword">in</span> words_set: <span class="comment"># å»é‡</span></span><br><span class="line">                words_set.add(word)</span><br><span class="line">    <span class="keyword">return</span> words_set</span><br></pre></td></tr></table></figure><p>In [145]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ç”Ÿæˆstopwords_set</span></span><br><span class="line">stopwords_file = <span class="string">'./stopwords_cn.txt'</span> <span class="comment"># åœç”¨è¯åˆ—è¡¨æ–‡ä»¶</span></span><br><span class="line">stopwords_set = make_word_set(stopwords_file) <span class="comment"># é¦–å…ˆåœç”¨è¯å»é‡</span></span><br><span class="line">print(len(stopwords_set))</span><br><span class="line">print(stopwords_set)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">428</span><br><span class="line">&#123;&apos;å¾—äº†&apos;, &apos;è¿˜æ˜¯&apos;, &apos;æ‰€åœ¨&apos;, &apos;ä¸ºæ­¤&apos;, &apos;å¦‚åŒä¸‹&apos;, &apos;å¹¶ä¸”&apos;, &apos;è®¸å¤š&apos;, &apos;ä½†&apos;, &apos;ä¸å°½ç„¶&apos;, &apos;æ— &apos;, &apos;å´&apos;, &apos;æ‰€&apos;, &apos;æ®æ­¤&apos;, &apos;åˆ†åˆ«&apos;, &apos;å‘&apos;, &apos;éµç…§&apos;, &apos;å¤šä¼š&apos;, &apos;è€Œå&apos;, &apos;å¦‚ä¸‹&apos;, &apos;å†æœ‰&apos;, &apos;çš„ç¡®&apos;, &apos;æ­¤å¤–&apos;, &apos;è·&apos;, &apos;è€Œå·²&apos;, &apos;ä½•å¤„&apos;, &apos;åœ¨äº&apos;, &apos;è¯´æ¥&apos;, &apos;ä¸æ–™&apos;, &apos;ä¸”&apos;, &apos;äº&apos;, &apos;äº¦&apos;, &apos;ä¸å•&apos;, &apos;è€Œæ˜¯&apos;, &apos;æœ¬äºº&apos;, &apos;æ­£å¦‚&apos;, &apos;å‰è€…&apos;, &apos;åˆ«&apos;, &apos;æ‰èƒ½&apos;, &apos;å•¦&apos;, &apos;åªå› &apos;, &apos;å—åˆ°&apos;, &apos;ç”šè‡³äº&apos;, &apos;å¦ä¸€æ–¹é¢&apos;, &apos;æ­¤&apos;, &apos;åªæœ‰&apos;, &apos;å¯æ˜¯&apos;, &apos;æ‚¨&apos;, &apos;åˆ«çš„&apos;, &apos;åˆ«å¤„&apos;, &apos;äº›&apos;, &apos;æˆ–&apos;, &apos;ä¸è®º&apos;, &apos;è¿™ä¼š&apos;, &apos;å…¶å®ƒ&apos;, &apos;å†µä¸”&apos;, &apos;æœ‰&apos;, &apos;æ­¤æ¬¡&apos;, &apos;å› æ­¤&apos;, &apos;å»&apos;, &apos;æ¯‹å®&apos;, &apos;å®ƒä»¬&apos;, &apos;æ ¹æ®&apos;, &apos;åŸºäº&apos;, &apos;å½“åœ°&apos;, &apos;ä¾æ®&apos;, &apos;ç„¶è€Œ&apos;, &apos;è™½ç„¶&apos;, &apos;å› ä¸º&apos;, &apos;ä»è€Œ&apos;, &apos;å¯¹æ¯”&apos;, &apos;æ€&apos;, &apos;ä»¥ä¸Š&apos;, &apos;è¯¸å¦‚&apos;, &apos;å€˜è‹¥&apos;, &apos;ä¸€äº›&apos;, &apos;å¦åˆ™&apos;, &apos;æ‰€ä»¥&apos;, &apos;é‚£è¾¹&apos;, &apos;æ¯&apos;, &apos;å¹¶é&apos;, &apos;ä¹‹&apos;, &apos;å¦&apos;, &apos;ç®€è¨€ä¹‹&apos;, &apos;åªé™&apos;, &apos;è¿åŒ&apos;, &apos;åä¹‹&apos;, &apos;è¿™èˆ¬&apos;, &apos;å‡ &apos;, &apos;å¾€&apos;, &apos;æ˜¯&apos;, &apos;æ—¢&apos;, &apos;å„è‡ª&apos;, &apos;è¯¥&apos;, &apos;å› ä¹‹&apos;, &apos;å¾—&apos;, &apos;æ¥&apos;, &apos;ä¸ç„¶&apos;, &apos;ä¹ˆ&apos;, &apos;ç”šè‡³&apos;, &apos;ä¸º&apos;, &apos;å¤„åœ¨&apos;, &apos;å…¨éƒ¨&apos;, &apos;å¦‚ä¸Š&apos;, &apos;æŒ‰ç…§&apos;, &apos;åŠ ä¹‹&apos;, &apos;ä»‹äº&apos;, &apos;æ­£å·§&apos;, &apos;å¥½&apos;, &apos;ä¼¼çš„&apos;, &apos;ä¸è¿‡&apos;, &apos;æœ‰äº›&apos;, &apos;é‚£æ ·&apos;, &apos;æ­¤åœ°&apos;, &apos;å‡¡æ˜¯&apos;, &apos;æ¯å½“&apos;, &apos;ä¸æ˜¯&apos;, &apos;ä¸‡ä¸€&apos;, &apos;ç”±äº&apos;, &apos;æ›¾&apos;, &apos;è€Œ&apos;, &apos;ç…§ç€&apos;, &apos;ä¾ç…§&apos;, &apos;å½¼æ—¶&apos;, &apos;å°±è¦&apos;, &apos;ç„¶å&apos;, &apos;ä»¥ä¸º&apos;, &apos;åªéœ€&apos;, &apos;ä¸ºä½•&apos;, &apos;è°&apos;, &apos;åˆ°&apos;, &apos;ä¸ä»…ä»…&apos;, &apos;æ—¢ç„¶&apos;, &apos;å½“ç„¶&apos;, &apos;èµ·&apos;, &apos;å—¡&apos;, &apos;æ­¤é—´&apos;, &apos;æœç„¶&apos;, &apos;ä¸å¦&apos;, &apos;éš&apos;, &apos;å› &apos;, &apos;å€¼æ­¤&apos;, &apos;å³ä¾¿&apos;, &apos;æ ¼é‡Œæ–¯&apos;, &apos;è¶ç€&apos;, &apos;è¦ä¸ç„¶&apos;, &apos;é‚£ä¸ª&apos;, &apos;è‡³äº&apos;, &apos;ä¹ƒ&apos;, &apos;éšå&apos;, &apos;æœ‰æ—¶&apos;, &apos;ä½•å†µ&apos;, &apos;å½“&apos;, &apos;ä½¿&apos;, &apos;åªæ˜¯&apos;, &apos;ä¸ºç€&apos;, &apos;å¯è§&apos;, &apos;å³ä½¿&apos;, &apos;ä»¥æ¥&apos;, &apos;ç€&apos;, &apos;å§&apos;, &apos;æˆªè‡³&apos;, &apos;ä¸ª&apos;, &apos;ä¸ºä»€ä¹ˆ&apos;, &apos;ç”¨&apos;, &apos;é™¤å¤–&apos;, &apos;ä»–ä»¬&apos;, &apos;éšæ—¶&apos;, &apos;è¿™äº›&apos;, &apos;è¿˜&apos;, &apos;äº†&apos;, &apos;è¿˜æœ‰&apos;, &apos;å•¥&apos;, &apos;ç”šè€Œ&apos;, &apos;ä»–&apos;, &apos;ä½†æ˜¯&apos;, &apos;å¹¶ä¸&apos;, &apos;æŸæŸ&apos;, &apos;å¦‚æœè¯´&apos;, &apos;ä»&apos;, &apos;å„&apos;, &apos;åˆ«äºº&apos;, &apos;è¶&apos;, &apos;è¿™é‡Œ&apos;, &apos;åˆ«è¯´&apos;, &apos;ä»¥&apos;, &apos;ä¸å…‰&apos;, &apos;å…¶æ¬¡&apos;, &apos;å°±ç®—&apos;, &apos;æ²¿ç€&apos;, &apos;å¦‚æœ&apos;, &apos;å¤§å®¶&apos;, &apos;æœç€&apos;, &apos;æ­£æ˜¯&apos;, &apos;å¯¹å¾…&apos;, &apos;è‡ªå·±&apos;, &apos;ä¸å°½&apos;, &apos;è™½&apos;, &apos;æœ‰å…³&apos;, &apos;æ›¿ä»£&apos;, &apos;å“Ÿ&apos;, &apos;å¯¹äº&apos;, &apos;ä»¥åŠ&apos;, &apos;è¿™å„¿&apos;, &apos;åŠ ä»¥&apos;, &apos;ä¸€&apos;, &apos;ä¸å¤–ä¹&apos;, &apos;å°½ç®¡å¦‚æ­¤&apos;, &apos;ä¸ªåˆ«&apos;, &apos;å†åˆ™&apos;, &apos;å“ª&apos;, &apos;å¥¹&apos;, &apos;é™¤æ­¤&apos;, &apos;ä¹Ÿ&apos;, &apos;è‡ªèº«&apos;, &apos;ç”¨æ¥&apos;, &apos;ä¸&apos;, &apos;ä»€ä¹ˆ&apos;, &apos;äººä»¬&apos;, &apos;ä¾¿äº&apos;, &apos;åˆ&apos;, &apos;æ­¤å¤„&apos;, &apos;éä½†&apos;, &apos;å¦‚ä½•&apos;, &apos;å“‡&apos;, &apos;é‚£é‡Œ&apos;, &apos;åªæ¶ˆ&apos;, &apos;æ—¢æ˜¯&apos;, &apos;å‡­&apos;, &apos;çš„&apos;, &apos;æ•…è€Œ&apos;, &apos;æ‰“&apos;, &apos;å˜»å˜»&apos;, &apos;å¯¹æ–¹&apos;, &apos;è°äºº&apos;, &apos;ä¹ƒè‡³&apos;, &apos;ä»¥è‡³&apos;, &apos;å†&apos;, &apos;ä»€ä¹ˆæ ·&apos;, &apos;ä½•&apos;, &apos;ä»»ä½•&apos;, &apos;æœ€&apos;, &apos;ç”±æ­¤&apos;, &apos;è€Œä¸”&apos;, &apos;è‡ª&apos;, &apos;ç›´åˆ°&apos;, &apos;ä¸ºäº†&apos;, &apos;å›ºç„¶&apos;, &apos;é™¤äº†&apos;, &apos;å‡å¦‚&apos;, &apos;äºº&apos;, &apos;æ‰æ˜¯&apos;, &apos;æ®&apos;, &apos;çš„è¯&apos;, &apos;æ¥è‡ª&apos;, &apos;æœ‰çš„&apos;, &apos;æˆ‘ä»¬&apos;, &apos;ä»æ­¤&apos;, &apos;å…³äº&apos;, &apos;å‘ç€&apos;, &apos;é‚£ä¹ˆ&apos;, &apos;ç»™&apos;, &apos;æˆ–è€…&apos;, &apos;æŸä¸ª&apos;, &apos;ç­‰ç­‰&apos;, &apos;å…‰æ˜¯&apos;, &apos;æ€ä¹ˆæ ·&apos;, &apos;å˜¿å˜¿&apos;, &apos;å¦‚æ­¤&apos;, &apos;åª&apos;, &apos;å¤šå°‘&apos;, &apos;æ¥è¯´&apos;, &apos;é‚£èˆ¬&apos;, &apos;å“ªä¸ª&apos;, &apos;é‚£æ—¶&apos;, &apos;é¦–å…ˆ&apos;, &apos;èµ–ä»¥&apos;, &apos;è¿™è¾¹&apos;, &apos;æˆ‘&apos;, &apos;äºæ˜¯&apos;, &apos;å¦å¤–&apos;, &apos;å¥¹ä»¬&apos;, &apos;å·²&apos;, &apos;ä¸å¦‚&apos;, &apos;å“ªå„¿&apos;, &apos;åŠ&apos;, &apos;åŠè‡³&apos;, &apos;å¾ˆ&apos;, &apos;å¤šä¹ˆ&apos;, &apos;å“ªäº›&apos;, &apos;åˆåŠ&apos;, &apos;å…¶&apos;, &apos;è¿˜è¦&apos;, &apos;æ—¢å¾€&apos;, &apos;ä»¥è‡´&apos;, &apos;æˆ–è€…è¯´&apos;, &apos;å¦‚æ˜¯&apos;, &apos;ä¸ä»…&apos;, &apos;ä¸ºæ­¢&apos;, &apos;æœ¬ç€&apos;, &apos;é‰´äº&apos;, &apos;ä»€ä¹ˆçš„&apos;, &apos;è€Œå¤–&apos;, &apos;è­¬å¦‚&apos;, &apos;é‚£å„¿&apos;, &apos;å’±ä»¬&apos;, &apos;åªè¦&apos;, &apos;å‡­å€Ÿ&apos;, &apos;åè€…&apos;, &apos;åˆ™&apos;, &apos;æ¯”å¦‚&apos;, &apos;ä¸€åˆ‡&apos;, &apos;ä¸ªäºº&apos;, &apos;ä½•ä»¥&apos;, &apos;é‚£&apos;, &apos;å’±&apos;, &apos;ä¸Š&apos;, &apos;åœ¨&apos;, &apos;å¦‚è‹¥&apos;, &apos;ä»–äºº&apos;, &apos;ä¸€æ—¦&apos;, &apos;å“ªæ€•&apos;, &apos;è¿™æ ·&apos;, &apos;åªé™äº&apos;, &apos;ä»&apos;, &apos;ä¹‹æ‰€ä»¥&apos;, &apos;æ‰€æœ‰&apos;, &apos;æˆ–æ˜¯&apos;, &apos;è¯¸ä½&apos;, &apos;æ€»ä¹‹&apos;, &apos;æ€ä¹ˆåŠ&apos;, &apos;å…¶ä¸­&apos;, &apos;æ€ä¹ˆ&apos;, &apos;è‹¥&apos;, &apos;ä½œä¸º&apos;, &apos;æ€æ ·&apos;, &apos;æœ¬èº«&apos;, &apos;å‡¡&apos;, &apos;è¿å¸¦&apos;, &apos;ç”±&apos;, &apos;ä¸ç®¡&apos;, &apos;ä¸ä½†&apos;, &apos;åªæ€•&apos;, &apos;å’Œ&apos;, &apos;çœ‹&apos;, &apos;åŒ&apos;, &apos;æŠŠ&apos;, &apos;å®å¯&apos;, &apos;é‚£äº›&apos;, &apos;å½¼æ­¤&apos;, &apos;ä¸åª&apos;, &apos;å”¯æœ‰&apos;, &apos;ç»§è€Œ&apos;, &apos;å‘µå‘µ&apos;, &apos;æ­£å€¼&apos;, &apos;è‡³&apos;, &apos;ä½ ä»¬&apos;, &apos;ä¸‹&apos;, &apos;è·Ÿ&apos;, &apos;é’ˆå¯¹&apos;, &apos;å¹¶&apos;, &apos;ä»¥å…&apos;, &apos;ä¸è‡³äº&apos;, &apos;ç»è¿‡&apos;, &apos;ä½ &apos;, &apos;å°±æ˜¯&apos;, &apos;è™½è¯´&apos;, &apos;å°&apos;, &apos;ä¸å…¶&apos;, &apos;è‡³ä»Š&apos;, &apos;ä¸€æ¥&apos;, &apos;è®©&apos;, &apos;ä»¬&apos;, &apos;å³&apos;, &apos;è¯¸&apos;, &apos;è¦ä¸&apos;, &apos;æ²¿&apos;, &apos;å‡ºæ¥&apos;, &apos;ä¸¤è€…&apos;, &apos;æ­¤æ—¶&apos;, &apos;éµå¾ª&apos;, &apos;å¦‚&apos;, &apos;è¿™&apos;, &apos;è¿™ä¹ˆ&apos;, &apos;å‡ºäº&apos;, &apos;è¾ƒä¹‹&apos;, &apos;æ¯”&apos;, &apos;å˜›&apos;, &apos;æŸäº›&apos;, &apos;ä»¥ä¾¿&apos;, &apos;å¯ä»¥&apos;, &apos;è‹¥é&apos;, &apos;å„ä½&apos;, &apos;ä»Š&apos;, &apos;é€æ­¥&apos;, &apos;è¿™ä¸ª&apos;, &apos;å®ƒ&apos;, &apos;ä¾‹å¦‚&apos;, &apos;å…¶ä»–&apos;, &apos;åè€Œ&apos;, &apos;å°±æ˜¯è¯´&apos;, &apos;éšç€&apos;, &apos;è‡´&apos;, &apos;åŒæ—¶&apos;, &apos;å¯&apos;, &apos;è¢«&apos;, &apos;æ¥ç€&apos;, &apos;é &apos;, &apos;é™¤é&apos;, &apos;æŸ&apos;, &apos;å&apos;, &apos;å°”&apos;, &apos;å…¶ä½™&apos;, &apos;ä¸&apos;, &apos;å…¨ä½“&apos;, &apos;ä»æ—§&apos;, &apos;è¿›è€Œ&apos;, &apos;å„¿&apos;, &apos;è‡ªä»&apos;, &apos;å¼€å¤–&apos;, &apos;æ‹¿&apos;, &apos;è¦æ˜¯&apos;, &apos;æ— è®º&apos;, &apos;è¦ä¹ˆ&apos;, &apos;è‹¥æ˜¯&apos;, &apos;å› è€Œ&apos;, &apos;æœ¬åœ°&apos;, &apos;å°½ç®¡&apos;, &apos;ä½•æ—¶&apos;&#125;</span><br></pre></td></tr></table></figure><h2 id="è¯è¢‹ä¸­é€‰å–æœ‰ä»£è¡¨æ€§çš„ç‰¹å¾è¯"><a href="#è¯è¢‹ä¸­é€‰å–æœ‰ä»£è¡¨æ€§çš„ç‰¹å¾è¯" class="headerlink" title="è¯è¢‹ä¸­é€‰å–æœ‰ä»£è¡¨æ€§çš„ç‰¹å¾è¯"></a>è¯è¢‹ä¸­é€‰å–æœ‰ä»£è¡¨æ€§çš„ç‰¹å¾è¯</h2><p>ç¬¬ä¸€æ­¥ç”Ÿæˆçš„è¯è¢‹é‡Œæœ‰å¾ˆå¤šé€šç”¨çš„ã€æ— æ„ä¹‰çš„è¯è¯­ï¼Œéœ€è¦å»æ‰ã€‚<br>æœ‰ä»£è¡¨æ€§çš„è¯è¯­å¾ˆå¤§æ¦‚ç‡æ˜¯ä¸€äº›å¯¹æœ€ç»ˆç±»åˆ«åŒºåˆ†æœ‰ä½œç”¨çš„è¯è¯­ã€‚å¹¶ä¸”åé¢è¿™äº›è¯è¯­ä¼šä½œä¸ºç‰¹å¾ä½œä¸ºæ¨¡å‹çš„è¾“å…¥ã€‚</p><p>In [125]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">words_dict</span><span class="params">(all_words_list, deleteN, stopwords_set=set<span class="params">()</span>)</span>:</span></span><br><span class="line">    <span class="comment"># é€‰å–ç‰¹å¾è¯</span></span><br><span class="line">    feature_words = []</span><br><span class="line">    n = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(deleteN, len(all_words_list), <span class="number">1</span>):</span><br><span class="line">        <span class="comment"># å¾ªç¯æ—¶ä»ç¬¬20ä¸ªå¼€å§‹ï¼Œä¹Ÿå°±æ˜¯èˆå¼ƒå‰20ä¸ªè¯è¯­</span></span><br><span class="line">        <span class="keyword">if</span> n &gt; <span class="number">1000</span>: <span class="comment"># feature_wordsçš„ç»´åº¦1000</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">            </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> all_words_list[t].isdigit() <span class="keyword">and</span> \</span><br><span class="line">        all_words_list[t] <span class="keyword">not</span> <span class="keyword">in</span> stopwords_set <span class="keyword">and</span> \</span><br><span class="line">        <span class="number">1</span>&lt;len(all_words_list[t])&lt;<span class="number">5</span>:</span><br><span class="line">        <span class="comment"># isdigit() æ–¹æ³•æ£€æµ‹å­—ç¬¦ä¸²æ˜¯å¦åªç”±æ•°å­—ç»„æˆ,è¿”å›Trueå’ŒFalse</span></span><br><span class="line">        <span class="comment"># æ»¡è¶³ä¸‰ä¸ªæ¡ä»¶ï¼šä¸æ˜¯æ•°å­—ï¼›ä¸åœ¨åœç”¨è¯è¡¨ï¼›é•¿åº¦2ï½4</span></span><br><span class="line">            feature_words.append(all_words_list[t])</span><br><span class="line">            n += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> feature_words</span><br></pre></td></tr></table></figure><p>In [149]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">deleteN = <span class="number">20</span> </span><br><span class="line"><span class="comment"># åˆ é™¤å‰20ä¸ªè¯è¯­,å¯ä»¥è°ƒæ•´è¿™ä¸ªæ•°å€¼</span></span><br><span class="line"><span class="comment"># è¶Šé å‰çš„è¯è¯­å‡ºç°çš„è¶Šé¢‘ç¹ï¼Œæœ‰å¯èƒ½æ‰€æœ‰ç±»åˆ«ä¸­éƒ½å‡ºç°å¾ˆå¤šæ¬¡ï¼Œè¿™ç±»è¯è¯­æ˜¯å¯ä»¥å»æ‰çš„ã€‚</span></span><br><span class="line">feature_words = words_dict(all_words_list, deleteN, stopwords_set)=</span><br><span class="line">print(feature_words[:<span class="number">100</span>])</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&apos;æ¸¸å®¢&apos;, &apos;æ—…æ¸¸&apos;, &apos;å¯¼å¼¹&apos;, &apos;å¤§é™†&apos;, &apos;ä¸€ä¸ª&apos;, &apos;å…¬å¸&apos;, &apos;ç«ç‚®&apos;, &apos;è€ƒç”Ÿ&apos;, &apos;å°å†›&apos;, &apos;è®¤ä¸º&apos;, &apos;åŒ—äº¬&apos;, &apos;å·²ç»&apos;, &apos;è§£æ”¾å†›&apos;, &apos;ä¸€ç§&apos;, &apos;æ—¶é—´&apos;, &apos;å„ç§&apos;, &apos;è¿›è¡Œ&apos;, &apos;å¸‚åœº&apos;, &apos;ä¸»è¦&apos;, &apos;ç¾å›½&apos;, &apos;äº”ä¸€&apos;, &apos;æ”¯ä»˜&apos;, &apos;é»„é‡‘å‘¨&apos;, &apos;å¢é•¿&apos;, &apos;æˆä¸º&apos;, &apos;å¤ä¹ &apos;, &apos;å¾ˆå¤š&apos;, &apos;ç›®å‰&apos;, &apos;æ²¡æœ‰&apos;, &apos;è®°è€…&apos;, &apos;é—®é¢˜&apos;, &apos;åˆ†æ&apos;, &apos;è¿œç¨‹&apos;, &apos;ä¸‡äººæ¬¡&apos;, &apos;å°„ç¨‹&apos;, &apos;æ¥å¾…&apos;, &apos;åŸºç¡€&apos;, &apos;éƒ¨åˆ†&apos;, &apos;éƒ¨ç½²&apos;, &apos;ä½œæˆ˜&apos;, &apos;ä¸€å®š&apos;, &apos;é€‰æ‹©&apos;, &apos;è¾…å¯¼ç­&apos;, &apos;è€ƒè¯•&apos;, &apos;è¯æ±‡&apos;, &apos;æŠ€æœ¯&apos;, &apos;æ¯”èµ›&apos;, &apos;æ–‡ç« &apos;, &apos;å®Œå…¨&apos;, &apos;å¯èƒ½&apos;, &apos;æ”¶å…¥&apos;, &apos;å·¥ä½œ&apos;, &apos;æ—¶å€™&apos;, &apos;ä»Šå¹´&apos;, &apos;è¡¨ç¤º&apos;, &apos;æœŸé—´&apos;, &apos;ä¼ä¸š&apos;, &apos;VS&apos;, &apos;èƒ½åŠ›&apos;, &apos;è¾¾åˆ°&apos;, &apos;æ¯•ä¸šç”Ÿ&apos;, &apos;ä¸Šæµ·&apos;, &apos;è¡¨ç°&apos;, &apos;å½±å“&apos;, &apos;æ¯”è¾ƒ&apos;, &apos;äººæ•°&apos;, &apos;ç”¨æˆ·&apos;, &apos;ç›¸å¯¹&apos;, &apos;ä¸“å®¶&apos;, &apos;æœåŠ¡&apos;, &apos;é‡è¦&apos;, &apos;æ‹¥æœ‰&apos;, &apos;éœ€è¦&apos;, &apos;è®­ç»ƒ&apos;, &apos;å¼€å§‹&apos;, &apos;é”€å”®&apos;, &apos;é€šè¿‡&apos;, &apos;é˜µåœ°&apos;, &apos;èµ„æ–™&apos;, &apos;æƒ…å†µ&apos;, &apos;è¦æ±‚&apos;, &apos;é˜…è¯»&apos;, &apos;è€å¸ˆ&apos;, &apos;æ–°æµª&apos;, &apos;å¦å…‹&apos;, &apos;ç½‘ç»œ&apos;, &apos;å†›äº‹&apos;, &apos;è‹±è¯­&apos;, &apos;é¡¹ç›®&apos;, &apos;å†å²&apos;, &apos;è®¾è®¡&apos;, &apos;å‡ ä¹&apos;, &apos;è¿™æ˜¯&apos;, &apos;å†™ä½œ&apos;, &apos;æ—¥æœ¬&apos;, &apos;è€ƒå¤&apos;, &apos;ä¸åŒ&apos;, &apos;æé«˜&apos;, &apos;æ´»åŠ¨&apos;, &apos;å…¬é‡Œ&apos;]</span><br></pre></td></tr></table></figure><h2 id="è®­ç»ƒå’Œæµ‹è¯•é›†ç”Ÿæˆå›ºå®šé•¿åº¦çš„è¯å‘é‡ç‰¹å¾"><a href="#è®­ç»ƒå’Œæµ‹è¯•é›†ç”Ÿæˆå›ºå®šé•¿åº¦çš„è¯å‘é‡ç‰¹å¾" class="headerlink" title="è®­ç»ƒå’Œæµ‹è¯•é›†ç”Ÿæˆå›ºå®šé•¿åº¦çš„è¯å‘é‡ç‰¹å¾"></a>è®­ç»ƒå’Œæµ‹è¯•é›†ç”Ÿæˆå›ºå®šé•¿åº¦çš„è¯å‘é‡ç‰¹å¾</h2><p>è¿™æ­¥ä¸ºåé¢æ•°æ®è¾“å…¥è¿›è´å¶æ–¯æ¨¡å‹è®­ç»ƒåšå‡†å¤‡ã€‚</p><p>å› ä¸ºæ–‡æœ¬é•¿åº¦ä¸ä¸€ï¼Œæ‰€ä»¥æ¯ä¸ªæ ·æœ¬éœ€è¦å›ºå®šå¥½ç»´åº¦ï¼Œæ‰èƒ½å–‚ç»™æ¨¡å‹è®­ç»ƒã€‚</p><p>In [153]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æ–‡æœ¬ç‰¹å¾</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">text_features</span><span class="params">(train_data_list, test_data_list, feature_words, flag=<span class="string">'nltk'</span>)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">text_features</span><span class="params">(text, feature_words)</span>:</span> <span class="comment"># textçš„å®šä¹‰åœ¨ä¸‹é¢</span></span><br><span class="line">        text_words = set(text) <span class="comment"># æ ·æœ¬å»é‡</span></span><br><span class="line">        <span class="comment">## -----------------------------------------------------------------------------------</span></span><br><span class="line">        <span class="keyword">if</span> flag == <span class="string">'nltk'</span>:</span><br><span class="line">            <span class="comment">## nltkç‰¹å¾ dict</span></span><br><span class="line">            features = &#123;word:<span class="number">1</span> <span class="keyword">if</span> word <span class="keyword">in</span> text_words <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> word <span class="keyword">in</span> feature_words&#125;</span><br><span class="line"><span class="comment"># éå†æ¯ä¸ªæ ·æœ¬è¯è¯­ï¼Œå‡¡æ˜¯æ ·æœ¬çš„è¯è¯­å‡ºç°åœ¨1000ä¸ªç‰¹å¾è¯é‡Œï¼Œå°±è®°å½•ä¸‹æ¥ï¼Œä¿å­˜ä¸ºå­—å…¸æ ¼å¼ï¼Œé”®ä¸ºè¯è¯­ï¼Œå€¼ä¸º1ï¼Œå¦åˆ™å€¼ä¸º0ã€‚</span></span><br><span class="line">            </span><br><span class="line">        <span class="keyword">elif</span> flag == <span class="string">'sklearn'</span>:</span><br><span class="line">            <span class="comment">## sklearnç‰¹å¾ list</span></span><br><span class="line">            features = [<span class="number">1</span> <span class="keyword">if</span> word <span class="keyword">in</span> text_words <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> word <span class="keyword">in</span> feature_words] </span><br><span class="line"><span class="comment"># åŒä¸Šï¼Œéå†æ¯ä¸ªæ ·æœ¬è¯è¯­ï¼Œç»“æœä¸æ˜¯å­—å…¸ï¼Œå‡ºç°å³ä¸º1ï¼Œä¸å‡ºç°ä¸º0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            features = []</span><br><span class="line">        <span class="comment">## -----------------------------------------------------------------------------------</span></span><br><span class="line">        <span class="keyword">return</span> features</span><br><span class="line">    train_feature_list = [text_features(text, feature_words) <span class="keyword">for</span> text <span class="keyword">in</span> train_data_list]</span><br><span class="line">    <span class="comment"># textä¸ºæ¯ä¸€ä¸ªè®­ç»ƒçš„æ ·æœ¬ï¼Œè¿”å›å€¼æ˜¯äºŒç»´åˆ—è¡¨</span></span><br><span class="line">    </span><br><span class="line">    test_feature_list = [text_features(text, feature_words) <span class="keyword">for</span> text <span class="keyword">in</span> test_data_list]</span><br><span class="line">    <span class="comment"># trainä¸ºæ¯ä¸€ä¸ªæµ‹è¯•æ ·æœ¬ï¼Œè¿”å›å€¼æ˜¯äºŒç»´åˆ—è¡¨</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> train_feature_list, test_feature_list</span><br></pre></td></tr></table></figure><p>In [169]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">flag = <span class="string">'sklearn'</span></span><br><span class="line">train_feature_list, test_feature_list = \</span><br><span class="line">text_features(train_data_list, test_data_list, feature_words, flag)</span><br><span class="line">print(len(train_feature_list)) <span class="comment">#</span></span><br><span class="line">print(len(test_feature_list))  <span class="comment"># </span></span><br><span class="line">print(len(test_feature_list[<span class="number">5</span>])) <span class="comment"># æ¯ä¸ªæ ·æœ¬çš„ç»´åº¦éƒ½æ˜¯1000 </span></span><br><span class="line">print(test_feature_list[<span class="number">5</span>][<span class="number">0</span>:<span class="number">100</span>]) <span class="comment"># æ‰“å°æµ‹è¯•é›†çš„ç¬¬5ä¸ªæ ·æœ¬çš„å‰100ä¸ªå€¼</span></span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">71</span><br><span class="line">19</span><br><span class="line">1000</span><br><span class="line">[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</span><br></pre></td></tr></table></figure><h2 id="è´å¶æ–¯æ¨¡å‹å¼€å§‹è®­ç»ƒå’Œé¢„æµ‹"><a href="#è´å¶æ–¯æ¨¡å‹å¼€å§‹è®­ç»ƒå’Œé¢„æµ‹" class="headerlink" title="è´å¶æ–¯æ¨¡å‹å¼€å§‹è®­ç»ƒå’Œé¢„æµ‹"></a>è´å¶æ–¯æ¨¡å‹å¼€å§‹è®­ç»ƒå’Œé¢„æµ‹</h2><p>In [176]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ†ç±»ï¼ŒåŒæ—¶è¾“å‡ºå‡†ç¡®ç‡ç­‰</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">text_classifier</span><span class="params">(train_feature_list, test_feature_list, </span></span></span><br><span class="line"><span class="function"><span class="params">                    train_class_list, test_class_list, flag=<span class="string">'nltk'</span>)</span>:</span></span><br><span class="line">    <span class="comment">## -----------------------------------------------------------------------------------</span></span><br><span class="line">    <span class="keyword">if</span> flag == <span class="string">'nltk'</span>:</span><br><span class="line">        <span class="comment">## ä½¿ç”¨nltkåˆ†ç±»å™¨</span></span><br><span class="line">        train_flist = zip(train_feature_list, train_class_list)</span><br><span class="line">        train_flist = list(train_flist) </span><br><span class="line">        test_flist = zip(test_feature_list, test_class_list)</span><br><span class="line">        train_flist = list(test_flist) </span><br><span class="line">        classifier = nltk.classify.NaiveBayesClassifier.train(train_flist)</span><br><span class="line">        test_accuracy = nltk.classify.accuracy(classifier, test_flist)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">elif</span> flag == <span class="string">'sklearn'</span>:</span><br><span class="line">        <span class="comment">## sklearnåˆ†ç±»å™¨</span></span><br><span class="line">        classifier = MultinomialNB().fit(train_feature_list, train_class_list)</span><br><span class="line">        <span class="comment"># MultinomialNB()çš„ä½¿ç”¨æ–¹æ³•å’Œå‚æ•°è§ï¼šhttps://www.cnblogs.com/pinard/p/6074222.html</span></span><br><span class="line">        </span><br><span class="line">        test_accuracy = classifier.score(test_feature_list, test_class_list)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        test_accuracy = []</span><br><span class="line">    <span class="keyword">return</span> test_accuracy</span><br></pre></td></tr></table></figure><p>In [177]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">flag=&apos;sklearn&apos;</span><br><span class="line">test_accuracy = text_classifier(train_feature_list, test_feature_list, </span><br><span class="line">                                    train_class_list, test_class_list, flag)</span><br><span class="line">print(test_accuracy)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.7368421052631579</span><br></pre></td></tr></table></figure><h2 id="å¯è§†åŒ–"><a href="#å¯è§†åŒ–" class="headerlink" title="å¯è§†åŒ–"></a>å¯è§†åŒ–</h2><p>è¿™æ­¥è°ƒå‚ï¼ŒæŸ¥çœ‹ä¸åŒçš„deleteNså¯¹æ¨¡å‹æ•ˆæœçš„å½±å“</p><p>In [179]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> (<span class="string">"start"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## æ–‡æœ¬é¢„å¤„ç†</span></span><br><span class="line">folder_path = <span class="string">'./Database/SogouC/Sample'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">all_words_list, train_data_list, test_data_list, train_class_list, test_class_list = text_processing(folder_path, test_size=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ç”Ÿæˆstopwords_set</span></span><br><span class="line">stopwords_file = <span class="string">'./stopwords_cn.txt'</span></span><br><span class="line">stopwords_set = make_word_set(stopwords_file)</span><br><span class="line"></span><br><span class="line"><span class="comment">## æ–‡æœ¬ç‰¹å¾æå–å’Œåˆ†ç±»</span></span><br><span class="line"><span class="comment"># flag = 'nltk'</span></span><br><span class="line">flag = <span class="string">'sklearn'</span></span><br><span class="line">deleteNs = range(<span class="number">0</span>, <span class="number">1000</span>, <span class="number">20</span>)</span><br><span class="line">test_accuracy_list = []</span><br><span class="line"><span class="keyword">for</span> deleteN <span class="keyword">in</span> deleteNs:</span><br><span class="line">    <span class="comment"># feature_words = words_dict(all_words_list, deleteN)</span></span><br><span class="line">    feature_words = words_dict(all_words_list, deleteN, stopwords_set)</span><br><span class="line">    train_feature_list, test_feature_list = text_features(train_data_list, test_data_list, feature_words, flag)</span><br><span class="line">    test_accuracy = text_classifier(train_feature_list, test_feature_list, train_class_list, test_class_list, flag)</span><br><span class="line">    test_accuracy_list.append(test_accuracy)</span><br><span class="line"><span class="keyword">print</span> (test_accuracy_list)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ç»“æœè¯„ä»·</span></span><br><span class="line"><span class="comment">#plt.figure()</span></span><br><span class="line">plt.plot(deleteNs, test_accuracy_list)</span><br><span class="line">plt.title(<span class="string">'Relationship of deleteNs and test_accuracy'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'deleteNs'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'test_accuracy'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment">#plt.savefig('result.png')</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (<span class="string">"finished"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">start</span><br><span class="line">[0.6842105263157895, 0.6842105263157895, 0.7368421052631579, 0.7368421052631579, 0.7368421052631579, 0.7368421052631579, 0.7368421052631579, 0.6842105263157895, 0.6842105263157895, 0.6842105263157895, 0.6842105263157895, 0.6842105263157895, 0.6842105263157895, 0.7368421052631579, 0.7368421052631579, 0.7894736842105263, 0.7368421052631579, 0.7368421052631579, 0.7368421052631579, 0.7368421052631579, 0.7368421052631579, 0.7894736842105263, 0.7894736842105263, 0.7894736842105263, 0.7894736842105263, 0.7894736842105263, 0.7894736842105263, 0.7894736842105263, 0.7894736842105263, 0.7368421052631579, 0.6842105263157895, 0.6842105263157895, 0.6842105263157895, 0.7368421052631579, 0.7368421052631579, 0.6842105263157895, 0.7368421052631579, 0.6842105263157895, 0.6842105263157895, 0.7368421052631579, 0.6842105263157895, 0.631578947368421, 0.6842105263157895, 0.6842105263157895, 0.7368421052631579, 0.7894736842105263, 0.7894736842105263, 0.7368421052631579, 0.7368421052631579, 0.7894736842105263]</span><br></pre></td></tr></table></figure><p><img src="data:image/png;base64,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" alt="img"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">finished</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jiaba </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>æœºå™¨å­¦ä¹ åŸºæœ¬æ¦‚å¿µ</title>
      <link href="/2019/08/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"/>
      <url>/2019/08/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</url>
      
        <content type="html"><![CDATA[<h2 id="æœºå™¨å­¦ä¹ åŸºæœ¬æ¦‚å¿µ"><a href="#æœºå™¨å­¦ä¹ åŸºæœ¬æ¦‚å¿µ" class="headerlink" title="æœºå™¨å­¦ä¹ åŸºæœ¬æ¦‚å¿µ"></a>æœºå™¨å­¦ä¹ åŸºæœ¬æ¦‚å¿µ</h2><p><strong>1  æœºå™¨å­¦ä¹ </strong></p><p><strong>1.1 æœºå™¨å­¦ä¹ çš„å®šä¹‰</strong></p><p>æ­£å¦‚æˆ‘ä»¬æ ¹æ®è¿‡å»çš„ç»éªŒæ¥åˆ¤æ–­æ˜å¤©çš„å¤©æ°”ï¼Œåƒè´§ä»¬å¸Œæœ›ä»è´­ä¹°ç»éªŒä¸­æŒ‘é€‰ä¸€ä¸ªå¥½ç“œï¼Œé‚£èƒ½ä¸èƒ½è®©è®¡ç®—æœºå¸®åŠ©äººç±»æ¥å®ç°è¿™ä¸ªå‘¢ï¼Ÿæœºå™¨å­¦ä¹ æ­£æ˜¯è¿™æ ·çš„ä¸€é—¨å­¦ç§‘ï¼Œäººçš„â€œç»éªŒâ€å¯¹åº”è®¡ç®—æœºä¸­çš„â€œæ•°æ®â€ï¼Œè®©è®¡ç®—æœºæ¥å­¦ä¹ è¿™äº›ç»éªŒæ•°æ®ï¼Œç”Ÿæˆä¸€ä¸ªç®—æ³•æ¨¡å‹ï¼Œåœ¨é¢å¯¹æ–°çš„æƒ…å†µä¸­ï¼Œè®¡ç®—æœºä¾¿èƒ½ä½œå‡ºæœ‰æ•ˆçš„åˆ¤æ–­ï¼Œè¿™ä¾¿æ˜¯æœºå™¨å­¦ä¹ ã€‚</p><p>å¦ä¸€æœ¬ç»å…¸æ•™æçš„ä½œè€…Mitchellç»™å‡ºäº†ä¸€ä¸ªå½¢å¼åŒ–çš„å®šä¹‰ï¼Œå‡è®¾ï¼š</p><ul><li>Pï¼šè®¡ç®—æœºç¨‹åºåœ¨æŸä»»åŠ¡ç±»Tä¸Šçš„æ€§èƒ½ã€‚</li><li>Tï¼šè®¡ç®—æœºç¨‹åºå¸Œæœ›å®ç°çš„ä»»åŠ¡ç±»ã€‚</li><li>Eï¼šè¡¨ç¤ºç»éªŒï¼Œå³å†å²çš„æ•°æ®é›†ã€‚</li></ul><p>è‹¥è¯¥è®¡ç®—æœºç¨‹åºé€šè¿‡åˆ©ç”¨ç»éªŒEåœ¨ä»»åŠ¡Tä¸Šè·å¾—äº†æ€§èƒ½Pçš„æ”¹å–„ï¼Œåˆ™ç§°è¯¥ç¨‹åºå¯¹Eè¿›è¡Œäº†å­¦ä¹ ã€‚</p><p><strong>1.2 æœºå™¨å­¦ä¹ çš„ä¸€äº›åŸºæœ¬æœ¯è¯­</strong><br><img src="../img/ml_concepts.png" alt><br>å‡è®¾æˆ‘ä»¬æ”¶é›†äº†ä¸€æ‰¹è¥¿ç“œçš„æ•°æ®ï¼Œä¾‹å¦‚ï¼šï¼ˆè‰²æ³½=é’ç»¿;æ ¹è’‚=èœ·ç¼©;æ•²å£°=æµŠå“)ï¼Œ (è‰²æ³½=ä¹Œé»‘;æ ¹è’‚=ç¨èœ·;æ•²å£°=æ²‰é—·)ï¼Œ (è‰²æ³½=æµ…è‡ª;æ ¹è’‚=ç¡¬æŒº;æ•²å£°=æ¸…è„†)â€¦â€¦æ¯å¯¹æ‹¬å·å†…æ˜¯ä¸€ä¸ªè¥¿ç“œçš„è®°å½•ï¼Œå®šä¹‰ï¼š     </p><ul><li><p>æ‰€æœ‰è®°å½•çš„é›†åˆä¸ºï¼šæ•°æ®é›†ã€‚</p></li><li><p>æ¯ä¸€æ¡è®°å½•ä¸ºï¼šä¸€ä¸ªå®ä¾‹ï¼ˆinstanceï¼‰æˆ–æ ·æœ¬ï¼ˆsampleï¼‰ã€‚</p></li><li><p>ä¾‹å¦‚ï¼šè‰²æ³½æˆ–æ•²å£°ï¼Œå•ä¸ªçš„ç‰¹ç‚¹ä¸ºç‰¹å¾ï¼ˆfeatureï¼‰æˆ–å±æ€§ï¼ˆattributeï¼‰ã€‚</p></li><li><p>å¯¹äºä¸€æ¡è®°å½•ï¼Œå¦‚æœåœ¨åæ ‡è½´ä¸Šè¡¨ç¤ºï¼Œæ¯ä¸ªè¥¿ç“œéƒ½å¯ä»¥ç”¨åæ ‡è½´ä¸­çš„ä¸€ä¸ªç‚¹è¡¨ç¤ºï¼Œä¸€ä¸ªç‚¹ä¹Ÿæ˜¯ä¸€ä¸ªå‘é‡ï¼Œä¾‹å¦‚ï¼ˆé’ç»¿ï¼Œèœ·ç¼©ï¼ŒæµŠå“ï¼‰ï¼Œå³æ¯ä¸ªè¥¿ç“œä¸ºï¼šä¸€ä¸ªç‰¹å¾å‘é‡ï¼ˆfeature vectorï¼‰ã€‚</p></li><li><p>ä¸€ä¸ªæ ·æœ¬çš„ç‰¹å¾æ•°ä¸ºï¼šç»´æ•°ï¼ˆdimensionalityï¼‰ï¼Œè¯¥è¥¿ç“œçš„ä¾‹å­ç»´æ•°ä¸º3ï¼Œå½“ç»´æ•°éå¸¸å¤§æ—¶ï¼Œä¹Ÿå°±æ˜¯ç°åœ¨è¯´çš„â€œç»´æ•°ç¾éš¾â€ã€‚</p><p> è®¡ç®—æœºç¨‹åºå­¦ä¹ ç»éªŒæ•°æ®ç”Ÿæˆç®—æ³•æ¨¡å‹çš„è¿‡ç¨‹ä¸­ï¼Œæ¯ä¸€æ¡è®°å½•ç§°ä¸ºä¸€ä¸ªâ€œè®­ç»ƒæ ·æœ¬â€ï¼ŒåŒæ—¶åœ¨è®­ç»ƒå¥½æ¨¡å‹åï¼Œæˆ‘ä»¬å¸Œæœ›ä½¿ç”¨æ–°çš„æ ·æœ¬æ¥æµ‹è¯•æ¨¡å‹çš„æ•ˆæœï¼Œåˆ™æ¯ä¸€ä¸ªæ–°çš„æ ·æœ¬ç§°ä¸ºä¸€ä¸ªâ€œæµ‹è¯•æ ·æœ¬â€ã€‚å®šä¹‰ï¼š    </p></li><li><p>æ‰€æœ‰è®­ç»ƒæ ·æœ¬çš„é›†åˆä¸ºï¼šè®­ç»ƒé›†ï¼ˆtrainning setï¼‰ï¼Œ[ç‰¹æ®Š]ã€‚</p></li><li><p>æ‰€æœ‰æµ‹è¯•æ ·æœ¬çš„é›†åˆä¸ºï¼šæµ‹è¯•é›†ï¼ˆtest setï¼‰ï¼Œ[ä¸€èˆ¬]ã€‚  </p></li><li><p>æœºå™¨å­¦ä¹ å‡ºæ¥çš„æ¨¡å‹é€‚ç”¨äºæ–°æ ·æœ¬çš„èƒ½åŠ›ä¸ºï¼šæ³›åŒ–èƒ½åŠ›ï¼ˆgeneralizationï¼‰ï¼Œå³ä»ç‰¹æ®Šåˆ°ä¸€èˆ¬ã€‚</p><p> è¥¿ç“œçš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬æ˜¯æƒ³è®¡ç®—æœºé€šè¿‡å­¦ä¹ è¥¿ç“œçš„ç‰¹å¾æ•°æ®ï¼Œè®­ç»ƒå‡ºä¸€ä¸ªå†³ç­–æ¨¡å‹ï¼Œæ¥åˆ¤æ–­ä¸€ä¸ªæ–°çš„è¥¿ç“œæ˜¯å¦æ˜¯å¥½ç“œã€‚å¯ä»¥å¾—çŸ¥æˆ‘ä»¬é¢„æµ‹çš„æ˜¯ï¼šè¥¿ç“œæ˜¯å¥½æ˜¯åï¼Œå³å¥½ç“œä¸å·®ç“œä¸¤ç§ï¼Œæ˜¯ç¦»æ•£å€¼ã€‚åŒæ ·åœ°ï¼Œä¹Ÿæœ‰é€šè¿‡å†å¹´çš„äººå£æ•°æ®ï¼Œæ¥é¢„æµ‹æœªæ¥çš„äººå£æ•°é‡ï¼Œäººå£æ•°é‡åˆ™æ˜¯è¿ç»­å€¼ã€‚å®šä¹‰ï¼š    </p></li><li><p>é¢„æµ‹å€¼ä¸ºç¦»æ•£å€¼çš„é—®é¢˜ä¸ºï¼šåˆ†ç±»ï¼ˆclassificationï¼‰ã€‚</p></li><li><p>é¢„æµ‹å€¼ä¸ºè¿ç»­å€¼çš„é—®é¢˜ä¸ºï¼šå›å½’ï¼ˆregressionï¼‰ã€‚</p><p> æˆ‘ä»¬é¢„æµ‹è¥¿ç“œæ˜¯å¦æ˜¯å¥½ç“œçš„è¿‡ç¨‹ä¸­ï¼Œå¾ˆæ˜æ˜¾å¯¹äºè®­ç»ƒé›†ä¸­çš„è¥¿ç“œï¼Œæˆ‘ä»¬äº‹å…ˆå·²ç»çŸ¥é“äº†è¯¥ç“œæ˜¯å¦æ˜¯å¥½ç“œï¼Œå­¦ä¹ å™¨é€šè¿‡å­¦ä¹ è¿™äº›å¥½ç“œæˆ–å·®ç“œçš„ç‰¹å¾ï¼Œä»è€Œæ€»ç»“å‡ºè§„å¾‹ï¼Œå³è®­ç»ƒé›†ä¸­çš„è¥¿ç“œæˆ‘ä»¬éƒ½åšäº†æ ‡è®°ï¼Œç§°ä¸ºæ ‡è®°ä¿¡æ¯ã€‚ä½†ä¹Ÿæœ‰æ²¡æœ‰æ ‡è®°ä¿¡æ¯çš„æƒ…å½¢ï¼Œä¾‹å¦‚ï¼šæˆ‘ä»¬æƒ³å°†ä¸€å †è¥¿ç“œæ ¹æ®ç‰¹å¾åˆ†æˆä¸¤ä¸ªå°å †ï¼Œä½¿å¾—æŸä¸€å †çš„è¥¿ç“œå°½å¯èƒ½ç›¸ä¼¼ï¼Œå³éƒ½æ˜¯å¥½ç“œæˆ–å·®ç“œï¼Œå¯¹äºè¿™ç§é—®é¢˜ï¼Œæˆ‘ä»¬äº‹å…ˆå¹¶ä¸çŸ¥é“è¥¿ç“œçš„å¥½åï¼Œæ ·æœ¬æ²¡æœ‰æ ‡è®°ä¿¡æ¯ã€‚å®šä¹‰ï¼š    </p></li><li><p>è®­ç»ƒæ•°æ®æœ‰æ ‡è®°ä¿¡æ¯çš„å­¦ä¹ ä»»åŠ¡ä¸ºï¼šç›‘ç£å­¦ä¹ ï¼ˆsupervised learningï¼‰ï¼Œå®¹æ˜“çŸ¥é“ä¸Šé¢æ‰€æè¿°çš„åˆ†ç±»å’Œå›å½’éƒ½æ˜¯ç›‘ç£å­¦ä¹ çš„èŒƒç•´ã€‚</p></li><li><p>è®­ç»ƒæ•°æ®æ²¡æœ‰æ ‡è®°ä¿¡æ¯çš„å­¦ä¹ ä»»åŠ¡ä¸ºï¼šæ— ç›‘ç£å­¦ä¹ ï¼ˆunsupervised learningï¼‰ï¼Œå¸¸è§çš„æœ‰èšç±»å’Œå…³è”è§„åˆ™ã€‚</p></li></ul><p><strong>2  æ¨¡å‹çš„è¯„ä¼°ä¸é€‰æ‹©</strong></p><p><strong>2.1 è¯¯å·®ä¸è¿‡æ‹Ÿåˆ</strong></p><p>æˆ‘ä»¬å°†å­¦ä¹ å™¨å¯¹æ ·æœ¬çš„å®é™…é¢„æµ‹ç»“æœä¸æ ·æœ¬çš„çœŸå®å€¼ä¹‹é—´çš„å·®å¼‚æˆä¸ºï¼šè¯¯å·®ï¼ˆerrorï¼‰ã€‚å®šä¹‰ï¼š    </p><ul><li>åœ¨è®­ç»ƒé›†ä¸Šçš„è¯¯å·®ç§°ä¸ºè®­ç»ƒè¯¯å·®ï¼ˆtraining errorï¼‰æˆ–ç»éªŒè¯¯å·®ï¼ˆempirical errorï¼‰ã€‚</li><li>åœ¨æµ‹è¯•é›†ä¸Šçš„è¯¯å·®ç§°ä¸ºæµ‹è¯•è¯¯å·®ï¼ˆtest errorï¼‰ã€‚</li><li>å­¦ä¹ å™¨åœ¨æ‰€æœ‰æ–°æ ·æœ¬ä¸Šçš„è¯¯å·®ç§°ä¸ºæ³›åŒ–è¯¯å·®ï¼ˆgeneralization errorï¼‰ã€‚</li></ul><p>æ˜¾ç„¶ï¼Œæˆ‘ä»¬å¸Œæœ›å¾—åˆ°çš„æ˜¯åœ¨æ–°æ ·æœ¬ä¸Šè¡¨ç°å¾—å¾ˆå¥½çš„å­¦ä¹ å™¨ï¼Œå³æ³›åŒ–è¯¯å·®å°çš„å­¦ä¹ å™¨ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åº”è¯¥è®©å­¦ä¹ å™¨å°½å¯èƒ½åœ°ä»è®­ç»ƒé›†ä¸­å­¦å‡ºæ™®é€‚æ€§çš„â€œä¸€èˆ¬ç‰¹å¾â€ï¼Œè¿™æ ·åœ¨é‡åˆ°æ–°æ ·æœ¬æ—¶æ‰èƒ½åšå‡ºæ­£ç¡®çš„åˆ¤åˆ«ã€‚ç„¶è€Œï¼Œå½“å­¦ä¹ å™¨æŠŠè®­ç»ƒé›†å­¦å¾—â€œå¤ªå¥½â€çš„æ—¶å€™ï¼Œå³æŠŠä¸€äº›è®­ç»ƒæ ·æœ¬çš„è‡ªèº«ç‰¹ç‚¹å½“åšäº†æ™®éç‰¹å¾ï¼›åŒæ—¶ä¹Ÿæœ‰å­¦ä¹ èƒ½åŠ›ä¸è¶³çš„æƒ…å†µï¼Œå³è®­ç»ƒé›†çš„åŸºæœ¬ç‰¹å¾éƒ½æ²¡æœ‰å­¦ä¹ å‡ºæ¥ã€‚æˆ‘ä»¬å®šä¹‰ï¼š</p><ul><li>å­¦ä¹ èƒ½åŠ›è¿‡å¼ºï¼Œä»¥è‡³äºæŠŠè®­ç»ƒæ ·æœ¬æ‰€åŒ…å«çš„ä¸å¤ªä¸€èˆ¬çš„ç‰¹æ€§éƒ½å­¦åˆ°äº†ï¼Œç§°ä¸ºï¼šè¿‡æ‹Ÿåˆï¼ˆoverfittingï¼‰ã€‚</li><li>å­¦ä¹ èƒ½å¤ªå·®ï¼Œè®­ç»ƒæ ·æœ¬çš„ä¸€èˆ¬æ€§è´¨å°šæœªå­¦å¥½ï¼Œç§°ä¸ºï¼šæ¬ æ‹Ÿåˆï¼ˆunderfittingï¼‰ã€‚</li></ul><p>å¯ä»¥å¾—çŸ¥ï¼šåœ¨è¿‡æ‹Ÿåˆé—®é¢˜ä¸­ï¼Œè®­ç»ƒè¯¯å·®ååˆ†å°ï¼Œä½†æµ‹è¯•è¯¯å·®æ•™å¤§ï¼›åœ¨æ¬ æ‹Ÿåˆé—®é¢˜ä¸­ï¼Œè®­ç»ƒè¯¯å·®å’Œæµ‹è¯•è¯¯å·®éƒ½æ¯”è¾ƒå¤§ã€‚ç›®å‰ï¼Œæ¬ æ‹Ÿåˆé—®é¢˜æ¯”è¾ƒå®¹æ˜“å…‹æœï¼Œä¾‹å¦‚å¢åŠ è¿­ä»£æ¬¡æ•°ç­‰ï¼Œä½†è¿‡æ‹Ÿåˆé—®é¢˜è¿˜æ²¡æœ‰ååˆ†å¥½çš„è§£å†³æ–¹æ¡ˆï¼Œè¿‡æ‹Ÿåˆæ˜¯æœºå™¨å­¦ä¹ é¢ä¸´çš„å…³é”®éšœç¢ã€‚</p><p><img src="https://i.loli.net/2018/10/17/5bc7181172996.png" alt></p><p><strong>2.2 è¯„ä¼°æ–¹æ³•</strong></p><p>åœ¨ç°å®ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬å¾€å¾€æœ‰å¤šç§ç®—æ³•å¯ä¾›é€‰æ‹©ï¼Œé‚£ä¹ˆæˆ‘ä»¬åº”è¯¥é€‰æ‹©å“ªä¸€ä¸ªç®—æ³•æ‰æ˜¯æœ€é€‚åˆçš„å‘¢ï¼Ÿå¦‚ä¸Šæ‰€è¿°ï¼Œæˆ‘ä»¬å¸Œæœ›å¾—åˆ°çš„æ˜¯æ³›åŒ–è¯¯å·®å°çš„å­¦ä¹ å™¨ï¼Œç†æƒ³çš„è§£å†³æ–¹æ¡ˆæ˜¯å¯¹æ¨¡å‹çš„æ³›åŒ–è¯¯å·®è¿›è¡Œè¯„ä¼°ï¼Œç„¶åé€‰æ‹©æ³›åŒ–è¯¯å·®æœ€å°çš„é‚£ä¸ªå­¦ä¹ å™¨ã€‚ä½†æ˜¯ï¼Œæ³›åŒ–è¯¯å·®æŒ‡çš„æ˜¯æ¨¡å‹åœ¨æ‰€æœ‰æ–°æ ·æœ¬ä¸Šçš„é€‚ç”¨èƒ½åŠ›ï¼Œæˆ‘ä»¬æ— æ³•ç›´æ¥è·å¾—æ³›åŒ–è¯¯å·®ã€‚</p><p>å› æ­¤ï¼Œé€šå¸¸æˆ‘ä»¬é‡‡ç”¨ä¸€ä¸ªâ€œæµ‹è¯•é›†â€æ¥æµ‹è¯•å­¦ä¹ å™¨å¯¹æ–°æ ·æœ¬çš„åˆ¤åˆ«èƒ½åŠ›ï¼Œç„¶åä»¥â€œæµ‹è¯•é›†â€ä¸Šçš„â€œæµ‹è¯•è¯¯å·®â€ä½œä¸ºâ€œæ³›åŒ–è¯¯å·®â€çš„è¿‘ä¼¼ã€‚æ˜¾ç„¶ï¼šæˆ‘ä»¬é€‰å–çš„æµ‹è¯•é›†åº”å°½å¯èƒ½ä¸è®­ç»ƒé›†äº’æ–¥ï¼Œä¸‹é¢ç”¨ä¸€ä¸ªå°æ•…äº‹æ¥è§£é‡Šwhyï¼š</p><p>å‡è®¾è€å¸ˆå‡ºäº†10 é“ä¹ é¢˜ä¾›åŒå­¦ä»¬ç»ƒä¹ ï¼Œè€ƒè¯•æ—¶è€å¸ˆåˆç”¨åŒæ ·çš„è¿™10é“é¢˜ä½œä¸ºè¯•é¢˜ï¼Œå¯èƒ½æœ‰çš„ç«¥é‹åªä¼šåšè¿™10 é“é¢˜å´èƒ½å¾—é«˜åˆ†ï¼Œå¾ˆæ˜æ˜¾ï¼šè¿™ä¸ªè€ƒè¯•æˆç»©å¹¶ä¸èƒ½æœ‰æ•ˆåœ°åæ˜ å‡ºçœŸå®æ°´å¹³ã€‚å›åˆ°æˆ‘ä»¬çš„é—®é¢˜ä¸Šæ¥ï¼Œæˆ‘ä»¬å¸Œæœ›å¾—åˆ°æ³›åŒ–æ€§èƒ½å¥½çš„æ¨¡å‹ï¼Œå¥½æ¯”å¸Œæœ›åŒå­¦ä»¬è¯¾ç¨‹å­¦å¾—å¥½å¹¶è·å¾—äº†å¯¹æ‰€å­¦çŸ¥è¯†â€ä¸¾ä¸€åä¸‰â€çš„èƒ½åŠ›ï¼›è®­ç»ƒæ ·æœ¬ç›¸å½“äºç»™åŒå­¦ä»¬ç»ƒä¹ çš„ä¹ é¢˜ï¼Œæµ‹è¯•è¿‡ç¨‹åˆ™ç›¸å½“äºè€ƒè¯•ã€‚æ˜¾ç„¶ï¼Œè‹¥æµ‹è¯•æ ·æœ¬è¢«ç”¨ä½œè®­ç»ƒäº†ï¼Œåˆ™å¾—åˆ°çš„å°†æ˜¯è¿‡äºâ€ä¹è§‚â€çš„ä¼°è®¡ç»“æœã€‚</p><p><strong>2.3 è®­ç»ƒé›†ä¸æµ‹è¯•é›†çš„åˆ’åˆ†æ–¹æ³•</strong></p><p>å¦‚ä¸Šæ‰€è¿°ï¼šæˆ‘ä»¬å¸Œæœ›ç”¨ä¸€ä¸ªâ€œæµ‹è¯•é›†â€çš„â€œæµ‹è¯•è¯¯å·®â€æ¥ä½œä¸ºâ€œæ³›åŒ–è¯¯å·®â€çš„è¿‘ä¼¼ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦å¯¹åˆå§‹æ•°æ®é›†è¿›è¡Œæœ‰æ•ˆåˆ’åˆ†ï¼Œåˆ’åˆ†å‡ºäº’æ–¥çš„â€œè®­ç»ƒé›†â€å’Œâ€œæµ‹è¯•é›†â€ã€‚ä¸‹é¢ä»‹ç»å‡ ç§å¸¸ç”¨çš„åˆ’åˆ†æ–¹æ³•ï¼š</p><p><strong>2.3.1 ç•™å‡ºæ³•</strong></p><p>å°†æ•°æ®é›†Dåˆ’åˆ†ä¸ºä¸¤ä¸ªäº’æ–¥çš„é›†åˆï¼Œä¸€ä¸ªä½œä¸ºè®­ç»ƒé›†Sï¼Œä¸€ä¸ªä½œä¸ºæµ‹è¯•é›†Tï¼Œæ»¡è¶³D=SâˆªTä¸”Sâˆ©T=âˆ…ï¼Œå¸¸è§çš„åˆ’åˆ†ä¸ºï¼šå¤§çº¦2/3-4/5çš„æ ·æœ¬ç”¨ä½œè®­ç»ƒï¼Œå‰©ä¸‹çš„ç”¨ä½œæµ‹è¯•ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼šè®­ç»ƒ/æµ‹è¯•é›†çš„åˆ’åˆ†è¦å°½å¯èƒ½ä¿æŒæ•°æ®åˆ†å¸ƒçš„ä¸€è‡´æ€§ï¼Œä»¥é¿å…ç”±äºåˆ†å¸ƒçš„å·®å¼‚å¼•å…¥é¢å¤–çš„åå·®ï¼Œå¸¸è§çš„åšæ³•æ˜¯é‡‡å–åˆ†å±‚æŠ½æ ·ã€‚åŒæ—¶ï¼Œç”±äºåˆ’åˆ†çš„éšæœºæ€§ï¼Œå•æ¬¡çš„ç•™å‡ºæ³•ç»“æœå¾€å¾€ä¸å¤Ÿç¨³å®šï¼Œä¸€èˆ¬è¦é‡‡ç”¨è‹¥å¹²æ¬¡éšæœºåˆ’åˆ†ï¼Œé‡å¤å®éªŒå–å¹³å‡å€¼çš„åšæ³•ã€‚</p><p><strong>2.3.2 äº¤å‰éªŒè¯æ³•</strong></p><p>å°†æ•°æ®é›†Dåˆ’åˆ†ä¸ºkä¸ªå¤§å°ç›¸åŒçš„äº’æ–¥å­é›†ï¼Œæ»¡è¶³D=D1âˆªD2âˆªâ€¦âˆªDkï¼ŒDiâˆ©Dj=âˆ…ï¼ˆiâ‰ jï¼‰ï¼ŒåŒæ ·åœ°å°½å¯èƒ½ä¿æŒæ•°æ®åˆ†å¸ƒçš„ä¸€è‡´æ€§ï¼Œå³é‡‡ç”¨åˆ†å±‚æŠ½æ ·çš„æ–¹æ³•è·å¾—è¿™äº›å­é›†ã€‚äº¤å‰éªŒè¯æ³•çš„æ€æƒ³æ˜¯ï¼šæ¯æ¬¡ç”¨k-1ä¸ªå­é›†çš„å¹¶é›†ä½œä¸ºè®­ç»ƒé›†ï¼Œä½™ä¸‹çš„é‚£ä¸ªå­é›†ä½œä¸ºæµ‹è¯•é›†ï¼Œè¿™æ ·å°±æœ‰Kç§è®­ç»ƒé›†/æµ‹è¯•é›†åˆ’åˆ†çš„æƒ…å†µï¼Œä»è€Œå¯è¿›è¡Œkæ¬¡è®­ç»ƒå’Œæµ‹è¯•ï¼Œæœ€ç»ˆè¿”å›kæ¬¡æµ‹è¯•ç»“æœçš„å‡å€¼ã€‚äº¤å‰éªŒè¯æ³•ä¹Ÿç§°â€œkæŠ˜äº¤å‰éªŒè¯â€ï¼Œkæœ€å¸¸ç”¨çš„å–å€¼æ˜¯10ï¼Œä¸‹å›¾ç»™å‡ºäº†10æŠ˜äº¤å‰éªŒè¯çš„ç¤ºæ„å›¾ã€‚</p><p><img src="https://i.loli.net/2018/10/17/5bc718115d224.png" alt></p><p>ä¸ç•™å‡ºæ³•ç±»ä¼¼ï¼Œå°†æ•°æ®é›†Dåˆ’åˆ†ä¸ºKä¸ªå­é›†çš„è¿‡ç¨‹å…·æœ‰éšæœºæ€§ï¼Œå› æ­¤KæŠ˜äº¤å‰éªŒè¯é€šå¸¸ä¹Ÿè¦é‡å¤pæ¬¡ï¼Œç§°ä¸ºpæ¬¡kæŠ˜äº¤å‰éªŒè¯ï¼Œå¸¸è§çš„æ˜¯10æ¬¡10æŠ˜äº¤å‰éªŒè¯ï¼Œå³è¿›è¡Œäº†100æ¬¡è®­ç»ƒ/æµ‹è¯•ã€‚ç‰¹æ®Šåœ°å½“åˆ’åˆ†çš„kä¸ªå­é›†çš„æ¯ä¸ªå­é›†ä¸­åªæœ‰ä¸€ä¸ªæ ·æœ¬æ—¶ï¼Œç§°ä¸ºâ€œç•™ä¸€æ³•â€ï¼Œæ˜¾ç„¶ï¼Œç•™ä¸€æ³•çš„è¯„ä¼°ç»“æœæ¯”è¾ƒå‡†ç¡®ï¼Œä½†å¯¹è®¡ç®—æœºçš„æ¶ˆè€—ä¹Ÿæ˜¯å·¨å¤§çš„ã€‚</p><p><strong>2.3.3 è‡ªåŠ©æ³•</strong></p><p>æˆ‘ä»¬å¸Œæœ›è¯„ä¼°çš„æ˜¯ç”¨æ•´ä¸ªDè®­ç»ƒå‡ºçš„æ¨¡å‹ã€‚ä½†åœ¨ç•™å‡ºæ³•å’Œäº¤å‰éªŒè¯æ³•ä¸­ï¼Œç”±äºä¿ç•™äº†ä¸€éƒ¨åˆ†æ ·æœ¬ç”¨äºæµ‹è¯•ï¼Œå› æ­¤å®é™…è¯„ä¼°çš„æ¨¡å‹æ‰€ä½¿ç”¨çš„è®­ç»ƒé›†æ¯”Då°ï¼Œè¿™å¿…ç„¶ä¼šå¼•å…¥ä¸€äº›å› è®­ç»ƒæ ·æœ¬è§„æ¨¡ä¸åŒè€Œå¯¼è‡´çš„ä¼°è®¡åå·®ã€‚ç•™ä¸€æ³•å—è®­ç»ƒæ ·æœ¬è§„æ¨¡å˜åŒ–çš„å½±å“è¾ƒå°ï¼Œä½†è®¡ç®—å¤æ‚åº¦åˆå¤ªé«˜äº†ã€‚â€œè‡ªåŠ©æ³•â€æ­£æ˜¯è§£å†³äº†è¿™æ ·çš„é—®é¢˜ã€‚</p><p>è‡ªåŠ©æ³•çš„åŸºæœ¬æ€æƒ³æ˜¯ï¼šç»™å®šåŒ…å«mä¸ªæ ·æœ¬çš„æ•°æ®é›†Dï¼Œæ¯æ¬¡éšæœºä»D ä¸­æŒ‘é€‰ä¸€ä¸ªæ ·æœ¬ï¼Œå°†å…¶æ‹·è´æ”¾å…¥Dâ€™ï¼Œç„¶åå†å°†è¯¥æ ·æœ¬æ”¾å›åˆå§‹æ•°æ®é›†D ä¸­ï¼Œä½¿å¾—è¯¥æ ·æœ¬åœ¨ä¸‹æ¬¡é‡‡æ ·æ—¶ä»æœ‰å¯èƒ½è¢«é‡‡åˆ°ã€‚é‡å¤æ‰§è¡Œm æ¬¡ï¼Œå°±å¯ä»¥å¾—åˆ°äº†åŒ…å«mä¸ªæ ·æœ¬çš„æ•°æ®é›†Dâ€™ã€‚å¯ä»¥å¾—çŸ¥åœ¨mæ¬¡é‡‡æ ·ä¸­ï¼Œæ ·æœ¬å§‹ç»ˆä¸è¢«é‡‡åˆ°çš„æ¦‚ç‡å–æé™ä¸ºï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc71811246dd.png" alt></p><p>è¿™æ ·ï¼Œé€šè¿‡è‡ªåŠ©é‡‡æ ·ï¼Œåˆå§‹æ ·æœ¬é›†Dä¸­å¤§çº¦æœ‰36.8%çš„æ ·æœ¬æ²¡æœ‰å‡ºç°åœ¨Dâ€™ä¸­ï¼Œäºæ˜¯å¯ä»¥å°†Dâ€™ä½œä¸ºè®­ç»ƒé›†ï¼ŒD-Dâ€™ä½œä¸ºæµ‹è¯•é›†ã€‚è‡ªåŠ©æ³•åœ¨æ•°æ®é›†è¾ƒå°ï¼Œéš¾ä»¥æœ‰æ•ˆåˆ’åˆ†è®­ç»ƒé›†/æµ‹è¯•é›†æ—¶å¾ˆæœ‰ç”¨ï¼Œä½†ç”±äºè‡ªåŠ©æ³•äº§ç”Ÿçš„æ•°æ®é›†ï¼ˆéšæœºæŠ½æ ·ï¼‰æ”¹å˜äº†åˆå§‹æ•°æ®é›†çš„åˆ†å¸ƒï¼Œå› æ­¤å¼•å…¥äº†ä¼°è®¡åå·®ã€‚åœ¨åˆå§‹æ•°æ®é›†è¶³å¤Ÿæ—¶ï¼Œç•™å‡ºæ³•å’Œäº¤å‰éªŒè¯æ³•æ›´åŠ å¸¸ç”¨ã€‚</p><p><strong>2.4 è°ƒå‚</strong></p><p>å¤§å¤šæ•°å­¦ä¹ ç®—æ³•éƒ½æœ‰äº›å‚æ•°(parameter) éœ€è¦è®¾å®šï¼Œå‚æ•°é…ç½®ä¸åŒï¼Œå­¦å¾—æ¨¡å‹çš„æ€§èƒ½å¾€å¾€æœ‰æ˜¾è‘—å·®åˆ«ï¼Œè¿™å°±æ˜¯é€šå¸¸æ‰€è¯´çš„â€å‚æ•°è°ƒèŠ‚â€æˆ–ç®€ç§°â€è°ƒå‚â€ (parameter tuning)ã€‚</p><p>å­¦ä¹ ç®—æ³•çš„å¾ˆå¤šå‚æ•°æ˜¯åœ¨å®æ•°èŒƒå›´å†…å–å€¼ï¼Œå› æ­¤ï¼Œå¯¹æ¯ç§å‚æ•°å–å€¼éƒ½è®­ç»ƒå‡ºæ¨¡å‹æ¥æ˜¯ä¸å¯è¡Œçš„ã€‚å¸¸ç”¨çš„åšæ³•æ˜¯ï¼šå¯¹æ¯ä¸ªå‚æ•°é€‰å®šä¸€ä¸ªèŒƒå›´å’Œæ­¥é•¿Î»ï¼Œè¿™æ ·ä½¿å¾—å­¦ä¹ çš„è¿‡ç¨‹å˜å¾—å¯è¡Œã€‚ä¾‹å¦‚ï¼šå‡å®šç®—æ³•æœ‰3 ä¸ªå‚æ•°ï¼Œæ¯ä¸ªå‚æ•°ä»…è€ƒè™‘5 ä¸ªå€™é€‰å€¼ï¼Œè¿™æ ·å¯¹æ¯ä¸€ç»„è®­ç»ƒ/æµ‹è¯•é›†å°±æœ‰5<em>5</em>5= 125 ä¸ªæ¨¡å‹éœ€è€ƒå¯Ÿï¼Œç”±æ­¤å¯è§ï¼šæ‹¿ä¸‹ä¸€ä¸ªå‚æ•°ï¼ˆå³ç»éªŒå€¼ï¼‰å¯¹äºç®—æ³•äººå‘˜æ¥è¯´æ˜¯æœ‰å¤šä¹ˆçš„happyã€‚</p><p>æœ€åéœ€è¦æ³¨æ„çš„æ˜¯ï¼šå½“é€‰å®šå¥½æ¨¡å‹å’Œè°ƒå‚å®Œæˆåï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨åˆå§‹çš„æ•°æ®é›†Dé‡æ–°è®­ç»ƒæ¨¡å‹ï¼Œå³è®©æœ€åˆåˆ’åˆ†å‡ºæ¥ç”¨äºè¯„ä¼°çš„æµ‹è¯•é›†ä¹Ÿè¢«æ¨¡å‹å­¦ä¹ ï¼Œå¢å¼ºæ¨¡å‹çš„å­¦ä¹ æ•ˆæœã€‚ç”¨ä¸Šé¢è€ƒè¯•çš„ä¾‹å­æ¥æ¯”å–»ï¼šå°±åƒé«˜ä¸­æ—¶å¤§å®¶æ¯æ¬¡è€ƒè¯•å®Œï¼Œè¦å°†è€ƒå·çš„é¢˜ç›®æ¶ˆåŒ–æ‰ï¼ˆå¤§å¤šæ•°é¢˜ç›®éƒ½è¿˜æ˜¯ä¹‹å‰æ²¡æœ‰è§è¿‡çš„å§ï¼Ÿï¼‰ï¼Œè¿™æ ·å³ä½¿è€ƒå·®äº†ä¹Ÿèƒ½å¼€å¿ƒçš„ç©è€äº†~ã€‚</p><p><strong>3  æœºå™¨å­¦ä¹ è¯„ä¼°ä¸åº¦é‡æŒ‡æ ‡</strong></p><p>è¿™é‡Œçš„å†…å®¹ä¸»è¦åŒ…æ‹¬ï¼šæ€§èƒ½åº¦é‡ã€æ¯”è¾ƒæ£€éªŒå’Œåå·®ä¸æ–¹å·®ã€‚åœ¨ä¸Šä¸€ä¸ªnotebookä¸­ï¼Œæˆ‘ä»¬è§£å†³äº†è¯„ä¼°å­¦ä¹ å™¨æ³›åŒ–æ€§èƒ½çš„æ–¹æ³•ï¼Œå³ç”¨æµ‹è¯•é›†çš„â€œæµ‹è¯•è¯¯å·®â€ä½œä¸ºâ€œæ³›åŒ–è¯¯å·®â€çš„è¿‘ä¼¼ï¼Œå½“æˆ‘ä»¬åˆ’åˆ†å¥½è®­ç»ƒ/æµ‹è¯•é›†åï¼Œé‚£å¦‚ä½•è®¡ç®—â€œæµ‹è¯•è¯¯å·®â€å‘¢ï¼Ÿè¿™å°±æ˜¯æ€§èƒ½åº¦é‡ï¼Œä¾‹å¦‚ï¼šå‡æ–¹å·®ï¼Œé”™è¯¯ç‡ç­‰ï¼Œå³â€œæµ‹è¯•è¯¯å·®â€çš„ä¸€ä¸ªè¯„ä»·æ ‡å‡†ã€‚æœ‰äº†è¯„ä¼°æ–¹æ³•å’Œæ€§èƒ½åº¦é‡ï¼Œå°±å¯ä»¥è®¡ç®—å‡ºå­¦ä¹ å™¨çš„â€œæµ‹è¯•è¯¯å·®â€ï¼Œä½†ç”±äºâ€œæµ‹è¯•è¯¯å·®â€å—åˆ°å¾ˆå¤šå› ç´ çš„å½±å“ï¼Œä¾‹å¦‚ï¼šç®—æ³•éšæœºæ€§æˆ–æµ‹è¯•é›†æœ¬èº«çš„é€‰æ‹©ï¼Œé‚£å¦‚ä½•å¯¹ä¸¤ä¸ªæˆ–å¤šä¸ªå­¦ä¹ å™¨çš„æ€§èƒ½åº¦é‡ç»“æœåšæ¯”è¾ƒå‘¢ï¼Ÿè¿™å°±æ˜¯æ¯”è¾ƒæ£€éªŒã€‚æœ€ååå·®ä¸æ–¹å·®æ˜¯è§£é‡Šå­¦ä¹ å™¨æ³›åŒ–æ€§èƒ½çš„ä¸€ç§é‡è¦å·¥å…·ã€‚</p><p><strong>3.1 æ€§èƒ½åº¦é‡</strong></p><p>æ€§èƒ½åº¦é‡ï¼ˆperformance measureï¼‰æ˜¯è¡¡é‡æ¨¡å‹æ³›åŒ–èƒ½åŠ›çš„è¯„ä»·æ ‡å‡†ï¼Œåœ¨å¯¹æ¯”ä¸åŒæ¨¡å‹çš„èƒ½åŠ›æ—¶ï¼Œä½¿ç”¨ä¸åŒçš„æ€§èƒ½åº¦é‡å¾€å¾€ä¼šå¯¼è‡´ä¸åŒçš„è¯„åˆ¤ç»“æœã€‚æœ¬èŠ‚é™¤2.5.1å¤–ï¼Œå…¶å®ƒä¸»è¦ä»‹ç»åˆ†ç±»æ¨¡å‹çš„æ€§èƒ½åº¦é‡ã€‚</p><p><strong>3.1.1 æœ€å¸¸è§çš„æ€§èƒ½åº¦é‡</strong></p><p>åœ¨å›å½’ä»»åŠ¡ä¸­ï¼Œå³é¢„æµ‹è¿ç»­å€¼çš„é—®é¢˜ï¼Œæœ€å¸¸ç”¨çš„æ€§èƒ½åº¦é‡æ˜¯â€œå‡æ–¹è¯¯å·®â€ï¼ˆmean squared errorï¼‰,å¾ˆå¤šçš„ç»å…¸ç®—æ³•éƒ½æ˜¯é‡‡ç”¨äº†MSEä½œä¸ºè¯„ä»·å‡½æ•°ï¼Œæƒ³å¿…å¤§å®¶éƒ½ååˆ†ç†Ÿæ‚‰ã€‚</p><p><img src="https://i.loli.net/2018/10/17/5bc71daf76276.png" alt="1.png"></p><p>åœ¨åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œå³é¢„æµ‹ç¦»æ•£å€¼çš„é—®é¢˜ï¼Œæœ€å¸¸ç”¨çš„æ˜¯é”™è¯¯ç‡å’Œç²¾åº¦ï¼Œé”™è¯¯ç‡æ˜¯åˆ†ç±»é”™è¯¯çš„æ ·æœ¬æ•°å æ ·æœ¬æ€»æ•°çš„æ¯”ä¾‹ï¼Œç²¾åº¦åˆ™æ˜¯åˆ†ç±»æ­£ç¡®çš„æ ·æœ¬æ•°å æ ·æœ¬æ€»æ•°çš„æ¯”ä¾‹ï¼Œæ˜“çŸ¥ï¼šé”™è¯¯ç‡+ç²¾åº¦=1ã€‚</p><p><img src="https://i.loli.net/2018/10/17/5bc71daf4c704.png" alt="2.png"></p><p><img src="https://i.loli.net/2018/10/17/5bc71daf6fb84.png" alt="3.png"></p><p><strong>3.1.2 æŸ¥å‡†ç‡/æŸ¥å…¨ç‡/F1</strong></p><p>é”™è¯¯ç‡å’Œç²¾åº¦è™½ç„¶å¸¸ç”¨ï¼Œä½†ä¸èƒ½æ»¡è¶³æ‰€æœ‰çš„éœ€æ±‚ï¼Œä¾‹å¦‚ï¼šåœ¨æ¨èç³»ç»Ÿä¸­ï¼Œæˆ‘ä»¬åªå…³å¿ƒæ¨é€ç»™ç”¨æˆ·çš„å†…å®¹ç”¨æˆ·æ˜¯å¦æ„Ÿå…´è¶£ï¼ˆå³æŸ¥å‡†ç‡ï¼‰ï¼Œæˆ–è€…è¯´æ‰€æœ‰ç”¨æˆ·æ„Ÿå…´è¶£çš„å†…å®¹æˆ‘ä»¬æ¨é€å‡ºæ¥äº†å¤šå°‘ï¼ˆå³æŸ¥å…¨ç‡ï¼‰ã€‚å› æ­¤ï¼Œä½¿ç”¨æŸ¥å‡†/æŸ¥å…¨ç‡æ›´é€‚åˆæè¿°è¿™ç±»é—®é¢˜ã€‚å¯¹äºäºŒåˆ†ç±»é—®é¢˜ï¼Œåˆ†ç±»ç»“æœæ··æ·†çŸ©é˜µä¸æŸ¥å‡†/æŸ¥å…¨ç‡å®šä¹‰å¦‚ä¸‹ï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc71daf885a4.png" alt="4.png"></p><p>åˆæ¬¡æ¥è§¦æ—¶ï¼ŒFNä¸FPå¾ˆéš¾æ­£ç¡®çš„ç†è§£ï¼ŒæŒ‰ç…§æƒ¯æ€§æ€ç»´å®¹æ˜“æŠŠFNç†è§£æˆï¼šFalse-&gt;Negtiveï¼Œå³å°†é”™çš„é¢„æµ‹ä¸ºé”™çš„ï¼Œè¿™æ ·FNå’ŒTNå°±åäº†ï¼Œåæ¥æ‰¾åˆ°ä¸€å¼ å›¾ï¼Œæè¿°å¾—å¾ˆè¯¦ç»†ï¼Œä¸ºæ–¹ä¾¿ç†è§£ï¼ŒæŠŠè¿™å¼ å›¾ä¹Ÿè´´åœ¨äº†ä¸‹è¾¹ï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc71daf871a6.png" alt="5.png"></p><p>æ­£å¦‚å¤©ä¸‹æ²¡æœ‰å…è´¹çš„åˆé¤ï¼ŒæŸ¥å‡†ç‡å’ŒæŸ¥å…¨ç‡æ˜¯ä¸€å¯¹çŸ›ç›¾çš„åº¦é‡ã€‚ä¾‹å¦‚æˆ‘ä»¬æƒ³è®©æ¨é€çš„å†…å®¹å°½å¯èƒ½ç”¨æˆ·å…¨éƒ½æ„Ÿå…´è¶£ï¼Œé‚£åªèƒ½æ¨é€æˆ‘ä»¬æŠŠæ¡é«˜çš„å†…å®¹ï¼Œè¿™æ ·å°±æ¼æ‰äº†ä¸€äº›ç”¨æˆ·æ„Ÿå…´è¶£çš„å†…å®¹ï¼ŒæŸ¥å…¨ç‡å°±ä½äº†ï¼›å¦‚æœæƒ³è®©ç”¨æˆ·æ„Ÿå…´è¶£çš„å†…å®¹éƒ½è¢«æ¨é€ï¼Œé‚£åªæœ‰å°†æ‰€æœ‰å†…å®¹éƒ½æ¨é€ä¸Šï¼Œå®å¯é”™æ€ä¸€åƒï¼Œä¸å¯æ”¾è¿‡ä¸€ä¸ªï¼Œè¿™æ ·æŸ¥å‡†ç‡å°±å¾ˆä½äº†ã€‚</p><p>â€œP-Ræ›²çº¿â€æ­£æ˜¯æè¿°æŸ¥å‡†/æŸ¥å…¨ç‡å˜åŒ–çš„æ›²çº¿ï¼ŒP-Ræ›²çº¿å®šä¹‰å¦‚ä¸‹ï¼šæ ¹æ®å­¦ä¹ å™¨çš„é¢„æµ‹ç»“æœï¼ˆä¸€èˆ¬ä¸ºä¸€ä¸ªå®å€¼æˆ–æ¦‚ç‡ï¼‰å¯¹æµ‹è¯•æ ·æœ¬è¿›è¡Œæ’åºï¼Œå°†æœ€å¯èƒ½æ˜¯â€œæ­£ä¾‹â€çš„æ ·æœ¬æ’åœ¨å‰é¢ï¼Œæœ€ä¸å¯èƒ½æ˜¯â€œæ­£ä¾‹â€çš„æ’åœ¨åé¢ï¼ŒæŒ‰æ­¤é¡ºåºé€ä¸ªæŠŠæ ·æœ¬ä½œä¸ºâ€œæ­£ä¾‹â€è¿›è¡Œé¢„æµ‹ï¼Œæ¯æ¬¡è®¡ç®—å‡ºå½“å‰çš„På€¼å’ŒRå€¼ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc71dafc4411.png" alt="6.png"></p><p>P-Ræ›²çº¿å¦‚ä½•è¯„ä¼°å‘¢ï¼Ÿè‹¥ä¸€ä¸ªå­¦ä¹ å™¨Açš„P-Ræ›²çº¿è¢«å¦ä¸€ä¸ªå­¦ä¹ å™¨Bçš„P-Ræ›²çº¿å®Œå…¨åŒ…ä½ï¼Œåˆ™ç§°ï¼šBçš„æ€§èƒ½ä¼˜äºAã€‚è‹¥Aå’ŒBçš„æ›²çº¿å‘ç”Ÿäº†äº¤å‰ï¼Œåˆ™è°çš„æ›²çº¿ä¸‹çš„é¢ç§¯å¤§ï¼Œè°çš„æ€§èƒ½æ›´ä¼˜ã€‚ä½†ä¸€èˆ¬æ¥è¯´ï¼Œæ›²çº¿ä¸‹çš„é¢ç§¯æ˜¯å¾ˆéš¾è¿›è¡Œä¼°ç®—çš„ï¼Œæ‰€ä»¥è¡ç”Ÿå‡ºäº†â€œå¹³è¡¡ç‚¹â€ï¼ˆBreak-Event Pointï¼Œç®€ç§°BEPï¼‰ï¼Œå³å½“P=Ræ—¶çš„å–å€¼ï¼Œå¹³è¡¡ç‚¹çš„å–å€¼è¶Šé«˜ï¼Œæ€§èƒ½æ›´ä¼˜ã€‚</p><p>På’ŒRæŒ‡æ ‡æœ‰æ—¶ä¼šå‡ºç°çŸ›ç›¾çš„æƒ…å†µï¼Œè¿™æ ·å°±éœ€è¦ç»¼åˆè€ƒè™‘ä»–ä»¬ï¼Œæœ€å¸¸è§çš„æ–¹æ³•å°±æ˜¯F-Measureï¼Œåˆç§°F-Scoreã€‚F-Measureæ˜¯På’ŒRçš„åŠ æƒè°ƒå’Œå¹³å‡ï¼Œå³ï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc71daf40ff6.png" alt="7.png"></p><p><img src="https://i.loli.net/2018/10/17/5bc71daf75407.png" alt="8.png"></p><p>ç‰¹åˆ«åœ°ï¼Œå½“Î²=1æ—¶ï¼Œä¹Ÿå°±æ˜¯å¸¸è§çš„F1åº¦é‡ï¼Œæ˜¯På’ŒRçš„è°ƒå’Œå¹³å‡ï¼Œå½“F1è¾ƒé«˜æ—¶ï¼Œæ¨¡å‹çš„æ€§èƒ½è¶Šå¥½ã€‚</p><p><img src="https://i.loli.net/2018/10/17/5bc71daf20885.png" alt="9.png"></p><p><img src="https://i.loli.net/2018/10/17/5bc71daf4b90a.png" alt="10.png"></p><p>æœ‰æ—¶å€™æˆ‘ä»¬ä¼šæœ‰å¤šä¸ªäºŒåˆ†ç±»æ··æ·†çŸ©é˜µï¼Œä¾‹å¦‚ï¼šå¤šæ¬¡è®­ç»ƒæˆ–è€…åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè®­ç»ƒï¼Œé‚£ä¹ˆä¼°ç®—å…¨å±€æ€§èƒ½çš„æ–¹æ³•æœ‰ä¸¤ç§ï¼Œåˆ†ä¸ºå®è§‚å’Œå¾®è§‚ã€‚ç®€å•ç†è§£ï¼Œå®è§‚å°±æ˜¯å…ˆç®—å‡ºæ¯ä¸ªæ··æ·†çŸ©é˜µçš„På€¼å’ŒRå€¼ï¼Œç„¶åå–å¾—å¹³å‡På€¼macro-På’Œå¹³å‡Rå€¼macro-Rï¼Œåœ¨ç®—å‡ºFÎ²æˆ–F1ï¼Œè€Œå¾®è§‚åˆ™æ˜¯è®¡ç®—å‡ºæ··æ·†çŸ©é˜µçš„å¹³å‡TPã€FPã€TNã€FNï¼Œæ¥ç€è¿›è¡Œè®¡ç®—Pã€Rï¼Œè¿›è€Œæ±‚å‡ºFÎ²æˆ–F1ã€‚</p><p><img src="https://i.loli.net/2018/10/17/5bc71ed70230e.png" alt="11.png"></p><p><strong>3.1.3 ROCä¸AUC</strong></p><p>å¦‚ä¸Šæ‰€è¿°ï¼šå­¦ä¹ å™¨å¯¹æµ‹è¯•æ ·æœ¬çš„è¯„ä¼°ç»“æœä¸€èˆ¬ä¸ºä¸€ä¸ªå®å€¼æˆ–æ¦‚ç‡ï¼Œè®¾å®šä¸€ä¸ªé˜ˆå€¼ï¼Œå¤§äºé˜ˆå€¼ä¸ºæ­£ä¾‹ï¼Œå°äºé˜ˆå€¼ä¸ºè´Ÿä¾‹ï¼Œå› æ­¤è¿™ä¸ªå®å€¼çš„å¥½åç›´æ¥å†³å®šäº†å­¦ä¹ å™¨çš„æ³›åŒ–æ€§èƒ½ï¼Œè‹¥å°†è¿™äº›å®å€¼æ’åºï¼Œåˆ™æ’åºçš„å¥½åå†³å®šäº†å­¦ä¹ å™¨çš„æ€§èƒ½é«˜ä½ã€‚ROCæ›²çº¿æ­£æ˜¯ä»è¿™ä¸ªè§’åº¦å‡ºå‘æ¥ç ”ç©¶å­¦ä¹ å™¨çš„æ³›åŒ–æ€§èƒ½ï¼ŒROCæ›²çº¿ä¸P-Ræ›²çº¿ååˆ†ç±»ä¼¼ï¼Œéƒ½æ˜¯æŒ‰ç…§æ’åºçš„é¡ºåºé€ä¸€æŒ‰ç…§æ­£ä¾‹é¢„æµ‹ï¼Œä¸åŒçš„æ˜¯ROCæ›²çº¿ä»¥â€œçœŸæ­£ä¾‹ç‡â€ï¼ˆTrue Positive Rateï¼Œç®€ç§°TPRï¼‰ä¸ºæ¨ªè½´ï¼Œçºµè½´ä¸ºâ€œå‡æ­£ä¾‹ç‡â€ï¼ˆFalse Positive Rateï¼Œç®€ç§°FPRï¼‰ï¼ŒROCåé‡ç ”ç©¶åŸºäºæµ‹è¯•æ ·æœ¬è¯„ä¼°å€¼çš„æ’åºå¥½åã€‚</p><p><img src="https://i.loli.net/2018/10/17/5bc71ed6bee91.png" alt="12.png"></p><p><img src="https://i.loli.net/2018/10/17/5bc71ed75cefe.png" alt="13.png"></p><p>ç®€å•åˆ†æå›¾åƒï¼Œå¯ä»¥å¾—çŸ¥ï¼šå½“FN=0æ—¶ï¼ŒTNä¹Ÿå¿…é¡»0ï¼Œåä¹‹ä¹Ÿæˆç«‹ï¼Œæˆ‘ä»¬å¯ä»¥ç”»ä¸€ä¸ªé˜Ÿåˆ—ï¼Œè¯•ç€ä½¿ç”¨ä¸åŒçš„æˆªæ–­ç‚¹ï¼ˆå³é˜ˆå€¼ï¼‰å»åˆ†å‰²é˜Ÿåˆ—ï¼Œæ¥åˆ†ææ›²çº¿çš„å½¢çŠ¶ï¼Œï¼ˆ0,0ï¼‰è¡¨ç¤ºå°†æ‰€æœ‰çš„æ ·æœ¬é¢„æµ‹ä¸ºè´Ÿä¾‹ï¼Œï¼ˆ1,1ï¼‰åˆ™è¡¨ç¤ºå°†æ‰€æœ‰çš„æ ·æœ¬é¢„æµ‹ä¸ºæ­£ä¾‹ï¼Œï¼ˆ0,1ï¼‰è¡¨ç¤ºæ­£ä¾‹å…¨éƒ¨å‡ºç°åœ¨è´Ÿä¾‹ä¹‹å‰çš„ç†æƒ³æƒ…å†µï¼Œï¼ˆ1,0ï¼‰åˆ™è¡¨ç¤ºè´Ÿä¾‹å…¨éƒ¨å‡ºç°åœ¨æ­£ä¾‹ä¹‹å‰çš„æœ€å·®æƒ…å†µã€‚é™äºç¯‡å¹…ï¼Œè¿™é‡Œä¸å†è®ºè¿°ã€‚</p><p>ç°å®ä¸­çš„ä»»åŠ¡é€šå¸¸éƒ½æ˜¯æœ‰é™ä¸ªæµ‹è¯•æ ·æœ¬ï¼Œå› æ­¤åªèƒ½ç»˜åˆ¶å‡ºè¿‘ä¼¼ROCæ›²çº¿ã€‚ç»˜åˆ¶æ–¹æ³•ï¼šé¦–å…ˆæ ¹æ®æµ‹è¯•æ ·æœ¬çš„è¯„ä¼°å€¼å¯¹æµ‹è¯•æ ·æœ¬æ’åºï¼Œæ¥ç€æŒ‰ç…§ä»¥ä¸‹è§„åˆ™è¿›è¡Œç»˜åˆ¶ã€‚</p><p><img src="https://i.loli.net/2018/10/17/5bc71ed740a24.png" alt="14.png"></p><p>åŒæ ·åœ°ï¼Œè¿›è¡Œæ¨¡å‹çš„æ€§èƒ½æ¯”è¾ƒæ—¶ï¼Œè‹¥ä¸€ä¸ªå­¦ä¹ å™¨Açš„ROCæ›²çº¿è¢«å¦ä¸€ä¸ªå­¦ä¹ å™¨Bçš„ROCæ›²çº¿å®Œå…¨åŒ…ä½ï¼Œåˆ™ç§°Bçš„æ€§èƒ½ä¼˜äºAã€‚è‹¥Aå’ŒBçš„æ›²çº¿å‘ç”Ÿäº†äº¤å‰ï¼Œåˆ™è°çš„æ›²çº¿ä¸‹çš„é¢ç§¯å¤§ï¼Œè°çš„æ€§èƒ½æ›´ä¼˜ã€‚ROCæ›²çº¿ä¸‹çš„é¢ç§¯å®šä¹‰ä¸ºAUCï¼ˆArea Uder ROC Curveï¼‰ï¼Œä¸åŒäºP-Rçš„æ˜¯ï¼Œè¿™é‡Œçš„AUCæ˜¯å¯ä¼°ç®—çš„ï¼Œå³AOCæ›²çº¿ä¸‹æ¯ä¸€ä¸ªå°çŸ©å½¢çš„é¢ç§¯ä¹‹å’Œã€‚æ˜“çŸ¥ï¼šAUCè¶Šå¤§ï¼Œè¯æ˜æ’åºçš„è´¨é‡è¶Šå¥½ï¼ŒAUCä¸º1æ—¶ï¼Œè¯æ˜æ‰€æœ‰æ­£ä¾‹æ’åœ¨äº†è´Ÿä¾‹çš„å‰é¢ï¼ŒAUCä¸º0æ—¶ï¼Œæ‰€æœ‰çš„è´Ÿä¾‹æ’åœ¨äº†æ­£ä¾‹çš„å‰é¢ã€‚</p><p><img src="https://i.loli.net/2018/10/17/5bc71ed6e2c57.png" alt="15.png"></p><p><strong>3.1.4 ä»£ä»·æ•æ„Ÿé”™è¯¯ç‡ä¸ä»£ä»·æ›²çº¿</strong></p><p>ä¸Šé¢çš„æ–¹æ³•ä¸­ï¼Œå°†å­¦ä¹ å™¨çš„çŠ¯é”™åŒç­‰å¯¹å¾…ï¼Œä½†åœ¨ç°å®ç”Ÿæ´»ä¸­ï¼Œå°†æ­£ä¾‹é¢„æµ‹æˆå‡ä¾‹ä¸å°†å‡ä¾‹é¢„æµ‹æˆæ­£ä¾‹çš„ä»£ä»·å¸¸å¸¸æ˜¯ä¸ä¸€æ ·çš„ï¼Œä¾‹å¦‚ï¼šå°†æ— ç–¾ç—…â€“&gt;æœ‰ç–¾ç—…åªæ˜¯å¢å¤šäº†æ£€æŸ¥ï¼Œä½†æœ‰ç–¾ç—…â€“&gt;æ— ç–¾ç—…å´æ˜¯å¢åŠ äº†ç”Ÿå‘½å±é™©ã€‚ä»¥äºŒåˆ†ç±»ä¸ºä¾‹ï¼Œç”±æ­¤å¼•å…¥äº†â€œä»£ä»·çŸ©é˜µâ€ï¼ˆcost matrixï¼‰ã€‚</p><p><img src="https://i.loli.net/2018/10/17/5bc71ed6ed582.png" alt="16.png"></p><p>åœ¨éå‡ç­‰é”™è¯¯ä»£ä»·ä¸‹ï¼Œæˆ‘ä»¬å¸Œæœ›çš„æ˜¯æœ€å°åŒ–â€œæ€»ä½“ä»£ä»·â€ï¼Œè¿™æ ·â€œä»£ä»·æ•æ„Ÿâ€çš„é”™è¯¯ç‡ï¼ˆ2.5.1èŠ‚ä»‹ç»ï¼‰ä¸ºï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc71ed70bebe.png" alt="17.png"></p><p>åŒæ ·å¯¹äºROCæ›²çº¿ï¼Œåœ¨éå‡ç­‰é”™è¯¯ä»£ä»·ä¸‹ï¼Œæ¼”å˜æˆäº†â€œä»£ä»·æ›²çº¿â€ï¼Œä»£ä»·æ›²çº¿æ¨ªè½´æ˜¯å–å€¼åœ¨[0,1]ä¹‹é—´çš„æ­£ä¾‹æ¦‚ç‡ä»£ä»·ï¼Œå¼ä¸­pè¡¨ç¤ºæ­£ä¾‹çš„æ¦‚ç‡ï¼Œçºµè½´æ˜¯å–å€¼ä¸º[0,1]çš„å½’ä¸€åŒ–ä»£ä»·ã€‚</p><p><img src="https://i.loli.net/2018/10/17/5bc71ed6e952e.png" alt="18.png"></p><p><img src="https://i.loli.net/2018/10/17/5bc71ed6eee7b.png" alt="19.png"></p><p>ä»£ä»·æ›²çº¿çš„ç»˜åˆ¶å¾ˆç®€å•ï¼šè®¾ROCæ›²çº¿ä¸Šä¸€ç‚¹çš„åæ ‡ä¸º(TPRï¼ŒFPR) ï¼Œåˆ™å¯ç›¸åº”è®¡ç®—å‡ºFNRï¼Œç„¶ååœ¨ä»£ä»·å¹³é¢ä¸Šç»˜åˆ¶ä¸€æ¡ä»(0ï¼ŒFPR) åˆ°(1ï¼ŒFNR) çš„çº¿æ®µï¼Œçº¿æ®µä¸‹çš„é¢ç§¯å³è¡¨ç¤ºäº†è¯¥æ¡ä»¶ä¸‹çš„æœŸæœ›æ€»ä½“ä»£ä»·ï¼›å¦‚æ­¤å°†ROC æ›²çº¿åœŸçš„æ¯ä¸ªç‚¹è½¬åŒ–ä¸ºä»£ä»·å¹³é¢ä¸Šçš„ä¸€æ¡çº¿æ®µï¼Œç„¶åå–æ‰€æœ‰çº¿æ®µçš„ä¸‹ç•Œï¼Œå›´æˆçš„é¢ç§¯å³ä¸ºåœ¨æ‰€æœ‰æ¡ä»¶ä¸‹å­¦ä¹ å™¨çš„æœŸæœ›æ€»ä½“ä»£ä»·ï¼Œå¦‚å›¾æ‰€ç¤ºï¼š</p><p><img src="https://i.loli.net/2018/10/17/5bc71ed716e0d.png" alt="20.png"></p><p><strong>4  æœºå™¨å­¦ä¹ æŒ‡æ ‡ROCä¸AUC</strong></p><p>AUCæ˜¯ä¸€ç§æ¨¡å‹åˆ†ç±»æŒ‡æ ‡ï¼Œä¸”ä»…ä»…æ˜¯äºŒåˆ†ç±»æ¨¡å‹çš„è¯„ä»·æŒ‡æ ‡ã€‚AUCæ˜¯Area Under Curveçš„ç®€ç§°ï¼Œé‚£ä¹ˆCurveå°±æ˜¯ROCï¼ˆReceiver Operating Characteristicï¼‰ï¼Œç¿»è¯‘ä¸ºâ€æ¥å—è€…æ“ä½œç‰¹æ€§æ›²çº¿â€ã€‚</p><h3 id="ROC"><a href="#ROC" class="headerlink" title="ROC"></a>ROC</h3><p>æ›²çº¿ç”±ä¸¤ä¸ªå˜é‡TPRå’ŒFPRç»„æˆï¼Œè¿™ä¸ªç»„åˆä»¥FPRå¯¹TPRï¼Œå³æ˜¯ä»¥ä»£ä»·(costs)å¯¹æ”¶ç›Š(benefits)ã€‚</p><ul><li><p>xè½´ä¸ºå‡é˜³æ€§ç‡ï¼ˆFPRï¼‰ï¼šåœ¨æ‰€æœ‰çš„è´Ÿæ ·æœ¬ä¸­ï¼Œåˆ†ç±»å™¨é¢„æµ‹é”™è¯¯çš„æ¯”ä¾‹</p><p>$$FPR = \frac {FP}{FP+TN}$$</p></li><li><p>yè½´ä¸ºçœŸé˜³æ€§ç‡ï¼ˆTPRï¼‰ï¼šåœ¨æ‰€æœ‰çš„æ­£æ ·æœ¬ä¸­ï¼Œåˆ†ç±»å™¨é¢„æµ‹æ­£ç¡®çš„æ¯”ä¾‹ï¼ˆç­‰äºRecallï¼‰</p><p>$$TPR = \frac {TP}{TP+FN}$$</p></li></ul><p>ä¸ºäº†æ›´å¥½åœ°ç†è§£ROCæ›²çº¿ï¼Œæˆ‘ä»¬ä½¿ç”¨å…·ä½“çš„å®ä¾‹æ¥è¯´æ˜ï¼š</p><p>å¦‚åœ¨åŒ»å­¦è¯Šæ–­ä¸­,åˆ¤æ–­æœ‰ç—…çš„æ ·æœ¬ã€‚é‚£ä¹ˆå°½é‡æŠŠæœ‰ç—…çš„æªå‡ºæ¥æ˜¯ä¸»è¦ä»»åŠ¡ï¼Œä¹Ÿå°±æ˜¯ç¬¬ä¸€ä¸ªæŒ‡æ ‡TPRï¼Œè¦è¶Šé«˜è¶Šå¥½ã€‚è€ŒæŠŠæ²¡ç—…çš„æ ·æœ¬è¯¯è¯Šä¸ºæœ‰ç—…çš„ï¼Œä¹Ÿå°±æ˜¯ç¬¬äºŒä¸ªæŒ‡æ ‡FPRï¼Œè¦è¶Šä½è¶Šå¥½ã€‚</p><p>ä¸éš¾å‘ç°,è¿™ä¸¤ä¸ªæŒ‡æ ‡ä¹‹é—´æ˜¯ç›¸äº’åˆ¶çº¦çš„ã€‚å¦‚æœæŸä¸ªåŒ»ç”Ÿå¯¹äºæœ‰ç—…çš„ç—‡çŠ¶æ¯”è¾ƒæ•æ„Ÿï¼Œç¨å¾®çš„å°ç—‡çŠ¶éƒ½åˆ¤æ–­ä¸ºæœ‰ç—…,é‚£ä¹ˆä»–çš„ç¬¬ä¸€ä¸ªæŒ‡æ ‡åº”è¯¥ä¼šå¾ˆé«˜ï¼Œä½†æ˜¯ç¬¬äºŒä¸ªæŒ‡æ ‡ä¹Ÿå°±ç›¸åº”åœ°å˜é«˜ã€‚æœ€æç«¯çš„æƒ…å†µä¸‹,ä»–æŠŠæ‰€æœ‰çš„æ ·æœ¬éƒ½çœ‹åšæœ‰ç—…,é‚£ä¹ˆç¬¬ä¸€ä¸ªæŒ‡æ ‡è¾¾åˆ°1,ç¬¬äºŒä¸ªæŒ‡æ ‡ä¹Ÿä¸º1ã€‚</p><p>æˆ‘ä»¬ä»¥FPRä¸ºæ¨ªè½´,TPRä¸ºçºµè½´,å¾—åˆ°å¦‚ä¸‹ROCç©ºé—´ã€‚</p><img src="/blog_picture/1.7.png" width="60%"><p>æˆ‘ä»¬å¯ä»¥çœ‹å‡ºï¼Œå·¦ä¸Šè§’çš„ç‚¹(TPR=1ï¼ŒFPR=0)ï¼Œä¸ºå®Œç¾åˆ†ç±»ï¼Œä¹Ÿå°±æ˜¯è¿™ä¸ªåŒ»ç”ŸåŒ»æœ¯é«˜æ˜ï¼Œè¯Šæ–­å…¨å¯¹ã€‚ç‚¹A(TPR&gt;FPR),åŒ»ç”ŸAçš„åˆ¤æ–­å¤§ä½“æ˜¯æ­£ç¡®çš„ã€‚ä¸­çº¿ä¸Šçš„ç‚¹B(TPR=FPR),ä¹Ÿå°±æ˜¯åŒ»ç”ŸBå…¨éƒ½æ˜¯è’™çš„ï¼Œè’™å¯¹ä¸€åŠï¼Œè’™é”™ä¸€åŠï¼›ä¸‹åŠå¹³é¢çš„ç‚¹C(TPR&lt;FPR)ï¼Œè¿™ä¸ªåŒ»ç”Ÿè¯´ä½ æœ‰ç—…ï¼Œé‚£ä¹ˆä½ å¾ˆå¯èƒ½æ²¡æœ‰ç—…ï¼ŒåŒ»ç”ŸCçš„è¯æˆ‘ä»¬è¦åç€å¬ï¼Œä¸ºçœŸåº¸åŒ»ã€‚ä¸Šå›¾ä¸­ä¸€ä¸ªé˜ˆå€¼ï¼Œå¾—åˆ°ä¸€ä¸ªç‚¹ã€‚ç°åœ¨æˆ‘ä»¬éœ€è¦ä¸€ä¸ªç‹¬ç«‹äºé˜ˆå€¼çš„è¯„ä»·æŒ‡æ ‡æ¥è¡¡é‡è¿™ä¸ªåŒ»ç”Ÿçš„åŒ»æœ¯å¦‚ä½•ï¼Œä¹Ÿå°±æ˜¯éå†æ‰€æœ‰çš„é˜ˆå€¼,å¾—åˆ°ROCæ›²çº¿ã€‚</p><p>å‡è®¾å¦‚ä¸‹å°±æ˜¯æŸä¸ªåŒ»ç”Ÿçš„è¯Šæ–­ç»Ÿè®¡å›¾ï¼Œç›´çº¿ä»£è¡¨é˜ˆå€¼ã€‚é€šè¿‡æ”¹å˜ä¸åŒçš„é˜ˆå€¼$1.0 \rightarrow 0$ï¼Œä»è€Œç»˜åˆ¶å‡ºROCæ›²çº¿ã€‚ä¸‹å›¾ä¸ºæœªå¾—ç—…äººç¾¤ï¼ˆè“è‰²ï¼‰å’Œå¾—ç—…äººç¾¤ï¼ˆçº¢è‰²ï¼‰çš„æ¨¡å‹è¾“å‡ºæ¦‚ç‡åˆ†å¸ƒå›¾ï¼ˆæ¨ªåæ ‡è¡¨ç¤ºæ¨¡å‹è¾“å‡ºæ¦‚ç‡ï¼Œçºµåæ ‡è¡¨ç¤ºæ¦‚ç‡å¯¹åº”çš„äººç¾¤çš„æ•°é‡ï¼‰ã€‚é˜ˆå€¼ä¸º1æ—¶ï¼Œä¸ç®¡ä½ ä»€ä¹ˆç—‡çŠ¶ï¼ŒåŒ»ç”Ÿå‡æœªè¯Šæ–­å‡ºç–¾ç—…ï¼ˆé¢„æµ‹å€¼éƒ½ä¸ºNï¼‰ï¼Œæ­¤æ—¶FPR=TPR=0ï¼Œä½äºå·¦ä¸‹ã€‚é˜ˆå€¼ä¸º0æ—¶ï¼Œä¸ç®¡ä½ ä»€ä¹ˆç—‡çŠ¶ï¼ŒåŒ»ç”Ÿéƒ½è¯Šæ–­ç»“æœéƒ½æ˜¯å¾—ç—…ï¼ˆé¢„æµ‹å€¼éƒ½ä¸ºPï¼‰ï¼Œæ­¤æ—¶FPR=TPR=1ï¼Œä½äºå³ä¸Šã€‚</p><img src="/blog_picture/1.8.png" width="50%"><p>æ›²çº¿è·ç¦»å·¦ä¸Šè§’è¶Šè¿‘,è¯æ˜åˆ†ç±»å™¨æ•ˆæœè¶Šå¥½ã€‚</p><img src="/blog_picture/1.9.png" width="60%"><p>å¦‚ä¸Šï¼Œæ˜¯ä¸‰æ¡ROCæ›²çº¿ï¼Œåœ¨0.23å¤„å–ä¸€æ¡ç›´çº¿ã€‚é‚£ä¹ˆï¼Œåœ¨åŒæ ·çš„ä½FPR=0.23çš„æƒ…å†µä¸‹ï¼Œçº¢è‰²åˆ†ç±»å™¨å¾—åˆ°æ›´é«˜çš„PTRã€‚ä¹Ÿå°±è¡¨æ˜ï¼ŒROCè¶Šå¾€å·¦ä¸Šï¼Œåˆ†ç±»å™¨æ•ˆæœè¶Šå¥½ã€‚æˆ‘ä»¬ç”¨ä¸€ä¸ªæ ‡é‡å€¼AUCæ¥é‡åŒ–å®ƒã€‚</p><h3 id="AUC"><a href="#AUC" class="headerlink" title="AUC"></a>AUC</h3><p><strong>AUCå®šä¹‰ï¼š</strong></p><p>AUCå€¼ä¸ºROCæ›²çº¿æ‰€è¦†ç›–çš„åŒºåŸŸé¢ç§¯ï¼Œæ˜¾ç„¶ï¼ŒAUCè¶Šå¤§ï¼Œåˆ†ç±»å™¨åˆ†ç±»æ•ˆæœè¶Šå¥½ã€‚</p><p>AUC = 1ï¼Œæ˜¯å®Œç¾åˆ†ç±»å™¨ã€‚ç»å¤§å¤šæ•°é¢„æµ‹çš„åœºåˆï¼Œä¸å­˜åœ¨å®Œç¾åˆ†ç±»å™¨ã€‚</p><p>0.5 &lt; AUC &lt; 1ï¼Œä¼˜äºéšæœºçŒœæµ‹ã€‚è¿™ä¸ªåˆ†ç±»å™¨ï¼ˆæ¨¡å‹ï¼‰å¦¥å–„è®¾å®šé˜ˆå€¼çš„è¯ï¼Œèƒ½æœ‰é¢„æµ‹ä»·å€¼ã€‚</p><p>AUC = 0.5ï¼Œè·ŸéšæœºçŒœæµ‹ä¸€æ ·ï¼ˆä¾‹ï¼šä¸¢é“œæ¿ï¼‰ï¼Œæ¨¡å‹æ²¡æœ‰é¢„æµ‹ä»·å€¼ã€‚</p><p>AUC &lt; 0.5ï¼Œæ¯”éšæœºçŒœæµ‹è¿˜å·®ï¼›ä½†åªè¦æ€»æ˜¯åé¢„æµ‹è€Œè¡Œï¼Œå°±ä¼˜äºéšæœºçŒœæµ‹ã€‚</p><p>æ³¨ï¼šå¯¹äºAUCå°äº0.5çš„æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥è€ƒè™‘å–åï¼ˆæ¨¡å‹é¢„æµ‹ä¸ºpositiveï¼Œé‚£æˆ‘ä»¬å°±å–negtiveï¼‰ï¼Œè¿™æ ·å°±å¯ä»¥ä¿è¯æ¨¡å‹çš„æ€§èƒ½ä¸å¯èƒ½æ¯”éšæœºçŒœæµ‹å·®ã€‚</p><p>ä»¥ä¸‹ä¸ºROCæ›²çº¿å’ŒAUCå€¼çš„å®ä¾‹ï¼š</p><img src="/blog_picture/1.12.png" width="70%"><p><strong>AUCçš„ç‰©ç†æ„ä¹‰</strong></p><p>AUCçš„ç‰©ç†æ„ä¹‰æ­£æ ·æœ¬çš„é¢„æµ‹ç»“æœå¤§äºè´Ÿæ ·æœ¬çš„é¢„æµ‹ç»“æœçš„æ¦‚ç‡ã€‚æ‰€ä»¥AUCååº”çš„æ˜¯åˆ†ç±»å™¨å¯¹æ ·æœ¬çš„æ’åºèƒ½åŠ›ã€‚  </p><p>å¦å¤–å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒAUCå¯¹æ ·æœ¬ç±»åˆ«æ˜¯å¦å‡è¡¡å¹¶ä¸æ•æ„Ÿï¼Œè¿™ä¹Ÿæ˜¯ä¸å‡è¡¡æ ·æœ¬é€šå¸¸ç”¨AUCè¯„ä»·åˆ†ç±»å™¨æ€§èƒ½çš„ä¸€ä¸ªåŸå› ã€‚</p><p>ä¸‹é¢ä»ä¸€ä¸ªå°ä¾‹å­è§£é‡ŠAUCçš„å«ä¹‰ï¼šå°æ˜ä¸€å®¶å››å£ï¼Œå°æ˜5å²ï¼Œå§å§10å²ï¼Œçˆ¸çˆ¸35å²ï¼Œå¦ˆå¦ˆ33å²å»ºç«‹ä¸€ä¸ªé€»è¾‘å›å½’åˆ†ç±»å™¨ï¼Œæ¥é¢„æµ‹å°æ˜å®¶äººä¸ºæˆå¹´äººæ¦‚ç‡ï¼Œå‡è®¾åˆ†ç±»å™¨å·²ç»å¯¹å°æ˜çš„å®¶äººåšè¿‡é¢„æµ‹ï¼Œå¾—åˆ°æ¯ä¸ªäººä¸ºæˆäººçš„æ¦‚ç‡ã€‚</p><ol><li>AUCæ›´å¤šçš„æ˜¯å…³æ³¨å¯¹è®¡ç®—æ¦‚ç‡çš„æ’åºï¼Œå…³æ³¨çš„æ˜¯æ¦‚ç‡å€¼çš„ç›¸å¯¹å¤§å°ï¼Œä¸é˜ˆå€¼å’Œæ¦‚ç‡å€¼çš„ç»å¯¹å¤§å°æ²¡æœ‰å…³ç³»</li></ol><p>ä¾‹å­ä¸­å¹¶ä¸å…³æ³¨å°æ˜æ˜¯ä¸æ˜¯æˆäººï¼Œè€Œå…³æ³¨çš„æ˜¯ï¼Œé¢„æµ‹ä¸ºæˆäººçš„æ¦‚ç‡çš„æ’åºã€‚</p><p><strong>é—®é¢˜â‘ªï¼š</strong>ä»¥ä¸‹ä¸ºä¸‰ç§æ¨¡å‹çš„è¾“å‡ºç»“æœï¼Œæ±‚ä¸‰ç§æ¨¡å‹çš„AUCã€‚</p><table><thead><tr><th></th><th>å°æ˜</th><th>å§å§</th><th>å¦ˆå¦ˆ</th><th>çˆ¸çˆ¸</th></tr></thead><tbody><tr><td>a</td><td>0.12</td><td>0.35</td><td>0.76</td><td>0.85</td></tr><tr><td>b</td><td>0.12</td><td>0.35</td><td>0.44</td><td>0.49</td></tr><tr><td>c</td><td>0.52</td><td>0.65</td><td>0.76</td><td>0.85</td></tr></tbody></table><p>AUCåªä¸æ¦‚ç‡çš„ç›¸å¯¹å¤§å°ï¼ˆæ¦‚ç‡æ’åºï¼‰æœ‰å…³ï¼Œå’Œç»å¯¹å¤§å°æ²¡å…³ç³»ã€‚ç”±äºä¸‰ä¸ªæ¨¡å‹æ¦‚ç‡æ’åºçš„å‰ä¸¤ä½éƒ½æ˜¯æœªæˆå¹´äººï¼ˆå°æ˜ï¼Œå§å§ï¼‰ï¼Œåä¸¤ä½éƒ½æ˜¯æˆå¹´äººï¼ˆå¦ˆå¦ˆï¼Œçˆ¸çˆ¸ï¼‰ï¼Œå› æ­¤ä¸‰ä¸ªæ¨¡å‹çš„AUCéƒ½ç­‰äºã€‚</p><ol><li><p>AUCåªå…³æ³¨æ­£è´Ÿæ ·æœ¬ä¹‹é—´çš„æ’åºï¼Œå¹¶ä¸å…³å¿ƒæ­£æ ·æœ¬å†…éƒ¨ï¼Œæˆ–è€…è´Ÿæ ·æœ¬å†…éƒ¨çš„æ’åºã€‚è¿™ä¹Ÿä½“ç°äº†AUCçš„æœ¬è´¨ï¼šä»»æ„ä¸ªæ­£æ ·æœ¬çš„æ¦‚ç‡éƒ½å¤§äºè´Ÿæ ·æœ¬çš„æ¦‚ç‡çš„èƒ½åŠ›  </p><p>ä¾‹å­ä¸­AUCåªéœ€è¦ä¿è¯ï¼ˆå°æ˜å’Œå§å§ï¼‰ï¼ˆçˆ¸çˆ¸å’Œå¦ˆå¦ˆï¼‰ï¼Œå°æ˜å’Œå§å§åœ¨å‰2ä¸ªæ’åºï¼Œçˆ¸çˆ¸å’Œå¦ˆå¦ˆåœ¨å2ä¸ªæ’åºï¼Œè€Œä¸ä¼šè€ƒè™‘å°æ˜å’Œå§å§è°åœ¨å‰ï¼Œæˆ–è€…çˆ¸çˆ¸å’Œå¦ˆå¦ˆè°åœ¨å‰ã€‚</p><p><strong>é—®é¢˜â‘«ï¼š</strong>ä»¥ä¸‹å·²ç»å¯¹åˆ†ç±»å™¨è¾“å‡ºæ¦‚ç‡ä»å°åˆ°å¤§è¿›è¡Œäº†æ’åˆ—ï¼Œå“ªäº›æƒ…å†µçš„AUCç­‰äº1ï¼Œ æƒ…å†µçš„AUCä¸º0ï¼ˆå…¶ä¸­èƒŒæ™¯è‰²è¡¨ç¤ºTrue valueï¼Œçº¢è‰²è¡¨ç¤ºæˆå¹´äººï¼Œè“è‰²è¡¨ç¤ºæœªæˆå¹´äººï¼‰ã€‚</p><img src="/blog_picture/1.10.png" width="70%"><p>D æ¨¡å‹, Eæ¨¡å‹å’ŒFæ¨¡å‹çš„AUCå€¼ä¸º1ï¼ŒCæ¨¡å‹çš„AUCå€¼ä¸º0ï¼ˆçˆ¸å¦ˆä¸ºæˆå¹´äººçš„æ¦‚ç‡å°äºå°æ˜å’Œå§å§ï¼Œæ˜¾ç„¶è¿™ä¸ªæ¨¡å‹é¢„æµ‹åäº†ï¼‰ã€‚</p></li></ol><p><strong>AUCçš„è®¡ç®—ï¼š</strong></p><ul><li><p>æ³•1ï¼šAUCä¸ºROCæ›²çº¿ä¸‹çš„é¢ç§¯ï¼Œé‚£æˆ‘ä»¬ç›´æ¥è®¡ç®—é¢ç§¯å¯å¾—ã€‚é¢ç§¯ä¸ºä¸€ä¸ªä¸ªå°çš„æ¢¯å½¢é¢ç§¯ï¼ˆæ›²çº¿ï¼‰ä¹‹å’Œã€‚è®¡ç®—çš„ç²¾åº¦ä¸é˜ˆå€¼çš„ç²¾åº¦æœ‰å…³ã€‚</p></li><li><p>æ³•2ï¼šæ ¹æ®AUCçš„ç‰©ç†æ„ä¹‰ï¼Œæˆ‘ä»¬è®¡ç®—æ­£æ ·æœ¬é¢„æµ‹ç»“æœå¤§äºè´Ÿæ ·æœ¬é¢„æµ‹ç»“æœçš„æ¦‚ç‡ã€‚å–n1*n0(n1ä¸ºæ­£æ ·æœ¬æ•°ï¼Œn0ä¸ºè´Ÿæ ·æœ¬æ•°)ä¸ªäºŒå…ƒç»„ï¼Œæ¯”è¾ƒscoreï¼ˆé¢„æµ‹ç»“æœï¼‰ï¼Œæœ€åå¾—åˆ°AUCã€‚æ—¶é—´å¤æ‚åº¦ä¸ºO(N*M)ã€‚</p></li><li><p>æ³•3ï¼šæˆ‘ä»¬é¦–å…ˆæŠŠæ‰€æœ‰æ ·æœ¬æŒ‰ç…§scoreæ’åºï¼Œä¾æ¬¡ç”¨rankè¡¨ç¤ºä»–ä»¬ï¼Œå¦‚æœ€å¤§scoreçš„æ ·æœ¬ï¼Œrank=n (n=n0+n1ï¼Œå…¶ä¸­n0ä¸ºè´Ÿæ ·æœ¬ä¸ªæ•°ï¼Œn1ä¸ºæ­£æ ·æœ¬ä¸ªæ•°)ï¼Œå…¶æ¬¡ä¸ºn-1ã€‚é‚£ä¹ˆå¯¹äºæ­£æ ·æœ¬ä¸­rankæœ€å¤§çš„æ ·æœ¬ï¼Œrank_maxï¼Œæœ‰n1-1ä¸ªå…¶ä»–æ­£æ ·æœ¬æ¯”ä»–scoreå°,é‚£ä¹ˆå°±æœ‰(rank_max-1)-(n1-1)ä¸ªè´Ÿæ ·æœ¬æ¯”ä»–scoreå°ã€‚å…¶æ¬¡ä¸º(rank_second-1)-(n1-2)ã€‚æœ€åæˆ‘ä»¬å¾—åˆ°æ­£æ ·æœ¬å¤§äºè´Ÿæ ·æœ¬çš„æ¦‚ç‡ä¸º</p><p><img src="/blog_picture/auc.jpg" alt="avatar"></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹  </tag>
            
            <tag> ROC </tag>
            
            <tag> AUC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ç®€æ´ç‰ˆæœºå™¨å­¦ä¹ é€ŸæŸ¥è¡¨</title>
      <link href="/2019/08/23/%E7%AE%80%E6%B4%81%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%80%9F%E6%9F%A5%E8%A1%A8/"/>
      <url>/2019/08/23/%E7%AE%80%E6%B4%81%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%80%9F%E6%9F%A5%E8%A1%A8/</url>
      
        <content type="html"><![CDATA[<p><img src="/blog_picture/ml_1.jpg" alt="avatar"><br><img src="/blog_picture/ml_2.jpg" alt="avatar"><br><img src="/blog_picture/ml_3.jpg" alt="avatar"><br><img src="/blog_picture/ml_4.jpg" alt="avatar"><br><img src="/blog_picture/ml_5.jpg" alt="avatar"></p>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CS229ç‰ˆæœºå™¨å­¦ä¹ é€ŸæŸ¥è¡¨</title>
      <link href="/2019/08/23/CS229%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%80%9F%E6%9F%A5%E8%A1%A8/"/>
      <url>/2019/08/23/CS229%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%80%9F%E6%9F%A5%E8%A1%A8/</url>
      
        <content type="html"><![CDATA[<p><img src="https://s1.ax1x.com/2020/04/24/JBZ8U0.jpg" alt="avatar"></p><p><img src="https://s1.ax1x.com/2020/04/24/JBZg2D.jpg" alt="avatar"><br><img src="https://s1.ax1x.com/2020/04/24/JBZHG8.jpg" alt="avatar"><br><img src="https://s1.ax1x.com/2020/04/24/JBZzaq.jpg" alt="avatar"><br><img src="https://s1.ax1x.com/2020/04/24/JBePRU.jpg" alt="avatar"><br><img src="https://s1.ax1x.com/2020/04/24/JBeAsJ.jpg" alt="avatar"><br><img src="https://s1.ax1x.com/2020/04/24/JBmBh6.jpg" alt="avatar"><br><img src="https://s1.ax1x.com/2020/04/24/JBm2Bd.jpg" alt="avatar"><br><img src="https://s1.ax1x.com/2020/04/24/JBmhNt.jpg" alt="avatar"><br><img src="https://s1.ax1x.com/2020/04/24/JBmo38.jpg" alt="avatar"><br><img src="https://s1.ax1x.com/2020/04/24/JBm7jg.jpg" alt="avatar"><br><img src="https://s1.ax1x.com/2020/04/24/JBmv40.jpg" alt="avatar"><br><img src="https://s1.ax1x.com/2020/04/24/JBniDJ.jpg" alt="avatar"><br><img src="https://s1.ax1x.com/2020/04/24/JBnAER.jpg" alt="avatar"><br><img src="https://s1.ax1x.com/2020/04/24/JBneC6.jpg" alt="avatar"><br><img src="https://s1.ax1x.com/2020/04/24/JBnYPP.jpg" alt="avatar"></p>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>è‘«èŠ¦ä¹¦å­¦ä¹ ç¬”è®°</title>
      <link href="/2019/08/08/%E8%91%AB%E8%8A%A6%E4%B9%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>/2019/08/08/%E8%91%AB%E8%8A%A6%E4%B9%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="1-ä¸ºä»€ä¹ˆéœ€è¦å¯¹æ•°å€¼ç±»å‹çš„ç‰¹å¾åšå½’ä¸€åŒ–å¤„ç†ï¼Ÿ"><a href="#1-ä¸ºä»€ä¹ˆéœ€è¦å¯¹æ•°å€¼ç±»å‹çš„ç‰¹å¾åšå½’ä¸€åŒ–å¤„ç†ï¼Ÿ" class="headerlink" title="1.ä¸ºä»€ä¹ˆéœ€è¦å¯¹æ•°å€¼ç±»å‹çš„ç‰¹å¾åšå½’ä¸€åŒ–å¤„ç†ï¼Ÿ"></a>1.ä¸ºä»€ä¹ˆéœ€è¦å¯¹æ•°å€¼ç±»å‹çš„ç‰¹å¾åšå½’ä¸€åŒ–å¤„ç†ï¼Ÿ</h1><ul><li>ä¸ºäº†æ–¹ä¾¿åç»­è¿›è¡Œæ¢¯åº¦ä¸‹é™çš„æ—¶å€™åŠ é€Ÿæ”¶æ•›</li><li>å½’ä¸€åŒ–é€šå¸¸ä¸»è¦åˆ†ä¸ºä¸¤ç§ï¼šmin-max(çº¿æ€§å‡½æ•°å½’ä¸€åŒ–)ï¼ŒZ-Score(é›¶å‡å€¼å½’ä¸€åŒ–)</li><li>éœ€è¦è¿›è¡Œå½’ä¸€åŒ–çš„æ¨¡å‹ï¼šçº¿æ€§å›å½’ï¼ŒLRï¼ŒSVMï¼Œç¥ç»ç½‘ç»œç­‰</li><li>å†³ç­–æ ‘æ¨¡å‹ä¸é€‚ç”¨å½’ä¸€åŒ–å¤„ç†ï¼Œå› ä¸ºå†³ç­–æ ‘åœ¨è¿›è¡ŒèŠ‚ç‚¹åˆ†è£‚æ—¶ä¸»è¦ä¾æ®æ•°æ®é›†Då…³äºç‰¹å¾xçš„ä¿¡æ¯å¢ç›Šæ¯”ï¼Œè€Œä¿¡æ¯å¢ç›Šæ¯”å’Œç‰¹å¾æ˜¯å¦è¿›è¡Œå½’ä¸€åŒ–æ— å…³ï¼Œå› ä¸ºå½’ä¸€åŒ–å¹¶ä¸æ”¹å˜æ ·æœ¬åœ¨ç‰¹å¾xä¸Šçš„ä¿¡æ¯å¢ç›Šã€‚</li></ul><h1 id="2-ô³‰ô´”ô³“åœ¨æ•°æ®è¿›è¡Œé¢„å¤„ç†æ—¶ï¼Œåº”è¯¥æ€æ ·å¤„ç†ç±»åˆ«å‹ç‰¹å¾ï¼Ÿ"><a href="#2-ô³‰ô´”ô³“åœ¨æ•°æ®è¿›è¡Œé¢„å¤„ç†æ—¶ï¼Œåº”è¯¥æ€æ ·å¤„ç†ç±»åˆ«å‹ç‰¹å¾ï¼Ÿ" class="headerlink" title="2.ô³‰ô´”ô³“åœ¨æ•°æ®è¿›è¡Œé¢„å¤„ç†æ—¶ï¼Œåº”è¯¥æ€æ ·å¤„ç†ç±»åˆ«å‹ç‰¹å¾ï¼Ÿ"></a>2.ô³‰ô´”ô³“åœ¨æ•°æ®è¿›è¡Œé¢„å¤„ç†æ—¶ï¼Œåº”è¯¥æ€æ ·å¤„ç†ç±»åˆ«å‹ç‰¹å¾ï¼Ÿ</h1><ul><li>ç±»åˆ«å‹ç‰¹å¾åŸå§‹è¾“å…¥å½¢å¼é€šå¸¸æ˜¯å­—ç¬¦ä¸²å½¢å¼ã€é™¤äº†å†³ç­–æ ‘ç­‰å°‘é‡æ¨¡å‹èƒ½ç›´æ¥å¤„ç†å­—ç¬¦ä¸²å½¢å¼çš„è¾“å…¥ï¼Œå¯¹äºLRã€SVMç­‰æ¨¡å‹æ¥è¯´ï¼Œç±»åˆ«å‹ç‰¹å¾å¿…é¡»ç»è¿‡å¤„ç†è½¬æ¢æˆæ•°å€¼å‹ç‰¹å¾æ‰èƒ½æ­£ç¡®å·¥ä½œ</li><li>åºå·ç¼–ç (ordinal)ï¼šç±»åˆ«é—´å…·æœ‰å¤§å°å…³ç³»</li><li>ç‹¬çƒ­ç¼–ç (one-hot)ï¼šç±»åˆ«é—´æ²¡æœ‰å¤§å°å…³ç³»ï¼Œç‰¹å¾çš„æ¯ä¸ªå€¼ä½œä¸ºä¸€åˆ—ã€‚ç»´åº¦è¿‡é«˜å¯èƒ½å¯¼è‡´ç»´åº¦ç¾éš¾ï¼Œäº§ç”Ÿè¿‡æ‹Ÿåˆé—®é¢˜ã€‚</li><li>äºŒè¿›åˆ¶ç¼–ç ï¼šå…ˆç”¨åºå·ç¼–ç ç»™æ¯ä¸ªç±»åˆ«èµ‹äºˆä¸€ä¸ªç±»åˆ«IDï¼Œç„¶åå°†IDè½¬ä¸ºäºŒè¿›åˆ¶ç¼–ç ä½œä¸ºç»“æœã€‚</li></ul><h1 id="3-ä»€ä¹ˆæ˜¯ç»„åˆç‰¹å¾ï¼Ÿå¦‚ä½•å¤„ç†é«˜ç»´ç»„åˆç‰¹å¾-è§£å†³é«˜ç»´ç»„åˆç‰¹å¾ç»´åº¦è¿‡é«˜çš„é—®é¢˜-ï¼Ÿ"><a href="#3-ä»€ä¹ˆæ˜¯ç»„åˆç‰¹å¾ï¼Ÿå¦‚ä½•å¤„ç†é«˜ç»´ç»„åˆç‰¹å¾-è§£å†³é«˜ç»´ç»„åˆç‰¹å¾ç»´åº¦è¿‡é«˜çš„é—®é¢˜-ï¼Ÿ" class="headerlink" title="3.ä»€ä¹ˆæ˜¯ç»„åˆç‰¹å¾ï¼Ÿå¦‚ä½•å¤„ç†é«˜ç»´ç»„åˆç‰¹å¾(è§£å†³é«˜ç»´ç»„åˆç‰¹å¾ç»´åº¦è¿‡é«˜çš„é—®é¢˜)ï¼Ÿ"></a>3.ä»€ä¹ˆæ˜¯ç»„åˆç‰¹å¾ï¼Ÿå¦‚ä½•å¤„ç†é«˜ç»´ç»„åˆç‰¹å¾(è§£å†³é«˜ç»´ç»„åˆç‰¹å¾ç»´åº¦è¿‡é«˜çš„é—®é¢˜)ï¼Ÿ</h1><ul><li>å¯ä»¥å°†M * NçŸ©é˜µåˆ†è§£ä¸ºM * Kå’ŒK * Nä¸¤ä¸ªçŸ©é˜µç›¸ä¹˜çš„å½¢å¼ï¼Œè¿™æ ·å‚æ•°ä»M * Né™åˆ° K * (M+N)</li><li>ä¸ºäº†æé«˜å¤æ‚å…³ç³»çš„æ‹Ÿåˆèƒ½åŠ›ï¼Œåœ¨ç‰¹å¾å·¥ç¨‹ä¸­ç»å¸¸ä¼šæŠŠä¸€é˜¶ç¦»æ•£ç‰¹å¾ä¸¤ä¸¤ç»„åˆï¼Œæ„æˆé«˜é˜¶ç»„åˆç‰¹å¾ã€‚</li></ul><p>#4.æ€æ ·æœ‰æ•ˆçš„æ‰¾åˆ°ç»„åˆç‰¹å¾ï¼Ÿ</p><ul><li>åŸºäºå†³ç­–æ ‘çš„ç‰¹å¾ç»„åˆå¯»æ‰¾ã€‚ï¼ˆåŸå§‹è¾“å…¥æ„å»ºå†³ç­–æ ‘å¯ä»¥é‡‡ç”¨æ¢¯åº¦æå‡å†³ç­–æ ‘å³æ¯æ¬¡éƒ½åœ¨ä¹‹å‰æ„å»ºçš„å†³ç­–æ ‘çš„æ®‹å·®ä¸Šæ„å»ºä¸‹ä¸€è¯¾å†³ç­–æ ‘ï¼‰</li></ul><h1 id="5-æœ‰å“ªäº›æ–‡æœ¬æ¨¡å‹ï¼Ÿä»–ä»¬å„æœ‰ä»€ä¹ˆä¼˜ç¼ºç‚¹ï¼Ÿ"><a href="#5-æœ‰å“ªäº›æ–‡æœ¬æ¨¡å‹ï¼Ÿä»–ä»¬å„æœ‰ä»€ä¹ˆä¼˜ç¼ºç‚¹ï¼Ÿ" class="headerlink" title="5.æœ‰å“ªäº›æ–‡æœ¬æ¨¡å‹ï¼Ÿä»–ä»¬å„æœ‰ä»€ä¹ˆä¼˜ç¼ºç‚¹ï¼Ÿ"></a>5.æœ‰å“ªäº›æ–‡æœ¬æ¨¡å‹ï¼Ÿä»–ä»¬å„æœ‰ä»€ä¹ˆä¼˜ç¼ºç‚¹ï¼Ÿ</h1><ul><li>è¯è¢‹æ¨¡å‹(bag of words)ï¼šæœ€åŸºç¡€çš„æ–‡æœ¬è¡¨ç¤ºæ¨¡å‹æ˜¯è¯è¢‹æ¨¡å‹ã€‚é¡¾åæ€ä¹‰ï¼Œå°±æ˜¯å°†æ¯ç¯‡æ–‡ç« çœ‹æˆä¸€è¢‹å­è¯ï¼Œå¹¶å¿½ç•¥æ¯ä¸ªè¯å‡ºç°çš„é¡ºåºã€‚å°†æ•´æ®µæ–‡æœ¬ä»¥è¯ä¸ºå•ä½åˆ‡åˆ†å¼€ï¼Œç„¶åæ¯ç¯‡æ–‡ç« å¯ä»¥è¡¨ç¤ºæˆä¸€ä¸ªé•¿å‘é‡ï¼Œå‘é‡ä¸­çš„æ¯ä¸€ç»´ä»£è¡¨ä¸€ä¸ªå•è¯ï¼Œè€Œè¯¥ç»´å¯¹åº”å¾—æƒé‡åˆ™åˆ™åæ˜ äº†è¿™ä¸ªè¯åœ¨åŸæ–‡ç« çš„é‡è¦ç¨‹åº¦ã€‚ä½†æ˜¯è¯è¢‹å¿½ç•¥äº†ç”±å‡ ä¸ªè¯ç»„æˆä¸€ä¸ªæ„æ€è¿™ç§æƒ…å†µï¼ˆâ€œå¦‚NBAåæ§½å¤§ä¼šâ€è¿™ç§ï¼Œåˆ†è§£æˆäº†NBAå’Œåæ§½å¤§ä¼šï¼Œç»“æœåŒ¹é…äº†å¾ˆå¤šæè¯è¿™æ ·å’ŒNBAå®Œå…¨ä¸ç›¸å…³çš„ç‰©æ–™ï¼‰</li><li>N-gramæ¨¡å‹ï¼šè¯è¢‹æ¨¡å‹çš„æ”¹è¿›ï¼ŒN-gramå°†è¿ç»­å‡ºç°çš„Nä¸ªè¯ç»„æˆçš„è¯ç»„ä¹Ÿä½œä¸ºä¸€ç»´æ”¾åˆ°å‘é‡è¡¨ç¤ºä¸­å»ã€‚ä½†æ˜¯N-gramä¸èƒ½è¯†åˆ«ä¸¤ä¸ªä¸åŒçš„è¯æœ‰ç›¸åŒçš„ä¸»é¢˜</li><li>TF-TDFï¼šTF-IDF(t,d) = TF(t,d)*IDF(t)å…¶ä¸­ï¼ŒTF(t,d)ä¸ºå•è¯tåœ¨æ–‡æ¡£dä¸­å‡ºç°çš„é¢‘ç‡ï¼ŒIDF(t) = log(æ–‡ç« æ€»æ•°/(åŒ…å«å•è¯tçš„æ–‡ç« æ€»æ•°+1)) ï¼ŒIDFå…¬å¼å¯ç†è§£ä¸ºå¦‚æœä¸€ä¸ªè¯å‡ºç°çš„æ–‡ç« æ•°è¶Šå¤šé‚£ä¹ˆè¯´æ˜å®ƒè¶Šæ˜¯ä¸€ä¸ªé€šç”¨è¯ï¼Œé€šç”¨è¯å¯¹æ–‡æ¡£å†…å®¹è´¡çŒ®åº¦æ¯”è¾ƒå°</li><li>ä¸»é¢˜æ¨¡å‹ï¼šä¸»é¢˜æ¨¡å‹ç”¨äºä»æ–‡æœ¬åº“å‘ç°æœ‰ä»£è¡¨æ€§çš„ä¸»é¢˜ï¼ˆå¾—åˆ°æ¯ä¸ªä¸»é¢˜ä¸Šé¢è¯çš„åˆ†å¸ƒç‰¹æ€§ï¼‰ï¼Œå¹¶ä¸”èƒ½å¤Ÿè®¡ç®—å‡ºæ¯ç¯‡æ–‡ç« çš„ä¸»é¢˜åˆ†å¸ƒã€‚</li><li>è¯åµŒå…¥ä¸æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼šè¯åµŒå…¥æ˜¯ä¸€ç±»å°†è¯å‘é‡åŒ–çš„æ¨¡å‹çš„ç»Ÿç§°ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯å°†æ¯ä¸ªè¯éƒ½æ˜ å°„æˆä½ç»´ç©ºé—´ï¼ˆé€šå¸¸50-300ç»´)ä¸Šçš„ä¸€ä¸ªç¨ å¯†å‘é‡ã€‚Kç»´ç©ºé—´ä¸­çš„æ¯ä¸€ç»´éƒ½å¯ä»¥çœ‹ä½œæ˜¯ä¸€ä¸ªéšå«çš„ä¸»é¢˜ï¼Œåªä¸è¿‡ä¸åƒä¸»é¢˜æ¨¡å‹ä¸­çš„ä¸»é¢˜é‚£ä¹ˆç›´è§‚ã€‚ç”±äºè¯åµŒå…¥å°†æ¯ä¸ªè¯æ˜ å°„æˆä¸€ä¸ªKç»´çš„å‘é‡ï¼Œå¦‚æœä¸€ç¯‡æ–‡ç« æœ‰Nä¸ªè¯ï¼Œå°±å¯ä»¥ç”¨ä¸€ä¸ªN*Kç»´çš„çŸ©é˜µæ¥è¡¨ç¤ºè¿™ç¯‡æ–‡æ¡£ï¼Œä½†æ˜¯è¿™æ ·è¡¨ç¤ºè¿‡å»åº•å±‚ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¦‚æœä»…ä»…æŠŠè¿™ä¸ªçŸ©é˜µä½œä¸ºæºæ–‡æœ¬çš„è¡¨ç¤ºç‰¹å¾è¾“å…¥åˆ°æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­ï¼Œé€šå¸¸å¾ˆéš¾å¾—åˆ°æ»¡æ„çš„ç»“æœã€‚å› æ­¤ï¼Œè¿˜éœ€è¦åœ¨æ­¤åŸºç¡€ä¸ŠåŠ å·¥å‡ºæ›´é«˜å±‚çš„ç‰¹å¾ã€‚åœ¨ä¼ ç»Ÿçš„æµ…å±‚æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­ï¼Œä¸€ä¸ªå¥½çš„ç‰¹å¾å·¥ç¨‹å¾€å¾€å¯ä»¥å¸¦æ¥ç®—æ³•æ•ˆæœçš„æ˜¾è‘—æç¤ºã€‚æ·±åº¦å­¦ä¹ æ¨¡å‹æ­£å¥½ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ç§è‡ªåŠ¨ çš„è¿›è¡Œç‰¹å¾å·¥ç¨‹çš„æ–¹å¼ï¼Œæ¨¡å‹ä¸­çš„æ¯ä¸ªéšå±‚éƒ½å¯ä»¥è®¤ä¸ºå¯¹åº”ç€ä¸åŒæŠ½è±¡å±‚æ¬¡çš„ç‰¹å¾ã€‚å·ç§¯ç¥ç»ç½‘ç»œå’Œå¾ªç¯ç¥ç»ç½‘ç»œçš„ç»“æ„åœ¨æ–‡æœ¬è¡¨ç¤ºä¸­å–å¾—å¾ˆå¥½çš„æ•ˆæœï¼Œä¸»è¦æ˜¯ç”±äºä»–ä»¬èƒ½å¤Ÿæ›´å¥½çš„å¯¹æ–‡æœ¬è¿›è¡Œå»ºæ¨¡ï¼ŒæŠ½å–å‡ºæ›´é«˜å±‚çš„è¯­ä¹‰ç‰¹å¾ã€‚ã€‚ä¸å…¨é“¾æ¥ç½‘ç»œç»“æ„ç›¸æ¯”ï¼Œå·ç§¯ç¥ç»ç½‘ç»œå’ŒRNNä¸€æ–¹é¢å¾ˆå¥½çš„æŠ“ä½äº†æ–‡æœ¬çš„ç‰¹å¾ï¼Œå¦ä¸€æ–¹é¢åˆå‡å°‘äº†ç½‘ç»œå­¦ä¹ ä¸­å¾…å­¦ä¹ çš„å‚æ•°ï¼Œæé«˜äº†è®­ç»ƒé€Ÿåº¦ï¼Œå¹¶ä¸”é™ä½äº†è¿‡æ‹Ÿåˆçš„é£é™©ã€‚</li></ul><h1 id="6-Word2Vecæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿå®ƒå’ŒLDAæœ‰ä»€ä¹ˆåŒºåˆ«ä¸è”ç³»ï¼Ÿ"><a href="#6-Word2Vecæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿå®ƒå’ŒLDAæœ‰ä»€ä¹ˆåŒºåˆ«ä¸è”ç³»ï¼Ÿ" class="headerlink" title="6.Word2Vecæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿå®ƒå’ŒLDAæœ‰ä»€ä¹ˆåŒºåˆ«ä¸è”ç³»ï¼Ÿ"></a>6.Word2Vecæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿå®ƒå’ŒLDAæœ‰ä»€ä¹ˆåŒºåˆ«ä¸è”ç³»ï¼Ÿ</h1><ul><li>word2vecå®é™…ä¸Šä¸€ç§æµ…å±‚çš„ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œå®ƒæœ‰ä¸¤ç§ç½‘ç»œç»“æ„ï¼Œåˆ†åˆ«æ˜¯CBOW(continues bag of words)å’ŒSkip-gram</li><li>CBOWçš„ç›®æ ‡æ˜¯æ ¹æ®ä¸Šä¸‹æ–‡å‡ºç°çš„è¯è¯­æ¥é¢„æµ‹å½“å‰è¯çš„ç”Ÿæˆæ¦‚ç‡ï¼›skip-gramæ˜¯æ ¹æ®å½“å‰è¯æ¥é¢„æµ‹ä¸Šä¸‹æ–‡ä¸­å„è¯çš„ç”Ÿæˆæ¦‚ç‡ã€‚</li><li>word2vecæ˜¯googleå¼€å‘çš„ä¸€ç§è¯å‘é‡åµŒå…¥çš„æ¨¡å‹ï¼Œä¸»è¦åˆ†ä¸ºCBOWå’Œskip-gramä¸¤ç§ï¼Œæœ€åå¾—åˆ°å¾—è¯å‘é‡æ˜¯dense vectorã€‚</li><li>LDAæ˜¯ä¸€ç§ç”Ÿæˆæ¨¡å‹ï¼Œæœ€åå¯ä»¥å¾—åˆ°æ–‡æ¡£ä¸ä¸»é¢˜ï¼Œä¸»é¢˜ä¸è¯ä¹‹é—´çš„æ¦‚ç‡åˆ†å¸ƒã€‚</li></ul><h1 id="7-åœ¨å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­ï¼Œè®­ç»ƒæ•°æ®ä¸è¶³ä¼šå¸¦æ¥ä»€ä¹ˆé—®é¢˜ï¼Ÿå¦‚ä½•ç¼“è§£æ•°æ®é‡ä¸è¶³å¸¦æ¥çš„é—®é¢˜ï¼Ÿ"><a href="#7-åœ¨å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­ï¼Œè®­ç»ƒæ•°æ®ä¸è¶³ä¼šå¸¦æ¥ä»€ä¹ˆé—®é¢˜ï¼Ÿå¦‚ä½•ç¼“è§£æ•°æ®é‡ä¸è¶³å¸¦æ¥çš„é—®é¢˜ï¼Ÿ" class="headerlink" title="7.åœ¨å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­ï¼Œè®­ç»ƒæ•°æ®ä¸è¶³ä¼šå¸¦æ¥ä»€ä¹ˆé—®é¢˜ï¼Ÿå¦‚ä½•ç¼“è§£æ•°æ®é‡ä¸è¶³å¸¦æ¥çš„é—®é¢˜ï¼Ÿ"></a>7.åœ¨å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­ï¼Œè®­ç»ƒæ•°æ®ä¸è¶³ä¼šå¸¦æ¥ä»€ä¹ˆé—®é¢˜ï¼Ÿå¦‚ä½•ç¼“è§£æ•°æ®é‡ä¸è¶³å¸¦æ¥çš„é—®é¢˜ï¼Ÿ</h1><ul><li>è®­ç»ƒæ•°æ®ä¸è¶³ä¸»è¦è¡¨ç°åœ¨è¿‡æ‹Ÿåˆæ–¹é¢ã€‚</li><li>ä¸¤ç±»å¤„ç†æ–¹æ³•ï¼šä¸€æ˜¯åŸºäºæ¨¡å‹çš„æ–¹æ³•ï¼Œä¸»è¦æ˜¯é‡‡ç”¨é™ä½è¿‡æ‹Ÿåˆé£é™©çš„æªæ–½åŒ…æ‹¬ç®€åŒ–æ¨¡å‹(éçº¿æ€§ç®€åŒ–ä¸ºçº¿æ€§)ã€æ·»åŠ çº¦æŸé¡¹ä»¥ç¼©å°å‡è®¾ç©ºé—´ã€é›†æˆå­¦ä¹ ã€Dropoutè¶…å‚æ•°ç­‰ã€‚äºŒæ˜¯åŸºäºæ•°æ®çš„çš„æ–¹æ³•ï¼Œä¸»è¦æ˜¯é€šè¿‡æ•°æ®æ‰©å……</li></ul><h1 id="8-å‡†ç¡®ç‡çš„å±€é™æ€§"><a href="#8-å‡†ç¡®ç‡çš„å±€é™æ€§" class="headerlink" title="8.å‡†ç¡®ç‡çš„å±€é™æ€§"></a>8.å‡†ç¡®ç‡çš„å±€é™æ€§</h1><ul><li>ä¸åŒç±»åˆ«çš„æ ·æœ¬æ¯”ä¾‹éå¸¸ä¸å‡åŒ€æ—¶ï¼Œå æ¯”å¤§çš„ç±»åˆ«å¾€å¾€æˆä¸ºå½±å“å‡†ç¡®ç‡çš„æœ€ä¸»è¦å› ç´ </li></ul><h1 id="9-ç²¾ç¡®ç‡ä¸å¬å›ç‡çš„æƒè¡¡"><a href="#9-ç²¾ç¡®ç‡ä¸å¬å›ç‡çš„æƒè¡¡" class="headerlink" title="9.ç²¾ç¡®ç‡ä¸å¬å›ç‡çš„æƒè¡¡"></a>9.ç²¾ç¡®ç‡ä¸å¬å›ç‡çš„æƒè¡¡</h1><ul><li>åªç”¨æŸä¸ªç‚¹å¯¹åº”çš„ç²¾ç¡®ç‡å’Œå¬å›ç‡ä¸èƒ½å…¨é¢åœ°è¡¡é‡æ¨¡å‹çš„æ€§èƒ½ï¼Œåªæœ‰é€šè¿‡P-Ræ›²çº¿çš„æ•´ä½“è¡¨ç°ï¼Œæ‰èƒ½å¤Ÿå¯¹æ¨¡å‹è¿›è¡Œæ›´ä¸ºå…¨é¢çš„è¯„ä¼°</li></ul><h1 id="10-å¹³æ–¹æ ¹è¯¯å·®çš„æ„å¤–"><a href="#10-å¹³æ–¹æ ¹è¯¯å·®çš„æ„å¤–" class="headerlink" title="10.å¹³æ–¹æ ¹è¯¯å·®çš„æ„å¤–"></a>10.å¹³æ–¹æ ¹è¯¯å·®çš„æ„å¤–</h1><ul><li>ä¸€èˆ¬æƒ…å†µä¸‹ï¼ŒRMSEèƒ½å¤Ÿå¾ˆå¥½çš„åæ˜ å›å½’æ¨¡å‹é¢„æµ‹å€¼ä¸çœŸå®å€¼çš„åç¦»ç¨‹åº¦ã€‚ä½†åœ¨å®é™…é—®é¢˜ä¸­ï¼Œå¦‚æœå­˜åœ¨ä¸ªåˆ«åç¦»ç¨‹åº¦éå¸¸å¤§çš„ç¦»ç¾¤ç‚¹æ—¶ï¼Œå³ä½¿ç¦»ç¾¤ç‚¹æ•°é‡éå¸¸å°‘ï¼Œä¹Ÿä¼šè®©RMSEæŒ‡æ ‡å˜å¾—å¾ˆå·®ã€‚</li><li>è§£å†³æ–¹æ³•ï¼šä¸€ï¼Œåœ¨æ•°æ®é¢„å¤„ç†æ—¶è¿‡æ»¤è¿™äº›å™ªå£°ç‚¹ã€‚äºŒï¼Œå¦‚æœä¸è®¤ä¸ºè¿™äº›ç¦»ç¾¤ç‚¹æ˜¯å™ªå£°çš„è¯å°±è¦è¿›ä¸€æ­¥æé«˜æ¨¡å‹çš„é¢„æµ‹èƒ½åŠ›ï¼Œå°†ç¦»ç¾¤ç‚¹äº§ç”Ÿçš„æœºåˆ¶å»ºæ¨¡è¿›å»ã€‚ä¸‰ï¼Œæ‰¾ä¸€ä¸ªæ›´åˆé€‚çš„æŒ‡æ ‡æ¥è¯„ä¼°è¯¥æ¨¡å‹ã€‚</li></ul><h1 id="11-ä»€ä¹ˆæ˜¯ROCæ›²çº¿"><a href="#11-ä»€ä¹ˆæ˜¯ROCæ›²çº¿" class="headerlink" title="11.ä»€ä¹ˆæ˜¯ROCæ›²çº¿"></a>11.ä»€ä¹ˆæ˜¯ROCæ›²çº¿</h1><ul><li>ROCôµ»ôµ²ô°‹æ›²çº¿æ˜¯Receiver Operating Characteristic Curveô°Šôµ±ô²’ô°¢ô±Ÿçš„ç®€ç§°ï¼Œä¸­æ–‡åä¸ºâ€œå—è¯•è€…å·¥ä½œç‰¹å¾æ›²çº¿â€ã€‚ROCæ›²çº¿çš„æ¨ªåæ ‡ä¸ºå‡é˜³æ€§ç‡FPRï¼›çºµåæ ‡ä¸ºçœŸé˜³æ€§ç‡TPRã€‚</li></ul><p>#12.å¦‚æœç»˜åˆ¶ROCôµ»ôµ²ô°‹æ›²çº¿</p><ul><li>ROCôµ»ôµ²ô°‹æ›²çº¿æ˜¯é€šè¿‡ä¸æ–­ç§»åŠ¨åˆ†ç±»å™¨çš„â€œæˆªæ–­ç‚¹â€æ¥ç”Ÿæˆæ›²çº¿ä¸Šä¸€ç»„å…³é”®ç‚¹çš„ã€‚</li><li>é¦–å…ˆæ ¹æ®æ ·æœ¬æ ‡ç­¾ç»Ÿè®¡å‡ºæ­£è´Ÿæ ·æœ¬çš„æ•°é‡ï¼Œå‡è®¾æ­£æ ·æœ¬æ•°é‡ä¸ºpï¼Œè´Ÿæ ·æœ¬æ•°é‡ä¸ºnï¼›æ¥ä¸‹æ¥ï¼ŒæŠŠæ¨ªè½´çš„åˆ»åº¦é—´éš”è®¾ç½®ä¸º1/n,çºµè½´çš„åˆ»åº¦é—´éš”è®¾ç½®ä¸º1/pï¼›å†æ ¹æ®æ¨¡å‹è¾“å‡ºçš„é¢„æµ‹æ¦‚ç‡å¯¹æ ·æœ¬è¿›è¡Œæ’åºä¾æ¬¡éå†æ ·æœ¬ï¼ŒåŒæ—¶ä»é›¶ç‚¹å¼€å§‹ç»˜åˆ¶ROCôµ»ôµ²ô°‹æ›²çº¿ï¼Œæ¯é‡åˆ°ä¸€ä¸ªæ­£æ ·æœ¬å°±æ²¿çºµè½´æ–¹å‘ç»˜åˆ¶ä¸€ä¸ªåˆ»åº¦é—´éš”çš„æ›²çº¿ï¼Œæ¯é‡åˆ°ä¸€ä¸ªè´Ÿæ ·æœ¬å°±æ²¿ç€æ¨ªè½´æ–¹å‘ç»˜åˆ¶ä¸€ä¸ªåˆ»åº¦é—´éš”çš„æ›²çº¿ï¼Œç›´åˆ°éå†å®Œæ‰€æœ‰æ ·æœ¬ï¼Œæ›²çº¿æœ€ç»ˆåœåœ¨ï¼ˆ1ï¼Œ1ï¼‰è¿™ä¸ªç‚¹ï¼Œæ•´ä¸ªROCæ›²çº¿ç»˜åˆ¶å®Œæˆã€‚</li></ul><h1 id="13-å¦‚ä½•è®¡ç®—AUC"><a href="#13-å¦‚ä½•è®¡ç®—AUC" class="headerlink" title="13.å¦‚ä½•è®¡ç®—AUC"></a>13.å¦‚ä½•è®¡ç®—AUC</h1><ul><li>æ²¿ç€ROCæ¨ªè½´åšç§¯åˆ†ã€‚</li></ul><h1 id="14-ROCæ›²çº¿ç›¸æ¯”P-Ræ›²çº¿æœ‰ä»€ä¹ˆç‰¹ç‚¹"><a href="#14-ROCæ›²çº¿ç›¸æ¯”P-Ræ›²çº¿æœ‰ä»€ä¹ˆç‰¹ç‚¹" class="headerlink" title="14.ROCæ›²çº¿ç›¸æ¯”P-Ræ›²çº¿æœ‰ä»€ä¹ˆç‰¹ç‚¹"></a>14.ROCæ›²çº¿ç›¸æ¯”P-Ræ›²çº¿æœ‰ä»€ä¹ˆç‰¹ç‚¹</h1><ul><li>å½“æ­£è´Ÿæ ·æœ¬çš„åˆ†å¸ƒå‘ç”Ÿå˜åŒ–æ—¶ï¼ŒROCæ›²çº¿çš„å½¢çŠ¶èƒ½å¤ŸåŸºæœ¬ä¿æŒä¸å˜ï¼Œè€ŒP-Ræ›²çº¿çš„å½¢çŠ¶ä¸€èˆ¬ä¼šå‘ç”Ÿè¾ƒå‰§çƒˆå˜åŒ–ã€‚</li><li>ROCæ›²çº¿èƒ½å¤Ÿå°½é‡é™ä½ä¸åŒæµ‹è¯•é›†å¸¦æ¥çš„å¹²æ‰°ï¼Œæ›´åŠ å®¢è§‚åœ°è¡¡é‡æ¨¡å‹æœ¬èº«çš„æ€§èƒ½ã€‚ROCæ›²çº¿çš„é€‚ç”¨èŒƒå›´æ›´å¹¿ï¼Œé€‚ç”¨äºæ’åºã€æ¨èã€å¹¿å‘Šã€‚é€‰æ‹©ROCæ›²çº¿è¿˜æ˜¯P-Ræ›²çº¿å› å®é™…é—®é¢˜è€Œå¼‚ï¼Œå¦‚æœå¸Œæœ›æ›´å¤šçš„çœ‹åˆ°æ¨¡å‹åœ¨ç‰¹å®šæ•°æ®é›†ä¸Šçš„è¡¨ç°ï¼ŒP-Ræ›²çº¿èƒ½å¤Ÿæ›´ç›´è§‚åœ°åæ˜ å…¶æ€§èƒ½ã€‚</li></ul><h1 id="15-ç»“åˆä½ çš„å­¦ä¹ å’Œç ”ç©¶ç»å†ï¼Œæ¢è®¨ä¸ºä»€ä¹ˆåœ¨ä¸€äº›åœºæ™¯ä¸­è¦ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦è€Œä¸æ˜¯æ¬§æ°è·ç¦»"><a href="#15-ç»“åˆä½ çš„å­¦ä¹ å’Œç ”ç©¶ç»å†ï¼Œæ¢è®¨ä¸ºä»€ä¹ˆåœ¨ä¸€äº›åœºæ™¯ä¸­è¦ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦è€Œä¸æ˜¯æ¬§æ°è·ç¦»" class="headerlink" title="15.ç»“åˆä½ çš„å­¦ä¹ å’Œç ”ç©¶ç»å†ï¼Œæ¢è®¨ä¸ºä»€ä¹ˆåœ¨ä¸€äº›åœºæ™¯ä¸­è¦ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦è€Œä¸æ˜¯æ¬§æ°è·ç¦»"></a>15.ç»“åˆä½ çš„å­¦ä¹ å’Œç ”ç©¶ç»å†ï¼Œæ¢è®¨ä¸ºä»€ä¹ˆåœ¨ä¸€äº›åœºæ™¯ä¸­è¦ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦è€Œä¸æ˜¯æ¬§æ°è·ç¦»</h1><ul><li>å½“ä¸€å¯¹æ–‡æœ¬ç›¸ä¼¼åº¦çš„é•¿åº¦å·®è·å¾ˆå¤§ã€ä½†å†…å®¹ç›¸è¿‘æ—¶ï¼Œå¦‚æœé‡‡ç”¨è¯é¢‘æˆ–è¯å‘é‡ä½œä¸ºç‰¹å¾ï¼Œå®ƒä»¬åœ¨ç‰¹å¾ç©ºé—´ä¸­çš„æ¬§å¼è·ç¦»é€šå¸¸å¾ˆå¤§ï¼›è€Œä½™å¼¦ç›¸ä¼¼åº¦ï¼Œå®ƒä»¬ä¹‹é—´çš„å¤¹è§’å¯èƒ½å¾ˆå°ï¼Œå› è€Œç›¸ä¼¼åº¦æ›´é«˜ã€‚æ­¤å¤–ï¼Œåœ¨æ–‡æœ¬ã€å›¾åƒã€è§†é¢‘ç­‰é¢†åŸŸï¼Œç ”ç©¶çš„å¯¹è±¡çš„ç‰¹å¾ç»´åº¦å¾€å¾€å¾ˆé«˜ï¼Œä½™å¼¦ç›¸ä¼¼åº¦åœ¨é«˜ç»´æƒ…å†µä¸‹ä¾ç„¶ä¿æŒâ€œ ç›¸åŒä¸º1ï¼Œæ­£äº¤æ˜¯ä¸º0ï¼Œç›¸åæ—¶ä¸º-1â€çš„æ€§è´¨ï¼Œè€Œæ¬§å¼è·ç¦»çš„æ•°å€¼åˆ™å—ç»´åº¦çš„å½±å“ï¼ŒèŒƒå›´ä¸å›ºå®šï¼Œå¹¶ä¸”å«ä¹‰ä¹Ÿæ¯”è¾ƒæ¨¡ç³Šã€‚</li><li>åœ¨ä¸€äº›åœºæ™¯ä¸­ï¼Œä¾‹å¦‚Word2Vecä¸­ï¼Œå…¶å‘é‡çš„æ¨¡é•¿æ˜¯ç»è¿‡å½’ä¸€åŒ–çš„ï¼Œæ­¤æ—¶æ¬§å¼è·ç¦»ä¸ä½™å¼¦è·ç¦»æœ‰ç€å•è°ƒçš„å…³ç³»ã€‚æ­¤åœºæ™¯ä¸‹ä½™å¼¦ç›¸ä¼¼åº¦å’Œæ¬§å¼è·ç¦»çš„ç»“æœæ˜¯ç›¸åŒçš„</li><li>æ¬§å¼è·ç¦»ä½“ç°æ•°å€¼ä¸Šçš„ç»å¯¹å·®å¼‚ï¼Œä½™å¼¦è·ç¦»ä½“ç°æ–¹å‘ä¸Šçš„ç›¸å¯¹å·®å¼‚ã€‚åˆ†æä¸¤ä¸ªä¸åŒç”¨æˆ·å¯¹äºä¸åŒè§†é¢‘çš„åå¥½ï¼Œæ›´å…³æ³¨ç›¸å¯¹å·®å¼‚ï¼Œæ˜¾ç„¶åº”å½“ç”¨ä½™å¼¦è·ç¦»ã€‚åˆ†æç”¨æˆ·æ´»è·ƒåº¦ï¼Œä»¥ç™»é™†æ¬¡æ•°å’Œå¹³å‡è§‚çœ‹æ—¶é•¿ä½œä¸ºç‰¹å¾ï¼Œä½™å¼¦è·ç¦»ä¸ºè®¤ä¸º(1,10)ô±¤(10,100)ä¸¤ä¸ªç”¨æˆ·è·ç¦»å¾ˆè¿‘ï¼›ä½†æ˜¾ç„¶è¿™ä¸¤ä¸ªç”¨æˆ·æ´»è·ƒåº¦æ˜¯æœ‰ç€æå¤§çš„å·®å¼‚çš„ï¼Œæ­¤æ—¶æ›´å…³æ³¨æ•°å€¼ç»å¯¹å·®å¼‚ï¼Œåº”å½“ä½¿ç”¨æ¬§å¼è·ç¦»ã€‚</li></ul>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
          <category> é¢è¯• </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ç®—æ³• </tag>
            
            <tag> é¢è¯• </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>æ•°å­¦åŸºç¡€çŸ¥è¯†æ•´ç†</title>
      <link href="/2019/08/06/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/"/>
      <url>/2019/08/06/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>##çº¿æ€§ä»£æ•°</p><h4 id="çº¿æ€§ç›¸å…³ä¸çº¿æ€§æ— å…³"><a href="#çº¿æ€§ç›¸å…³ä¸çº¿æ€§æ— å…³" class="headerlink" title="çº¿æ€§ç›¸å…³ä¸çº¿æ€§æ— å…³"></a>çº¿æ€§ç›¸å…³ä¸çº¿æ€§æ— å…³</h4><ul><li><img src="/blog_picture/linear.jpg" alt="avatar"></li></ul><p>çº¿æ€§ç›¸å…³çš„åˆ¤å®šï¼šæ ¹æ®è§‚å¯Ÿï¼Œåˆ©ç”¨å®šä¹‰å³å¯åˆ¤æ–­ã€‚</p><p>çº¿æ€§ç›¸å…³çš„åˆ¤æ–­å®šç†ï¼š</p><ul><li><p><img src="/blog_picture/2.jpg" alt="avatar"></p></li><li><p><img src="/blog_picture/3.jpg" alt="avatar"></p></li></ul><h4 id="çŸ©é˜µçš„ç§©"><a href="#çŸ©é˜µçš„ç§©" class="headerlink" title="çŸ©é˜µçš„ç§©"></a>çŸ©é˜µçš„ç§©</h4><p>ä¸€ä¸ªå‘é‡ç»„Açš„ç§©æ˜¯Açš„çº¿æ€§æ— å…³çš„å‘é‡çš„ä¸ªæ•°</p><p>å¦‚æœæŠŠä¸€ä¸ªå‘é‡ç»„çœ‹æˆä¸€ä¸ªçŸ©é˜µï¼Œåˆ™å‘é‡ç»„çš„ç§©å°±æ˜¯çŸ©é˜µçš„ç§©</p><ul><li><p><img src="/blog_picture/4.jpg" alt="avatar"></p></li><li><p><img src="/blog_picture/5.jpg" alt="avatar"></p></li></ul><h4 id="å‘é‡çš„èŒƒæ•°"><a href="#å‘é‡çš„èŒƒæ•°" class="headerlink" title="å‘é‡çš„èŒƒæ•°"></a>å‘é‡çš„èŒƒæ•°</h4><ul><li><img src="/blog_picture/6.jpg" alt="avatar"></li></ul><p>####å¸¸ç”¨çš„å‘é‡èŒƒæ•°</p><p>1-èŒƒæ•° $||x||<em>1=\sum</em>{i=1}^{n}|x|$</p><p>2-èŒƒæ•°  $||x||<em>2=\sqrt{\sum</em>{i=1}^{n}{x_i}^2}$æ¬§å¼èŒƒæ•°</p><p>æ— ç©·èŒƒæ•°   $||x||_n=max|x_i|$</p><h4 id="çŸ©é˜µçš„èŒƒæ•°"><a href="#çŸ©é˜µçš„èŒƒæ•°" class="headerlink" title="çŸ©é˜µçš„èŒƒæ•°"></a>çŸ©é˜µçš„èŒƒæ•°</h4><p><img src="/blog_picture/8.jpg" alt="avatar"></p><p>####å¸¸ç”¨çš„çŸ©é˜µèŒƒæ•°</p><p><img src="/blog_picture/9.jpg" alt="avatar"></p><p><img src="/blog_picture/10.jpg" alt="avatar"></p><p>èŒƒæ•°çš„ä½œç”¨ï¼šæœºå™¨å­¦ä¹ çš„åˆ†ç±»é—®é¢˜ä¸­ï¼Œä½¿ç”¨èŒƒæ•°å¯ä»¥åˆ¤æ–­ä¸¤ä¸ªç‰¹å¾å‘é‡å’ŒçŸ©é˜µçš„ç›¸ä¼¼æ€§</p><p>####çŸ©é˜µçš„è¿¹</p><p><img src="/blog_picture/11.jpg" alt="avatar"></p><h4 id="çº¿æ€§å˜æ¢åŠå…¶çŸ©é˜µè¡¨ç¤º"><a href="#çº¿æ€§å˜æ¢åŠå…¶çŸ©é˜µè¡¨ç¤º" class="headerlink" title="çº¿æ€§å˜æ¢åŠå…¶çŸ©é˜µè¡¨ç¤º"></a>çº¿æ€§å˜æ¢åŠå…¶çŸ©é˜µè¡¨ç¤º</h4><p><img src="/blog_picture/12.jpg" alt="avatar"></p><h4 id="ç‰¹å¾å€¼ã€ç‰¹å¾å‘é‡"><a href="#ç‰¹å¾å€¼ã€ç‰¹å¾å‘é‡" class="headerlink" title="ç‰¹å¾å€¼ã€ç‰¹å¾å‘é‡"></a>ç‰¹å¾å€¼ã€ç‰¹å¾å‘é‡</h4><p><img src="/blog_picture/13.jpg" alt="avatar"></p><p>####ç‰¹å¾å€¼çš„æ€§è´¨</p><p><img src="/blog_picture/14.jpg" alt="avatar"></p><p>####ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡çš„æ±‚æ³•</p><p><img src="/blog_picture/15.jpg" alt="avatar"></p><p><img src="/blog_picture/16.jpg" alt="avatar"></p><p>ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡åœ¨æœºå™¨å­¦ä¹ ä¸­çš„åº”ç”¨ï¼šâ€¢ ä¸»æˆåˆ†åˆ†æâ€¢ æµè¡Œå­¦ä¹ â€¢ LDA</p><h4 id="æ­£äº¤æŠ•å½±"><a href="#æ­£äº¤æŠ•å½±" class="headerlink" title="æ­£äº¤æŠ•å½±"></a>æ­£äº¤æŠ•å½±</h4><p>åœ¨çº¿æ€§ä»£æ•°å’Œæ³›å‡½åˆ†æä¸­ï¼ŒæŠ•å½±æ˜¯ä»å‘é‡ç©ºé—´æ˜ å°„åˆ°è‡ªèº«çš„ä¸€ç§çº¿æ€§å˜æ¢ã€‚å…·ä½“æ¥è¯´ï¼Œæ­£äº¤æŠ•å½±æ˜¯æŒ‡åƒç©ºé—´Uå’Œé›¶ç©ºé—´Wç›¸äº’æ­£äº¤å­ç©ºé—´çš„æŠ•å½±</p><p>ä»è§£æ–¹ç¨‹è§’åº¦çœ‹ï¼ŒA x = b å¯èƒ½æ— è§£ï¼Œå› ä¸ºå¯¹ä»»æ„ çš„ x , Ax æ€»æ˜¯åœ¨Açš„åˆ—å­ç©ºé—´é‡Œï¼Œè‹¥ å‘é‡ b ä¸åœ¨ åˆ—ç©ºé—´é‡Œï¼Œåˆ™æ–¹ç¨‹æ— è§£ã€‚ä½†æ˜¯æˆ‘ä»¬å¯ä»¥å°† b åˆ©ç”¨æ­£ äº¤æŠ•å½±çŸ©é˜µæŠ•å½±åˆ° A çš„åˆ—å­ç©ºé—´é‡Œå¾—åˆ°æ­£äº¤æŠ•å½± yï¼Œ ç„¶åæ±‚è§£A x = yï¼Œå¯»æ‰¾ä¸€ä¸ªæœ€ä½³è¿‘ä¼¼è§£ xã€‚</p><p><img src="/blog_picture/17.jpg" alt="avatar"></p><h4 id="äºŒæ¬¡å‹"><a href="#äºŒæ¬¡å‹" class="headerlink" title="äºŒæ¬¡å‹"></a>äºŒæ¬¡å‹</h4><p><img src="/blog_picture/18.jpg" alt="avatar"></p><p><img src="/blog_picture/19.jpg" alt="avatar"></p><p>äºŒæ¬¡å‹è¡¥å……çŸ¥è¯†ç‚¹</p><p><img src="/blog_picture/20.jpg" alt="avatar"></p><h4 id="çŸ©é˜µçš„QRåˆ†è§£"><a href="#çŸ©é˜µçš„QRåˆ†è§£" class="headerlink" title="çŸ©é˜µçš„QRåˆ†è§£"></a>çŸ©é˜µçš„QRåˆ†è§£</h4><p><img src="/blog_picture/21.jpg" alt="avatar"></p><h4 id="SVDå¥‡å¼‚å€¼åˆ†è§£"><a href="#SVDå¥‡å¼‚å€¼åˆ†è§£" class="headerlink" title="SVDå¥‡å¼‚å€¼åˆ†è§£"></a>SVDå¥‡å¼‚å€¼åˆ†è§£</h4><p><img src="/blog_picture/22.jpg" alt="avatar"></p><p>##å¾®ç§¯åˆ†</p><h4 id="é›†åˆçš„å®šä¹‰"><a href="#é›†åˆçš„å®šä¹‰" class="headerlink" title="é›†åˆçš„å®šä¹‰"></a>é›†åˆçš„å®šä¹‰</h4><p><img src="/blog_picture/23.jpg" alt="avatar"></p><p>####é›†åˆçš„è¡¨ç¤ºæ–¹æ³•</p><p><img src="/blog_picture/24.jpg" alt="avatar"></p><p>####é›†åˆçš„åˆ†ç±»</p><p><img src="/blog_picture/25.jpg" alt="avatar"></p><h4 id="é›†åˆè¿ç®—"><a href="#é›†åˆè¿ç®—" class="headerlink" title="é›†åˆè¿ç®—"></a>é›†åˆè¿ç®—</h4><p><img src="/blog_picture/26.jpg" alt="avatar"></p><h4 id="Vennå›¾"><a href="#Vennå›¾" class="headerlink" title="Vennå›¾"></a>Vennå›¾</h4><p>è¡¨ç¤ºé›†åˆçš„å¦ä¸€ç§å½¢å¼</p><p><img src="/blog_picture/27.jpg" alt="avatar"></p><h4 id="å‡½æ•°å®šä¹‰"><a href="#å‡½æ•°å®šä¹‰" class="headerlink" title="å‡½æ•°å®šä¹‰"></a>å‡½æ•°å®šä¹‰</h4><p><img src="/blog_picture/28.jpg" alt="avatar"></p><h4 id="é¢†åŸŸçš„å®šä¹‰"><a href="#é¢†åŸŸçš„å®šä¹‰" class="headerlink" title="é¢†åŸŸçš„å®šä¹‰"></a>é¢†åŸŸçš„å®šä¹‰</h4><p><img src="/blog_picture/29.jpg" alt="avatar"></p><p>####å‡½æ•°çš„æé™æ€§è´¨</p><h5 id="å››åˆ™è¿ç®—"><a href="#å››åˆ™è¿ç®—" class="headerlink" title="å››åˆ™è¿ç®—"></a>å››åˆ™è¿ç®—</h5><p><img src="/blog_picture/30.jpg" alt="avatar"></p><p>#####å¤åˆå‡½æ•°çš„æé™</p><p><img src="/blog_picture/31.jpg" alt="avatar"></p><p>#####ä¿å·æ€§</p><p><img src="/blog_picture/32.jpg" alt="avatar"></p><p>#####å¤¹é€¼å®šç†</p><p><img src="/blog_picture/33.jpg" alt="avatar"></p><p>#####æ´›å¿…è¾¾æ³•åˆ™</p><p><img src="/blog_picture/34.jpg" alt="avatar"></p><p>####å‡½æ•°çš„è¿ç»­æ€§</p><p><img src="/blog_picture/35.jpg" alt="avatar"></p><p>####é—´æ–­çš„å®šä¹‰</p><p><img src="/blog_picture/36.jpg" alt="avatar"></p><p><img src="/blog_picture/37.jpg" alt="avatar"></p><h4 id="å‡½æ•°çš„å¯¼æ•°"><a href="#å‡½æ•°çš„å¯¼æ•°" class="headerlink" title="å‡½æ•°çš„å¯¼æ•°"></a>å‡½æ•°çš„å¯¼æ•°</h4><p><img src="/blog_picture/38.jpg" alt="avatar"></p><p>####å¯¼æ•°çš„å¸¸ç”¨å…¬å¼</p><p><img src="/blog_picture/39.jpg" alt="avatar"></p><h4 id="å¯¼æ•°çš„æ€§è´¨"><a href="#å¯¼æ•°çš„æ€§è´¨" class="headerlink" title="å¯¼æ•°çš„æ€§è´¨"></a>å¯¼æ•°çš„æ€§è´¨</h4><p>#####å››åˆ™è¿ç®—</p><p><img src="/blog_picture/40.jpg" alt="avatar"></p><p>#####å¤åˆå‡½æ•°æ±‚å¯¼</p><p><img src="/blog_picture/41.jpg" alt="avatar"></p><h5 id="å¯¼æ•°ä½œç”¨"><a href="#å¯¼æ•°ä½œç”¨" class="headerlink" title="å¯¼æ•°ä½œç”¨"></a>å¯¼æ•°ä½œç”¨</h5><p>é“¾å¼æ±‚å¯¼æ³•åˆ™:ç¥ç»ç½‘ç»œåå‘ä¼ æ’­åŸºç¡€ </p><p>æ¢¯åº¦ä¸‹é™æ³•:æœ€ç®€å•çš„ä¼˜åŒ–æ–¹æ³•</p><h4 id="å‡½æ•°çš„å¾®åˆ†"><a href="#å‡½æ•°çš„å¾®åˆ†" class="headerlink" title="å‡½æ•°çš„å¾®åˆ†"></a>å‡½æ•°çš„å¾®åˆ†</h4><p><img src="/blog_picture/42.jpg" alt="avatar"></p><h4 id="åŸå‡½æ•°"><a href="#åŸå‡½æ•°" class="headerlink" title="åŸå‡½æ•°"></a>åŸå‡½æ•°</h4><p><img src="/blog_picture/43.jpg" alt="avatar"></p><h4 id="ä¸å®šç§¯åˆ†"><a href="#ä¸å®šç§¯åˆ†" class="headerlink" title="ä¸å®šç§¯åˆ†"></a>ä¸å®šç§¯åˆ†</h4><p><img src="/blog_picture/44.jpg" alt="avatar"></p><p><img src="/blog_picture/45.jpg" alt="avatar"></p><p><img src="/blog_picture/46.jpg" alt="avatar"></p><p>####ä¸å®šç§¯åˆ†æ€§è´¨</p><p><img src="/blog_picture/47.jpg" alt="avatar"></p><p>####ä¸å®šç§¯åˆ†çš„åŸºæœ¬å…¬å¼</p><p><img src="/blog_picture/48.jpg" alt="avatar"></p><h4 id="å®šç§¯åˆ†"><a href="#å®šç§¯åˆ†" class="headerlink" title="å®šç§¯åˆ†"></a>å®šç§¯åˆ†</h4><p><img src="/blog_picture/49.jpg" alt="avatar"></p><p><img src="/blog_picture/50.jpg" alt="avatar"></p><p><img src="/blog_picture/51.jpg" alt="avatar"></p><p><img src="/blog_picture/52.jpg" alt="avatar"></p><p><img src="/blog_picture/53.jpg" alt="avatar"></p><p>####å®šç§¯åˆ†çš„æ€§è´¨</p><p><img src="/blog_picture/54.jpg" alt="avatar"></p><p>ç‰›é¡¿-è±å¸ƒå°¼å…¹å…¬å¼</p><p><img src="/blog_picture/55.jpg" alt="avatar"></p><p><img src="/blog_picture/56.jpg" alt="avatar"></p><p>####äºŒé‡ç§¯åˆ†</p><p><img src="/blog_picture/57.jpg" alt="avatar"></p><p><img src="/blog_picture/58.jpg" alt="avatar"></p><p><img src="/blog_picture/59.jpg" alt="avatar"></p><p><img src="/blog_picture/60.jpg" alt="avatar"></p><p>####å¯¼æ•°</p><p><img src="/blog_picture/61.jpg" alt="avatar"></p><p>#####æ ‡é‡å…³äºæ ‡é‡Xçš„æ±‚å¯¼</p><p><img src="/blog_picture/62.jpg" alt="avatar"></p><p>#####å‘é‡å…³äºæ ‡é‡Xçš„æ±‚å¯¼</p><p><img src="/blog_picture/63.jpg" alt="avatar"></p><p>####çŸ©é˜µå…³äºæ ‡é‡Xçš„æ±‚å¯¼</p><p><img src="/blog_picture/64.jpg" alt="avatar"></p><p>####æ ‡é‡å…³äºå‘é‡xçš„å¯¼æ•°</p><p><img src="/blog_picture/65.jpg" alt="avatar"></p><p>####å‘é‡å…³äºå‘é‡xçš„å¯¼æ•°</p><p><img src="/blog_picture/66.jpg" alt="avatar"></p><p>####çŸ©é˜µå…³äºå‘é‡ x çš„å¯¼æ•°</p><p><img src="/blog_picture/67.jpg" alt="avatar"></p><p>####æ ‡é‡å…³äºçŸ©é˜µçš„å¯¼æ•°</p><p><img src="/blog_picture/68.jpg" alt="avatar"></p><p>####å‘é‡å…³äºçŸ©é˜µçš„å¯¼æ•°</p><p><img src="/blog_picture/69.jpg" alt="avatar"></p><h4 id="çŸ©é˜µå…³äºçŸ©é˜µçš„å¯¼æ•°"><a href="#çŸ©é˜µå…³äºçŸ©é˜µçš„å¯¼æ•°" class="headerlink" title="çŸ©é˜µå…³äºçŸ©é˜µçš„å¯¼æ•°"></a>çŸ©é˜µå…³äºçŸ©é˜µçš„å¯¼æ•°</h4><p><img src="/blog_picture/70.jpg" alt="avatar"></p><p>####åˆ†å­å¸ƒå±€æ³•ä¸åˆ†æ¯å±€éƒ¨æ³•åŒºåˆ«</p><p><img src="/blog_picture/71.jpg" alt="avatar"></p><p>####HessiançŸ©é˜µ</p><p><img src="/blog_picture/72.jpg" alt="avatar"></p><p><img src="/blog_picture/73.jpg" alt="avatar"></p><p>##æ¦‚ç‡è®ºåŸºç¡€</p><p>####æ¦‚ç‡è®ºåŸºç¡€</p><p>æ¦‚ç‡è®ºä¸æ•°ç†ç»Ÿè®¡æ˜¯ç ”ç©¶ä»€ä¹ˆçš„?</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">éšæœºç°è±¡:ä¸ç¡®å®šæ€§ä¸ç»Ÿè®¡è§„å¾‹æ€§ </span><br><span class="line">æ¦‚ç‡è®º:ä»æ•°é‡ä¸Šç ”ç©¶éšæœºç°è±¡çš„ç»Ÿè®¡è§„å¾‹æ€§çš„ç§‘å­¦</span><br><span class="line">æ•°ç†ç»Ÿè®¡:ä»åº”ç”¨è§’åº¦ç ”ç©¶å¤„ç†éšæœºæ€§æ•°æ®ï¼Œå»ºç«‹æœ‰æ•ˆçš„ç»Ÿè®¡æ–¹æ³•ï¼Œè¿›è¡Œç»Ÿè®¡æ¨ç†</span><br></pre></td></tr></table></figure><p>éšæœºè¯•éªŒ</p><p>åœ¨æ¦‚ç‡è®ºä¸­ï¼Œå°†å…·æœ‰ä¸‹è¿°ä¸‰ä¸ªç‰¹ç‚¹çš„è¯•éªŒç§°ä¸º<strong>éšæœºè¯•éªŒ</strong>ï¼Œç®€ç§°è¯•éªŒã€‚ éšæœºè¯•éªŒå¸¸ç”¨Eè¡¨ç¤º</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.è¯•éªŒçš„å¯é‡å¤æ€§ â€”â€” åœ¨ç›¸åŒæ¡ä»¶ä¸‹å¯é‡å¤è¿›è¡Œ;</span><br><span class="line">2.ä¸€æ¬¡è¯•éªŒç»“æœçš„éšæœºæ€§ â€”â€” ä¸€æ¬¡è¯•éªŒçš„å¯èƒ½ç»“æœä¸æ­¢ä¸€ä¸ªï¼Œä¸”è¯•éªŒä¹‹å‰æ— æ³•ç¡®å®šå…·ä½“æ˜¯å“ªç§ç»“æœå‡ºç°; </span><br><span class="line">3.å…¨éƒ¨è¯•éªŒç»“æœçš„å¯çŸ¥æ€§ â€”â€” æ‰€æœ‰å¯èƒ½çš„ç»“æœæ˜¯é¢„å…ˆå¯çŸ¥çš„ï¼Œä¸”æ¯æ¬¡è¯•éªŒæœ‰ä¸”ä»…æœ‰ä¸€ä¸ªç»“æœå‡ºç°ã€‚</span><br></pre></td></tr></table></figure><p>####æ ·æœ¬ç©ºé—´ä¸æ ·æœ¬ç‚¹</p><p><img src="/blog_picture/74.jpg" alt="avatar"></p><p>####éšæœºäº‹ä»¶</p><p><img src="/blog_picture/75.jpg" alt="avatar"></p><p>####äº‹ä»¶çš„æ€§è´¨ä¸è¿ç®—</p><p>äº‹ä»¶çš„æœ¬è´¨æ˜¯é›†åˆï¼Œé›†åˆçš„ä¸€åˆ‡æ€§è´¨å’Œè¿ç®—éƒ½é€‚ç”¨ä¸äº‹ä»¶</p><p>####é¢‘ç‡ä¸æ¦‚ç‡</p><p><img src="/blog_picture/76.jpg" alt="avatar"></p><h4 id="æ¦‚ç‡çš„æ€§è´¨"><a href="#æ¦‚ç‡çš„æ€§è´¨" class="headerlink" title="æ¦‚ç‡çš„æ€§è´¨"></a>æ¦‚ç‡çš„æ€§è´¨</h4><p><img src="/blog_picture/77.jpg" alt="avatar"></p><h4 id="å¤å…¸æ¦‚å‹"><a href="#å¤å…¸æ¦‚å‹" class="headerlink" title="å¤å…¸æ¦‚å‹"></a>å¤å…¸æ¦‚å‹</h4><p><img src="/blog_picture/78.jpg" alt="avatar"></p><p><img src="/blog_picture/79.jpg" alt="avatar"></p><h4 id="å‡ ä½•æ¦‚å‹"><a href="#å‡ ä½•æ¦‚å‹" class="headerlink" title="å‡ ä½•æ¦‚å‹"></a>å‡ ä½•æ¦‚å‹</h4><p><img src="/blog_picture/80.jpg" alt="avatar"></p><p><img src="/blog_picture/1565069627088.jpg" alt="avatar"></p><h4 id="æ¡ä»¶æ¦‚ç‡"><a href="#æ¡ä»¶æ¦‚ç‡" class="headerlink" title="æ¡ä»¶æ¦‚ç‡"></a>æ¡ä»¶æ¦‚ç‡</h4><p><img src="/blog_picture/1565069696978.jpg" alt="avatar"></p><p><img src="/blog_picture/1565069726956.jpg" alt="avatar"></p><p>####æ¡ä»¶æ¦‚ç‡çš„å‡ ä½•æ„ä¹‰</p><p><img src="/blog_picture/1565069854934.jpg" alt="avatar"></p><p>####åŠ æ³•å…¬å¼</p><p><img src="/blog_picture/1565069969698.jpg" alt="avatar"></p><p>####ä¹˜æ³•å…¬å¼</p><p><img src="/blog_picture/1565070039368.jpg" alt="avatar"></p><p>####æ’åˆ—ç»„åˆ</p><p><img src="/blog_picture/1565070090722.jpg" alt="avatar"></p><p>####å…¨æ¦‚ç‡å…¬å¼</p><p><img src="/blog_picture/1565070149616.jpg" alt="avatar"></p><p>####ç¦»æ•£åˆ†å¸ƒ vs è¿ç»­åˆ†å¸ƒ</p><p><img src="/blog_picture/1565070338442.jpg" alt="avatar"></p><p>####ä¼¯åŠªåˆ©åˆ†å¸ƒ</p><p><img src="/blog_picture/1565070378085.jpg" alt="avatar"></p><p>####äºŒé¡¹åˆ†å¸ƒ</p><p><img src="/blog_picture/1565070413168.jpg" alt="avatar"></p><p>####æœŸæœ›</p><p><img src="/blog_picture/1565070571975.jpg" alt="avatar"></p><h5 id="æœŸæœ›çš„æ€§è´¨"><a href="#æœŸæœ›çš„æ€§è´¨" class="headerlink" title="æœŸæœ›çš„æ€§è´¨"></a>æœŸæœ›çš„æ€§è´¨</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">1ã€E (C ) = C</span><br><span class="line">2ã€E (aX ) = a E (X )</span><br><span class="line">3ã€E (X + Y ) = E (X ) + E (Y )</span><br><span class="line">4ã€å½“X ,Y ç›¸äº’ç‹¬ç«‹æ—¶ï¼ŒE (X Y ) = E (X )E (Y )</span><br></pre></td></tr></table></figure><h5 id="æœŸæœ›çš„æ•°å­¦å«ä¹‰"><a href="#æœŸæœ›çš„æ•°å­¦å«ä¹‰" class="headerlink" title="æœŸæœ›çš„æ•°å­¦å«ä¹‰"></a>æœŸæœ›çš„æ•°å­¦å«ä¹‰</h5><p>ååº”äº†æ•°æ®çš„å¹³å‡å–å€¼æƒ…å†µ</p><p>####æ–¹å·®</p><p><img src="/blog_picture/1565070731625.jpg" alt="avatar"></p><p><img src="/blog_picture/1565070796641.jpg" alt="avatar"></p><p>####æ•°æ®å½’ä¸€åŒ–</p><p><img src="/blog_picture/1565070856261.jpg" alt="avatar"></p><p>####é«˜æ–¯åˆ†å¸ƒ</p><p><img src="/blog_picture/1565070907312.jpg" alt="avatar"></p><p><img src="/blog_picture/1565070933026.jpg" alt="avatar"></p><p>####åˆ†å¸ƒå‡½æ•°</p><p><img src="/blog_picture/1565071005463.jpg" alt="avatar"></p><p><img src="/blog_picture/1565071040441.jpg" alt="avatar"></p><p>####å‡åŒ€åˆ†å¸ƒ</p><p><img src="/blog_picture/1565071087634.jpg" alt="avatar"></p><p><img src="/blog_picture/1565071126393.jpg" alt="avatar"></p><p>####æŒ‡æ•°åˆ†å¸ƒ</p><p><img src="/blog_picture/1565071160548.jpg" alt="avatar"></p><p><img src="/blog_picture/1565071258034.jpg" alt="avatar"></p><p>####äºŒç»´éšæœºå˜é‡</p><p><img src="/blog_picture/1565071336855.jpg" alt="avatar"></p><p>####è”åˆåˆ†å¸ƒå‡½æ•°</p><p><img src="/blog_picture/1565071371964.jpg" alt="avatar"></p><p><img src="/blog_picture/1565071397963.jpg" alt="avatar"></p><p>####è”åˆåˆ†å¸ƒåˆ—</p><p><img src="/blog_picture/1565071449242.jpg" alt="avatar"></p><p>####äºŒç»´è¿ç»­å‹éšæœºå˜é‡åŠå…¶å¯†åº¦å‡½æ•°</p><p><img src="/blog_picture/1565071492637.jpg" alt="avatar"></p><p>####è”åˆå¯†åº¦æ€§è´¨</p><p><img src="/blog_picture/1565071532659.jpg" alt="avatar"></p><p><img src="/blog_picture/1565071741870.jpg" alt="avatar"></p><p><img src="/blog_picture/1565071745834.jpg" alt="avatar"></p><p><img src="/blog_picture/1565071749581.jpg" alt="avatar"></p><p>####è¾¹ç¼˜åˆ†å¸ƒ</p><p><img src="/blog_picture/1565071827339.jpg" alt="avatar"></p><p><img src="/blog_picture/1565071830825.jpg" alt="avatar"></p><p><img src="/blog_picture/1565072132127.jpg" alt="avatar"></p><p><img src="/blog_picture/1565072287072.jpg" alt="avatar"></p><p>####å¤šç»´åˆ†å¸ƒ</p><p>åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œä¸€ä¸ª æ ·æœ¬æœ‰å¤šä¸ªç‰¹å¾ï¼Œç ”ç©¶å¤šä¸ªç‰¹å¾çš„æ¦‚ç‡åˆ†å¸ƒä¸ç»Ÿè®¡æƒ…å†µ</p><p>####äºŒç»´éšæœºå˜é‡</p><p><img src="/blog_picture/1565072474902.jpg" alt="avatar"></p><p>####ä¸ºä»€ä¹ˆéœ€è¦åæ–¹å·®?</p><p><img src="/blog_picture/1565072501064.jpg" alt="avatar"></p><p>####åæ–¹å·®</p><p><img src="/blog_picture/1565072546171.jpg" alt="avatar"></p><p>####åæ–¹å·®çš„æ€§è´¨</p><p><img src="/blog_picture/1565072627923.jpg" alt="avatar"></p><p>####åæ–¹å·®çŸ©é˜µ</p><p><img src="/blog_picture/1565072672838.jpg" alt="avatar"></p><h4 id="ä¸»æˆåˆ†åˆ†ææ³•"><a href="#ä¸»æˆåˆ†åˆ†ææ³•" class="headerlink" title="ä¸»æˆåˆ†åˆ†ææ³•"></a>ä¸»æˆåˆ†åˆ†ææ³•</h4><p>#####PCAçš„æ„ä¹‰</p><p><img src="/blog_picture/1565072734381.jpg" alt="avatar"></p><p>#####PCAçš„æ•°å­¦æ¨¡å‹</p><p><img src="/blog_picture/1565072773199.jpg" alt="avatar"></p><p>####PCAæ¨å¯¼</p><p><img src="/blog_picture/1565072881626.jpg" alt="avatar"></p><p><img src="/blog_picture/1565072885469.jpg" alt="avatar"></p><p><img src="/blog_picture/1565072888797.jpg" alt="avatar"></p><p>####PCAå®æ–½</p><p><img src="/blog_picture/1565072955696.jpg" alt="avatar"></p><p><img src="/blog_picture/1565072959543.jpg" alt="avatar"></p><h2 id="æ¦‚ç‡è®ºä¸ä¿¡æ¯è®º"><a href="#æ¦‚ç‡è®ºä¸ä¿¡æ¯è®º" class="headerlink" title="æ¦‚ç‡è®ºä¸ä¿¡æ¯è®º"></a>æ¦‚ç‡è®ºä¸ä¿¡æ¯è®º</h2><p>####åˆ‡æ¯”é›ªå¤«ä¸ç­‰å¼</p><p><img src="/blog_picture/1565073174283.jpg" alt="avatar"></p><p>####ä¸­å¿ƒæé™å®šç†</p><p><img src="/blog_picture/1565073177541.jpg" alt="avatar"></p><p><img src="/blog_picture/1565073180613.jpg" alt="avatar"></p><p>####å…³äºæ­£æ€åˆ†å¸ƒè®¡ç®—çš„è¡¥å……</p><p><img src="/blog_picture/1565073253138.jpg" alt="avatar"></p><p>####çŸ©çš„æ¦‚å¿µ</p><p><img src="/blog_picture/1565073324278.jpg" alt="avatar"></p><p><img src="/blog_picture/1565073327543.jpg" alt="avatar"></p><p>####çŸ©ä¼°è®¡</p><p><img src="/blog_picture/1565073407133.jpg" alt="avatar"></p><p><img src="/blog_picture/1565073410261.jpg" alt="avatar"></p><p>####æå¤§ä¼¼ç„¶ä¼°è®¡çš„æ€æƒ³</p><p><img src="/blog_picture/1565073555795.jpg" alt="avatar"></p><p>####æå¤§ä¼¼ç„¶ä¼°è®¡</p><p><img src="/blog_picture/1565073575910.jpg" alt="avatar"></p><p><img src="/blog_picture/1565073579745.jpg" alt="avatar"></p><p>####æå¤§ä¼¼ç„¶ä¼°è®¡æ±‚æ³•</p><p><img src="/blog_picture/1565073673751.jpg" alt="avatar"></p><p><img src="/blog_picture/1565073677603.jpg" alt="avatar"></p><p><img src="/blog_picture/1565073681686.jpg" alt="avatar"></p><h4 id="MLEåœ¨æœºå™¨å­¦ä¹ ä¸­çš„åº”ç”¨"><a href="#MLEåœ¨æœºå™¨å­¦ä¹ ä¸­çš„åº”ç”¨" class="headerlink" title="MLEåœ¨æœºå™¨å­¦ä¹ ä¸­çš„åº”ç”¨"></a>MLEåœ¨æœºå™¨å­¦ä¹ ä¸­çš„åº”ç”¨</h4><p>å‚æ•°ä¼°è®¡ é€»è¾‘å›å½’çš„å‚æ•°ä¼°è®¡</p><h4 id="æœ€å¤§åéªŒä¼°MAP"><a href="#æœ€å¤§åéªŒä¼°MAP" class="headerlink" title="æœ€å¤§åéªŒä¼°MAP"></a>æœ€å¤§åéªŒä¼°MAP</h4><p>####å…ˆéªŒä¿¡æ¯</p><p><img src="/blog_picture/1565073949228.jpg" alt="avatar"></p><p>####å…ˆéªŒåˆ†å¸ƒ</p><p><img src="/blog_picture/1565073979451.jpg" alt="avatar"></p><p>####å¦‚ä½•åˆ©ç”¨å…ˆéªŒä¿¡æ¯?</p><p>åœ¨æ ·æœ¬å°‘çš„æƒ…å†µä¸‹ï¼Œå¦‚ä½• åŠ å…¥å…ˆéªŒä¿¡æ¯? åéªŒæ¦‚ç‡</p><p>####åéªŒæ¦‚ç‡</p><p><img src="/blog_picture/1565074058577.jpg" alt="avatar"></p><p>####æœ€å¤§åéªŒä¼°è®¡</p><p><img src="/blog_picture/1565074072524.jpg" alt="avatar"></p><p>####è´å¶æ–¯æ³•åˆ™</p><p><img src="/blog_picture/1565074197261.jpg" alt="avatar"></p><p><img src="/blog_picture/1565074201110.jpg" alt="avatar"></p><p><img src="/blog_picture/1565074204451.jpg" alt="avatar"></p><p>####è´å¶æ–¯æ„ä¹‰</p><p><img src="/blog_picture/1565074264162.jpg" alt="avatar"></p><p>####è´å¶æ–¯å…¬å¼çš„å¯†åº¦å‡½æ•°å½¢å¼</p><p><img src="/blog_picture/1565074294912.jpg" alt="avatar"></p><p><img src="/blog_picture/1565074306035.jpg" alt="avatar"></p><p>####å…±è½­åˆ†å¸ƒ</p><p><img src="/blog_picture/1565074406347.jpg" alt="avatar"></p><p><img src="/blog_picture/1565074410909.jpg" alt="avatar"></p><p><img src="/blog_picture/1565074415028.jpg" alt="avatar"></p><p>####å¦‚ä½•åº¦é‡ä¿¡æ¯çš„å¤šå°‘?</p><p><img src="/blog_picture/1565074557282.jpg" alt="avatar"></p><p>####è‡ªä¿¡æ¯é‡</p><p><img src="/blog_picture/1565074568602.jpg" alt="avatar"></p><p>####ä¿¡æ¯ç†µ</p><p><img src="/blog_picture/1565074580286.jpg" alt="avatar"></p><p><img src="/blog_picture/1565074642251.jpg" alt="avatar"></p><p>####äº¤å‰ç†µ</p><p><img src="/blog_picture/1565074679965.jpg" alt="avatar"></p><p>####äº¤å‰ç†µåœ¨æœºå™¨å­¦ä¹ ä¸­çš„åº”ç”¨</p><p>äº¤å‰ç†µæŸå¤±å‡½æ•°   è¡¡é‡ä¸¤ä¸ªéšæœºå˜é‡ä¹‹é—´çš„ç›¸ä¼¼åº¦</p><p>####äº’ä¿¡æ¯</p><p><img src="/blog_picture/1565074818018.jpg" alt="avatar"></p><p>####KLæ•£åº¦</p><p><img src="/blog_picture/1565074821449.jpg" alt="avatar"></p><p>####KLæ•£åº¦çš„æ€§è´¨</p><p><img src="/blog_picture/1565074832615.jpg" alt="avatar"></p><p><img src="/blog_picture/1565074846596.jpg" alt="avatar"></p><p>##ä¼˜åŒ–æ–¹æ³•</p><h4 id="ä¼˜åŒ–æ–¹æ³•"><a href="#ä¼˜åŒ–æ–¹æ³•" class="headerlink" title="ä¼˜åŒ–æ–¹æ³•"></a>ä¼˜åŒ–æ–¹æ³•</h4><p>æ‰€è°“æœ€ä¼˜åŒ–é—®é¢˜ï¼ŒæŒ‡åœ¨æŸäº›çº¦æŸæ¡ä»¶ä¸‹ï¼Œå†³å®šæŸäº›å¯é€‰æ‹©çš„å˜é‡åº”è¯¥å–ä½•å€¼ï¼Œä½¿æ‰€é€‰å®šçš„ç›®æ ‡å‡½æ•°è¾¾åˆ°æœ€ä¼˜çš„é—®é¢˜ã€‚å³è¿ç”¨æœ€æ–°ç§‘æŠ€æ‰‹æ®µå’Œå¤„ç†æ–¹æ³•ï¼Œä½¿ç³»ç»Ÿè¾¾åˆ°æ€»ä½“æœ€ä¼˜ï¼Œä»è€Œä¸ºç³»ç»Ÿæå‡º è®¾è®¡ã€æ–½å·¥ã€ç®¡ç†ã€è¿è¡Œçš„æœ€ä¼˜æ–¹æ¡ˆã€‚</p><p>ä¸ºä»€ä¹ˆè¦ç”¨ä¼˜åŒ–ç®—æ³•?</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">æ±‚å¯¼æ‰¾å‡½æ•°çš„æœ€å°(å¤§)å€¼ä¸è¡Œå—?</span><br><span class="line">è€ƒè™‘:1ã€å¤šå…ƒå‡½æ•°</span><br><span class="line">2ã€å±€éƒ¨æœ€å¤§æœ€å°å€¼</span><br></pre></td></tr></table></figure><p>####çº¿æ€§è§„åˆ’</p><p><img src="/blog_picture/1565076518810.jpg" alt="avatar"></p><p><img src="/blog_picture/1565076541128.jpg" alt="avatar"></p><h4 id="æ¢¯åº¦ä¸‹é™æ³•"><a href="#æ¢¯åº¦ä¸‹é™æ³•" class="headerlink" title="æ¢¯åº¦ä¸‹é™æ³•"></a>æ¢¯åº¦ä¸‹é™æ³•</h4><p><img src="/blog_picture/1565076888078.jpg" alt="avatar"></p><h4 id="ä¸€ç»´å‡½æ•°æ¢¯åº¦"><a href="#ä¸€ç»´å‡½æ•°æ¢¯åº¦" class="headerlink" title="ä¸€ç»´å‡½æ•°æ¢¯åº¦"></a>ä¸€ç»´å‡½æ•°æ¢¯åº¦</h4><p><img src="/blog_picture/1565077155760.jpg" alt="avatar"></p><p>####æ¢¯åº¦ä¸‹é™æ³•</p><p><img src="/blog_picture/1565077206152.jpg" alt="avatar"></p><p><img src="/blog_picture/1565077232963.jpg" alt="avatar"></p><p><img src="/blog_picture/1565077254742.jpg" alt="avatar"></p><p>####æ¢¯åº¦æ³•çš„è¿­ä»£è¿‡ç¨‹</p><p><img src="/blog_picture/1565077296818.jpg" alt="avatar"></p><p>####æ‰¹é‡æ¢¯åº¦ä¸‹é™BGD</p><p><img src="/blog_picture/1565077637320.jpg" alt="avatar"></p><p><img src="/blog_picture/1565077674463.jpg" alt="avatar"></p><p>####éšæœºæ¢¯åº¦ä¸‹é™SGD</p><p><img src="/blog_picture/1565078179419.jpg" alt="avatar"></p><p><img src="/blog_picture/1565078182517.jpg" alt="avatar"></p><p>####å°æ‰¹é‡æ¢¯åº¦ä¸‹é™æ³•MBGD</p><p><img src="/blog_picture/1565078253357.jpg" alt="avatar"></p><p><img src="/blog_picture/1565078257221.jpg" alt="avatar"></p><h4 id="ç‰›é¡¿æ³•"><a href="#ç‰›é¡¿æ³•" class="headerlink" title="ç‰›é¡¿æ³•"></a>ç‰›é¡¿æ³•</h4><p>æ±‚è§£æ— çº¦æŸæå€¼é—®é¢˜å¾—æœ€å¤è€ç®—æ³•ä¹‹ä¸€ï¼Œå·²å‘å±•æˆä¸ºä¸€ç±»ç®—æ³•:Newtonå‹æ–¹æ³•ã€‚<br>åœ¨å±€éƒ¨ï¼Œç”¨ä¸€ä¸ªäºŒæ¬¡å‡½æ•°è¿‘ä¼¼ä»£æ›¿ç›®æ ‡å‡½æ•° f(x)ï¼Œç„¶åç”¨è¿‘ä¼¼å‡½æ•°çš„æå° ç‚¹ä½œä¸ºf(x) çš„è¿‘ä¼¼æå°ç‚¹ã€‚</p><p><img src="/blog_picture/1565078413953.jpg" alt="avatar"></p><p><img src="/blog_picture/1565078417533.jpg" alt="avatar"></p><p><img src="/blog_picture/1565078421199.jpg" alt="avatar"></p><p><img src="/blog_picture/1565078424695.jpg" alt="avatar"></p><p><img src="/blog_picture/1565078428776.jpg" alt="avatar"></p><p><img src="/blog_picture/1565078432769.jpg" alt="avatar"></p><p><img src="/blog_picture/1565078436246.jpg" alt="avatar"></p><h4 id="æ‹Ÿç‰›é¡¿æ³•"><a href="#æ‹Ÿç‰›é¡¿æ³•" class="headerlink" title="æ‹Ÿç‰›é¡¿æ³•"></a>æ‹Ÿç‰›é¡¿æ³•</h4><p>æ‹Ÿç‰›é¡¿æ³•çš„æœ¬è´¨æ€æƒ³æ˜¯æ”¹å–„ç‰›é¡¿æ³•æ¯æ¬¡éœ€è¦æ±‚è§£å¤æ‚çš„HessiançŸ©é˜µçš„é€†çŸ©é˜µçš„ç¼ºé™·ï¼Œå®ƒä½¿ç”¨ æ­£å®šçŸ©é˜µæ¥è¿‘ä¼¼HessiançŸ©é˜µçš„é€†ï¼Œä»è€Œç®€åŒ–äº†è¿ç®—çš„å¤æ‚åº¦ã€‚ æ‹Ÿç‰›é¡¿æ³•å’Œæœ€é€Ÿä¸‹é™æ³•ä¸€æ ·åªè¦æ±‚æ¯ä¸€æ­¥è¿­ä»£æ—¶çŸ¥é“ç›®æ ‡å‡½æ•°çš„æ¢¯åº¦ã€‚é€šè¿‡æµ‹é‡æ¢¯åº¦çš„å˜åŒ–ï¼Œ æ„é€ ä¸€ä¸ªç›®æ ‡å‡½æ•°çš„æ¨¡å‹ä½¿ä¹‹è¶³ä»¥äº§ç”Ÿè¶…çº¿æ€§æ”¶æ•›æ€§ã€‚ è¿™ç±»æ–¹æ³•å¤§å¤§ä¼˜äºæœ€é€Ÿä¸‹é™æ³•ï¼Œå°¤å…¶å¯¹äºå›°éš¾çš„é—®é¢˜ã€‚å¦å¤–ï¼Œå› ä¸ºæ‹Ÿç‰›é¡¿æ³•ä¸éœ€è¦äºŒé˜¶å¯¼æ•°çš„ ä¿¡æ¯ï¼Œæ‰€ä»¥æœ‰æ—¶æ¯”ç‰›é¡¿æ³•æ›´ä¸ºæœ‰æ•ˆã€‚</p><p><strong>ç”¨ä¸åŒ…å«äºŒé˜¶å¯¼æ•°çš„çŸ©é˜µè¿‘ä¼¼<em>Hesse*</em></strong>çŸ©é˜µçš„*</p><p><img src="/blog_picture/1565078600068.jpg" alt="avatar"></p><p><img src="/blog_picture/1565078603177.jpg" alt="avatar"></p><p>####å¸¸ç”¨çš„æ‹Ÿç‰›é¡¿æ³•</p><p><img src="/blog_picture/1565078654456.jpg" alt="avatar"></p><h4 id="å…±è½­æ–¹å‘æ³•"><a href="#å…±è½­æ–¹å‘æ³•" class="headerlink" title="å…±è½­æ–¹å‘æ³•"></a>å…±è½­æ–¹å‘æ³•</h4><p><strong>å…±è½­æ–¹å‘æ³•</strong>æ˜¯ä»‹äºæœ€é€Ÿä¸‹é™æ³•ä¸ç‰›é¡¿æ³•ä¹‹é—´çš„ä¸€ç±»æ–¹æ³•ã€‚</p><p>å®ƒä»…éœ€åˆ©ç”¨ä¸€é˜¶å¯¼æ•°ä¿¡æ¯ï¼Œä½†å…‹æœäº†æœ€é€Ÿä¸‹é™æ³•æ”¶æ•›æ…¢çš„ç¼ºç‚¹ï¼Œåˆé¿å…äº†å­˜å‚¨å’Œ è®¡ç®—ç‰›é¡¿æ³•æ‰€éœ€è¦çš„äºŒé˜¶å¯¼æ•°ä¿¡æ¯ã€‚</p><p><img src="/blog_picture/1565078732264.jpg" alt="avatar"></p><p><img src="/blog_picture/1565078735596.jpg" alt="avatar"></p><p>####å…±è½­æ–¹å‘æ³•çš„å‡ ä½•æ„ä¹‰</p><p><img src="/blog_picture/1565078861764.jpg" alt="avatar"></p><p><img src="/blog_picture/1565078864870.jpg" alt="avatar"></p><p><img src="/blog_picture/1565078867892.jpg" alt="avatar"></p><h4 id="å…±è½­æ¢¯åº¦æ³•"><a href="#å…±è½­æ¢¯åº¦æ³•" class="headerlink" title="å…±è½­æ¢¯åº¦æ³•"></a>å…±è½­æ¢¯åº¦æ³•</h4><p>âš« <strong>å…±è½­æ¢¯åº¦æ³•</strong>(conjugate gradient method, CG)æ˜¯ä»¥å…±è½­æ–¹å‘(conjugate direction)ä½œä¸º æœç´¢æ–¹å‘çš„ä¸€ç±»ç®—æ³•ã€‚</p><p>âš« CGæ³•æ˜¯ç”±Hestenesså’ŒStiefeläº1952å¹´ä¸ºæ±‚è§£çº¿æ€§æ–¹ç¨‹ç»„è€Œæå‡ºçš„ã€‚åæ¥ç”¨äºæ±‚è§£æ— çº¦æŸæœ€ä¼˜ åŒ–é—®é¢˜ï¼Œå®ƒæ˜¯ä¸€ç§é‡è¦çš„æ•°å­¦ä¼˜åŒ–æ–¹æ³•ã€‚è¿™ç§æ–¹æ³•å…·æœ‰<strong>äºŒæ¬¡ç»ˆæ­¢æ€§</strong></p><p>CGçš„åŸºæœ¬æ€æƒ³æ˜¯æŠŠå…±è½­æ€§ä¸æœ€é€Ÿä¸‹é™æ³•ç›¸ç»“åˆï¼Œåˆ©ç”¨å·²çŸ¥è¿­ä»£ç‚¹çš„æ¢¯åº¦æ–¹å‘ æ„é€ ä¸€ç»„å…±è½­æ–¹å‘ï¼Œå¹¶æ²¿ç€æ­¤ç»„æ–¹å‘è¿›è¡Œæœç´¢ï¼Œæ±‚å‡ºç›®æ ‡å‡½æ•°çš„æå°ç‚¹ã€‚</p><p><strong>ä»€ä¹ˆæ˜¯äºŒæ¬¡ç»ˆæ­¢æ€§?</strong></p><p>å¦‚æœæŸç®—æ³•ç”¨äºæ±‚è§£ç›®æ ‡å‡½æ•°ä¸ºäºŒæ¬¡å‡½æ•°çš„æ— çº¦æŸé—®é¢˜æ—¶ï¼Œåªéœ€è¦ç»è¿‡æœ‰é™è¿­ä»£å°±èƒ½ è¾¾åˆ°æœ€ä¼˜è§£ï¼Œåˆ™è¯¥ç®—æ³•å…·æœ‰äºŒæ¬¡ç»ˆæ­¢æ€§ã€‚<br>å…±è½­æ¢¯åº¦æ³•å°±æœ‰äºŒæ¬¡ç»ˆæ­¢æ€§</p><p><img src="/blog_picture/1565078980017.jpg" alt="avatar"></p><p><img src="/blog_picture/1565079002662.jpg" alt="avatar"></p><p><img src="/blog_picture/1565079045462.jpg" alt="avatar"></p><p><img src="/blog_picture/1565079049180.jpg" alt="avatar"></p><p>####åŠ¨é‡æ¢¯åº¦ä¸‹é™æ³•æ³•Momentum</p><p><img src="/blog_picture/1565079107750.jpg" alt="avatar"></p><p><img src="/blog_picture/1565079110804.jpg" alt="avatar"></p><p>####å‡æ–¹æ ¹ä¼˜åŒ–æ³•RMSp</p><p><img src="/blog_picture/1565079198345.jpg" alt="avatar"></p><p><img src="/blog_picture/1565079201526.jpg" alt="avatar"></p><p>####è‡ªé€‚åº”çŸ©ä¼°è®¡æ³•Adam</p><p><img src="/blog_picture/1565079255381.jpg" alt="avatar"></p><p><img src="/blog_picture/1565079258315.jpg" alt="avatar"></p><p>####å­¦ä¹ ç‡è¡°å‡</p><p><img src="/blog_picture/1565079349701.jpg" alt="avatar"></p><p><img src="/blog_picture/1565079353025.jpg" alt="avatar"></p><p>####æ—©åœ</p><p><img src="/blog_picture/1565079408798.jpg" alt="avatar"></p><p><strong>æ ¸å¿ƒæ€æƒ³:</strong></p><p>å¦‚æœè®­ç»ƒæ•°è½®åå‡†ç¡®ç‡(æŸå¤±å‡½æ•°)æ²¡æœ‰ä¸Šå‡(ä¸‹é™)ï¼Œå°±åœæ­¢è®­ç»ƒ</p><p><strong>åº”ç”¨åœºæ™¯:</strong></p><p>å¤§æ‰¹é‡æ•°æ®ï¼Œè®­ç»ƒæ—¶é—´é•¿</p><p>####å±€éƒ¨æœ€ä¼˜å€¼</p><p><img src="/blog_picture/1565079488243.jpg" alt="avatar"></p><p>####éç‚¹é—®é¢˜</p><p><img src="/blog_picture/1565079501278.jpg" alt="avatar"></p>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> çº¿æ€§ä»£æ•° </tag>
            
            <tag> ä¼˜åŒ–æ–¹æ³• </tag>
            
            <tag> å¾®ç§¯åˆ† </tag>
            
            <tag> æ¦‚ç‡ </tag>
            
            <tag> ç»Ÿè®¡ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>å¤§æ•°æ®åŸºç¡€</title>
      <link href="/2019/07/24/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/"/>
      <url>/2019/07/24/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h1 id="pyspark-RDDåŸºç¡€"><a href="#pyspark-RDDåŸºç¡€" class="headerlink" title="pyspark-RDDåŸºç¡€"></a>pyspark-RDDåŸºç¡€</h1><h3 id="spark"><a href="#spark" class="headerlink" title="spark"></a>spark</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pysparkæ˜¯sparkçš„python API,å…è®¸pythonè°ƒç”¨sparkç¼–ç¨‹æ¨¡å‹</span><br></pre></td></tr></table></figure><h3 id="åˆå§‹åŒ–spark"><a href="#åˆå§‹åŒ–spark" class="headerlink" title="åˆå§‹åŒ–spark"></a>åˆå§‹åŒ–spark</h3><h4 id="SparkContext"><a href="#SparkContext" class="headerlink" title="SparkContext"></a>SparkContext</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line">sc = SparkContext(master=<span class="string">'local[2]'</span>)</span><br></pre></td></tr></table></figure><h4 id="æ ¸æŸ¥SparkContext"><a href="#æ ¸æŸ¥SparkContext" class="headerlink" title="æ ¸æŸ¥SparkContext"></a>æ ¸æŸ¥SparkContext</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sc.versionè·å–SparkContextçš„ç‰ˆæœ¬</span><br><span class="line">sc.pythonVerè·å–pythonç‰ˆæœ¬</span><br><span class="line">sc.masterè¦è¿æ¥çš„Master URL</span><br><span class="line">str(sc.sparkHome)sparkå·¥ä½œèŠ‚ç‚¹çš„å®‰è£…è·¯å¾„</span><br><span class="line">str(sc.sparkUser())è·å–SparkContextçš„sparkç”¨æˆ·å</span><br><span class="line">sc.appNameè¿”å›åº”ç”¨åç§°</span><br><span class="line">sc.applicationIdè¿”å›åº”ç”¨ç¨‹åºID</span><br><span class="line">sc.defaultParallelismè¿”å›é»˜è®¤å¹¶è¡Œçº§åˆ«</span><br><span class="line">sc.defaultMinPatitionsRDDé»˜è®¤æœ€å°åˆ†åŒºæ•°</span><br></pre></td></tr></table></figure><h4 id="é…ç½®"><a href="#é…ç½®" class="headerlink" title="é…ç½®"></a>é…ç½®</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf,SparkContext</span><br><span class="line">conf = (SparkConf().setMaster(<span class="string">"local"</span>).setAppName(<span class="string">"my APP"</span>).set(<span class="string">"spark.executor.memory"</span>,<span class="string">"1g"</span>))</span><br><span class="line">sc = SparkContext(conf=conf)</span><br></pre></td></tr></table></figure><h4 id="ä½¿ç”¨shell"><a href="#ä½¿ç”¨shell" class="headerlink" title="ä½¿ç”¨shell"></a>ä½¿ç”¨shell</h4><p>pyspark shellå·²ç»ä¸ºSparkContextåˆ›å»ºäº†åä¸ºscçš„å˜é‡</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-shell --master local[2]</span><br><span class="line">./bin/pyspark --master local[4] --py-files code.py</span><br></pre></td></tr></table></figure><p>ç”¨â€”masterå‚æ•°è®¾å®šContextè¿æ¥åˆ°å“ªä¸ªMasteræœåŠ¡å™¨ï¼Œé€šè¿‡ä¼ é€’é€—å·åˆ†éš”åˆ—è¡¨è‡³â€”py-filesæ·»åŠ Python.zipã€eggæˆ–.pyæ–‡ä»¶åˆ°Runtimeè·¯å¾„</p><h3 id="åŠ è½½æ•°æ®"><a href="#åŠ è½½æ•°æ®" class="headerlink" title="åŠ è½½æ•°æ®"></a>åŠ è½½æ•°æ®</h3><h4 id="å¹¶è¡Œé›†åˆ"><a href="#å¹¶è¡Œé›†åˆ" class="headerlink" title="å¹¶è¡Œé›†åˆ"></a>å¹¶è¡Œé›†åˆ</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rdd = sc.parallelize([(<span class="string">'a'</span>,<span class="number">7</span>),(<span class="string">'a'</span>,<span class="number">2</span>),(<span class="string">'b'</span>,<span class="number">2</span>)])</span><br><span class="line">rdd2 = sc.parallelize([(<span class="string">'a'</span>,<span class="number">2</span>),(<span class="string">'d'</span>,<span class="number">1</span>),(<span class="string">'b'</span>,<span class="number">1</span>)])</span><br><span class="line">rdd3 = sc.parallelize(range(<span class="number">100</span>))</span><br><span class="line">rdd4 = sc.parallelize([(<span class="string">"a"</span>,[<span class="string">"x"</span>,<span class="string">"y"</span>,<span class="string">"z"</span>]),(<span class="string">"b"</span>,[<span class="string">"p"</span>,<span class="string">"r"</span>])])</span><br></pre></td></tr></table></figure><h4 id="å¤–éƒ¨æ•°æ®"><a href="#å¤–éƒ¨æ•°æ®" class="headerlink" title="å¤–éƒ¨æ•°æ®"></a>å¤–éƒ¨æ•°æ®</h4><p>ä½¿ç”¨textFile()å‡½æ•°ä»HDFSã€æœ¬åœ°æ–‡ä»¶æˆ–å…¶å®ƒæ”¯æŒhadoopçš„æ–‡ä»¶ç³»ç»Ÿé‡Œè¯»å–æ–‡ä»¶ï¼Œæˆ–ä½¿ç”¨wholeTextFiles()å‡½æ•°è¯»å–ç›®å½•ä¸‹æ‰€æœ‰æ–‡æœ¬æ–‡ä»¶</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">textFile = sc.textFile(<span class="string">'a.txt'</span>)</span><br><span class="line">textFile2 = sc.wholeTextFiles(/aa)</span><br></pre></td></tr></table></figure><h3 id="æå–RDDä¿¡æ¯"><a href="#æå–RDDä¿¡æ¯" class="headerlink" title="æå–RDDä¿¡æ¯"></a>æå–RDDä¿¡æ¯</h3><h4 id="åŸºç¡€ä¿¡æ¯"><a href="#åŸºç¡€ä¿¡æ¯" class="headerlink" title="åŸºç¡€ä¿¡æ¯"></a>åŸºç¡€ä¿¡æ¯</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">rdd.getNumPatitions()åˆ—å‡ºåˆ†åŒºæ•°</span><br><span class="line">rdd.count()è®¡ç®—RDDçš„å®ä¾‹æ•°é‡</span><br><span class="line">rdd.countByKey()æŒ‰é”®è®¡ç®—RDDå®ä¾‹æ•°é‡</span><br><span class="line">defaultdict(&lt;type <span class="string">'int'</span>&gt;,(<span class="string">'a'</span>:<span class="number">2</span>,<span class="string">'b'</span>:<span class="number">1</span>))</span><br><span class="line">rdd.countByValue()æŒ‰å€¼è®¡ç®—RDDå®ä¾‹æ•°é‡</span><br><span class="line">defaultdict(&lt;type <span class="string">'int'</span>&gt;,((<span class="string">'b'</span>,<span class="number">2</span>):<span class="number">1</span>,(<span class="string">'a'</span>,<span class="number">2</span>):<span class="number">1</span>,(<span class="string">'a'</span>,<span class="number">7</span>):<span class="number">1</span>))</span><br><span class="line">rdd.collectAsMap()ä»¥å­—å…¸çš„å½¢å¼è¿”å›é”®å€¼</span><br><span class="line">(<span class="string">'a'</span>:<span class="number">2</span>,<span class="string">'b'</span>:<span class="number">2</span>)</span><br><span class="line">rdd.sum()æ±‡æ€»RDDå…ƒç´ </span><br><span class="line"><span class="number">4959</span></span><br><span class="line">sc.parallelize([]).isEmpty()æ£€æŸ¥RDDæ˜¯å¦ä¸ºç©º</span><br></pre></td></tr></table></figure><h4 id="æ±‡æ€»"><a href="#æ±‡æ€»" class="headerlink" title="æ±‡æ€»"></a>æ±‡æ€»</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">rdd.max()RDDå…ƒç´ çš„æœ€å¤§å€¼</span><br><span class="line">rdd.min()RDDå…ƒç´ çš„æœ€å°å€¼</span><br><span class="line">rdd.mean()RDDå…ƒç´ çš„å¹³å‡å€¼</span><br><span class="line">rdd.stdev()RDDå…ƒç´ çš„æ ‡å‡†å·®</span><br><span class="line">rdd.variance()RDDå…ƒç´ çš„æ–¹å·®</span><br><span class="line">rdd.histogram(<span class="number">3</span>)åˆ†ç®±ï¼ˆbinï¼‰ç”Ÿæˆç›´æ–¹å›¾</span><br><span class="line">rdd.stats()ç»¼åˆç»Ÿè®¡åŒ…æ‹¬ï¼šè®¡æ•°ã€å¹³å‡å€¼ã€æ ‡å‡†å·®ã€æœ€å¤§å€¼å’Œæœ€å°å€¼</span><br></pre></td></tr></table></figure><h4 id="åº”ç”¨å‡½æ•°"><a href="#åº”ç”¨å‡½æ•°" class="headerlink" title="åº”ç”¨å‡½æ•°"></a>åº”ç”¨å‡½æ•°</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rdd.map(<span class="keyword">lambda</span> x:x+(x[<span class="number">1</span>],x[<span class="number">0</span>])).collect()å¯¹æ¯ä¸ªRDDå…ƒç´ æ‰§è¡Œå‡½æ•°</span><br><span class="line">rdd.flatMap(<span class="keyword">lambda</span> x:x+(x[<span class="number">1</span>],x[<span class="number">0</span>]))å¯¹æ¯ä¸ªRDDå…ƒç´ æ‰§è¡Œå‡½æ•°ï¼Œå¹¶æ‹‰å¹³ç»“æœ</span><br><span class="line">rdd.collect()</span><br><span class="line">rdd.flatMapValues(<span class="keyword">lambda</span> x:x).collect()ä¸æ”¹å˜é”®ï¼Œå¯¹rddçš„æ¯ä¸ªé”®å€¼å¯¹æ‰§è¡ŒflatMapå‡½æ•°</span><br></pre></td></tr></table></figure><h4 id="é€‰æ‹©æ•°æ®"><a href="#é€‰æ‹©æ•°æ®" class="headerlink" title="é€‰æ‹©æ•°æ®"></a>é€‰æ‹©æ•°æ®</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">è·å–</span><br><span class="line">rdd.collect()è¿”å›åŒ…å«æ‰€ä»¥RDDå…ƒç´ çš„åˆ—è¡¨</span><br><span class="line">rdd.take(<span class="number">4</span>)æå–å‰<span class="number">4</span>ä¸ªRDDå…ƒç´ </span><br><span class="line">rdd.first()æå–ç¬¬ä¸€ä¸ªRDDå…ƒç´ </span><br><span class="line">rdd.top(<span class="number">2</span>)æå–å‰ä¸¤ä¸ªRDDå…ƒç´ </span><br><span class="line">æŠ½æ ·</span><br><span class="line">rdd.sample(<span class="literal">False</span>,<span class="number">0.15</span>,<span class="number">81</span>)è¿”å›RDDçš„é‡‡æ ·å­é›†</span><br><span class="line">ç­›é€‰</span><br><span class="line">rdd.filter(<span class="keyword">lambda</span> x:<span class="string">'a'</span> <span class="keyword">in</span> x)ç­›é€‰RDD</span><br><span class="line">rdd.distinct()è¿”å›RDDé‡Œçš„å”¯ä¸€å€¼</span><br><span class="line">rdd.keys()è¿”å›RDDé”®å€¼å¯¹é‡Œçš„é”®</span><br></pre></td></tr></table></figure><h4 id="è¿­ä»£"><a href="#è¿­ä»£" class="headerlink" title="è¿­ä»£"></a>è¿­ä»£</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">g</span><span class="params">(x)</span>:</span>print(x)     </span><br><span class="line">rdd.foreach(g)</span><br></pre></td></tr></table></figure><h4 id="æ”¹å˜æ•°æ®å½¢çŠ¶"><a href="#æ”¹å˜æ•°æ®å½¢çŠ¶" class="headerlink" title="æ”¹å˜æ•°æ®å½¢çŠ¶"></a>æ”¹å˜æ•°æ®å½¢çŠ¶</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">è§„çº¦</span><br><span class="line">rdd.reduceByKey(<span class="keyword">lambda</span> x,y:x+y)åˆå¹¶æ¯ä¸ªé”®çš„å€¼</span><br><span class="line">rdd.reduce(<span class="keyword">lambda</span> x,y:x+y)åˆå¹¶RDDçš„å€¼</span><br><span class="line">åˆ†ç»„</span><br><span class="line">rdd.groupBy(<span class="keyword">lambda</span> x:x%<span class="number">2</span>).mapValues(list)è¿”å›RDDçš„åˆ†ç»„å€¼</span><br><span class="line">rdd.groupByKey().mapValues(list)æŒ‰é”®åˆ†ç»„RDD</span><br><span class="line">é›†åˆ</span><br><span class="line">seqOp = (<span class="keyword">lambda</span> x,y:(x[<span class="number">0</span>]+y,x[<span class="number">1</span>]+<span class="number">1</span>))</span><br><span class="line">combOP = (<span class="keyword">lambda</span> x,y:(x[<span class="number">0</span>]+y[<span class="number">0</span>],x[<span class="number">1</span>]+y[<span class="number">1</span>]))</span><br><span class="line">rdd.aggregate((<span class="number">0</span>,<span class="number">0</span>),seqOp,combOP) æ±‡æ€»æ¯ä¸ªåˆ†åŒºé‡Œçš„RDDå…ƒç´ ï¼Œå¹¶è¾“å‡ºç»“æœ</span><br><span class="line">rdd.aggregeteByKey((<span class="number">0</span>,<span class="number">0</span>),seqOp,combOP)æ±‡æ€»æ¯ä¸ªRDDçš„é”®çš„å€¼</span><br><span class="line">rdd.fold(<span class="number">0</span>,add)æ±‡æ€»æ¯ä¸ªåˆ†åŒºé‡Œçš„RDDå…ƒç´ ï¼Œå¹¶è¾“å‡ºç»“æœ</span><br><span class="line">rdd.foldByKey(<span class="number">0</span>,add)åˆå¹¶æ¯ä¸ªé”®çš„å€¼</span><br><span class="line">rdd,keyBy(<span class="keyword">lambda</span> x:x+x)é€šè¿‡æ‰§è¡Œå‡½æ•°ï¼Œåˆ›å»ºRDDå…ƒç´ çš„å…ƒç»„</span><br></pre></td></tr></table></figure><h4 id="æ•°å­¦è¿ç®—"><a href="#æ•°å­¦è¿ç®—" class="headerlink" title="æ•°å­¦è¿ç®—"></a>æ•°å­¦è¿ç®—</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rdd.subtract(rdd2)è¿”å›RDD2é‡Œæ²¡æœ‰åŒ¹é…é”®çš„rddçš„å…¼èŒå¯¹</span><br><span class="line">rdd2.subtractByKey(rdd)è¿”å›rdd2é‡Œçš„æ¯ä¸ªï¼ˆé”®ã€å€¼ï¼‰å¯¹ï¼Œrddä¸­ï¼Œæ²¡æœ‰åŒ¹é…çš„é”®</span><br><span class="line">rdd.cartesian(rdd2)è¿”å›rddå’Œrdd2çš„ç¬›å¡å°”ç§¯</span><br></pre></td></tr></table></figure><h4 id="æ’åº"><a href="#æ’åº" class="headerlink" title="æ’åº"></a>æ’åº</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rdd.sortBy(lambda x:x[1])æŒ‰ç»™å®šå‡½æ•°æ’åºRDD</span><br><span class="line">rdd.sortByKey()æŒ‰é”®æ’åºRDDçš„é”®å€¼å¯¹</span><br></pre></td></tr></table></figure><h4 id="é‡åˆ†åŒº"><a href="#é‡åˆ†åŒº" class="headerlink" title="é‡åˆ†åŒº"></a>é‡åˆ†åŒº</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rdd.repartition(4)æ–°å»ºä¸€ä¸ªå«4ä¸ªåˆ†åŒºçš„RDD</span><br><span class="line">rdd.coalesce(1)å°†RDDä¸­çš„åˆ†åŒºæ•°ç¼©å‡ä¸º1ä¸ª</span><br></pre></td></tr></table></figure><h4 id="ä¿å­˜"><a href="#ä¿å­˜" class="headerlink" title="ä¿å­˜"></a>ä¿å­˜</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rdd.saveAsTextFile(&quot;rdd.txt&quot;)</span><br><span class="line">rdd.saveAsHadoopFile(&quot;hdfs://namenodehost/parent/child&quot;,&apos;org.apache.hadoop.mapred.TextOutputFormat&apos;)</span><br></pre></td></tr></table></figure><h4 id="ç»ˆæ­¢SparkContext"><a href="#ç»ˆæ­¢SparkContext" class="headerlink" title="ç»ˆæ­¢SparkContext"></a>ç»ˆæ­¢SparkContext</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sc.stop()</span><br></pre></td></tr></table></figure><h4 id="æ‰§è¡Œç¨‹åº"><a href="#æ‰§è¡Œç¨‹åº" class="headerlink" title="æ‰§è¡Œç¨‹åº"></a>æ‰§è¡Œç¨‹åº</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-submit examples/src/main/python/pi.py</span><br></pre></td></tr></table></figure><h1 id="Pyspark-sql"><a href="#Pyspark-sql" class="headerlink" title="Pyspark_sql"></a>Pyspark_sql</h1><h4 id="Pysparkä¸Spark-SQL"><a href="#Pysparkä¸Spark-SQL" class="headerlink" title="Pysparkä¸Spark SQL"></a>Pysparkä¸Spark SQL</h4><p>Spark SQLæ˜¯Apache Sparkå¤„ç†ç»“æ„åŒ–æ•°æ®çš„æ¨¡å—</p><h4 id="åˆå§‹åŒ–SparkSession"><a href="#åˆå§‹åŒ–SparkSession" class="headerlink" title="åˆå§‹åŒ–SparkSession"></a>åˆå§‹åŒ–SparkSession</h4><p>SparkSessionç”¨äºåˆ›å»ºæ•°æ®æ¡†ï¼Œå°†æ•°æ®æ¡†æ³¨å†Œä¸ºè¡¨ï¼Œæ‰§è¡ŒSQLæŸ¥è¯¢ï¼Œç¼“å­˜è¡¨åŠè¯»å–Parquetæ–‡ä»¶</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import SparkSession</span><br><span class="line">spark = SparkSession.builder.appName(&quot;my app&quot;).config(&quot;spark.some.config.option&quot;,&quot;some-value&quot;).getOrCreate()</span><br></pre></td></tr></table></figure><h4 id="åˆ›å»ºæ•°æ®æ¡†"><a href="#åˆ›å»ºæ•°æ®æ¡†" class="headerlink" title="åˆ›å»ºæ•°æ®æ¡†"></a>åˆ›å»ºæ•°æ®æ¡†</h4><h5 id="ä»RDDåˆ›å»º"><a href="#ä»RDDåˆ›å»º" class="headerlink" title="ä»RDDåˆ›å»º"></a>ä»RDDåˆ›å»º</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql.types import *</span><br><span class="line">æ¨æ–­Schema</span><br><span class="line">sc = spark.sparkContext</span><br><span class="line">lines = sc.textFile(&quot;people.txt&quot;)</span><br><span class="line">parts = lines.map(lambda l:l.split(&quot;,&quot;))</span><br><span class="line">people = parts.map(lambda p:Row(name=p[0],age=int(p[1])))</span><br><span class="line">peopledf = spark.createDataFrame(people)</span><br><span class="line">æŒ‡å®šSchema</span><br><span class="line">people = parts.map(lambda p:Row(name=p[0],age=int(p[1].strip())))</span><br><span class="line">schemaString = &quot;name age&quot;</span><br><span class="line">fields = [StructField(field_name,StringType(),True) for field_name in schemaString.split()]</span><br><span class="line">schema = StructType(fields)</span><br><span class="line">spark.createDataFrame(people,schema).show()</span><br></pre></td></tr></table></figure><h5 id="ä»sparkæ•°æ®æºåˆ›å»º"><a href="#ä»sparkæ•°æ®æºåˆ›å»º" class="headerlink" title="ä»sparkæ•°æ®æºåˆ›å»º"></a>ä»sparkæ•°æ®æºåˆ›å»º</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">json</span><br><span class="line">df = spark.read.json(<span class="string">"customer.json"</span>)</span><br><span class="line">df.show()</span><br><span class="line">df2 = spark.read.load(<span class="string">"people.json"</span>,format = <span class="string">"json"</span>)</span><br><span class="line">Parquetæ–‡ä»¶</span><br><span class="line">df3 = spark.read.load(<span class="string">"users.parquet"</span>)</span><br><span class="line">æ–‡æœ¬æ–‡ä»¶</span><br><span class="line">df4 = spark.read.text(<span class="string">"people.txt"</span>)</span><br></pre></td></tr></table></figure><h5 id="æŸ¥é˜…æ•°æ®ä¿¡æ¯"><a href="#æŸ¥é˜…æ•°æ®ä¿¡æ¯" class="headerlink" title="æŸ¥é˜…æ•°æ®ä¿¡æ¯"></a>æŸ¥é˜…æ•°æ®ä¿¡æ¯</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">df.dtypesè¿”å›dfçš„åˆ—åä¸æ•°æ®ç±»å‹</span><br><span class="line">df.show()æ˜¾ç¤ºdfå†…å®¹</span><br><span class="line">df.head()è¿”å›å‰nè¡Œæ•°æ®</span><br><span class="line">df.first()è¿”å›ç¬¬ä¸€è¡Œæ•°æ®</span><br><span class="line">df.take(2)è¿”å›å‰ä¸¤è¡Œæ•°æ®</span><br><span class="line">df.schemaè¿”å›dfçš„schema</span><br><span class="line">df.describe().show()æ±‡æ€»ç»Ÿè®¡æ•°æ®</span><br><span class="line">df.columnsè¿”å›dfåˆ—å</span><br><span class="line">df.count()è¿”å›dfçš„è¡Œæ•°</span><br><span class="line">df.distinct().count()è¿”å›dfä¸­ä¸é‡å¤çš„è¡Œæ•°</span><br><span class="line">df.printSchema()è¿”å›dfçš„Schema</span><br><span class="line">df.explain()è¿”å›é€»è¾‘ä¸å®ä½“æ–¹æ¡ˆ</span><br></pre></td></tr></table></figure><h5 id="é‡å¤å€¼"><a href="#é‡å¤å€¼" class="headerlink" title="é‡å¤å€¼"></a>é‡å¤å€¼</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df = df.dropDuplicates()</span><br></pre></td></tr></table></figure><h5 id="æŸ¥è¯¢"><a href="#æŸ¥è¯¢" class="headerlink" title="æŸ¥è¯¢"></a>æŸ¥è¯¢</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> functions <span class="keyword">as</span> F</span><br><span class="line">Select</span><br><span class="line">df.select(<span class="string">"firstName"</span>).show()æ˜¾ç¤ºfirstNameåˆ—çš„æ‰€æœ‰æ¡ç›®</span><br><span class="line">df.select(<span class="string">"firstName"</span>,<span class="string">"lastName"</span>.show())</span><br><span class="line">df.select(<span class="string">"firstName"</span>,<span class="string">"age"</span>,\</span><br><span class="line">          explode(<span class="string">"phoneNumber"</span>)\æ˜¾ç¤ºfirstNameã€ageçš„æ‰€æœ‰æ¡ç›®å’Œç±»å‹</span><br><span class="line">          .alias(<span class="string">"contactInfo"</span>))\</span><br><span class="line">.select(<span class="string">"ContactInfo.type"</span>,<span class="string">"firstName"</span>,<span class="string">"age"</span>)</span><br><span class="line">df.select(df[<span class="string">"firstName"</span>],df[<span class="string">"age"</span>]+<span class="number">1</span>).show()æ˜¾ç¤ºfirstNameå’Œageåˆ—çš„æ‰€æœ‰è®°å½•æ·»åŠ </span><br><span class="line">df.select(df[<span class="string">"age"</span>]&gt;<span class="number">24</span>).show()æ˜¾ç¤ºæ‰€æœ‰å°äº<span class="number">24</span>çš„è®°å½•</span><br><span class="line">When</span><br><span class="line">df.select(<span class="string">"firstName"</span>,F.when(df.age&gt;<span class="number">30</span>,<span class="number">1</span>))\æ˜¾ç¤ºfirstNameï¼Œä¸”å¤§äº<span class="number">30</span>å²æ˜¾ç¤º<span class="number">1</span>ï¼Œå°äº<span class="number">30</span>æ˜¾ç¤º<span class="number">0</span></span><br><span class="line">.otherwise(<span class="number">0</span>).show()</span><br><span class="line">df[df.firstName.isin(<span class="string">"Jane"</span>,<span class="string">"Boris"</span>)].collect()æ˜¾ç¤ºç¬¦åˆç‰¹å®šæ¡ä»¶çš„firstNameåˆ—çš„è®°å½•</span><br><span class="line">Like</span><br><span class="line">df.select(<span class="string">"firstName"</span>,df.lastName,\æ˜¾ç¤ºlastNameåˆ—ä¸­åŒ…å«Smithçš„firstNameåˆ—çš„è®°å½•</span><br><span class="line">          like(<span class="string">"Smith"</span>)).show()</span><br><span class="line">Startswith-Endwith</span><br><span class="line">df.select(<span class="string">"firstName"</span>,df.lastName.\æ˜¾ç¤ºlastNameåˆ—ä¸­ä»¥Små¼€å¤´çš„firstNameåˆ—çš„è®°å½•</span><br><span class="line">          startswith(<span class="string">"Sm"</span>)).show()</span><br><span class="line">df.select(df.lastName.endswith(<span class="string">"th"</span>)).show()æ˜¾ç¤ºä»¥thç»“å°¾çš„lastName</span><br><span class="line">Substring</span><br><span class="line">df.select(df.firstName.substr(<span class="number">1</span>,<span class="number">3</span>).alias(<span class="string">"name"</span>))è¿”å›firstNameçš„å­å­—ç¬¦ä¸²</span><br><span class="line">Between</span><br><span class="line">df.select(df.age.between(<span class="number">22</span>,<span class="number">24</span>)).show()æ˜¾ç¤ºä»‹äº<span class="number">22</span>åˆ°<span class="number">24</span>ç›´æ¥çš„ageåˆ—çš„æ‰€æœ‰è®°å½•</span><br></pre></td></tr></table></figure><h4 id="æ·»åŠ ã€ä¿®æ”¹ã€åˆ é™¤åˆ—"><a href="#æ·»åŠ ã€ä¿®æ”¹ã€åˆ é™¤åˆ—" class="headerlink" title="æ·»åŠ ã€ä¿®æ”¹ã€åˆ é™¤åˆ—"></a>æ·»åŠ ã€ä¿®æ”¹ã€åˆ é™¤åˆ—</h4><h5 id="æ·»åŠ åˆ—"><a href="#æ·»åŠ åˆ—" class="headerlink" title="æ·»åŠ åˆ—"></a>æ·»åŠ åˆ—</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df = df.withColumn(<span class="string">'city'</span>,df.address.city) \</span><br><span class="line">       .withColumn(<span class="string">'postalCode'</span>,df.address.postalCode) \</span><br><span class="line">    .withColumn(<span class="string">'state'</span>,df.address.state) \</span><br><span class="line">    .withColumn(<span class="string">'streetAddress'</span>,df.address.streetAddress) \</span><br><span class="line">    .withColumn(<span class="string">'telePhoneNumber'</span>,explode(df.phoneNumber.number)) \</span><br><span class="line">    .withColumn(<span class="string">'telePhoneType'</span>,explode(df.phoneNumber.type)) \</span><br></pre></td></tr></table></figure><h5 id="ä¿®æ”¹åˆ—"><a href="#ä¿®æ”¹åˆ—" class="headerlink" title="ä¿®æ”¹åˆ—"></a>ä¿®æ”¹åˆ—</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df = df.withColumnRenamed(<span class="string">'telePhoneNumber'</span>,<span class="string">'phoneNumber'</span>)</span><br></pre></td></tr></table></figure><h5 id="åˆ é™¤åˆ—"><a href="#åˆ é™¤åˆ—" class="headerlink" title="åˆ é™¤åˆ—"></a>åˆ é™¤åˆ—</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = df.drop(&quot;address&quot;,&quot;phoneNumber&quot;)</span><br><span class="line">df = df.drop(df.address).drop(df.phoneNumber)</span><br></pre></td></tr></table></figure><h5 id="åˆ†ç»„"><a href="#åˆ†ç»„" class="headerlink" title="åˆ†ç»„"></a>åˆ†ç»„</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.groupBy(<span class="string">"age"</span>).count().show()æŒ‰ageåˆ—åˆ†ç»„ï¼Œç»Ÿè®¡æ¯ç»„äººæ•°</span><br></pre></td></tr></table></figure><h5 id="ç­›é€‰"><a href="#ç­›é€‰" class="headerlink" title="ç­›é€‰"></a>ç­›é€‰</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.filter(df[<span class="string">"age"</span>]&gt;<span class="number">24</span>).show()æŒ‰ageåˆ—ç­›é€‰ï¼Œä¿ç•™å¹´é¾„å¤§äº<span class="number">24</span>å²çš„</span><br></pre></td></tr></table></figure><h5 id="æ’åº-1"><a href="#æ’åº-1" class="headerlink" title="æ’åº"></a>æ’åº</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">peopledf.sort(peopledf.age.desc()).collect()</span><br><span class="line">df.sort(&quot;age&quot;,ascending=False).collect()</span><br><span class="line">df.orderBy([&quot;age&quot;,&quot;city&quot;],ascending=[0,1]).collect()</span><br></pre></td></tr></table></figure><h5 id="æ›¿æ¢ç¼ºå¤±å€¼"><a href="#æ›¿æ¢ç¼ºå¤±å€¼" class="headerlink" title="æ›¿æ¢ç¼ºå¤±å€¼"></a>æ›¿æ¢ç¼ºå¤±å€¼</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df.na.fill(<span class="number">50</span>).show()ç”¨ä¸€ä¸ªå€¼æ›¿æ¢ç©ºå€¼</span><br><span class="line">df.na.drop().show()å»é™¤dfä¸­ä¸ºç©ºå€¼çš„è¡Œ</span><br><span class="line">df.na.replace(<span class="number">10</span>,<span class="number">20</span>).show()ç”¨ä¸€ä¸ªå€¼å»æ›¿æ¢å¦ä¸€ä¸ªå€¼</span><br></pre></td></tr></table></figure><h5 id="é‡åˆ†åŒº-1"><a href="#é‡åˆ†åŒº-1" class="headerlink" title="é‡åˆ†åŒº"></a>é‡åˆ†åŒº</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.repartition(<span class="number">10</span>).rdd.getNumPartitions()å°†dfæ‹†åˆ†ä¸º<span class="number">10</span>ä¸ªåˆ†åŒº</span><br><span class="line">df.coalesce(<span class="number">1</span>).rdd.getNumPartitions()å°†dfåˆå¹¶ä¸º<span class="number">1</span>ä¸ªåˆ†åŒº</span><br></pre></td></tr></table></figure><h4 id="è¿è¡ŒSQLæŸ¥è¯¢"><a href="#è¿è¡ŒSQLæŸ¥è¯¢" class="headerlink" title="è¿è¡ŒSQLæŸ¥è¯¢"></a>è¿è¡ŒSQLæŸ¥è¯¢</h4><h5 id="å°†æ•°æ®æ¡†æ³¨å†Œä¸ºè§†å›¾"><a href="#å°†æ•°æ®æ¡†æ³¨å†Œä¸ºè§†å›¾" class="headerlink" title="å°†æ•°æ®æ¡†æ³¨å†Œä¸ºè§†å›¾"></a>å°†æ•°æ®æ¡†æ³¨å†Œä¸ºè§†å›¾</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">peopledf.createGlobalTempView(<span class="string">"people"</span>)</span><br><span class="line">df.createTempView(<span class="string">"customer"</span>)</span><br><span class="line">df.createOrReplaceTempView(<span class="string">"customer"</span>)</span><br></pre></td></tr></table></figure><h5 id="æŸ¥è¯¢è§†å›¾"><a href="#æŸ¥è¯¢è§†å›¾" class="headerlink" title="æŸ¥è¯¢è§†å›¾"></a>æŸ¥è¯¢è§†å›¾</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = spark.sql(<span class="string">"select * from customer"</span>).show()</span><br><span class="line">peopledf = spark.sql(<span class="string">"select * from global_temp.people"</span>).show()</span><br></pre></td></tr></table></figure><h4 id="è¾“å‡º"><a href="#è¾“å‡º" class="headerlink" title="è¾“å‡º"></a>è¾“å‡º</h4><h5 id="æ•°æ®ç»“æ„"><a href="#æ•°æ®ç»“æ„" class="headerlink" title="æ•°æ®ç»“æ„"></a>æ•°æ®ç»“æ„</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rdd1 = df.rddå°†dfè½¬ä¸ºrdd</span><br><span class="line">df.toJSON().first()å°†dfè½¬ä¸ºrddå­—ç¬¦ä¸²</span><br><span class="line">df.toPandas()å°†dfçš„å†…å®¹è½¬ä¸ºPandasçš„æ•°æ®æ¡†</span><br></pre></td></tr></table></figure><h5 id="ä¿å­˜è‡³æ–‡ä»¶"><a href="#ä¿å­˜è‡³æ–‡ä»¶" class="headerlink" title="ä¿å­˜è‡³æ–‡ä»¶"></a>ä¿å­˜è‡³æ–‡ä»¶</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.select(<span class="string">"firstName"</span>,<span class="string">"city"</span>).write.save(<span class="string">"nameAndCity.parquet"</span>)</span><br><span class="line">df.select(<span class="string">"firstName"</span>,<span class="string">"age"</span>).write.save(<span class="string">"nameAndAges.json"</span>,format=<span class="string">"json"</span>)</span><br></pre></td></tr></table></figure><h5 id="ç»ˆæ­¢SparkSession"><a href="#ç»ˆæ­¢SparkSession" class="headerlink" title="ç»ˆæ­¢SparkSession"></a>ç»ˆæ­¢SparkSession</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark.stop()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pyspark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>æ•°æ®åˆ†æå¸¸ç”¨å·¥å…·æ€»ç»“</title>
      <link href="/2019/07/22/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E6%80%BB%E7%BB%93/"/>
      <url>/2019/07/22/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h1 id="numpy"><a href="#numpy" class="headerlink" title="numpy"></a>numpy</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">1. ä¼˜ç‚¹:å‘é‡åŒ–æ•°æ®æ“ä½œæ¯”forå¾ªç¯,é€Ÿåº¦å¤§å¤§åŠ å¼ºï¼Œnumpy arrayæ¯”listå¥½çš„åœ°æ–¹åœ¨äºåˆ‡ç‰‡</span><br><span class="line">2. arrayå±æ€§</span><br><span class="line">    np.random.random((2,2)) # 0-1éšæœºæ•°</span><br><span class="line">    np.random.randint(1,10,(3,3)) # éšæœºæ•´æ•°</span><br><span class="line">    array.shape, array.dtype # numpyä¸¤ä¸ªå±æ€§</span><br><span class="line">    array.astype(np.float64) # ç±»å‹è½¬æ¢</span><br><span class="line">3. arrayåˆ‡ç‰‡æ“ä½œ</span><br><span class="line">    a[0,1] # ç¬¬ä¸€ä¸ªç»´åº¦ä¸º0,ç¬¬äºŒä¸ªç»´åº¦1,ç¬¬ä¸‰ä¸ªç»´åº¦å…¨é€‰,ç±»ä¼¼äºa[0,1,:]</span><br><span class="line">    a[a&gt;2] # boolean indexing, åˆ©ç”¨broadcastingè¿›è¡Œåˆ¤æ–­, ä¹‹åå¯ä»¥ä½œä¸ºindexè¿›è¡Œæ•°æ®çš„æå–</span><br><span class="line">    a[a&gt;2]=0 # ä¹Ÿå¯ä»¥å¯¹æ»¡è¶³æ¡ä»¶çš„å…ƒç´ è¿›è¡Œèµ‹å€¼</span><br><span class="line">4. arrayæ•°å­¦è¿ç®—</span><br><span class="line">    broadcasting, å¯¹ä¸åŒ¹é…çš„æ•°æ®åœ¨é«˜ç»´ä¸Šè¿›è¡Œæ‰©å±•,åœ¨å–æœ€å°å…¬å€æ•°</span><br><span class="line">    np.sum(array) # ç»Ÿè®¡è¿ç®—</span><br><span class="line">    np.dot # çŸ©é˜µä¹˜æ³•,ç‚¹ä¹˜</span><br><span class="line">    np.multiply  # é€ä¸ªå…ƒç´ ä¹˜æ³•,å¯¹åº”ç›¸ä¹˜</span><br></pre></td></tr></table></figure><p>#pandas</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">åŸºäºNumpyæ„å»ºï¼Œåˆ©ç”¨å®ƒçš„é«˜çº§æ•°æ®ç»“æ„å’Œæ“ä½œå·¥å…·ï¼Œå¯ä½¿æ•°æ®åˆ†æå·¥ä½œå˜å¾—æ›´åŠ ä¾¿æ·é«˜æ•ˆã€‚</span><br><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br></pre></td></tr></table></figure><h2 id="åŸºæœ¬æ•°æ®ç»“æ„"><a href="#åŸºæœ¬æ•°æ®ç»“æ„" class="headerlink" title="åŸºæœ¬æ•°æ®ç»“æ„"></a>åŸºæœ¬æ•°æ®ç»“æ„</h2><h3 id="Series"><a href="#Series" class="headerlink" title="Series"></a>Series</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">1. åŸºæœ¬æ¦‚å¿µ</span><br><span class="line">    pd.__version__ # æŸ¥çœ‹ç‰ˆæœ¬</span><br><span class="line">    pd.Series # å¯ä»¥ä½¿ç”¨ä¸åŒç±»å‹,å’ŒliståŒºåˆ«åœ¨äºæœ‰index, å¯ä»¥æŒ‡å®šindex</span><br><span class="line"></span><br><span class="line">2. Seriesæ„å»º</span><br><span class="line">    pd.Series([1,2,3], index=[&apos;a&apos;, &apos;b&apos;, &apos;c&apos;])</span><br><span class="line">    pd.Series(&#123;...&#125;, name=&quot;xxx&quot;) # é€šè¿‡å¯¹dictionaryè¿›è¡Œæ„å»ºpandas, ç»™Seriesèµ‹äºˆåå­—</span><br><span class="line"></span><br><span class="line">3. åˆ‡ç‰‡</span><br><span class="line">    aseries[[1,4,3]]; aseries[1:]; aseries[:-1]  # æ•°å­—ä¸‹æ ‡åˆ‡ç‰‡,å³ä½¿indexä¸æ˜¯æ•°å­—ä¹Ÿok</span><br><span class="line"></span><br><span class="line">4. è¿ç®—è§„åˆ™</span><br><span class="line">    seriesçš„ç›¸åŠ æ˜¯æ ¹æ®indexå¯¹åº”ç›¸åŠ çš„</span><br><span class="line"></span><br><span class="line">5. å–å€¼</span><br><span class="line">    æ•°å­¦è¿ç®—ä¹Ÿæ˜¯broadcastingæ–¹å¼</span><br><span class="line">    &apos;xxx&apos; in aseries # åˆ¤æ–­xxxæ˜¯å¦åœ¨aseriesçš„indexä¸­</span><br><span class="line">    aseries.get(&apos;xxx&apos;, 0) # ç±»ä¼¼äºå­—å…¸</span><br><span class="line">    aseries[aseries&lt;20] # boolean indexä¹Ÿå¯ä»¥</span><br><span class="line">    aseries.median() # é™¤å»ç¼ºå¤±å€¼ä¹‹åè¿›è¡Œç»Ÿè®¡è¿ç®—</span><br><span class="line">    aseries[&apos;xxx&apos;] = 1000 # å¯¹aseries[&apos;xxx&apos;]é‡æ–°èµ‹å€¼</span><br><span class="line">    np.square(aseries) # å¯¹æ¯ä¸ªè¿ç®—è¿›è¡Œè®¡ç®—å¹³æ–¹</span><br></pre></td></tr></table></figure><h3 id="DataFrame"><a href="#DataFrame" class="headerlink" title="DataFrame"></a>DataFrame</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">1. åŸºæœ¬æ¦‚å¿µ</span><br><span class="line">    ä¸€ç»„Seriesé›†åˆåœ¨ä¸€èµ·</span><br><span class="line"></span><br><span class="line">2. DataFrameçš„æ„å»º</span><br><span class="line">    - pd.DataFrame(&#123;&apos;a&apos;:[1,2,3], &apos;b&apos;:[1,4,3]&#125;, columns = [&apos;b&apos;, &apos;a&apos;], index = [&apos;one&apos;, &apos;two&apos;, &apos;three&apos;]) # æ„å»ºDF, æŒ‡å®šåˆ—åä»¥åŠindexå</span><br><span class="line">    - pd.DataFrame([&#123;&apos;a&apos;:100,&apos;b&apos;:200&#125;, &#123;&apos;a&apos;:200, &apos;b&apos;:300&#125;], index=[&apos;one&apos;, &apos;two&apos;]) # æŒ‰ç…§ä¸€è¡Œä¸€è¡Œæ„å»ºDF</span><br><span class="line">    - pd.DataFrame(&#123;&apos;a&apos;:seriesa, &apos;b&apos;:seriesb&#125; # è®°ä½æŒ‰ç…§indexå¯¹é½, ç¼ºå¤±å€¼ç›´æ¥Nanå¡«å……</span><br><span class="line"></span><br><span class="line">3. å…ƒç´ çš„æå–ä»¥åŠå¢åŠ åŠé€»è¾‘æ“ä½œåŠè½¬ç½®</span><br><span class="line">    - aDF[&apos;xxx&apos;]/aDF.xxx # å–å‡ºæ¥çš„æ˜¯ä¸€ä¸ªSeries</span><br><span class="line">    - aDF[[&apos;xxx&apos;]] # å–å‡ºæ¥çš„æ˜¯ä¸€ä¸ªDF</span><br><span class="line">    - aDF.loc([&apos;a&apos;,&apos;b&apos;],[&apos;c&apos;,&apos;d&apos;]) # å–å¯¹åº”çš„æ•°æ®</span><br><span class="line">    - aDF.loc[:, &apos;newcol&apos;] = 2000 # å¦‚æœæ²¡æœ‰newcolé‚£ä¹ˆå°±æ–°åŠ ä¸€åˆ—</span><br><span class="line">    - aDF.loc[(aDF[&apos;a&apos;]&gt;10) &amp; (aDF[&apos;b&apos;]&lt;100), :] # ä¹Ÿå¯ä»¥ç»™æ¡ä»¶è¿›è¡Œç­›é€‰,&amp; | ~è¿›è¡Œé€»è¾‘è¿ç®—</span><br><span class="line">    - aDF.T # è¿›è¡Œè½¬ç½®</span><br><span class="line">4. æ•°æ®è¯»å…¥ä»¥åŠåŸºæœ¬ä¿¡æ¯ä»¥åŠåˆ é™¤</span><br><span class="line">    - pd.read_csv(path, sep=&apos;\t&apos;, index_col=&apos;&apos;/int, usecols=[...], header=0, parse_dates=[0]/[&apos;Date&apos;]) # è¯»æ–‡ä»¶ï¼Œç¬¬ä¸€åˆ—ä½œä¸ºæ—¥æœŸå‹ï¼Œæ—¥æœŸå‹å¤„ç†å‚ç…§: http://hshsh.me/post/2016-04-12-python-pandas-notes-01/</span><br><span class="line">    - aDF.to_csv(&apos;xxx.csv&apos;, sep=&apos;\t&apos;, index=True, header=True) # å†™æ–‡ä»¶</span><br><span class="line">    - aDF.describe(include=[np.float64...]) / aDF.info() # å¯¹æ•°æ®è¿›è¡Œç»Ÿè®¡ï¼ŒæŸ¥çœ‹ç¼ºå¤±å€¼</span><br><span class="line">    - aDF.shape</span><br><span class="line">    - aDF.isnull() # åˆ¤æ–­æ˜¯æ˜¯å¦ä¸ºç©º</span><br><span class="line">    - aDF[aDF[&apos;xxx&apos;].isnull(), :] = 10 # å¯¹ç©ºå€¼èµ‹å€¼</span><br><span class="line">    - aDF.notnull() # æŸ¥çœ‹æ˜¯å¦æœ‰å€¼</span><br><span class="line">    - aDF.drop([&apos;one&apos;, &apos;two&apos;], axis=0) # å¯¹indexä¸ºoneå’Œtwoçš„ä¸¤è¡Œè¿›è¡Œåˆ é™¤, axis=1åˆ é™¤åˆ—</span><br><span class="line"></span><br><span class="line">5. æ•°æ®åˆ†ç»„èšåˆ</span><br><span class="line">    - aDF.groupby(&apos;name&apos;, sort=False).sum() # å¯¹DFè¿›è¡Œèšåˆæ“ä½œ,åŒæ—¶å¯¹ç›¸åº”èšåˆçš„åˆ—è¿›è¡Œæ’åº,ç„¶åè®¡ç®—å…¶ä»–å€¼çš„å’Œ</span><br><span class="line">    - groupbyname=aDF.groupby(&apos;name&apos;); groupbyname.groups; len(groupbyname) # å¾—åˆ°å¯¹åº”çš„å„ä¸ªç»„åˆ«åŒ…å«çš„index, å¹¶ä¸”å¯ä»¥è·å–å¯¹åº”çš„groupé•¿åº¦</span><br><span class="line">    - aDF.groupby(&apos;name&apos;).agg([np.sum, np.mean, np.std]) # å¯¹ä¸åŒç±»åˆ«çš„æ•°æ®è¿›è¡Œå„ç±»è¿ç®—, æ¯ä¸ªnameå¯¹åº”ä¸‰åˆ—åˆ†åˆ«æ˜¯åˆ†ç»„ä¹‹ånp.sum, np.mean, np.stdè®¡ç®—</span><br><span class="line">    - aDF.groupby(&apos;name&apos;).agg([&apos;sum&apos;, &apos;median&apos;, &apos;mean&apos;]) # å’Œä¸Šé¢çš„ä½œç”¨ç›¸åŒ</span><br><span class="line">    - aDF.groupby(&apos;name&apos;).agg([&apos;a&apos;:np.sum, &apos;b&apos;:median, &apos;c&apos;:np.mean]) # å¯¹ä¸åŒåˆ—è¿›è¡Œä¸åŒæ“ä½œ</span><br><span class="line">    - aDF.groupby([&apos;name&apos;, &apos;year&apos;]).sum()/mean()/median()/describe() # å¤šç»„åˆ†ç±»</span><br><span class="line">    - aDF.groupby([&apos;name&apos;, &apos;year&apos;]).size() # å¤šç»„åˆ†ç±», æ¯ä¸€ç»„æœ‰å¤šå°‘ä¸ªè®°å½•</span><br><span class="line">    - æå–groupç±»åˆ«åç§°ä»¥åŠç±»åˆ«å¯¹åº”çš„æ•°æ®è¡Œ</span><br><span class="line">        for name,group in groupbyname:</span><br><span class="line">            print(name) # ç±»åˆ«åç§°</span><br><span class="line">            print(group) # åç§°å¯¹åº”çš„æ•°æ®è¡Œ</span><br><span class="line">        groupbyname.get_group(&apos;jason&apos;) # å¯ä»¥å¾—åˆ°å¯¹åº”ç»„åˆ«çš„æ•°æ®è¡Œ,DFæ ¼å¼</span><br><span class="line">6. transform/apply/filter æ•°æ®å˜æ¢</span><br><span class="line">    transfromå¯ä»¥å¯¹åˆ†ç»„è¿›è¡Œå˜æ¢, applyå¯¹æ•´ä¸ªDFè¿›è¡Œåˆ†ç±»,filterå¯¹åˆ†ç»„è¿›è¡Œåˆ¤æ–­</span><br><span class="line">    - aDF[&apos;Date&apos;].dt.dayofweek # å¯ä»¥å¾—åˆ°å¯¹åº”çš„æ—¥æœŸä¸­çš„ç¬¬å‡ å¤©</span><br><span class="line">    - aDF.groupby(aDF.index.year).mean() # å¯ä»¥å¯¹ç›¸åº”çš„æ—¥æœŸå‹çš„å¹´è¿›è¡Œåˆ†ç»„èšåˆ</span><br><span class="line">    - aDF.groupby(aDF.index.year).transform(lambda x: (x-x.mean())/x.std()) # å¯¹æ¯ä¸€å¹´çš„æ•°æ®æ±‚å‡å€¼ä»¥åŠæ ‡å‡†å·®,å¹¶å¯¹æ¯ä¸ªæ•°æ®è¿›è¡Œæ“ä½œ,ä¹‹æ‰€ä»¥æ²¡ä»¥æ¯å¹´ä¸ºå•ä½è¿›è¡Œå±•ç¤ºä¸»è¦æ˜¯è·Ÿfunctionæœ‰å…³,å› ä¸ºä¹‹å‰çš„æ˜¯meanä¹‹ç±»çš„</span><br><span class="line">    - aDF.groupby(aDF.index.year).apply(lambda x: (x-x.mean())/x.std()) # å¯ä»¥èµ·åˆ°ç›¸åŒçš„æ•ˆæœ</span><br><span class="line">    - aDF.loc[:,&apos;new&apos;] = aDF[&apos;xxx&apos;].apply(afunc) # å¯ä»¥å¯¹xxxè¿™ä¸€åˆ—è¿›è¡Œæ“ä½œæŒ‰ç…§afuncè¿›è¡Œæ“ä½œ,ç„¶ååˆ›å»ºæ–°çš„åˆ—</span><br><span class="line">    - aSer = pd.Series([1,1,2,2,2,3,3,4,5,5]); sSer.groupby(sSer).filter(lambda x:x.sum()&gt;4) # å¯¹serè¿›è¡Œè¿‡æ»¤,ç•™ä¸‹é‚£äº›å’Œå¤§äº4çš„ç±»åˆ«</span><br><span class="line"></span><br><span class="line">7. è¡¨æ ¼çš„æ‹¼æ¥ä¸åˆå¹¶(concat/append/merge/join)</span><br><span class="line">    - df1.append(df2, sort=False, ignore_index=True) # è¿½åŠ åœ¨è¡Œä¸Š,åŒæ—¶å¿½ç•¥åŸå…ˆdf1å’Œdf2çš„index,åˆå¹¶ä¸ºæ–°çš„index</span><br><span class="line">    - df1.append([df2, df3])  # ä¹Ÿå¯ä»¥è¿½åŠ ä¸¤ä¸ªDF, å‚è€ƒ: https://zhuanlan.zhihu.com/p/38184619</span><br><span class="line">    - pd.concat([df1.set_index(&apos;a&apos;), df2.set_index(&apos;a&apos;)], sort=False, axis=1, join=&apos;inner&apos;) # å’Œä¸Šè¿°åˆ©ç”¨mergeåœ¨aå­—æ®µä¸Šè¿›è¡Œå†…è¿æ¥çš„æ•ˆæœç±»ä¼¼,å› ä¸ºconcatæ˜¯åŸºäºindexè¿›è¡Œè¿æ¥çš„,mergeå¯ä»¥ä¸åŸºäºindex,æŒ‡å®šå­—æ®µ</span><br><span class="line">    - pd.concat([df1, df2, df3], keys=[&apos;a&apos;, &apos;b&apos;, &apos;c&apos;], axis=0, join=&apos;outer&apos;, sort=False) #åˆ—å¯¹é½çš„æ–¹å¼å¯¹è¡Œè¿›è¡Œæ‹¼æ¥,ç¼ºå°‘å€¼åˆ™è¡¥å……ä¸ºNone,å¯ä»¥å¯¹æ‹¼æ¥çš„æ¯ä¸ªdfè¿›è¡Œkeyçš„å‘½å,axis=1çš„æ—¶å€™è¡Œå¯¹é½åˆ—æ‹¼æ¥; joinæŒ‡å®šè¿æ¥æ–¹å¼,outerè¡¨ç¤ºå¤–è¿æ¥,innerè¡¨ç¤ºå†…è¿æ¥,sortæ˜¯å¦å¯¹åˆå¹¶çš„æ•°æ®è¿›è¡Œæ’åº</span><br><span class="line">    - merge # åŸºäºæŸä¸ªå­—æ®µè¿›è¡Œè¿æ¥,ä¹‹å‰çš„appendå’Œconcatéƒ½æ˜¯åœ¨è¡Œä¸Šæˆ–è€…åˆ—ä¸Šè¿›è¡Œè¿æ¥çš„,mergeç±»ä¼¼äºSQLé‡Œé¢çš„è¿æ¥,å¯ä»¥æŒ‡å®šæŸä¸ªå­—æ®µæˆ–æŸå‡ ä¸ªå­—æ®µ,ä½“ç°åœ¨onä¸Š,onæ¥listå°±æ˜¯å¤šä¸ªå­—æ®µä¸ºkey</span><br><span class="line">    - pd.merge(df1, df4, on=&apos;city&apos;, how=&apos;outer&apos;/&apos;inner&apos;/&apos;left&apos;/&apos;right&apos;) # åŸºäºä¸¤ä¸ªè¡¨ä¸­çš„cityå­—æ®µè¿›è¡Œè¡¨æ ¼çš„è¿æ¥,æŠŠå…¶ä»–çš„åˆ—è¿›è¡Œcombineåˆ°ä¸€èµ·,ä¸æŒ‡å®šonçš„è¯å°±ä¼šæ‰¾å­—æ®µç›¸åŒçš„é‚£ä¸ªè¿›è¡Œæ‹¼æ¥,æ³¨æ„concatæ˜¯åŸºäºindexè¿›è¡Œæ‹¼æ¥çš„</span><br><span class="line">    - pd.merge(df1, df2, how=&apos;inner&apos;, left_index=True, right_on=&apos;id&apos;) # å¯¹æ•°æ®è¿›è¡Œmerge,å·¦è¡¨ä»¥indexä½œä¸ºè¿æ¥å…³é”®å­—,å³è¡¨ç”¨idä½œä¸ºå…³é”®å­—</span><br><span class="line">8. é“¾å®¶Case studyæµç¨‹</span><br><span class="line">    - pd.to_datetime() # æ—¥æœŸç±»å‹è½¬æ¢</span><br><span class="line">    - df.drop(droplist, inplace=True, axis=1) # åˆ é™¤ä¸€äº›åˆ—</span><br><span class="line">    - aDF.describe(include=&apos;all&apos;) # å­—ç¬¦ä¸²å˜é‡ä¹Ÿä¼šåŒæ—¶ç»Ÿè®¡</span><br><span class="line">    - aDF.sort_values(by = &apos;xxx&apos;).tail() # æ‰¾å‡ºæ›´æ–°æœ€æ™šçš„20å¥—,ä½†æ˜¯æœ‰å¯èƒ½åŒä¸€å¤©è¶…è¿‡20å¥—</span><br><span class="line">    - å¦‚æœå¯¹æ•°æ®è¿›è¡Œå¤„ç†å‘ç°è½¬æ¢æœªæœå¯èƒ½æ˜¯å› ä¸ºæ•°æ®æœ‰ç¼ºå¤±,åšå¼‚å¸¸å¤„ç†,ç¼ºå¤±å€¼ä½œä¸ºNan</span><br><span class="line">    - aDF.nsmallest(columns=&apos;age&apos;, n=20) # å–å‡ºå¹´é¾„æœ€å°çš„20ä¸ªæ•°æ®</span><br><span class="line">    - groupby().agg() ä¹‹åä¸€èˆ¬ä¼šä½¿ç”¨reset_index() å¯¹æ•°æ®è¿›è¡Œå½’ç½®ç„¶åå†è¿›è¡Œæ“ä½œ,ascending=False</span><br><span class="line">    - adf.value_counts(normalize=True) # é»˜è®¤æ˜¯æŒ‰ç…§valueè¿›è¡Œæ’åºçš„</span><br><span class="line">    - aDF.apply(lambda x: &apos;xxx&apos; in x) # ç­›é€‰å‡ºxxxåœ¨æŸåˆ—çš„å€¼ä¸­ä¸å¦,è¿”å›Ture, Falseï¼Œæ­£åˆ™è¡¨è¾¾å¼çš„å­—ç¬¦ä¸²åŒ¹é…</span><br><span class="line">    - å¯ä»¥å®šä¹‰æ­£åˆ™è¡¨è¾¾å¼å¯¹æ–‡æœ¬ä¿¡æ¯è¿›è¡Œæå–</span><br><span class="line">        def get_info(s, pattern, n):</span><br><span class="line">            result = re.search(pattern, s)</span><br><span class="line">            if result:</span><br><span class="line">                return result.group(n)</span><br><span class="line">            else:</span><br><span class="line">                return &apos;&apos;</span><br><span class="line">    - .astype(int) # è½¬æ¢pdç±»å‹</span><br><span class="line">    - help(pd.Series.value_counts) # æ‰“å°å¸®åŠ©æ–‡æ¡£</span><br></pre></td></tr></table></figure><h1 id="pythonç»˜å›¾"><a href="#pythonç»˜å›¾" class="headerlink" title="pythonç»˜å›¾"></a>pythonç»˜å›¾</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line">1. pandas ç»˜å›¾</span><br><span class="line">    - pd.date_range(&apos;2018/12/28&apos;, periods=10) # äº§ç”Ÿæ—¥æœŸæ ¼å¼, ä»¥2018/12/28ä¸ºèµ·å§‹äº§ç”Ÿä»¥å¤©ä¸ºå•ä½çš„æ—¥æœŸæ—¶é—´list</span><br><span class="line">    - pandasç»˜å›¾éœ€è¦æŠŠæ¨ªåæ ‡ä½œä¸ºindex,ä¹‹åå†ç”»å›¾</span><br><span class="line">    - æŠ˜çº¿å›¾ç»˜åˆ¶éœ€è¦æ³¨æ„å„åˆ—å¹…åº¦ï¼Œå¦åˆ™æ•°å€¼ä¸æ˜æ˜¾</span><br><span class="line">    - df.plot.bar() # barplot, stacked=True, å †å </span><br><span class="line">    - df.plot.barh() # ç»˜åˆ¶æ°´å¹³çš„barplot</span><br><span class="line">    - df.plot.hist(bins = 20) # ç»˜åˆ¶ç›´æ–¹å›¾,å•ç»´åº¦</span><br><span class="line">    - df.plot.box() # å¯¹æ¯åˆ—å»çœ‹ä¸€äº›åˆ†å¸ƒoutlier</span><br><span class="line">    - df.plot.area # å †å åŒºåŸŸå›¾</span><br><span class="line">    - df.plot.scatter(x=&apos;a&apos;, y=&apos;b&apos;) # æ•£ç‚¹å›¾</span><br><span class="line">    - df.plot.pie(subplots=True) # ç»˜åˆ¶å¸¦å›¾ä¾‹çš„é¥¼å›¾</span><br><span class="line">    </span><br><span class="line">2. matplotlib ç»˜å›¾</span><br><span class="line">    - plt.rcParams[&apos;figure.figsize&apos;] = (12,8) / plt.figure(figsize=(12,8)) # è®¾ç½®ç”»å¸ƒå¤§å°</span><br><span class="line">    - ax = plt.plot(x,y,color=&apos;green&apos;, linewidth=&apos;-&apos;, marker=&apos;./*/x&apos;, label=r&apos;$y=cos&#123;x&#125;$&apos;/r&apos;$y=sin&#123;x&#125;$&apos;/r&apos;$y=\sqrt&#123;x&#125;$&apos;) # ç»˜å›¾</span><br><span class="line">    - ax.spines[&apos;right&apos;].set_color(&apos;none&apos;) # å»æ‰å³è¾¹çš„è¾¹æ¡†</span><br><span class="line">    - ax.xaxis.set_ticks_position(&apos;bottem&apos;) # ??????????????</span><br><span class="line">    - plt.xticks([2,4,6], [r&apos;a&apos;,r&apos;b&apos;,r&apos;c&apos;]) # è®¾ç½®åæ ‡è½´åˆ»åº¦</span><br><span class="line">    - ax.spines[&apos;bottem&apos;].set_position(&apos;data&apos;, 0)  # è®¾ç½®åæ ‡è½´ä»0å¼€å§‹</span><br><span class="line">    - plt.xlim(1,3) # è®¾ç½®åæ ‡ä½ç½®</span><br><span class="line">    - plt.title() # æ ‡é¢˜</span><br><span class="line">    - plt.xlabel(r&apos;xxx&apos;, fontsize=18, labelpad=12.5) # ç»˜åˆ¶label, rå€¼çš„æ˜¯ä¸è½¬ä¹‰çš„,$$å€¼çš„æ˜¯markdownæ ¼å¼</span><br><span class="line">    - plt.text(0.8, 0.9, r&apos;$$&apos;, color=&apos;k&apos;, fontsize=15) # è¿›è¡Œæ³¨è§£</span><br><span class="line">    - plt.scatter([8], [8], 50, color=&apos;m&apos;) # åœ¨æŸä¸ªä½ç½®,ç‚¹æœ‰å¤šå¤§,é¢œè‰²æ˜¯ä»€ä¹ˆ</span><br><span class="line">    - plt.annotate(r&apos;$xxx$&apos;, xy=(8,8), xytext=(8.2, 8.2), fontsize=16, color=&apos;m&apos;, arrowprops=dict(arrowstyle=&apos;-&gt;&apos;, connectionstyle=&apos;arc3, rad=0.1&apos;, color=&apos;m&apos;)) # å¯¹æŸä¸ªç‚¹è¿›è¡Œæ³¨è§£, è¿›è¡ŒåŠ ç®­å¤´ç­‰ç­‰</span><br><span class="line">    - plt.grid(True) # ç½‘æ ¼çº¿ </span><br><span class="line">    - plt.plot(x, y) # xyåº”ä¸ºnp array,å¦‚æœæ˜¯pandasé‚£ä¹ˆå¯ä»¥é€šè¿‡valuesè¿›è¡Œå–å€¼è½¬æ¢</span><br><span class="line">3. matplotlib ç»˜å›¾case</span><br><span class="line">    - æ–‡ä»¶è§£å‹</span><br><span class="line">        x = zipfile.ZipFile(xxx, &apos;r&apos;) # è§£å‹æ–‡ä»¶å¤¹</span><br><span class="line">        x.extractall(&apos;xxxdir&apos;) # è§£å‹åˆ°æŸä¸ªæ–‡ä»¶å¤¹ä¸‹</span><br><span class="line">        x.close() # è®°å¾—å…³é—­</span><br><span class="line">    - matplotlib.rc(&apos;figure&apos;, figsize=(14,7)) # è®¾ç½®ä¸€ä¸‹å›¾ç‰‡å°ºå¯¸</span><br><span class="line">    - matplotlib.rc(&apos;font&apos;, size=14) # è®¾ç½®å­—ä½“</span><br><span class="line">    - matplotlib.rc(&apos;axes.spines&apos;, top=False, right=False) # è®¾ç½®è¾¹çº¿</span><br><span class="line">    - matplotlib.rc(&apos;axes&apos;, grid=False) # è®¾ç½®ç½‘æ ¼</span><br><span class="line">    - matplotlib.rc(&apos;axes&apos;, facecolor=&apos;white&apos;) # è®¾ç½®é¢œè‰²</span><br><span class="line">    - fig,axå«ä¹‰</span><br><span class="line">        fig,ax = plt.subplots() # åˆ›å»ºç»˜å›¾å¯¹è±¡ä¹‹åå¯¹axè¿›è¡Œæ“ä½œï¼Œç›¸å½“äºå…ˆfig=plt.figure()å†ax=fig.add_subplot(1,1,1)</span><br><span class="line">        https://blog.csdn.net/htuhxf/article/details/82986440</span><br><span class="line">    - ax.fill_between(x, low, upper, alpha=) # å¯¹å›å½’è¿›è¡Œç½®ä¿¡åº¦ç»˜åˆ¶</span><br><span class="line">    - ax2 = ax1.twinx() # å…±äº«åŒä¸€ä¸ªxè½´</span><br><span class="line">    - ax2.spines[&apos;right&apos;].set_visible(True) # å¯¹å³ä¾§åæ ‡è½´è¿›è¡Œè®¾ç½®,å¾—åˆ°ç›¸åº”çš„å›¾</span><br><span class="line">    - å›¾çš„ä½¿ç”¨</span><br><span class="line">        å…³è”åˆ†æ:æ•£ç‚¹å›¾,æ›²çº¿å›¾,ç½®ä¿¡åŒºé—´æ›²çº¿å›¾,åŒåæ ‡æ›²çº¿å›¾</span><br><span class="line">        åˆ†å¸ƒåˆ†æ:å †å ç›´æ–¹å›¾, å¯†åº¦å›¾</span><br><span class="line">        ç»„é—´åˆ†æ:æŸ±çŠ¶å›¾(å¸¦errorbar),boxplot,è¿™ä¸ªéœ€è¦å¤šçœ‹çœ‹,</span><br><span class="line">        </span><br><span class="line"> 4. seaborn ç»˜å›¾</span><br><span class="line">    - å¼•å…¥seabornçš„åŒæ—¶ä¹Ÿè¦å¼•å…¥matplotlibå› ä¸º,æ˜¯åº•å±‚</span><br><span class="line">    - é¢œè‰²è®¾ç½®</span><br><span class="line">        sns.set(color_codes=True) # ä¸€äº›é›†æˆçš„é¢œè‰²</span><br><span class="line">        https://seaborn.pydata.org/tutorial/color_palettes.html</span><br><span class="line">    - sns.displot(x, kde=True, bins=20, rug=True, fit=stats.gamma) # histgramåŠ å¯†åº¦çº¿,æ ·æœ¬åˆ†å¸ƒæƒ…å†µ, æ‹ŸåˆæŸäº›åˆ†å¸ƒfit</span><br><span class="line">    - sns.kdeplot # ç±»ä¼¼äºä¸Šé¢çš„,kdeæ˜¯æ¯ä¸ªæ ·æœ¬ç”¨æ­£æ€åˆ†å¸ƒç”»,å¦‚æœæ ·æœ¬å¤š,é«˜åº¦å°±é«˜,ä¹‹åå†åšå½’ä¸€åŒ–</span><br><span class="line">    - sns.jointplot(x,y,data) # ç»˜åˆ¶å¸¦æœ‰histgramä»¥åŠæ•£ç‚¹å›¾çš„å›¾ï¼Œä¸¤ä¸ªå˜é‡</span><br><span class="line">    - sns.pairplot(df) # ç›´æ¥ç»˜åˆ¶å„ä¸ªåˆ—ä¹‹é—´çš„æ•£ç‚¹å›¾ä»¥åŠå¯¹åº”çš„histgramï¼Œå¤šä¸ªå˜é‡</span><br><span class="line">    - scatter plotçš„å¯†åº¦ç‰ˆ</span><br><span class="line">        with sns.axes_style(&apos;ticks&apos;):</span><br><span class="line">            sns.jointplot(x,y,data, kind=&apos;hex&apos;/&apos;kde&apos;,color=&apos;m&apos;) #ç›¸å½“äºå¯¹ç‚¹å¾ˆå¤šçš„æ—¶å€™,å…­è§’ç®±å›¾å°±èƒ½ä½“ç°å‡ºç‚¹çš„å¤šå°‘,kdeæ˜¯ç­‰é«˜çº¿,å¯†åº¦è”åˆåˆ†å¸ƒ</span><br><span class="line">    - å¤šå›¾ç»˜åˆ¶1</span><br><span class="line">        g = sns.PairGrik(df) # å„ä¸ªåˆ—æ··åˆ,äº§å‡ºn*nä¸ªæ ¼å­</span><br><span class="line">        g.map_diag(sns.kdeplot) # å¯¹è§’çº¿ç»˜åˆ¶</span><br><span class="line">        g.map_offdiag(sns.kdeplot, cmap=&apos;Blues_d&apos;, n_levels=20) # ç»˜åˆ¶å¯¹è§’çº¿æ˜¯kdeå¯†åº¦å›¾å…¶ä»–ä¸ºç­‰é«˜çº¿çš„å›¾</span><br><span class="line">    - å¤šå›¾ç»˜åˆ¶2</span><br><span class="line">        g = FaceGrid(row=[..],aspect=1.5, data=)</span><br><span class="line">        g.map(sns.boxplot, x, y, hue, hue_order=[], ...)</span><br><span class="line">    - å¤šå›¾ç»˜åˆ¶3</span><br><span class="line">        g = sns.PairGrid(data, x_vars=[], y_vars=[], aspect=0.5, size=3.5)</span><br><span class="line">        g.map(sns.violinplot, palette=&apos;bright&apos;) # x_varsæ•°é‡*y_varsæ•°é‡ä¸ªå­å›¾ï¼Œç„¶åæ¯ä¸ªå­å›¾éƒ½ç»˜åˆ¶violinplot</span><br><span class="line">    - å…³è”åˆ†æ sns.lmplot</span><br><span class="line">        Â· sns.lmplot(x, y, data) # æ•£ç‚¹å›¾+çº¿æ€§å›å½’,95%ç½®ä¿¡åŒºé—´,é€‚ç”¨äºè¿ç»­å€¼</span><br><span class="line">        Â· sns.lmplot(x, y, data, x_jitter=0.08) # å·¦å³æŠ–åŠ¨, ç‚¹å¦‚æœç¦»å¾—è¿‘,ä¼šæŠŠç‚¹å·¦å³æŠ–åŠ¨å¼€,é€‚ç”¨äºç¦»æ•£å€¼</span><br><span class="line">        Â· sns.lmplot(x, y, data, x_estimator=np.mean, ci=95, scatter_kws=&#123;&apos;s&apos;:80&#125;, order=2, robust=True) # å¯¹äºç¦»æ•£å€¼è¿˜å¯ä»¥è¿™æ ·æ“ä½œ,å…ˆæ±‚å‡å€¼å’Œ95ç½®ä¿¡åŒºé—´,ä¹‹åå†è¿›è¡Œæ‹Ÿåˆ, scatter_kwså¯¹ç‚¹è¿›è¡Œæ“ä½œ,orderæ˜¯è¯´å¯¹æ•°æ®ç‚¹è¿›è¡ŒäºŒæ¬¡æ–¹çš„åˆ†å¸ƒ,è€Œä¸æ˜¯çº¿æ€§åˆ†å¸ƒ,robustæ‰“å¼€çš„ä½œç”¨æ˜¯è¸¢é™¤å¼‚å¸¸ç‚¹,ç„¶åå†è¿›è¡Œç»˜åˆ¶å›¾</span><br><span class="line">        Â· sns.lmplot(x, y, data, x_estimator=np.mean, ci=95, scatter_kws=&#123;&apos;s&apos;:80&#125;, order=1, robust=True, logistic=True) # ç›¸å½“äºæ˜¯è¯´å¯¹äºŒå€¼åŒ–çš„æ•°æ®è¿›è¡Œlogisticå›å½’æ‹Ÿåˆ,sigmoidæ‹Ÿåˆ</span><br><span class="line">        Â· sns.lmplot(x, y, data, hue, col, row, col_wrap, aspect=0.5) # æ•£ç‚¹å›¾.çº¿æ€§å›å½’,95%ç½®ä¿¡åŒºé—´,é€‚ç”¨äºè¿ç»­å€¼,hueè¿›è¡Œåˆ†ç»„ç±»ä¼¼äºpandasé‡Œé¢çš„groupby, hueå˜é‡ä¸€å®šæ˜¯ä¸ªç¦»æ•£å˜é‡, colä¹Ÿå¯ä»¥åŠ ä¸€ä¸ªå˜é‡,å¯ä»¥æŠŠå›¾åˆ†æˆå¤šåˆ—,rowå¯ä»¥å¤šè¡Œ,å¦‚æœrow,colä»¥åŠhueéƒ½æŒ‡å®š,é‚£ä¹ˆç›¸å½“äºåœ¨pandasé‡Œé¢groupbyä¸‰ä¸ªå†…å®¹,col_wrapç”¨äºä¹‹æŒ‡å®šæ¯ä¸ªcolä¸­çš„ç»˜å›¾æ•°é‡</span><br><span class="line">    - sns.residplot() # æ®‹å·®å›¾</span><br><span class="line">    - sns.barplot(x,y,hue,ci=None)  # æ˜¯å¦æ‰“å¼€ç½®ä¿¡åŒºé—´</span><br><span class="line">    - sns.stripplot(x, y, data, jitter =True) # åŸºäºxä¸ºç¦»æ•£æ•°æ®çš„,ç±»ä¼¼äºæ•£ç‚¹å›¾çš„boxplot</span><br><span class="line">    - sns.swarmplot(x, y, data) #  èœ‚ç¾¤å›¾ï¼Œç±»ä¼¼äºå°æç´å›¾çš„ç‚¹ç‰ˆ</span><br><span class="line">    - sns.boxplot()</span><br><span class="line">    - sns.violinplot(bw) # å±äºkdeä»¥åŠboxplotçš„ç»„åˆï¼Œæ—¢çœ‹äº†å•å˜é‡åˆ†å¸ƒï¼Œä¹Ÿçœ‹äº†å„å˜é‡ä¹‹é—´çš„å·®å¼‚</span><br><span class="line">    - sns.violinplot(split=Trueï¼Œ hueï¼Œ inner=&apos;stick&apos;) # splitå°†hueä¸ºä¸¤ä¸ªç±»å‹çš„è¿›è¡Œæ‹¼æ¥ç»˜åˆ¶å°æç´å›¾ï¼Œstickï¼Œæ¯ä¸ªæ ·æœ¬ç»˜åˆ¶ç«–çº¿</span><br><span class="line">    - sns.countplot(x, data) # ç»˜åˆ¶ç¦»æ•£å˜é‡æ•°é‡åˆ†å¸ƒï¼Œç±»ä¼¼äºvalue_counts()ï¼Œç±»ä¼¼äºbarplotä½†æ˜¯ä½¿ç”¨çš„ç»Ÿè®¡é‡æ˜¯æ•°é‡</span><br><span class="line">    - sns.pointplot(x, y, hue) # æŸ¥çœ‹ç¦»æ•£å˜é‡xä»¥åŠhueåœ¨ç¦»æ•£å˜é‡yä¸Šçš„å·®åˆ«ï¼Œä½¿ç”¨å‡å€¼ï¼Œç”»ç‚¹</span><br><span class="line">    - sns.factorplot(x, y, hue, col, data, kind=&apos;swarm&apos;) # æ˜¯ä¸€ç§æ³›åŒ–çš„ç»˜å›¾å‡½æ•°</span><br><span class="line">    - a.savefig(&apos;xx&apos;) # è¿›è¡Œå›¾ç‰‡å­˜å‚¨ pltå‡½æ•°</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mumpy </tag>
            
            <tag> pandas </tag>
            
            <tag> seaborn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pythonåŸºç¡€çŸ¥è¯†æ•´ç†</title>
      <link href="/2019/07/20/python%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/"/>
      <url>/2019/07/20/python%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>#Candaç¯å¢ƒå®‰è£…ä»¥åŠåŒ…ç®¡ç†</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">æ¸…åé•œåƒä¸‹è½½https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/</span><br><span class="line">å‘½ä»¤è¡Œå¯åŠ¨jupyter notebookæˆ–ç‚¹å‡»å¿«æ·å›¾æ ‡æ–¹å¼å¯åŠ¨</span><br><span class="line">conda list <span class="comment"># æŸ¥çœ‹æ‰€åœ¨ç¯å¢ƒçš„å®‰è£…çš„åŒ…</span></span><br><span class="line">conda upgrade --all <span class="comment"># å¯¹åŒ…è¿›è¡Œæ›´æ–°</span></span><br><span class="line">spyder <span class="comment"># å¯åŠ¨anacondaä¸­çš„IDE</span></span><br><span class="line">conda install numpy pandas <span class="comment"># åœ¨æŸä¸ªç¯å¢ƒä¸‹èƒ½å¤Ÿå®‰è£…æŸäº›PythonåŒ…</span></span><br><span class="line">conda install numpy=<span class="number">1.10</span> <span class="comment"># å®‰è£…ç‰¹å®šç‰ˆæœ¬çš„åŒ…</span></span><br><span class="line">conda remove &lt; package_name &gt; <span class="comment"># åˆ é™¤åŒ…</span></span><br><span class="line">conda env list <span class="comment"># åˆ—å‡ºå½“å‰æœºå™¨ä¸Šåˆ›å»ºçš„è™šæ‹Ÿç¯å¢ƒ</span></span><br><span class="line">conda create -n env1 python=<span class="number">2.7</span> <span class="comment"># åˆ›å»ºä¸€ä¸ªåä¸ºenv1çš„ç¯å¢ƒç„¶ååœ¨å…¶ä¸­å®‰è£…python2.7</span></span><br><span class="line">conda create -n env1 numpy <span class="comment"># åˆ›å»ºä¸€ä¸ªåä¸ºenv1çš„ç¯å¢ƒç„¶ååœ¨å…¶ä¸­å®‰è£…numpy</span></span><br><span class="line">source activate env1 <span class="comment"># è¿›å…¥env1è™šæ‹Ÿç¯å¢ƒï¼Œåœ¨windowä¸Šä¸ç”¨åŠ source</span></span><br><span class="line">source deactivate <span class="comment"># ç¦»å¼€ç¯å¢ƒ</span></span><br><span class="line">conda install -n py27 ipykernel <span class="comment"># åœ¨è™šæ‹Ÿç¯å¢ƒpy27ä¸‹å®‰è£…ipykernel</span></span><br><span class="line">python -m ipykernel install --user --name py27 --display-name <span class="string">"python2"</span> <span class="comment"># åœ¨py27ç¯å¢ƒå†…å®‰è£…ipykernelå¹¶åœ¨èœå•é‡Œå‘½åä¸ºpython2</span></span><br><span class="line">conda env remove -n py27 <span class="comment"># ç§»é™¤py27çš„è™šæ‹Ÿç¯å¢ƒ</span></span><br><span class="line">conda install jupyter notebook <span class="comment"># åœ¨condaç¯å¢ƒä¸­å®‰è£…jupyter notebook</span></span><br><span class="line">%matplotlib <span class="comment"># jupyter notebookä¸­å·²äº¤äº’å¼æ–¹å¼å®ç°matplotlibçš„ç»˜å›¾</span></span><br><span class="line">%matplotlib inline <span class="comment"># ä¸è·³å‡ºï¼Œç›´æ¥å†…åµŒåœ¨webä¸­</span></span><br></pre></td></tr></table></figure><h1 id="jupyter-notebookå¸¸ç”¨é…ç½®"><a href="#jupyter-notebookå¸¸ç”¨é…ç½®" class="headerlink" title="jupyter notebookå¸¸ç”¨é…ç½®"></a>jupyter notebookå¸¸ç”¨é…ç½®</h1><h2 id="notebookä¸­çš„magicå¼€å…³"><a href="#notebookä¸­çš„magicå¼€å…³" class="headerlink" title="notebookä¸­çš„magicå¼€å…³"></a>notebookä¸­çš„magicå¼€å…³</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ä¸ºå®ç°ä¸€äº›å¿«æ·æ“ä½œï¼Œæå‡æ•ˆç‡ã€‚notebookä¸­æä¾›magicå¼€å…³ï¼Œèƒ½æå¤§çš„ä¼˜åŒ–ä½¿ç”¨notebookçš„ä½“éªŒã€‚</span><br><span class="line">magicå¼€å…³åˆ†ä¸ºä¸¤å¤§ç±»ï¼š%line magic &amp; %%cell magic</span><br></pre></td></tr></table></figure><p>â€‹        </p><h2 id="magicå¼€å…³æ€»è§ˆ"><a href="#magicå¼€å…³æ€»è§ˆ" class="headerlink" title="magicå¼€å…³æ€»è§ˆ"></a>magicå¼€å…³æ€»è§ˆ</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">%quickref<span class="comment"># æ‰€æœ‰magicå‘½ä»¤ </span></span><br><span class="line">%lsmagic<span class="comment"># æ‰“å°æ‰€æœ‰magicå‘½ä»¤</span></span><br><span class="line"></span><br><span class="line">%config ZMQInteractiveShell.ast_node_interactivity=<span class="string">'all'</span>/<span class="string">'last_expr'</span></span><br><span class="line">%pprint <span class="comment"># æ‰“å°æ‰€æœ‰ç»“æœ,ä¿è¯æ¯æ¬¡æ‰§è¡Œéƒ½è¾“å‡º,é»˜è®¤åªè¾“å‡ºæœ€åä¸€ä¸ªå†…å®¹</span></span><br><span class="line">%config ZMQInteractiveShellå¯ä»¥æŸ¥çœ‹å¯é€‰æ‹©çš„è¾“å‡ºç±»å‹</span><br><span class="line">æˆ–è€…æ‰§è¡Œè¿™ä¸ªå‘½ä»¤ä¿è¯å¤šè¾“å‡º</span><br><span class="line"><span class="keyword">from</span> IPython.core.interactiveshell <span class="keyword">import</span> InteractiveShell</span><br><span class="line">InteractiveShell.ast_node_interactivity = <span class="string">'all'</span>/<span class="string">'last_expr'</span></span><br><span class="line"></span><br><span class="line"> %%æ•´ä¸ªcell magic</span><br><span class="line"> %%writefile test.py <span class="comment"># å°†cellä¸­çš„å‘½ä»¤å†™å…¥æ–‡ä»¶test.py</span></span><br><span class="line"> %%timeitä»£ç è®¡æ—¶</span><br><span class="line"> %%bash <span class="comment"># åœ¨cellå†…å¯ä»¥æ‰§è¡Œbashå‘½ä»¤</span></span><br><span class="line"> %%writefile xx.py <span class="comment"># æŠŠæ•´ä¸ªcellä¸­çš„å†…å®¹è¾“å…¥åˆ°xx.pyä¸­,å¦‚æœæ–°åŠ å†…å®¹å¯ä»¥%%writefile -a xx.py</span></span><br><span class="line"></span><br><span class="line"> %line magicå‘½ä»¤</span><br><span class="line"> %matplotline inline <span class="comment"># åœ¨jupyterå†…æ‰“å°å›¾ç‰‡</span></span><br><span class="line"> %run utils.ipynb <span class="comment"># æ‰§è¡Œæœ¬åœ°çš„utils.ipynbæ–‡ä»¶,è¿›è¡Œé…ç½®</span></span><br><span class="line"></span><br><span class="line"> line magicå’Œcell magicåŒºåˆ«å°±åœ¨äºline magicåªåœ¨ä¸€è¡Œæœ‰æ•ˆ,cell magicåœ¨å¤šè¡Œéƒ½æœ‰æ•ˆ</span><br><span class="line"> å…·ä½“å‚è€ƒ:https://gispark.readthedocs.io/zh_CN/latest/pystart/jupyter_magics.html</span><br></pre></td></tr></table></figure><h2 id="Jupyter-notebookæ‰©å±•"><a href="#Jupyter-notebookæ‰©å±•" class="headerlink" title="Jupyter notebookæ‰©å±•"></a>Jupyter notebookæ‰©å±•</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">jupyter_contrib_nbextensions</span><br><span class="line">ç›´æ¥å®‰è£…å®˜ç½‘condaå‘½ä»¤å®‰è£…å³å¯</span><br><span class="line">conda install jupyter notebook</span><br><span class="line">conda install -c conda-forge jupyter_contrib_nbextensions </span><br><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple autopep8 </span><br><span class="line">pipå®‰è£…åŠ é€Ÿé•œåƒ:https://www.cnblogs.com/microman/p/6107879.html</span><br><span class="line">jupyter ä½¿ç”¨å‚è€ƒèµ„æ–™:https://zhuanlan.zhihu.com/p/33105153</span><br><span class="line">jupyter extension å‚è€ƒèµ„æ–™:https://zhuanlan.zhihu.com/p/52890101</span><br></pre></td></tr></table></figure><h3 id="jupyter-ä½¿ç”¨linuxå‘½ä»¤"><a href="#jupyter-ä½¿ç”¨linuxå‘½ä»¤" class="headerlink" title="jupyter ä½¿ç”¨linuxå‘½ä»¤"></a>jupyter ä½¿ç”¨linuxå‘½ä»¤</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!head -n 5 xx.txt # ç›´æ¥é€šè¿‡jupyterè¡Œä½¿linuxå‘½ä»¤</span><br></pre></td></tr></table></figure><h1 id="python"><a href="#python" class="headerlink" title="python"></a>python</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">pythonè¯­è¨€æ˜¯ä¸€ç§é¢å‘å¯¹è±¡ã€åŠ¨æ€æ•°æ®ç±»å‹çš„è§£é‡Šå‹è¯­è¨€</span><br><span class="line">1.è¿è¡Œæ–¹å¼</span><br><span class="line">    è§£é‡Šè¿è¡Œ:ç›´æ¥pyè„šæœ¬è¿è¡Œ</span><br><span class="line">    äº¤äº’è¿è¡Œ:jupyterè¾“å…¥ä¸€ä¸ªè¾“å‡ºä¸€ä¸ª</span><br><span class="line"></span><br><span class="line">2.å‘½åè§„åˆ™:</span><br><span class="line">    å¸¸é‡å¤§å†™ï¼Œä¸‹åˆ’çº¿éš”å¼€å•è¯</span><br><span class="line">    ç±»ç”¨é©¼å³°å‘½å</span><br><span class="line">     del xx åˆ é™¤å˜é‡xx</span><br><span class="line"></span><br><span class="line">3.æ“ä½œä¼˜å…ˆçº§ï¼š</span><br><span class="line">    å‡½æ•°è°ƒç”¨ï¼Œå¯»å€ï¼Œä¸‹æ ‡</span><br><span class="line">    å¹‚è¿ç®—</span><br><span class="line">    ç¿»è½¬è¿ç®—ç¬¦</span><br><span class="line">    æ­£è´Ÿå·</span><br><span class="line">    * / %</span><br><span class="line">    - + </span><br><span class="line">4.èµ‹å€¼</span><br><span class="line">    å¤šé‡èµ‹å€¼:a=b=10ç›¸å½“äºa=10,b=10</span><br><span class="line">    å¤šå…ƒèµ‹å€¼ a,b,c = 1,2,3</span><br><span class="line">    äº¤æ¢èµ‹å€¼ a,b = b,a # æŒ‡é’ˆ</span><br><span class="line"></span><br><span class="line">5.è§£åŒ…(éœ€è¦æ‹“å±• å‚è€ƒ:https://zhuanlan.zhihu.com/p/33896402?utm_source=wechat_session&amp;utm_medium=social&amp;s_r=0)</span><br><span class="line">    l1 = [1,2,3,4,5,&apos;6&apos;]; a,b,*c,d = l1</span><br><span class="line">    l1=[1,2,3,4];b=&apos;sdaad&apos;;[*l1,*b]</span><br><span class="line">    b,=[[3,4,5]] # é€—å·è§£åŒ… </span><br><span class="line"></span><br><span class="line">6.pythonè¿›åˆ¶åŠåŸºæœ¬ç±»å‹</span><br><span class="line">    bin() äºŒè¿›åˆ¶</span><br><span class="line">    oct() å…«è¿›åˆ¶</span><br><span class="line">    hex() åå…­è¿›åˆ¶</span><br><span class="line"></span><br><span class="line">    float(&apos;inf&apos;) æ­£æ— ç©·</span><br></pre></td></tr></table></figure><h2 id="åŸºæœ¬æ“ä½œ"><a href="#åŸºæœ¬æ“ä½œ" class="headerlink" title="åŸºæœ¬æ“ä½œ"></a>åŸºæœ¬æ“ä½œ</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#è¡Œå†…æ³¨é‡Š</span><br><span class="line">&quot;&quot;&quot; &quot;&quot;&quot;å¤šè¡Œæ³¨é‡Š</span><br><span class="line">ï¼Ÿå†…çœï¼Œæ˜¾ç¤ºå¯¹è±¡çš„é€šç”¨ä¿¡æ¯</span><br><span class="line">ï¼Ÿï¼Ÿå†…çœï¼Œæ˜¾ç¤ºå‡ºå¤§éƒ¨åˆ†å‡½æ•°çš„æºä»£ç </span><br><span class="line">help()æ˜¾ç¤ºä¸€ä¸ªå¯¹è±¡çš„å¸®åŠ©æ–‡æ¡£</span><br><span class="line">%timeit é­”æ³•å‘½ä»¤ï¼Œè®¡ç®—è¯­å¥çš„å¹³å‡æ‰§è¡Œæ—¶é—´</span><br><span class="line">typeï¼ˆxï¼‰æŸ¥çœ‹å˜é‡xçš„æ•°æ®ç±»å‹</span><br><span class="line">in(x) å°†å˜é‡xçš„æ•°æ®ç±»å‹è½¬æ¢ä¸ºæ•´å‹</span><br><span class="line">isinstance(x,float)æ£€æµ‹å˜é‡xæ˜¯å¦ä¸ºæµ®ç‚¹å‹ï¼Œè¿”å›ä¸€ä¸ªå¸ƒå°”å‹æ•°å€¼</span><br></pre></td></tr></table></figure><p>##å­—ç¬¦ä¸²</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">s=u&quot; &quot;å®šä¹‰Unicodeå­—ç¬¦ä¸²</span><br><span class="line">s=r&quot; &quot;å®šä¹‰åŸå§‹å­—ç¬¦ä¸²ï¼Œé¿å…å­—ç¬¦ä¸²ä¸­çš„å­—ç¬¦ä¸²è½¬ä¹‰ï¼Œåœ¨æ­£åˆ™è¡¨è¾¾å¼ä¸­ç»å¸¸ä½¿ç”¨åˆ°</span><br><span class="line">len(s)è¿”å›så­—ç¬¦ä¸²çš„å­—æ•°</span><br><span class="line">s.lower()å­—æ¯å…¨éƒ¨è½¬ä¸ºå°å†™</span><br><span class="line">s.upper()å­—æ¯å…¨éƒ¨è½¬ä¸ºå¤§å†™</span><br><span class="line">s.capitalize()å°†å­—ç¬¦ä¸²sä¸­çš„é¦–ä¸ªå­—ç¬¦è½¬æ¢ä¸ºå¤§å†™ï¼Œå…¶ä½™éƒ¨åˆ†è½¬æ¢ä¸ºå°å†™</span><br><span class="line">s.replace(&apos;k&apos;,&apos;l&apos;)ä½¿ç”¨å­—ç¬¦&quot;l&quot;æ›¿æ¢æ‰sä¸­æ‰€æœ‰çš„å­—ç¬¦&quot;k&quot;,è¿”å›ç»“æœæ˜¯cooldata</span><br><span class="line">s.strip()å»æ‰sæœ€å‰é¢å’Œæœ€åé¢çš„ç©ºæ ¼</span><br><span class="line">s.split(&quot;\t&quot;)ä½¿ç”¨åˆ¶è¡¨ç¬¦&quot;\t&quot;åˆ†å‰²å­—ç¬¦ä¸²</span><br><span class="line">&apos;%s is No.%d&apos;%(s,1)æ ¼å¼åŒ–</span><br><span class="line">&apos;&#123;&#125; is No.&#123;&#125;&apos;.format(s,1)æ ¼å¼åŒ–</span><br></pre></td></tr></table></figure><h2 id="åˆ—è¡¨"><a href="#åˆ—è¡¨" class="headerlink" title="åˆ—è¡¨"></a>åˆ—è¡¨</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">list()ç©ºåˆ—è¡¨</span><br><span class="line">l[-1]è¿”å›åˆ—è¡¨çš„æœ€åä¸€ä¸ªå…ƒç´ </span><br><span class="line">l[1:3]è¿”å›åˆ—è¡¨çš„ç¬¬äºŒä¸ªå’Œç¬¬ä¸‰ä¸ªå…ƒç´ </span><br><span class="line">len(l)è¿”å›åˆ—è¡¨é•¿åº¦</span><br><span class="line">l[::-1]å°†åˆ—è¡¨è¿›è¡Œé€†åºæ’åˆ—</span><br><span class="line">l.reverse()å°†åˆ—è¡¨è¿›è¡Œé€†åºæ’åˆ—</span><br><span class="line">l.insert(1,&quot;b&quot;)åœ¨æŒ‡å®šçš„ç´¢å¼•ä½ç½®æ’å…¥&apos;b&apos;</span><br><span class="line">l.append()åœ¨åˆ—è¡¨æœ«å°¾æ·»åŠ å…ƒç´ </span><br><span class="line">l.extend()ç­‰ä»·äº&quot;1+L&quot;ï¼Œå°†åˆ—è¡¨Lä¸­çš„å…ƒç´ ä¾æ¬¡æ·»åŠ åˆ°1çš„æœ«å°¾</span><br><span class="line">l.remove()åˆ é™¤åˆ—è¡¨ä¸­çš„æŸä¸ªå…ƒç´ </span><br><span class="line">l.pop()ç­‰ä»·äºdel l[]ï¼Œåˆ é™¤åˆ—è¡¨ä¸­å¯¹åº”ç´¢å¼•ä½ç½®çš„å…ƒç´ </span><br><span class="line">&quot; &quot;.join([&apos;&apos;c,&apos;o&apos;,&apos;o&apos;,&apos;k&apos;])å°†åˆ—è¡¨ä¸­çš„å„ä¸ªå­—ç¬¦ä¸²å…ƒç´ ç”¨ç©ºæ ¼è¿æ¥èµ·æ¥å¹¶è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œè¿”å›ç»“æœä¸ºcook</span><br></pre></td></tr></table></figure><h2 id="æ¡ä»¶åˆ¤æ–­å’Œå¾ªç¯è¯­å¥"><a href="#æ¡ä»¶åˆ¤æ–­å’Œå¾ªç¯è¯­å¥" class="headerlink" title="æ¡ä»¶åˆ¤æ–­å’Œå¾ªç¯è¯­å¥"></a>æ¡ä»¶åˆ¤æ–­å’Œå¾ªç¯è¯­å¥</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">if condition1:</span><br><span class="line">statement1</span><br><span class="line">elif condition2:</span><br><span class="line">statement2</span><br><span class="line">else:</span><br><span class="line">statement3</span><br><span class="line"></span><br><span class="line">for item in sequence:</span><br><span class="line">statement</span><br><span class="line"></span><br><span class="line">while condition:</span><br><span class="line">statement</span><br><span class="line"></span><br><span class="line">range(5)äº§ç”Ÿä¸€ä¸ªä»0åˆ°5ä¸”é—´éš”ä¸º1çš„æ•´æ•°åˆ—è¡¨[0ï¼Œ1ï¼Œ2ï¼Œ3ï¼Œ4]</span><br><span class="line">breakä»æœ€å†…å±‚forå¾ªç¯æˆ–whileå¾ªç¯ä¸­è·³å‡º</span><br><span class="line">continueç»§ç»­æ‰§è¡Œä¸‹ä¸€æ¬¡å¾ªç¯</span><br><span class="line">passå ä½ç¬¦</span><br></pre></td></tr></table></figure><h2 id="enumerateï¼ˆï¼‰and-zipï¼ˆï¼‰"><a href="#enumerateï¼ˆï¼‰and-zipï¼ˆï¼‰" class="headerlink" title="enumerateï¼ˆï¼‰and zipï¼ˆï¼‰"></a>enumerateï¼ˆï¼‰and zipï¼ˆï¼‰</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">for i,item in emumerate(l)åœ¨æ¯ä¸€æ¬¡å¾ªç¯æ—¶å–å‡ºç´¢å¼•å·å’Œç›¸åº”çš„å€¼åˆ†åˆ«èµ‹ç»™å’Œitem</span><br><span class="line">s=&#123;item**2 for item in l&#125;é›†åˆæ¨å¯¼å¼ï¼Œå¯¹lä¸­çš„æ¯ä¸€ä¸ªå…ƒç´ å–å¹³æ–¹å¾—åˆ°çš„æ–°é›†åˆ</span><br><span class="line">D=&#123;key:value for key,value in zip(l,k)&#125;å­—å…¸æ¨å¯¼å¼ï¼Œé€šè¿‡zip()å‡½æ•°å°†ä¸¤ä¸ªåˆ—è¡¨lå’Œkä¸­çš„å…ƒç´ ç»„æˆé”®å¯¹å¹¶å½¢æˆå­—å…¸</span><br><span class="line">enumerate(list/set, start=0) # éå†å…ƒç´ ï¼ŒstartæŒ‡å®šä»å“ªä¸ªæ•°å­—ä½œä¸ºå¼€å§‹ä¸‹æ ‡</span><br><span class="line">c = list(zip(a,b))</span><br><span class="line">c = set(zip(a,b))</span><br><span class="line">c = dict(zip(a,b))</span><br><span class="line">list(zip(*c)) # è§£å‹</span><br></pre></td></tr></table></figure><h2 id="æ¨å¯¼å¼"><a href="#æ¨å¯¼å¼" class="headerlink" title="æ¨å¯¼å¼"></a>æ¨å¯¼å¼</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">L=[item**2 for item in l]åˆ—è¡¨æ¨å¯¼å¼ï¼Œå¯¹lä¸­æ¯ä¸€ä¸ªå…ƒç´ å–å¹³æ–¹å¾—åˆ°æ–°çš„åˆ—è¡¨</span><br><span class="line">S=&#123;item**2 for item in l&#125;é›†åˆæ¨å¯¼å¼ï¼Œå¯¹lä¸­çš„æ¯ä¸€ä¸ªå…ƒç´ å–å¹³æ–¹å¾—åˆ°æ–°çš„é›†åˆ</span><br><span class="line">D=&#123;key:value for key,value in zip(l,k)&#125;å­—å…¸æ¨å¯¼å¼ï¼Œé€šè¿‡zip()å‡½æ•°å°†ä¸¤ä¸ªåˆ—è¡¨lå’Œkä¸­çš„å…ƒç´ ç»„æˆé”®å€¼å¯¹å¹¶å½¢æˆå­—å…¸</span><br><span class="line">[i for i in range(30) if 1%2==0] # å–0-29ä¹‹é—´å¶æ•°</span><br><span class="line">[function(i) for i in range(30) if 1%2==0] # functionå¯ä»¥è‡ªå·±å®šä¹‰</span><br><span class="line">[ x**2 if x%2 ==0 else x**3 for x in range(10)] # ä¸¤ä¸ªæ¡ä»¶</span><br></pre></td></tr></table></figure><h2 id="æ–‡ä»¶è¯»å†™"><a href="#æ–‡ä»¶è¯»å†™" class="headerlink" title="æ–‡ä»¶è¯»å†™"></a>æ–‡ä»¶è¯»å†™</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">è¯»å–æ–‡ä»¶</span><br><span class="line">f=open(filename,mode)è¿”å›ä¸€ä¸ªæ–‡ä»¶å¯¹è±¡fï¼Œè¯»æ–‡ä»¶&quot;mode=r&quot;,å†™æ–‡ä»¶&quot;mode=w&quot;</span><br><span class="line">f.read(size)è¿”å›åŒ…å«å‰sizeä¸ªå­—ç¬¦çš„å­—ç¬¦ä¸²</span><br><span class="line">f.readline()æ¯æ¬¡è¯»å–ä¸€è¡Œï¼Œè¿”å›è¯¥è¡Œå­—ç¬¦ä¸²</span><br><span class="line">f.readlines()è¿”å›åŒ…å«æ¯ä¸ªæ–‡ä»¶å†…å®¹çš„åˆ—è¡¨ï¼Œåˆ—è¡¨çš„å…ƒç´ ä¸ºæ–‡ä»¶çš„æ¯ä¸€è¡Œå†…å®¹æ‰€æ„æˆçš„å­—ç¬¦ä¸²</span><br><span class="line">f.close()å…³é—­æ–‡ä»¶å¹¶é‡Šæ”¾å®ƒæ‰€å ç”¨çš„ç³»ç»Ÿèµ„æº</span><br><span class="line">with open(&quot;aa.txt&quot;,&quot;r&quot;) as f:</span><br><span class="line">content = f.readlines()</span><br><span class="line">åœ¨withä¸»ä½“å—è¯­å¥æ‰§è¡Œå®Œåï¼Œè‡ªåŠ¨å…³é—­æ–‡ä»¶å¹¶é‡Šæ”¾å ç”¨çš„ç³»ç»Ÿèµ„æº</span><br><span class="line">import csv</span><br><span class="line">f=open(&quot;aa.csv&quot;,&quot;r&quot;)</span><br><span class="line">csvreader = csv.reader(f)</span><br><span class="line">content_list=list(csvreader)</span><br><span class="line">è¯»å–csvæ–‡ä»¶ï¼Œå¹¶æŠŠæ•°æ®å­˜å‚¨ä¸ºä¸€ä¸ªåµŒå¥—åˆ—è¡¨(åˆ—è¡¨çš„å…ƒç´ æ‰”æ˜¯ä¸€ä¸ªå¯¹è±¡)content_list</span><br><span class="line"></span><br><span class="line">å†™å…¥æ–‡ä»¶</span><br><span class="line">f.write(s)</span><br><span class="line">print(s,file=f)</span><br><span class="line">ä¸¤ç§ç­‰ä»·çš„æ–¹å¼ï¼Œå°†å­—ç¬¦ä¸²så†™å…¥æ–‡ä»¶å¯¹è±¡fä¸­</span><br></pre></td></tr></table></figure><h2 id="å‡½æ•°"><a href="#å‡½æ•°" class="headerlink" title="å‡½æ•°"></a>å‡½æ•°</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def sum(a,b=1)</span><br><span class="line">return a+b</span><br><span class="line">def sum(*args,**kwargs)ä¸å®šé•¿å‚æ•°ï¼Œ*argsæ¥æ”¶åŒ…å«å¤šä¸ªä½ç½®å‚æ•°çš„å…ƒç»„ï¼Œ**kwargsæ¥æ”¶åŒ…å«å¤šä¸ªå…³é”®å­—å‚æ•°çš„å­—å…¸ã€‚</span><br><span class="line">obj.methodnameä¸€ä¸ªæ–¹æ³•æ˜¯ä¸€ä¸ª&quot;å±äº&quot;å¯¹è±¡å¹¶è¢«å‘½åä¸ºobj.methodnameçš„å‡½æ•°</span><br></pre></td></tr></table></figure><h2 id="map-å’Œlambda"><a href="#map-å’Œlambda" class="headerlink" title="map()å’Œlambda()"></a>map()å’Œlambda()</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">map(func,sequence)å°†å‡½æ•°ä¾æ¬¡ä½œç”¨åœ¨åºåˆ—çš„æ¯ä¸ªå…ƒç´ ä¸Šï¼ŒæŠŠç»“æœä½œä¸ºä¸€ä¸ªæ–°çš„åºåˆ—è¿”å›ã€‚</span><br><span class="line">lambda a,b:a+båŒ¿åå‡½æ•°ï¼Œæ­£å¸¸å‡½æ•°å®šä¹‰çš„è¯­æ³•ç³–</span><br><span class="line">lambda [å‚æ•°åˆ—è¡¨]:è¡¨è¾¾å¼</span><br><span class="line">ä¾‹å¦‚: sum = lambda x,y:x+y # å¯ä»¥æœ‰å¤šä¸ªå‚æ•°,è¿”å›åªèƒ½æœ‰ä¸€ä¸ªå¼å­</span><br><span class="line">å¯ä»¥ä½œä¸ºä¸€ä¸ªå‡½æ•°çš„å‚æ•°èµ‹ç»™å¦å¤–ä¸€ä¸ªå‚æ•°</span><br><span class="line">å½“ç„¶æ™®é€šå‡½æ•°ä¹Ÿå¯ä»¥ä½œä¸ºå‚æ•°ä¼ å…¥</span><br><span class="line">a = [&#123;&apos;name&apos;:&apos;ss&apos;,&apos;age&apos;:10&#125;,&#123;&apos;name&apos;:&apos;yy&apos;,&apos;age&apos;:7&#125;,&#123;&apos;name&apos;:&apos;zz&apos;,&apos;age&apos;:15&#125;] # å°†åŒ¿åå‡½æ•°ä½œä¸ºå‚æ•°ä¼ å…¥ç¬¬ä¸‰æ–¹å‡½æ•°çš„å‚æ•°</span><br><span class="line">a.sort(key=lambda x:x[&apos;age&apos;]) # sortæ–¹æ³•éœ€è¦ä¼ å…¥ä¸€ä¸ªkeyï¼Œè¿™ä¸ªkeyå¯ä»¥ä½œä¸ºæ’åºä¾æ®ï¼Œlambdaå¯ä»¥æå–æ¯ä¸ªå…ƒç´ ï¼Œå¹¶å¯¹å…ƒç´ æ’åˆ—</span><br><span class="line">a.sort(key=lambda x:x[&apos;age&apos;]ï¼Œ reverse=True) # é™åº</span><br></pre></td></tr></table></figure><h2 id="åŒ…æ¨¡å—"><a href="#åŒ…æ¨¡å—" class="headerlink" title="åŒ…æ¨¡å—"></a>åŒ…æ¨¡å—</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">åŒ…æ˜¯ä¸€ä¸ªæ–‡ä»¶å¤¹</span><br><span class="line">æ¨¡å—æ˜¯ä¸åŒçš„pythonæ–‡ä»¶</span><br><span class="line">import package.module.func()</span><br><span class="line">import package1.module1, package2.module1 # å¤šä¸ªæ¨¡å—è°ƒç”¨</span><br><span class="line">import package1.module1 as p1m1 # å¯¹æ¨¡å—è¿›è¡Œé‡å‘½åä½¿ç”¨</span><br><span class="line">from package.module import func1 # è°ƒç”¨æŸä¸ªåŒ…æŸä¸ªæ¨¡å—çš„æŸä¸ªå‡½æ•°</span><br><span class="line">import sys;sys.path # æœç´¢æ¨¡å—è·¯å¾„ï¼ŒåŒ…å«å½“å‰æ–‡ä»¶å¤¹</span><br><span class="line">package.module.__file__ # å¯ä»¥ç¡®å®šå½“å‰çš„æ¨¡å—æ‰€åœ¨çš„è·¯å¾„</span><br><span class="line">__init__.py  #åœ¨åŒ…è¢«åŠ è½½çš„æ—¶å€™ï¼Œä¼šè¢«æ‰§è¡Œã€‚åœ¨ä¸€ä¸ªåŒ…ä¸‹é¢å¯ä»¥æœ‰ä¹Ÿå¯ä»¥æ²¡æœ‰__init__.py</span><br><span class="line">from package import * # å¼•ç”¨åŒ…ä¸‹é¢æ‰€æœ‰çš„æ¨¡å—éƒ½åŠ è½½ï¼Œè‡ªåŠ¨æœç´¢æ˜¯ä¸ä¼šå‘ç”Ÿçš„ï¼Œ</span><br><span class="line">    éœ€è¦æˆ‘ä»¬åœ¨__init__.pyä¸‹è¿›è¡Œå®šä¹‰æ‰å¯ä»¥å®ç°,å®šä¹‰çš„å†…å®¹æ˜¯__all__=[&quot;module1&quot;,&quot;module2&quot;],</span><br><span class="line">    å°†packageä¸‹çš„module1å’Œmodule2éƒ½åŠ è½½è¿›æ¥</span><br><span class="line">    å¦‚æœæƒ³ç›´æ¥åŠ è½½æŸä¸ªå‡½æ•°ï¼Œåœ¨__init__.pyé‡Œé¢åŠ å…¥from .module1 import func1, __all__=[&quot;func1&quot;]</span><br><span class="line">    è¿™æ ·ä¿®æ”¹å®Œä¹‹åï¼Œå¯ä»¥ç›´æ¥from package import *ï¼Œç„¶åç›´æ¥è°ƒç”¨func1å³å¯ï¼Œä¸ç”¨å¸¦package.module</span><br><span class="line">    restart kernel</span><br><span class="line">å¦‚æœæƒ³è¦ç›´æ¥å¼•ç”¨åŒ…,å¦‚ï¼šimport package,è¿™æ ·çš„è¯ï¼Œéœ€è¦ä¸€å®šè¦æœ‰__init__.pyï¼Œå¦åˆ™ä¼šåœ¨æ‰“å°package.__file__çš„æ—¶å€™æŠ¥é”™ã€‚</span><br><span class="line">æ³¨æ„import packageå’Œfrom package import *æ•ˆæœç›¸åŒ</span><br></pre></td></tr></table></figure><h2 id="Counter"><a href="#Counter" class="headerlink" title="Counter"></a>Counter</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">å­—å…¸çš„ç»§æ‰¿ç±»</span><br><span class="line">set dict list tuple ä½œä¸ºkey</span><br><span class="line">from collection import Counter # å¯¼å…¥</span><br><span class="line">cnt = Counter()</span><br><span class="line">for i in [1,1,2,2,2,3]:</span><br><span class="line">    cnt[i] += 1</span><br><span class="line">print cnt</span><br><span class="line">å¦‚æœç”¨keyçš„è¯ä¼šæŠ¥é”™å…ˆåšç¬¬ä¸€æ¬¡åˆå§‹åŒ–æ‰è¡Œ</span><br><span class="line">cnt2 = Counter(alist)  #å¯ä»¥ç»Ÿè®¡æ¯ä¸ªå…ƒç´ å‡ºç°çš„æ¬¡æ•°ï¼ˆå­—ç¬¦ä¸²ï¼Œset,list,ï¼‰</span><br><span class="line">Counter(cat=4,dogs=8,abc=-1) # åˆå§‹åŒ–counteræ¬¡æ•°ï¼Œæˆ–è€…ç”¨dictionaryæ„å»º</span><br><span class="line">Counter(&#123;&apos;cat&apos;:4,&apos;dogs&apos;:8,&apos;abc&apos;:-1&#125;)</span><br><span class="line">Counterè¿”å›ä¸€ä¸ªå­—å…¸ï¼Œå¦‚æœç¼ºå¤±çš„è¯ä¼šè¿”å›0</span><br><span class="line">del cnt2[&apos;xx&apos;]</span><br><span class="line">.values()</span><br><span class="line">list(cnt),set(cnt),dict(cnt) # å‰ä¸¤ä¸ªåªè¿”å›key</span><br><span class="line">cnt.most_common()[0] # å¯¹å‡ºç°æ¬¡æ•°æ’åº</span><br><span class="line">cnt.clear()</span><br><span class="line">cnt1+cnt2 # å¯¹äºkeyç›¸åŒçš„valueåšåŠ æ³•ï¼Œå¦‚æœä¸º0åˆ™ä¸ä¿ç•™</span><br><span class="line">cnt1-cnt2 # å¯¹äºkeyç›¸åŒçš„valueåšå‡æ³•</span><br><span class="line">&amp; # æ±‚keyç›¸åŒvalueçš„æœ€å°å€¼</span><br><span class="line">| # æ±‚keyç›¸åŒvalueçš„æœ€å¤§å€¼</span><br></pre></td></tr></table></figure><h2 id="random"><a href="#random" class="headerlink" title="random"></a>random</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import random #å¼•å…¥</span><br><span class="line">random.random() # 0-1</span><br><span class="line">random.uniform(1,10) # åŒ…å«1ï¼Œ10çš„æµ®ç‚¹æ•°</span><br><span class="line">random.randint(1,10)  # åŒ…å«1ï¼Œ10çš„æ•´æ•°</span><br><span class="line">random.randrange(0,20,3) # 0-20èƒ½è¢«3æ•´é™¤çš„æ•°</span><br><span class="line">random.choice([1,2,3]) # éšæœºå–å…ƒç´ </span><br><span class="line">random.choice(&quot;qwdwq&quot;) # éšæœºå–å…ƒç´ </span><br><span class="line">random.shuffle([12,3,1,4,2,3]) # æ··æ´—</span><br><span class="line">random.sample([1,2,3,4,5], 3) # ä»å‰é¢çš„listä¸­é€‰3ä¸ª</span><br></pre></td></tr></table></figure><h2 id="ç¼–ç å’Œè§£ç "><a href="#ç¼–ç å’Œè§£ç " class="headerlink" title="ç¼–ç å’Œè§£ç "></a>ç¼–ç å’Œè§£ç </h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import chardet</span><br><span class="line">chardet.detect(s)</span><br><span class="line">æ£€æµ‹å­—ç¬¦ä¸²çš„ç¼–ç æ–¹å¼</span><br></pre></td></tr></table></figure><h2 id="å¼‚å¸¸å¤„ç†"><a href="#å¼‚å¸¸å¤„ç†" class="headerlink" title="å¼‚å¸¸å¤„ç†"></a>å¼‚å¸¸å¤„ç†</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">try:</span><br><span class="line">statement</span><br><span class="line">except:</span><br><span class="line">pass</span><br><span class="line"></span><br><span class="line">try:</span><br><span class="line">statement</span><br><span class="line">except Exception as e:</span><br><span class="line">print(e)</span><br><span class="line"></span><br><span class="line">try:</span><br><span class="line">statement</span><br><span class="line">except (Exception1,Exception2) as e:</span><br><span class="line">statement1</span><br><span class="line">else:</span><br><span class="line">statement2</span><br><span class="line">finally:</span><br><span class="line">statement3#æ— è®ºå¯¹é”™éƒ½è¿è¡Œ</span><br><span class="line">æŠ›å‡ºå¼‚å¸¸</span><br><span class="line">raise Exception(&apos;Oopsï¼&apos;)</span><br><span class="line">assert statement,e#è‹¥ç»§ç»­è¿è¡Œä»£ç ã€å¦åˆ™æŠ›å‡ºeçš„é”™è¯¯æç¤ºä¿¡æ¯</span><br></pre></td></tr></table></figure><h2 id="æ­£åˆ™è¡¨è¾¾å¼"><a href="#æ­£åˆ™è¡¨è¾¾å¼" class="headerlink" title="æ­£åˆ™è¡¨è¾¾å¼"></a>æ­£åˆ™è¡¨è¾¾å¼</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line">raw_s=r&apos;\d&#123;17&#125;[\d|x]|\d&#123;15&#125;&apos;</span><br><span class="line">pattern=re.compile(raw_s)</span><br><span class="line">re.search(pattern,s)</span><br><span class="line">ç”¨äºåŒ¹é…èº«ä»½è¯å·</span><br><span class="line">é¦–å…ˆä½¿ç”¨åŸå§‹å­—ç¬¦ä¸²å®šä¹‰æ­£åˆ™è¡¨è¾¾å¼ï¼›ç„¶åç¼–è¯‘åŸå§‹å­—ç¬¦ä¸ºæ­£åˆ™è¡¨è¾¾å¼Patternå¯¹è±¡ï¼›æœ€åå¯¹æ•´ä¸ªå­—ç¬¦ä¸²sè¿›è¡Œæ¨¡å¼æœç´¢ï¼Œå¦‚æœæ¨¡å¼åŒ¹é…ï¼Œåˆ™è¿”å›MatchObjectçš„å®ä¾‹ï¼Œå¦‚æœè¯¥å­—ç¬¦ä¸²æ²¡æœ‰æ¨¡å¼åŒ¹é…ï¼Œåˆ™è¿”å›å¼„none</span><br><span class="line">re.search(r&apos;\d&#123;17&#125;[\d|x]|\d&#123;15&#125;&apos;,s)å°†Patternç¼–è¯‘è¿‡ç¨‹ä¸æœç´¢è¿‡ç¨‹åˆäºŒä¸ºä¸€</span><br><span class="line">re.match(pattern,s)ä»å­—ç¬¦ä¸²sçš„èµ·å§‹ä½ç½®åŒ¹é…ä¸€ä¸ªæ¨¡å¼ï¼Œå¦‚æœåŒ¹é…ä¸æˆåŠŸè¿”å›None</span><br><span class="line">re.findall(pattern,s)è¿”å›ä¸€ä¸ªåŒ…å«æ‰€æœ‰æ»¡è¶³æ¡ä»¶çš„å­—ä¸²åˆ—è¡¨</span><br><span class="line">re.sub(pattern,repl,s)ä½¿ç”¨æ›¿æ¢å­—ç¬¦ä¸²replæ›¿æ¢åŒ¹é…åˆ°çš„å­—ç¬¦ä¸²</span><br><span class="line">re.split(pattern,s)åˆ©ç”¨æ»¡è¶³åŒ¹é…æ¨¡å¼çš„å­—ç¬¦ä¸²å°†å­—ç¬¦ä¸²såˆ†éš”å¼€ï¼Œå¹¶è¿”å›ä¸€ä¸ªåˆ—è¡¨</span><br><span class="line"></span><br><span class="line">1.æ­£åˆ™è¡¨è¾¾å¼çš„matchä¸searchåŒºåˆ«</span><br><span class="line">    https://segmentfault.com/a/1190000006736033</span><br><span class="line"></span><br><span class="line">2.è´ªå©ªåŒ¹é…ä¸éè´ªå©ªåŒ¹é…çš„åŒºåˆ«</span><br><span class="line">    https://segmentfault.com/a/1190000002640851</span><br><span class="line">    https://blog.csdn.net/lxcnn/article/details/4756030</span><br><span class="line"></span><br><span class="line">3. ç»ƒä¹ ç½‘ç«™</span><br><span class="line">    https://alf.nu/RegexGolf ä¸€ä¸ªæ­£åˆ™è¡¨è¾¾å¼ç»ƒä¹ ç½‘ç«™</span><br><span class="line">    https://regexr.com/ éªŒè¯ç½‘ç«™</span><br><span class="line"></span><br><span class="line">4. å•å­—ç¬¦åŒ¹é…</span><br><span class="line">    . # åŒ¹é…å‡ºç‚¹æ¢è¡Œç¬¦ä¹‹å¤–çš„ä»»æ„å­—ç¬¦</span><br><span class="line">    \. # åŒ¹é…å•ä¸ª.å­—ç¬¦</span><br><span class="line">    [abd] # åŒ¹é…a/b/då•ä¸ªå­—ç¬¦</span><br><span class="line">    \d # åŒ¹é…æ•°å­—, ç›¸å½“äº[1,2,3,4,5,6,7,8,9]</span><br><span class="line">    \D # æ‰€æœ‰éå­—ç¬¦</span><br><span class="line">    \s # ç©ºç™½ç¬¦,ç©ºæ ¼ tabç­‰ç­‰</span><br><span class="line">    \S # æ‰€æœ‰éç©ºæ ¼</span><br><span class="line">    \w # a-z,A-Z,0-9,_</span><br><span class="line">    \W # é™¤äº† a-z,A-Z,0-9</span><br><span class="line"></span><br><span class="line">5. æ•°é‡è¯ç”¨æ¥å¤šåŒ¹é…</span><br><span class="line">    m&#123;2&#125; # è¡¨ç¤ºåŒ¹é…ä¸¤ä¸ªm</span><br><span class="line">    m&#123;2,4&#125; # è¡¨ç¤ºåŒ¹é…2/3/4ä¸ªm,è´ªå©ªåŒ¹é…</span><br><span class="line">    m* # 0ä¸ªæˆ–è€…æ›´å¤šä¸ª,è´ªå©ªåŒ¹é…</span><br><span class="line">    m+ # 1ä¸ªæˆ–è€…æ›´å¤šä¸ª,è´ªå©ªåŒ¹é…</span><br><span class="line">    m? # 0ä¸ªæˆ–è€…1ä¸ª</span><br><span class="line">    ^xx # æ–‡æœ¬å¼€å¤´æ˜¯xxè¿›è¡ŒåŒ¹é…</span><br><span class="line">    xxx$ # å¯¹ç»“å°¾è¿›è¡ŒåŒ¹é…</span><br><span class="line">    (re)su(lt) # group</span><br><span class="line"></span><br><span class="line">6. pythonä¸­çš„æ­£åˆ™è¡¨è¾¾å¼æ­¥éª¤</span><br><span class="line">    å†™ä¸€ä¸ªæ–‡æœ¬pattern</span><br><span class="line">    è¿›è¡ŒåŒ¹é…</span><br><span class="line">    å¯¹åŒ¹é…çš„æ–‡æœ¬è¿›è¡Œåç»­æ“ä½œ</span><br><span class="line">    ä¾‹å­:</span><br><span class="line">        import re</span><br><span class="line">        pattern = re.compile(r&apos;hello.*\!&apos;) # helloåé¢æœ‰è‹¥å¹²ä¸ªå­—ç¬¦ä¸²ç›´åˆ°æœ‰!</span><br><span class="line">        match = pattern.match(&apos;hello, xxx! how are you?&apos;) # å¯¹æ–‡æœ¬è¿›è¡ŒåŒ¹é…</span><br><span class="line">        if match: # æ˜¯å¦åŒ¹é…</span><br><span class="line">            print match.group() # å¦‚æœåŒ¹é…ä¸Šäº†è¿”å›ç›¸åº”çš„åŒ¹é…åˆ°çš„éƒ¨åˆ†</span><br><span class="line"></span><br><span class="line">7. ä½¿ç”¨å®ä¾‹</span><br><span class="line">    import re</span><br><span class="line">    re.compile(r&quot;&quot;&quot;</span><br><span class="line">    \d+ # æ•°å­—éƒ¨åˆ†</span><br><span class="line">    \. # å°æ•°ç‚¹</span><br><span class="line">    \d # å°æ•°éƒ¨åˆ†</span><br><span class="line">    &quot;&quot;&quot;, re.X)</span><br><span class="line">    è¿™ç§æ¨¡å¼ä¸‹å¯ä»¥å†™æ³¨è§£</span><br><span class="line">    re.compile(r&quot;\d+\.\d&quot;) # ä¸è¿™ä¸ªæ¨¡å¼ç»“æœä¸€æ ·</span><br><span class="line"></span><br><span class="line">8.ä¸€äº›å‘½ä»¤</span><br><span class="line">    match # ä¸€æ¬¡åŒ¹é…ç»“æœ,ä»å¤´åŒ¹é…,å¼€å¤´æ²¡æœ‰å°±åŒ¹é…ä¸ä¸Šäº†</span><br><span class="line">    search # æ‰€æœ‰åŒ¹é…åˆ°çš„</span><br><span class="line">    findall # searchè¿”å›ç¬¬ä¸€ä¸ªåŒ¹é…çš„ç»“æœ,findallä¼šè¿”å›æ‰€æœ‰çš„ç»“æœ</span><br><span class="line">    m=re.match()</span><br><span class="line">    m.string # åŒ¹é…çš„å­—ç¬¦ä¸²</span><br><span class="line">    m.group(1,2) # åŒ¹é…1å’Œ2å¤„å­—ç¬¦ä¸²</span><br><span class="line"></span><br><span class="line">9. æ›¿æ¢å’Œåˆ†å‰²</span><br><span class="line">     splitä¹Ÿå¯ä»¥ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¿›è¡Œåˆ†å‰²</span><br><span class="line">        p = re.compile(r&apos;\d+&apos;)</span><br><span class="line">        p.split(&apos;adwdwad1dawwd23dwadw&apos;) # å­—ç¬¦ä¸²å¤æ‚åˆ†å‰²</span><br><span class="line">    sub # ç”¨æ¥æ›¿æ¢</span><br><span class="line">        p = re.compile(r&apos;(\w+) (\w+)&apos;)</span><br><span class="line">        p.sub(r&apos;\2 \1&apos;, s) # åŒ¹é…å­—ç¬¦ä¸²å¹¶ä¸”åœ¨åŒ¹é…åˆ°çš„å­—ç¬¦ä¸²å¤„è¿›è¡Œå‰åé¢ å€’ </span><br><span class="line">    subn # å’Œsubç±»ä¼¼,åªä¸è¿‡é™¤äº†è¿”å›æ›¿æ¢çš„è¿œè¶³ä¹‹å¤–,è¿˜è¿”å›ç›¸åº”çš„æ›¿æ¢æ¬¡æ•°,å¯ä»¥p.subn(afunc, s), afuncå¯ä»¥è‡ªå·±å®šä¹‰</span><br></pre></td></tr></table></figure><h2 id="æ—¥æœŸå¤„ç†"><a href="#æ—¥æœŸå¤„ç†" class="headerlink" title="æ—¥æœŸå¤„ç†"></a>æ—¥æœŸå¤„ç†</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from datetime import datetimes</span><br><span class="line">format=&quot;%Y-%m-%d %H:%M:%S&quot;æŒ‡å®šæ—¥æœŸæ ¼å¼</span><br><span class="line">date_s=datetime.striptime(s,format)</span><br><span class="line">date_s.year</span><br><span class="line">date_s.month</span><br><span class="line">date_s.now()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pythonæ­£åˆ™è¡¨è¾¾å¼</title>
      <link href="/2019/07/08/python%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
      <url>/2019/07/08/python%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="Pythonæ­£åˆ™è¡¨è¾¾å¼"><a href="#Pythonæ­£åˆ™è¡¨è¾¾å¼" class="headerlink" title="Pythonæ­£åˆ™è¡¨è¾¾å¼"></a>Pythonæ­£åˆ™è¡¨è¾¾å¼</h2><p><strong>by å¯’å°é˜³(<a href="mailto:hanxiaoyang.ml@gmail.com" target="_blank" rel="noopener">hanxiaoyang.ml@gmail.com</a>)</strong></p><p>æ­£åˆ™è¡¨è¾¾å¼æ˜¯<strong>å¤„ç†å­—ç¬¦ä¸²</strong>çš„å¼ºå¤§å·¥å…·ï¼Œæ‹¥æœ‰ç‹¬ç‰¹çš„è¯­æ³•å’Œç‹¬ç«‹çš„å¤„ç†å¼•æ“ã€‚</p><p>æˆ‘ä»¬åœ¨å¤§æ–‡æœ¬ä¸­åŒ¹é…å­—ç¬¦ä¸²æ—¶ï¼Œæœ‰äº›æƒ…å†µç”¨strè‡ªå¸¦çš„å‡½æ•°(æ¯”å¦‚find, in)å¯èƒ½å¯ä»¥å®Œæˆï¼Œæœ‰äº›æƒ…å†µä¼šç¨ç¨å¤æ‚ä¸€äº›(æ¯”å¦‚è¯´æ‰¾å‡ºæ‰€æœ‰â€œåƒé‚®ç®±â€çš„å­—ç¬¦ä¸²ï¼Œæ‰€æœ‰å’Œjulyeduç›¸å…³çš„å¥å­)ï¼Œè¿™ä¸ªæ—¶å€™æˆ‘ä»¬éœ€è¦ä¸€ä¸ªæŸç§æ¨¡å¼çš„å·¥å…·ï¼Œè¿™ä¸ªæ—¶å€™<strong>æ­£åˆ™è¡¨è¾¾å¼</strong>å°±æ´¾ä¸Šç”¨åœºäº†ã€‚</p><p>è¯´èµ·æ¥æ­£åˆ™è¡¨è¾¾å¼æ•ˆç‡ä¸Šå¯èƒ½ä¸å¦‚strè‡ªå¸¦çš„æ–¹æ³•ï¼Œä½†åŒ¹é…åŠŸèƒ½å®åœ¨å¼ºå¤§å¤ªå¤šã€‚å¯¹å•¦ï¼Œæ­£åˆ™è¡¨è¾¾å¼ä¸æ˜¯Pythonç‹¬æœ‰çš„ï¼Œå¦‚æœå·²ç»åœ¨å…¶ä»–è¯­è¨€é‡Œä½¿ç”¨è¿‡æ­£åˆ™è¡¨è¾¾å¼ï¼Œè¿™é‡Œçš„è¯´æ˜åªéœ€è¦ç®€å•çœ‹ä¸€çœ‹å°±å¯ä»¥ä¸Šæ‰‹å•¦ã€‚</p><h2 id="1-è¯­æ³•"><a href="#1-è¯­æ³•" class="headerlink" title="1.è¯­æ³•"></a>1.è¯­æ³•</h2><p>åºŸè¯å°‘è¯´ï¼Œç›´æ¥ä¸ŠæŠ€èƒ½</p><p>ä¸‹é¢æ˜¯ä¸€å¼ æœ‰äº›åŒå­¦æ¯”è¾ƒç†Ÿçš„å›¾ï¼Œæˆ‘ä»¬ä¿—ç§°pythonæ­£åˆ™è¡¨è¾¾å¼å°æŠ„ï¼ŒæŠŠå†™æ­£åˆ™è¡¨è¾¾å¼å½“åšä¸€ä¸ªå¼€å·è€ƒè¯•ï¼Œæ˜¾ç„¶å®¹æ˜“å¾—å¤šã€‚</p><p>å½“ä½ è¦åŒ¹é… <strong>ä¸€ä¸ª/å¤šä¸ª/ä»»æ„ä¸ª æ•°å­—/å­—æ¯/éæ•°å­—/éå­—æ¯/æŸå‡ ä¸ªå­—ç¬¦/ä»»æ„å­—ç¬¦</strong>ï¼Œæƒ³è¦ <strong>è´ªå©ª/éè´ªå©ª</strong> åŒ¹é…ï¼Œæƒ³è¦æ•è·åŒ¹é…å‡ºæ¥çš„ <strong>ç¬¬ä¸€ä¸ª/æ‰€æœ‰</strong> å†…å®¹çš„æ—¶å€™ï¼Œè®°å¾—è¿™é‡Œæœ‰ä¸ªå°æ‰‹å†Œä¾›ä½ å‚è€ƒã€‚</p><p><img src="http://life.chinaunix.net/bbsfile/forum/month_1012/101218124873e7f28d80d99801.jpg" alt="img"></p><h2 id="2-éªŒè¯å·¥å…·"><a href="#2-éªŒè¯å·¥å…·" class="headerlink" title="2.éªŒè¯å·¥å…·"></a>2.éªŒè¯å·¥å…·</h2><p>æˆ‘ä»¬æœ€å–œçˆ±çš„æ­£åˆ™è¡¨è¾¾å¼åœ¨çº¿éªŒè¯å·¥å…·ä¹‹ä¸€æ˜¯<a href="http://regexr.com/" target="_blank" rel="noopener">http://regexr.com/</a></p><p>è°ç”¨è°çŸ¥é“ï¼Œç”¨è¿‡ä¸€æ¬¡ä»¥åæ¬²ç½¢ä¸èƒ½ã€‚</p><p><img src="http://7xo0y8.com1.z0.glb.clouddn.com/regext.png" alt="img"></p><h2 id="3-æŒ‘æˆ˜ä¸æå‡"><a href="#3-æŒ‘æˆ˜ä¸æå‡" class="headerlink" title="3.æŒ‘æˆ˜ä¸æå‡"></a>3.æŒ‘æˆ˜ä¸æå‡</h2><p>é•¿æœŸåšè‡ªç„¶è¯­è¨€å¤„ç†çš„åŒå­¦æ­£åˆ™è¡¨è¾¾å¼éƒ½éå¸¸ç†Ÿï¼Œæ›¾ç»æœ‰åŠå¹´å†™äº†å¤§é‡çš„æ­£åˆ™è¡¨è¾¾å¼ï¼Œä»¥è‡³äºåŒäº‹é—´å¼€ç©ç¬‘è¯´ï¼Œåªè¦æ˜¯ç¬¦åˆæŸç§è§„å¾‹æˆ–è€…æ¨¡å¼çš„ä¸²ï¼Œè‚¯å®šåˆ†åˆ†é’Ÿèƒ½åŒ¹é…å‡ºæ¥ã€‚</p><p>å¯¹äºæƒ³ç»ƒä¹ æ­£åˆ™è¡¨è¾¾å¼ï¼Œæˆ–è€…çŸ­æœŸå†…å¿«é€Ÿgetå¤æ‚æŠ€èƒ½ï¼Œoræƒ³æŒ‘æˆ˜æ›´å¤æ‚çš„æ­£åˆ™è¡¨è¾¾å¼çš„åŒå­¦ä»¬ã€‚ è¯·æˆ³<a href="https://alf.nu/RegexGolf" target="_blank" rel="noopener">æ­£åˆ™è¡¨è¾¾å¼è¿›é˜¶ç»ƒä¹ </a></p><p>so, å„ä½å®å®enjoy yourself</p><p><img src="http://7xo0y8.com1.z0.glb.clouddn.com/regext_2.png" alt="img"></p><h2 id="4-Pythonæ¡ˆä¾‹"><a href="#4-Pythonæ¡ˆä¾‹" class="headerlink" title="4.Pythonæ¡ˆä¾‹"></a>4.Pythonæ¡ˆä¾‹</h2><h3 id="reæ¨¡å—"><a href="#reæ¨¡å—" class="headerlink" title="reæ¨¡å—"></a>reæ¨¡å—</h3><p>Pythoné€šè¿‡reæ¨¡å—æä¾›å¯¹æ­£åˆ™è¡¨è¾¾å¼çš„æ”¯æŒã€‚</p><p>ä½¿ç”¨reçš„ä¸€èˆ¬æ­¥éª¤æ˜¯</p><ul><li>1.å°†æ­£åˆ™è¡¨è¾¾å¼çš„å­—ç¬¦ä¸²å½¢å¼ç¼–è¯‘ä¸ºPatternå®ä¾‹</li><li>2.ä½¿ç”¨Patternå®ä¾‹å¤„ç†æ–‡æœ¬å¹¶è·å¾—åŒ¹é…ç»“æœï¼ˆä¸€ä¸ªMatchå®ä¾‹ï¼‰</li><li>3.ä½¿ç”¨Matchå®ä¾‹è·å¾—ä¿¡æ¯ï¼Œè¿›è¡Œå…¶ä»–çš„æ“ä½œã€‚</li></ul><p>In [13]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># encoding: UTF-8</span><br><span class="line">import re</span><br><span class="line"> </span><br><span class="line"># å°†æ­£åˆ™è¡¨è¾¾å¼ç¼–è¯‘æˆPatternå¯¹è±¡</span><br><span class="line">pattern = re.compile(r&apos;hello.*\!&apos;)</span><br><span class="line"> </span><br><span class="line"># ä½¿ç”¨PatternåŒ¹é…æ–‡æœ¬ï¼Œè·å¾—åŒ¹é…ç»“æœï¼Œæ— æ³•åŒ¹é…æ—¶å°†è¿”å›None</span><br><span class="line">match = pattern.match(&apos;hello, hanxiaoyang! How are you?&apos;)</span><br><span class="line"> </span><br><span class="line">if match:</span><br><span class="line">    # ä½¿ç”¨Matchè·å¾—åˆ†ç»„ä¿¡æ¯</span><br><span class="line">    print match.group()</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hello, hanxiaoyang!</span><br></pre></td></tr></table></figure><h4 id="re-compile-strPattern-flag"><a href="#re-compile-strPattern-flag" class="headerlink" title="re.compile(strPattern[, flag]):"></a>re.compile(strPattern[, flag]):</h4><p>è¿™ä¸ªæ–¹æ³•æ˜¯Patternç±»çš„å·¥å‚æ–¹æ³•ï¼Œç”¨äºå°†å­—ç¬¦ä¸²å½¢å¼çš„æ­£åˆ™è¡¨è¾¾å¼ç¼–è¯‘ä¸ºPatternå¯¹è±¡ã€‚</p><p>ç¬¬äºŒä¸ªå‚æ•°flagæ˜¯åŒ¹é…æ¨¡å¼ï¼Œå–å€¼å¯ä»¥ä½¿ç”¨æŒ‰ä½æˆ–è¿ç®—ç¬¦â€™|â€™è¡¨ç¤ºåŒæ—¶ç”Ÿæ•ˆï¼Œæ¯”å¦‚re.I | re.Mã€‚</p><p>å½“ç„¶ï¼Œä½ ä¹Ÿå¯ä»¥åœ¨regexå­—ç¬¦ä¸²ä¸­æŒ‡å®šæ¨¡å¼ï¼Œæ¯”å¦‚<strong>re.compile(â€˜patternâ€™, re.I | re.M)</strong>ç­‰ä»·äº<strong>re.compile(â€˜(?im)patternâ€™)</strong></p><p>flagå¯é€‰å€¼æœ‰ï¼š</p><ul><li>re.I(re.IGNORECASE): å¿½ç•¥å¤§å°å†™ï¼ˆæ‹¬å·å†…æ˜¯å®Œæ•´å†™æ³•ï¼Œä¸‹åŒï¼‰</li><li>re.M(MULTILINE): å¤šè¡Œæ¨¡å¼ï¼Œæ”¹å˜â€™^â€™å’Œâ€™$â€™çš„è¡Œä¸ºï¼ˆå‚è§ä¸Šå›¾ï¼‰</li><li>re.S(DOTALL): ç‚¹ä»»æ„åŒ¹é…æ¨¡å¼ï¼Œæ”¹å˜â€™.â€™çš„è¡Œä¸º</li><li>re.L(LOCALE): ä½¿é¢„å®šå­—ç¬¦ç±» \w \W \b \B \s \S å–å†³äºå½“å‰åŒºåŸŸè®¾å®š</li><li>re.U(UNICODE): ä½¿é¢„å®šå­—ç¬¦ç±» \w \W \b \B \s \S \d \D å–å†³äºunicodeå®šä¹‰çš„å­—ç¬¦å±æ€§</li><li>re.X(VERBOSE): è¯¦ç»†æ¨¡å¼ã€‚è¿™ä¸ªæ¨¡å¼ä¸‹æ­£åˆ™è¡¨è¾¾å¼å¯ä»¥æ˜¯å¤šè¡Œï¼Œå¿½ç•¥ç©ºç™½å­—ç¬¦ï¼Œå¹¶å¯ä»¥åŠ å…¥æ³¨é‡Šã€‚ä»¥ä¸‹ä¸¤ä¸ªæ­£åˆ™è¡¨è¾¾å¼æ˜¯ç­‰ä»·çš„ï¼š</li></ul><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">regex_1 = re.compile(r&quot;&quot;&quot;\d +  # æ•°å­—éƒ¨åˆ†</span><br><span class="line">                         \.    # å°æ•°ç‚¹éƒ¨åˆ†</span><br><span class="line">                         \d *  # å°æ•°çš„æ•°å­—éƒ¨åˆ†&quot;&quot;&quot;, re.X)</span><br><span class="line">regex_2 = re.compile(r&quot;\d+\.\d*&quot;)</span><br></pre></td></tr></table></figure><h3 id="Match"><a href="#Match" class="headerlink" title="Match"></a>Match</h3><p>Matchå¯¹è±¡æ˜¯ä¸€æ¬¡åŒ¹é…çš„ç»“æœï¼ŒåŒ…å«äº†å¾ˆå¤šå…³äºæ­¤æ¬¡åŒ¹é…çš„ä¿¡æ¯ï¼Œå¯ä»¥ä½¿ç”¨Matchæä¾›çš„å¯è¯»å±æ€§æˆ–æ–¹æ³•æ¥è·å–è¿™äº›ä¿¡æ¯ã€‚</p><h4 id="matchå±æ€§ï¼š"><a href="#matchå±æ€§ï¼š" class="headerlink" title="matchå±æ€§ï¼š"></a>matchå±æ€§ï¼š</h4><ul><li>string: åŒ¹é…æ—¶ä½¿ç”¨çš„æ–‡æœ¬ã€‚</li><li>re: åŒ¹é…æ—¶ä½¿ç”¨çš„Patternå¯¹è±¡ã€‚</li><li>pos: æ–‡æœ¬ä¸­æ­£åˆ™è¡¨è¾¾å¼å¼€å§‹æœç´¢çš„ç´¢å¼•ã€‚å€¼ä¸Pattern.match()å’ŒPattern.seach()æ–¹æ³•çš„åŒåå‚æ•°ç›¸åŒã€‚</li><li>endpos: æ–‡æœ¬ä¸­æ­£åˆ™è¡¨è¾¾å¼ç»“æŸæœç´¢çš„ç´¢å¼•ã€‚å€¼ä¸Pattern.match()å’ŒPattern.seach()æ–¹æ³•çš„åŒåå‚æ•°ç›¸åŒã€‚</li><li>lastindex: æœ€åä¸€ä¸ªè¢«æ•è·çš„åˆ†ç»„åœ¨æ–‡æœ¬ä¸­çš„ç´¢å¼•ã€‚å¦‚æœæ²¡æœ‰è¢«æ•è·çš„åˆ†ç»„ï¼Œå°†ä¸ºNoneã€‚</li><li>lastgroup: æœ€åä¸€ä¸ªè¢«æ•è·çš„åˆ†ç»„çš„åˆ«åã€‚å¦‚æœè¿™ä¸ªåˆ†ç»„æ²¡æœ‰åˆ«åæˆ–è€…æ²¡æœ‰è¢«æ•è·çš„åˆ†ç»„ï¼Œå°†ä¸ºNoneã€‚</li></ul><h4 id="æ–¹æ³•ï¼š"><a href="#æ–¹æ³•ï¼š" class="headerlink" title="æ–¹æ³•ï¼š"></a>æ–¹æ³•ï¼š</h4><ul><li>group([group1, â€¦]):<br>è·å¾—ä¸€ä¸ªæˆ–å¤šä¸ªåˆ†ç»„æˆªè·çš„å­—ç¬¦ä¸²ï¼›æŒ‡å®šå¤šä¸ªå‚æ•°æ—¶å°†ä»¥å…ƒç»„å½¢å¼è¿”å›ã€‚group1å¯ä»¥ä½¿ç”¨ç¼–å·ä¹Ÿå¯ä»¥ä½¿ç”¨åˆ«åï¼›ç¼–å·0ä»£è¡¨æ•´ä¸ªåŒ¹é…çš„å­ä¸²ï¼›ä¸å¡«å†™å‚æ•°æ—¶ï¼Œè¿”å›group(0)ï¼›æ²¡æœ‰æˆªè·å­—ç¬¦ä¸²çš„ç»„è¿”å›Noneï¼›æˆªè·äº†å¤šæ¬¡çš„ç»„è¿”å›æœ€åä¸€æ¬¡æˆªè·çš„å­ä¸²ã€‚</li><li>groups([default]):<br>ä»¥å…ƒç»„å½¢å¼è¿”å›å…¨éƒ¨åˆ†ç»„æˆªè·çš„å­—ç¬¦ä¸²ã€‚ç›¸å½“äºè°ƒç”¨group(1,2,â€¦last)ã€‚defaultè¡¨ç¤ºæ²¡æœ‰æˆªè·å­—ç¬¦ä¸²çš„ç»„ä»¥è¿™ä¸ªå€¼æ›¿ä»£ï¼Œé»˜è®¤ä¸ºNoneã€‚</li><li>groupdict([default]):<br>è¿”å›ä»¥æœ‰åˆ«åçš„ç»„çš„åˆ«åä¸ºé”®ã€ä»¥è¯¥ç»„æˆªè·çš„å­ä¸²ä¸ºå€¼çš„å­—å…¸ï¼Œæ²¡æœ‰åˆ«åçš„ç»„ä¸åŒ…å«åœ¨å†…ã€‚defaultå«ä¹‰åŒä¸Šã€‚</li><li>start([group]):<br>è¿”å›æŒ‡å®šçš„ç»„æˆªè·çš„å­ä¸²åœ¨stringä¸­çš„èµ·å§‹ç´¢å¼•ï¼ˆå­ä¸²ç¬¬ä¸€ä¸ªå­—ç¬¦çš„ç´¢å¼•ï¼‰ã€‚groupé»˜è®¤å€¼ä¸º0ã€‚</li><li>end([group]):<br>è¿”å›æŒ‡å®šçš„ç»„æˆªè·çš„å­ä¸²åœ¨stringä¸­çš„ç»“æŸç´¢å¼•ï¼ˆå­ä¸²æœ€åä¸€ä¸ªå­—ç¬¦çš„ç´¢å¼•+1ï¼‰ã€‚groupé»˜è®¤å€¼ä¸º0ã€‚</li><li>span([group]):<br>è¿”å›(start(group), end(group))ã€‚</li><li>expand(template):<br>å°†åŒ¹é…åˆ°çš„åˆ†ç»„ä»£å…¥templateä¸­ç„¶åè¿”å›ã€‚templateä¸­å¯ä»¥ä½¿ç”¨\idæˆ–\gã€\gå¼•ç”¨åˆ†ç»„ï¼Œä½†ä¸èƒ½ä½¿ç”¨ç¼–å·0ã€‚\idä¸\gæ˜¯ç­‰ä»·çš„ï¼›ä½†\10å°†è¢«è®¤ä¸ºæ˜¯ç¬¬10ä¸ªåˆ†ç»„ï¼Œå¦‚æœä½ æƒ³è¡¨è¾¾\1ä¹‹åæ˜¯å­—ç¬¦â€™0â€™ï¼Œåªèƒ½ä½¿ç”¨\g&lt;1&gt;0ã€‚</li></ul><p>In [14]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line">m = re.match(r&apos;(\w+) (\w+)(?P&lt;sign&gt;.*)&apos;, &apos;hello hanxiaoyang!&apos;)</span><br><span class="line"> </span><br><span class="line">print &quot;m.string:&quot;, m.string</span><br><span class="line">print &quot;m.re:&quot;, m.re</span><br><span class="line">print &quot;m.pos:&quot;, m.pos</span><br><span class="line">print &quot;m.endpos:&quot;, m.endpos</span><br><span class="line">print &quot;m.lastindex:&quot;, m.lastindex</span><br><span class="line">print &quot;m.lastgroup:&quot;, m.lastgroup</span><br><span class="line"> </span><br><span class="line">print &quot;m.group(1,2):&quot;, m.group(1, 2)</span><br><span class="line">print &quot;m.groups():&quot;, m.groups()</span><br><span class="line">print &quot;m.groupdict():&quot;, m.groupdict()</span><br><span class="line">print &quot;m.start(2):&quot;, m.start(2)</span><br><span class="line">print &quot;m.end(2):&quot;, m.end(2)</span><br><span class="line">print &quot;m.span(2):&quot;, m.span(2)</span><br><span class="line">print r&quot;m.expand(r&apos;\2 \1\3&apos;):&quot;, m.expand(r&apos;\2 \1\3&apos;)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">m.string: hello hanxiaoyang!</span><br><span class="line">m.re: &lt;_sre.SRE_Pattern object at 0x10b111be0&gt;</span><br><span class="line">m.pos: 0</span><br><span class="line">m.endpos: 18</span><br><span class="line">m.lastindex: 3</span><br><span class="line">m.lastgroup: sign</span><br><span class="line">m.group(1,2): (&apos;hello&apos;, &apos;hanxiaoyang&apos;)</span><br><span class="line">m.groups(): (&apos;hello&apos;, &apos;hanxiaoyang&apos;, &apos;!&apos;)</span><br><span class="line">m.groupdict(): &#123;&apos;sign&apos;: &apos;!&apos;&#125;</span><br><span class="line">m.start(2): 6</span><br><span class="line">m.end(2): 17</span><br><span class="line">m.span(2): (6, 17)</span><br><span class="line">m.expand(r&apos;\2 \1\3&apos;): hanxiaoyang hello!</span><br></pre></td></tr></table></figure><h3 id="Pattern"><a href="#Pattern" class="headerlink" title="Pattern"></a>Pattern</h3><p>Patternå¯¹è±¡æ˜¯ä¸€ä¸ªç¼–è¯‘å¥½çš„æ­£åˆ™è¡¨è¾¾å¼ï¼Œé€šè¿‡Patternæä¾›çš„ä¸€ç³»åˆ—æ–¹æ³•å¯ä»¥å¯¹æ–‡æœ¬è¿›è¡ŒåŒ¹é…æŸ¥æ‰¾ã€‚</p><p>Patternä¸èƒ½ç›´æ¥å®ä¾‹åŒ–ï¼Œå¿…é¡»ä½¿ç”¨re.compile()è¿›è¡Œæ„é€ ã€‚</p><p>Patternæä¾›äº†å‡ ä¸ªå¯è¯»å±æ€§ç”¨äºè·å–è¡¨è¾¾å¼çš„ç›¸å…³ä¿¡æ¯ï¼š</p><ul><li>pattern: ç¼–è¯‘æ—¶ç”¨çš„è¡¨è¾¾å¼å­—ç¬¦ä¸²ã€‚</li><li>flags: ç¼–è¯‘æ—¶ç”¨çš„åŒ¹é…æ¨¡å¼ã€‚æ•°å­—å½¢å¼ã€‚</li><li>groups: è¡¨è¾¾å¼ä¸­åˆ†ç»„çš„æ•°é‡ã€‚</li><li>groupindex: ä»¥è¡¨è¾¾å¼ä¸­æœ‰åˆ«åçš„ç»„çš„åˆ«åä¸ºé”®ã€ä»¥è¯¥ç»„å¯¹åº”çš„ç¼–å·ä¸ºå€¼çš„å­—å…¸ï¼Œæ²¡æœ‰åˆ«åçš„ç»„ä¸åŒ…å«åœ¨å†…ã€‚</li></ul><p>In [15]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line">p = re.compile(r&apos;(\w+) (\w+)(?P&lt;sign&gt;.*)&apos;, re.DOTALL)</span><br><span class="line"> </span><br><span class="line">print &quot;p.pattern:&quot;, p.pattern</span><br><span class="line">print &quot;p.flags:&quot;, p.flags</span><br><span class="line">print &quot;p.groups:&quot;, p.groups</span><br><span class="line">print &quot;p.groupindex:&quot;, p.groupindex</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">p.pattern: (\w+) (\w+)(?P&lt;sign&gt;.*)</span><br><span class="line">p.flags: 16</span><br><span class="line">p.groups: 3</span><br><span class="line">p.groupindex: &#123;&apos;sign&apos;: 3&#125;</span><br></pre></td></tr></table></figure><h3 id="ä½¿ç”¨pattern"><a href="#ä½¿ç”¨pattern" class="headerlink" title="ä½¿ç”¨pattern"></a>ä½¿ç”¨pattern</h3><ul><li><p>match(string[, pos[, endpos]]) | re.match(pattern, string[, flags])</p><p>:</p></li></ul><p>  è¿™ä¸ªæ–¹æ³•å°†ä»stringçš„posä¸‹æ ‡å¤„èµ·å°è¯•åŒ¹é…pattern</p><p>  :</p><ul><li>å¦‚æœpatternç»“æŸæ—¶ä»å¯åŒ¹é…ï¼Œåˆ™è¿”å›ä¸€ä¸ªMatchå¯¹è±¡</li><li>å¦‚æœåŒ¹é…è¿‡ç¨‹ä¸­patternæ— æ³•åŒ¹é…ï¼Œæˆ–è€…åŒ¹é…æœªç»“æŸå°±å·²åˆ°è¾¾endposï¼Œåˆ™è¿”å›Noneã€‚ </li><li>poså’Œendposçš„é»˜è®¤å€¼åˆ†åˆ«ä¸º0å’Œlen(string)ã€‚<br><strong>æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•å¹¶ä¸æ˜¯å®Œå…¨åŒ¹é…ã€‚å½“patternç»“æŸæ—¶è‹¥stringè¿˜æœ‰å‰©ä½™å­—ç¬¦ï¼Œä»ç„¶è§†ä¸ºæˆåŠŸã€‚æƒ³è¦å®Œå…¨åŒ¹é…ï¼Œå¯ä»¥åœ¨è¡¨è¾¾å¼æœ«å°¾åŠ ä¸Šè¾¹ç•ŒåŒ¹é…ç¬¦â€™$â€™ã€‚</strong> </li></ul><ul><li><p>search(string[, pos[, endpos]]) | re.search(pattern, string[, flags])</p><p>:</p></li></ul><p>  è¿™ä¸ªæ–¹æ³•ä»stringçš„posä¸‹æ ‡å¤„èµ·å°è¯•åŒ¹é…pattern</p><ul><li>å¦‚æœpatternç»“æŸæ—¶ä»å¯åŒ¹é…ï¼Œåˆ™è¿”å›ä¸€ä¸ªMatchå¯¹è±¡</li><li>è‹¥æ— æ³•åŒ¹é…ï¼Œåˆ™å°†posåŠ 1åé‡æ–°å°è¯•åŒ¹é…ï¼Œç›´åˆ°pos=endposæ—¶ä»æ— æ³•åŒ¹é…åˆ™è¿”å›Noneã€‚ </li><li>poså’Œendposçš„é»˜è®¤å€¼åˆ†åˆ«ä¸º0å’Œlen(string))</li></ul><p>In [18]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># encoding: UTF-8 </span><br><span class="line">import re </span><br><span class="line"> </span><br><span class="line"># å°†æ­£åˆ™è¡¨è¾¾å¼ç¼–è¯‘æˆPatternå¯¹è±¡ </span><br><span class="line">pattern = re.compile(r&apos;H.*g&apos;) </span><br><span class="line"> </span><br><span class="line"># ä½¿ç”¨search()æŸ¥æ‰¾åŒ¹é…çš„å­ä¸²ï¼Œä¸å­˜åœ¨èƒ½åŒ¹é…çš„å­ä¸²æ—¶å°†è¿”å›None </span><br><span class="line"># è¿™ä¸ªä¾‹å­ä¸­ä½¿ç”¨match()æ— æ³•æˆåŠŸåŒ¹é… </span><br><span class="line">match = pattern.search(&apos;hello Hanxiaoyang!&apos;) </span><br><span class="line"> </span><br><span class="line">if match: </span><br><span class="line">    # ä½¿ç”¨Matchè·å¾—åˆ†ç»„ä¿¡æ¯ </span><br><span class="line">    print match.group()</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Hanxiaoyang</span><br></pre></td></tr></table></figure><ul><li>split(string[, maxsplit]) | re.split(pattern, string[, maxsplit]):<ul><li>æŒ‰ç…§èƒ½å¤ŸåŒ¹é…çš„å­ä¸²å°†stringåˆ†å‰²åè¿”å›åˆ—è¡¨ã€‚</li><li>maxsplitç”¨äºæŒ‡å®šæœ€å¤§åˆ†å‰²æ¬¡æ•°ï¼Œä¸æŒ‡å®šå°†å…¨éƒ¨åˆ†å‰²ã€‚ </li></ul></li></ul><p>In [19]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line"> </span><br><span class="line">p = re.compile(r&apos;\d+&apos;)</span><br><span class="line">print p.split(&apos;one1two2three3four4&apos;)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&apos;one&apos;, &apos;two&apos;, &apos;three&apos;, &apos;four&apos;, &apos;&apos;]</span><br></pre></td></tr></table></figure><ul><li><p>findall(string[, pos[, endpos]]) | re.findall(pattern, string[, flags])</p><p>:</p></li></ul><ul><li>æœç´¢stringï¼Œä»¥åˆ—è¡¨å½¢å¼è¿”å›å…¨éƒ¨èƒ½åŒ¹é…çš„å­ä¸²ã€‚</li></ul><p>In [21]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line"> </span><br><span class="line">p = re.compile(r&apos;\d+&apos;)</span><br><span class="line">print p.findall(&apos;one1two2three3four4&apos;)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&apos;1&apos;, &apos;2&apos;, &apos;3&apos;, &apos;4&apos;]</span><br></pre></td></tr></table></figure><ul><li>finditer(string[, pos[, endpos]]) | re.finditer(pattern, string[, flags]): <ul><li>æœç´¢stringï¼Œè¿”å›ä¸€ä¸ªé¡ºåºè®¿é—®æ¯ä¸€ä¸ªåŒ¹é…ç»“æœï¼ˆMatchå¯¹è±¡ï¼‰çš„è¿­ä»£å™¨ã€‚ </li></ul></li></ul><p>In [23]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line"> </span><br><span class="line">p = re.compile(r&apos;\d+&apos;)</span><br><span class="line">for m in p.finditer(&apos;one1two2three3four4&apos;):</span><br><span class="line">    print m.group()</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td></tr></table></figure><ul><li><p>sub(repl, string[, count]) | re.sub(pattern, repl, string[, count]): </p><ul><li>ä½¿ç”¨replæ›¿æ¢stringä¸­æ¯ä¸€ä¸ªåŒ¹é…çš„å­ä¸²åè¿”å›æ›¿æ¢åçš„å­—ç¬¦ä¸²ã€‚</li></ul></li></ul><pre><code>- å½“replæ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²æ—¶ï¼Œå¯ä»¥ä½¿ç”¨\idæˆ–\gã€\gå¼•ç”¨åˆ†ç»„ï¼Œä½†ä¸èƒ½ä½¿ç”¨ç¼–å·0ã€‚ - å½“replæ˜¯ä¸€ä¸ªæ–¹æ³•æ—¶ï¼Œè¿™ä¸ªæ–¹æ³•åº”å½“åªæ¥å—ä¸€ä¸ªå‚æ•°ï¼ˆMatchå¯¹è±¡ï¼‰ï¼Œå¹¶è¿”å›ä¸€ä¸ªå­—ç¬¦ä¸²ç”¨äºæ›¿æ¢ï¼ˆè¿”å›çš„å­—ç¬¦ä¸²ä¸­ä¸èƒ½å†å¼•ç”¨åˆ†ç»„ï¼‰ã€‚ countç”¨äºæŒ‡å®šæœ€å¤šæ›¿æ¢æ¬¡æ•°ï¼Œä¸æŒ‡å®šæ—¶å…¨éƒ¨æ›¿æ¢ã€‚</code></pre><p>In [26]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line"> </span><br><span class="line">p = re.compile(r&apos;(\w+) (\w+)&apos;)</span><br><span class="line">s = &apos;i say, hello hanxiaoyang!&apos;</span><br><span class="line"> </span><br><span class="line">print p.sub(r&apos;\2 \1&apos;, s)</span><br><span class="line"> </span><br><span class="line">def func(m):</span><br><span class="line">    return m.group(1).title() + &apos; &apos; + m.group(2).title()</span><br><span class="line"> </span><br><span class="line">print p.sub(func, s)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">say i, hanxiaoyang hello!</span><br><span class="line">I Say, Hello Hanxiaoyang!</span><br></pre></td></tr></table></figure><ul><li>subn(repl, string[, count]) |re.sub(pattern, repl, string[, count]): <ul><li>è¿”å› (sub(repl, string[, count]), æ›¿æ¢æ¬¡æ•°)ã€‚</li></ul></li></ul><p>In [28]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line"> </span><br><span class="line">p = re.compile(r&apos;(\w+) (\w+)&apos;)</span><br><span class="line">s = &apos;i say, hello hanxiaoyang!&apos;</span><br><span class="line"> </span><br><span class="line">print p.subn(r&apos;\2 \1&apos;, s)</span><br><span class="line"> </span><br><span class="line">def func(m):</span><br><span class="line">    return m.group(1).title() + &apos; &apos; + m.group(2).title()</span><br><span class="line"> </span><br><span class="line">print p.subn(func, s)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(&apos;say i, hanxiaoyang hello!&apos;, 2)</span><br><span class="line">(&apos;I Say, Hello Hanxiaoyang!&apos;, 2)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ­£åˆ™è¡¨è¾¾å¼ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>jiebaä¸­æ–‡å¤„ç†</title>
      <link href="/2019/06/08/jieba%E4%B8%AD%E6%96%87%E5%A4%84%E7%90%86/"/>
      <url>/2019/06/08/jieba%E4%B8%AD%E6%96%87%E5%A4%84%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h2 id="jiebaä¸­æ–‡å¤„ç†"><a href="#jiebaä¸­æ–‡å¤„ç†" class="headerlink" title="jiebaä¸­æ–‡å¤„ç†"></a>jiebaä¸­æ–‡å¤„ç†</h2><p>å’Œæ‹‰ä¸è¯­ç³»ä¸åŒï¼Œäºšæ´²è¯­è¨€æ˜¯ä¸ç”¨ç©ºæ ¼åˆ†å¼€æ¯ä¸ªæœ‰æ„ä¹‰çš„è¯çš„ã€‚è€Œå½“æˆ‘ä»¬è¿›è¡Œè‡ªç„¶è¯­è¨€å¤„ç†çš„æ—¶å€™ï¼Œå¤§éƒ¨åˆ†æƒ…å†µä¸‹ï¼Œè¯æ±‡æ˜¯æˆ‘ä»¬å¯¹å¥å­å’Œæ–‡ç« ç†è§£çš„åŸºç¡€ï¼Œå› æ­¤éœ€è¦ä¸€ä¸ªå·¥å…·å»æŠŠå®Œæ•´çš„æ–‡æœ¬ä¸­åˆ†è§£æˆç²’åº¦æ›´ç»†çš„è¯ã€‚</p><p>jiebaå°±æ˜¯è¿™æ ·ä¸€ä¸ªéå¸¸å¥½ç”¨çš„ä¸­æ–‡å·¥å…·ï¼Œæ˜¯ä»¥åˆ†è¯èµ·å®¶çš„ï¼Œä½†æ˜¯åŠŸèƒ½æ¯”åˆ†è¯è¦å¼ºå¤§å¾ˆå¤šã€‚</p><h3 id="1-åŸºæœ¬åˆ†è¯å‡½æ•°ä¸ç”¨æ³•"><a href="#1-åŸºæœ¬åˆ†è¯å‡½æ•°ä¸ç”¨æ³•" class="headerlink" title="1.åŸºæœ¬åˆ†è¯å‡½æ•°ä¸ç”¨æ³•"></a>1.åŸºæœ¬åˆ†è¯å‡½æ•°ä¸ç”¨æ³•</h3><p>jieba.cut ä»¥åŠ jieba.cut_for_search è¿”å›çš„ç»“æ„éƒ½æ˜¯ä¸€ä¸ªå¯è¿­ä»£çš„ generatorï¼Œå¯ä»¥ä½¿ç”¨ for å¾ªç¯æ¥è·å¾—åˆ†è¯åå¾—åˆ°çš„æ¯ä¸€ä¸ªè¯è¯­(unicode)</p><p><strong>jieba.cut</strong> æ–¹æ³•æ¥å—ä¸‰ä¸ªè¾“å…¥å‚æ•°:</p><ul><li>éœ€è¦åˆ†è¯çš„å­—ç¬¦ä¸²</li><li>cut_all å‚æ•°ç”¨æ¥æ§åˆ¶æ˜¯å¦é‡‡ç”¨å…¨æ¨¡å¼</li><li>HMM å‚æ•°ç”¨æ¥æ§åˆ¶æ˜¯å¦ä½¿ç”¨ HMM æ¨¡å‹</li></ul><p><strong>jieba.cut_for_search</strong> æ–¹æ³•æ¥å—ä¸¤ä¸ªå‚æ•°</p><ul><li>éœ€è¦åˆ†è¯çš„å­—ç¬¦ä¸²</li><li>æ˜¯å¦ä½¿ç”¨ HMM æ¨¡å‹ã€‚</li></ul><p>è¯¥æ–¹æ³•é€‚åˆç”¨äºæœç´¢å¼•æ“æ„å»ºå€’æ’ç´¢å¼•çš„åˆ†è¯ï¼Œç²’åº¦æ¯”è¾ƒç»†</p><p>In [1]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># encoding=utf-8</span></span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line">seg_list = jieba.cut(<span class="string">"æˆ‘åœ¨å­¦ä¹ è‡ªç„¶è¯­è¨€å¤„ç†"</span>, cut_all=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">print</span> seg_list</span><br><span class="line">print(<span class="string">"Full Mode: "</span> + <span class="string">"/ "</span>.join(seg_list))  <span class="comment"># å…¨æ¨¡å¼</span></span><br><span class="line"></span><br><span class="line">seg_list = jieba.cut(<span class="string">"æˆ‘åœ¨å­¦ä¹ è‡ªç„¶è¯­è¨€å¤„ç†"</span>, cut_all=<span class="literal">False</span>)</span><br><span class="line">print(<span class="string">"Default Mode: "</span> + <span class="string">"/ "</span>.join(seg_list))  <span class="comment"># ç²¾ç¡®æ¨¡å¼</span></span><br><span class="line"></span><br><span class="line">seg_list = jieba.cut(<span class="string">"ä»–æ¯•ä¸šäºä¸Šæµ·äº¤é€šå¤§å­¦ï¼Œåœ¨ç™¾åº¦æ·±åº¦å­¦ä¹ ç ”ç©¶é™¢è¿›è¡Œç ”ç©¶"</span>)  <span class="comment"># é»˜è®¤æ˜¯ç²¾ç¡®æ¨¡å¼</span></span><br><span class="line">print(<span class="string">", "</span>.join(seg_list))</span><br><span class="line"></span><br><span class="line">seg_list = jieba.cut_for_search(<span class="string">"å°æ˜ç¡•å£«æ¯•ä¸šäºä¸­å›½ç§‘å­¦é™¢è®¡ç®—æ‰€ï¼Œååœ¨å“ˆä½›å¤§å­¦æ·±é€ "</span>)  <span class="comment"># æœç´¢å¼•æ“æ¨¡å¼</span></span><br><span class="line">print(<span class="string">", "</span>.join(seg_list))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Building prefix dict from the default dictionary ...</span><br><span class="line">Loading model from cache /var/folders/pn/xp31896922n9rqxgftrqk3l00000gn/T/jieba.cache</span><br><span class="line">Loading model cost 0.496 seconds.</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;generator object cut at 0x10bbd91e0&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Prefix dict has been built succesfully.</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Full Mode: æˆ‘/ åœ¨/ å­¦ä¹ / è‡ªç„¶/ è‡ªç„¶è¯­è¨€/ è¯­è¨€/ å¤„ç†</span><br><span class="line">Default Mode: æˆ‘/ åœ¨/ å­¦ä¹ / è‡ªç„¶è¯­è¨€/ å¤„ç†</span><br><span class="line">ä»–, æ¯•ä¸š, äº, ä¸Šæµ·äº¤é€šå¤§å­¦, ï¼Œ, åœ¨, ç™¾åº¦, æ·±åº¦, å­¦ä¹ , ç ”ç©¶é™¢, è¿›è¡Œ, ç ”ç©¶</span><br><span class="line">å°æ˜, ç¡•å£«, æ¯•ä¸š, äº, ä¸­å›½, ç§‘å­¦, å­¦é™¢, ç§‘å­¦é™¢, ä¸­å›½ç§‘å­¦é™¢, è®¡ç®—, è®¡ç®—æ‰€, ï¼Œ, å, åœ¨, å“ˆä½›, å¤§å­¦, å“ˆä½›å¤§å­¦, æ·±é€ </span><br></pre></td></tr></table></figure><p><strong>jieba.lcut</strong>ä»¥åŠ<strong>jieba.lcut_for_search</strong>ç›´æ¥è¿”å› list</p><p>In [2]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">result_lcut = jieba.lcut(<span class="string">"å°æ˜ç¡•å£«æ¯•ä¸šäºä¸­å›½ç§‘å­¦é™¢è®¡ç®—æ‰€ï¼Œååœ¨å“ˆä½›å¤§å­¦æ·±é€ "</span>)</span><br><span class="line"><span class="keyword">print</span> result_lcut</span><br><span class="line"><span class="keyword">print</span> <span class="string">" "</span>.join(result_lcut)</span><br><span class="line"><span class="keyword">print</span> <span class="string">" "</span>.join(jieba.lcut_for_search(<span class="string">"å°æ˜ç¡•å£«æ¯•ä¸šäºä¸­å›½ç§‘å­¦é™¢è®¡ç®—æ‰€ï¼Œååœ¨å“ˆä½›å¤§å­¦æ·±é€ "</span>))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">u'\u5c0f\u660e'</span>, <span class="string">u'\u7855\u58eb'</span>, <span class="string">u'\u6bd5\u4e1a'</span>, <span class="string">u'\u4e8e'</span>, <span class="string">u'\u4e2d\u56fd\u79d1\u5b66\u9662'</span>, <span class="string">u'\u8ba1\u7b97\u6240'</span>, <span class="string">u'\uff0c'</span>, <span class="string">u'\u540e'</span>, <span class="string">u'\u5728'</span>, <span class="string">u'\u54c8\u4f5b\u5927\u5b66'</span>, <span class="string">u'\u6df1\u9020'</span>]</span><br><span class="line">å°æ˜ ç¡•å£« æ¯•ä¸š äº ä¸­å›½ç§‘å­¦é™¢ è®¡ç®—æ‰€ ï¼Œ å åœ¨ å“ˆä½›å¤§å­¦ æ·±é€ </span><br><span class="line">å°æ˜ ç¡•å£« æ¯•ä¸š äº ä¸­å›½ ç§‘å­¦ å­¦é™¢ ç§‘å­¦é™¢ ä¸­å›½ç§‘å­¦é™¢ è®¡ç®— è®¡ç®—æ‰€ ï¼Œ å åœ¨ å“ˆä½› å¤§å­¦ å“ˆä½›å¤§å­¦ æ·±é€ </span><br></pre></td></tr></table></figure><h4 id="æ·»åŠ ç”¨æˆ·è‡ªå®šä¹‰è¯å…¸"><a href="#æ·»åŠ ç”¨æˆ·è‡ªå®šä¹‰è¯å…¸" class="headerlink" title="æ·»åŠ ç”¨æˆ·è‡ªå®šä¹‰è¯å…¸"></a>æ·»åŠ ç”¨æˆ·è‡ªå®šä¹‰è¯å…¸</h4><p>å¾ˆå¤šæ—¶å€™æˆ‘ä»¬éœ€è¦é’ˆå¯¹è‡ªå·±çš„åœºæ™¯è¿›è¡Œåˆ†è¯ï¼Œä¼šæœ‰ä¸€äº›é¢†åŸŸå†…çš„ä¸“æœ‰è¯æ±‡ã€‚</p><ul><li>1.å¯ä»¥ç”¨jieba.load_userdict(file_name)åŠ è½½ç”¨æˆ·å­—å…¸</li><li>2.å°‘é‡çš„è¯æ±‡å¯ä»¥è‡ªå·±ç”¨ä¸‹é¢æ–¹æ³•æ‰‹åŠ¨æ·»åŠ ï¼š<ul><li>ç”¨ add_word(word, freq=None, tag=None) å’Œ del_word(word) åœ¨ç¨‹åºä¸­åŠ¨æ€ä¿®æ”¹è¯å…¸</li><li>ç”¨ suggest_freq(segment, tune=True) å¯è°ƒèŠ‚å•ä¸ªè¯è¯­çš„è¯é¢‘ï¼Œä½¿å…¶èƒ½ï¼ˆæˆ–ä¸èƒ½ï¼‰è¢«åˆ†å‡ºæ¥ã€‚</li></ul></li></ul><p>In [3]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(&apos;/&apos;.join(jieba.cut(&apos;å¦‚æœæ”¾åˆ°æ—§å­—å…¸ä¸­å°†å‡ºé”™ã€‚&apos;, HMM=False)))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">å¦‚æœ/æ”¾åˆ°/æ—§/å­—å…¸/ä¸­å°†/å‡ºé”™/ã€‚</span><br></pre></td></tr></table></figure><p>In [4]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jieba.suggest_freq((&apos;ä¸­&apos;, &apos;å°†&apos;), True)</span><br></pre></td></tr></table></figure><p>Out[4]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">494</span><br></pre></td></tr></table></figure><p>In [5]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(&apos;/&apos;.join(jieba.cut(&apos;å¦‚æœæ”¾åˆ°æ—§å­—å…¸ä¸­å°†å‡ºé”™ã€‚&apos;, HMM=False)))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">å¦‚æœ/æ”¾åˆ°/æ—§/å­—å…¸/ä¸­/å°†/å‡ºé”™/ã€‚</span><br></pre></td></tr></table></figure><h3 id="å…³é”®è¯æå–"><a href="#å…³é”®è¯æå–" class="headerlink" title="å…³é”®è¯æå–"></a>å…³é”®è¯æå–</h3><h4 id="åŸºäº-TF-IDF-ç®—æ³•çš„å…³é”®è¯æŠ½å–"><a href="#åŸºäº-TF-IDF-ç®—æ³•çš„å…³é”®è¯æŠ½å–" class="headerlink" title="åŸºäº TF-IDF ç®—æ³•çš„å…³é”®è¯æŠ½å–"></a>åŸºäº TF-IDF ç®—æ³•çš„å…³é”®è¯æŠ½å–</h4><p>import jieba.analyse</p><ul><li>jieba.analyse.extract_tags(sentence, topK=20, withWeight=False, allowPOS=())<ul><li>sentence ä¸ºå¾…æå–çš„æ–‡æœ¬</li><li>topK ä¸ºè¿”å›å‡ ä¸ª TF/IDF æƒé‡æœ€å¤§çš„å…³é”®è¯ï¼Œé»˜è®¤å€¼ä¸º 20</li><li>withWeight ä¸ºæ˜¯å¦ä¸€å¹¶è¿”å›å…³é”®è¯æƒé‡å€¼ï¼Œé»˜è®¤å€¼ä¸º False</li><li>allowPOS ä»…åŒ…æ‹¬æŒ‡å®šè¯æ€§çš„è¯ï¼Œé»˜è®¤å€¼ä¸ºç©ºï¼Œå³ä¸ç­›é€‰</li></ul></li></ul><p>In [6]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import jieba.analyse as analyse</span><br><span class="line">lines = open(&apos;NBA.txt&apos;).read()</span><br><span class="line">print &quot;  &quot;.join(analyse.extract_tags(lines, topK=20, withWeight=False, allowPOS=()))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">éŸ¦å°‘  æœå…°ç‰¹  å…¨æ˜æ˜Ÿ  å…¨æ˜æ˜Ÿèµ›  MVP  å¨å°‘  æ­£èµ›  ç§‘å°”  æŠ•ç¯®  å‹‡å£«  çƒå‘˜  æ–¯å¸ƒé²å…‹  æ›´è¡£æŸœ  å¼ å«å¹³  ä¸‰è¿åº„  NBA  è¥¿éƒ¨  æŒ‡å¯¼  é›·éœ†  æ˜æ˜Ÿé˜Ÿ</span><br></pre></td></tr></table></figure><p>In [7]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lines = open(u&apos;è¥¿æ¸¸è®°.txt&apos;).read()</span><br><span class="line">print &quot;  &quot;.join(analyse.extract_tags(lines, topK=20, withWeight=False, allowPOS=()))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">è¡Œè€…  å…«æˆ’  å¸ˆçˆ¶  ä¸‰è—  å”åƒ§  å¤§åœ£  æ²™åƒ§  å¦–ç²¾  è©è¨  å’Œå°š  é‚£æ€ª  é‚£é‡Œ  é•¿è€  å‘†å­  å¾’å¼Ÿ  æ€ä¹ˆ  ä¸çŸ¥  è€å­™  å›½ç‹  ä¸€ä¸ª</span><br></pre></td></tr></table></figure><h4 id="å…³äºTF-IDF-ç®—æ³•çš„å…³é”®è¯æŠ½å–è¡¥å……"><a href="#å…³äºTF-IDF-ç®—æ³•çš„å…³é”®è¯æŠ½å–è¡¥å……" class="headerlink" title="å…³äºTF-IDF ç®—æ³•çš„å…³é”®è¯æŠ½å–è¡¥å……"></a>å…³äºTF-IDF ç®—æ³•çš„å…³é”®è¯æŠ½å–è¡¥å……</h4><ul><li>å…³é”®è¯æå–æ‰€ä½¿ç”¨é€†å‘æ–‡ä»¶é¢‘ç‡ï¼ˆIDFï¼‰æ–‡æœ¬è¯­æ–™åº“å¯ä»¥åˆ‡æ¢æˆè‡ªå®šä¹‰è¯­æ–™åº“çš„è·¯å¾„<ul><li>ç”¨æ³•ï¼š jieba.analyse.set_idf_path(file_name) # file_nameä¸ºè‡ªå®šä¹‰è¯­æ–™åº“çš„è·¯å¾„<ul><li>è‡ªå®šä¹‰è¯­æ–™åº“ç¤ºä¾‹è§<a href="https://github.com/fxsjy/jieba/blob/master/extra_dict/idf.txt.big" target="_blank" rel="noopener">è¿™é‡Œ</a></li><li>ç”¨æ³•ç¤ºä¾‹è§<a href="https://github.com/fxsjy/jieba/blob/master/test/extract_tags_idfpath.py" target="_blank" rel="noopener">è¿™é‡Œ</a></li></ul></li><li>å…³é”®è¯æå–æ‰€ä½¿ç”¨åœæ­¢è¯ï¼ˆStop Wordsï¼‰æ–‡æœ¬è¯­æ–™åº“å¯ä»¥åˆ‡æ¢æˆè‡ªå®šä¹‰è¯­æ–™åº“çš„è·¯å¾„<ul><li>ç”¨æ³•ï¼š jieba.analyse.set_stop_words(file_name) # file_nameä¸ºè‡ªå®šä¹‰è¯­æ–™åº“çš„è·¯å¾„</li><li>è‡ªå®šä¹‰è¯­æ–™åº“ç¤ºä¾‹è§<a href="https://github.com/fxsjy/jieba/blob/master/extra_dict/stop_words.txt" target="_blank" rel="noopener">è¿™é‡Œ</a></li><li>ç”¨æ³•ç¤ºä¾‹è§<a href="https://github.com/fxsjy/jieba/blob/master/test/extract_tags_stop_words.py" target="_blank" rel="noopener">è¿™é‡Œ</a></li></ul></li></ul></li><li>å…³é”®è¯ä¸€å¹¶è¿”å›å…³é”®è¯æƒé‡å€¼ç¤ºä¾‹<ul><li>ç”¨æ³•ç¤ºä¾‹è§<a href="https://github.com/fxsjy/jieba/blob/master/test/extract_tags_with_weight.py" target="_blank" rel="noopener">è¿™é‡Œ</a></li></ul></li></ul><h4 id="åŸºäº-TextRank-ç®—æ³•çš„å…³é”®è¯æŠ½å–"><a href="#åŸºäº-TextRank-ç®—æ³•çš„å…³é”®è¯æŠ½å–" class="headerlink" title="åŸºäº TextRank ç®—æ³•çš„å…³é”®è¯æŠ½å–"></a>åŸºäº TextRank ç®—æ³•çš„å…³é”®è¯æŠ½å–</h4><ul><li>jieba.analyse.textrank(sentence, topK=20, withWeight=False, allowPOS=(â€˜nsâ€™, â€˜nâ€™, â€˜vnâ€™, â€˜vâ€™)) ç›´æ¥ä½¿ç”¨ï¼Œæ¥å£ç›¸åŒï¼Œæ³¨æ„é»˜è®¤è¿‡æ»¤è¯æ€§ã€‚</li><li>jieba.analyse.TextRank() æ–°å»ºè‡ªå®šä¹‰ TextRank å®ä¾‹</li></ul><p>ç®—æ³•è®ºæ–‡ï¼š <a href="http://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf" target="_blank" rel="noopener">TextRank: Bringing Order into Texts</a></p><p>åŸºæœ¬æ€æƒ³:</p><ul><li>å°†å¾…æŠ½å–å…³é”®è¯çš„æ–‡æœ¬è¿›è¡Œåˆ†è¯</li><li>ä»¥å›ºå®šçª—å£å¤§å°(é»˜è®¤ä¸º5ï¼Œé€šè¿‡spanå±æ€§è°ƒæ•´)ï¼Œè¯ä¹‹é—´çš„å…±ç°å…³ç³»ï¼Œæ„å»ºå›¾</li><li>è®¡ç®—å›¾ä¸­èŠ‚ç‚¹çš„PageRankï¼Œæ³¨æ„æ˜¯æ— å‘å¸¦æƒå›¾</li></ul><p>In [8]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba.analyse <span class="keyword">as</span> analyse</span><br><span class="line">lines = open(<span class="string">'NBA.txt'</span>).read()</span><br><span class="line"><span class="keyword">print</span> <span class="string">"  "</span>.join(analyse.textrank(lines, topK=<span class="number">20</span>, withWeight=<span class="literal">False</span>, allowPOS=(<span class="string">'ns'</span>, <span class="string">'n'</span>, <span class="string">'vn'</span>, <span class="string">'v'</span>)))</span><br><span class="line"><span class="keyword">print</span> <span class="string">"---------------------æˆ‘æ˜¯åˆ†å‰²çº¿----------------"</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">"  "</span>.join(analyse.textrank(lines, topK=<span class="number">20</span>, withWeight=<span class="literal">False</span>, allowPOS=(<span class="string">'ns'</span>, <span class="string">'n'</span>)))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">å…¨æ˜æ˜Ÿèµ›  å‹‡å£«  æ­£èµ›  æŒ‡å¯¼  å¯¹æ–¹  æŠ•ç¯®  çƒå‘˜  æ²¡æœ‰  å‡ºç°  æ—¶é—´  å¨å°‘  è®¤ä¸º  çœ‹æ¥  ç»“æœ  ç›¸éš”  åŠ©æ”»  ç°åœº  ä¸‰è¿åº„  ä»‹ç»  å˜‰å®¾</span><br><span class="line">---------------------æˆ‘æ˜¯åˆ†å‰²çº¿----------------</span><br><span class="line">å‹‡å£«  æ­£èµ›  å…¨æ˜æ˜Ÿèµ›  æŒ‡å¯¼  æŠ•ç¯®  ç©å‘½  æ—¶é—´  å¯¹æ–¹  ç°åœº  ç»“æœ  çƒå‘˜  å˜‰å®¾  æ—¶å€™  å…¨é˜Ÿ  ä¸»æŒäºº  ç‰¹ç‚¹  å¤§ä¼™  è‚¥çš‚å‰§  å…¨ç¨‹  å¿«èˆ¹é˜Ÿ</span><br></pre></td></tr></table></figure><p>In [9]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lines = open(u&apos;è¥¿æ¸¸è®°.txt&apos;).read()</span><br><span class="line">print &quot;  &quot;.join(analyse.textrank(lines, topK=20, withWeight=False, allowPOS=(&apos;ns&apos;, &apos;n&apos;, &apos;vn&apos;, &apos;v&apos;)))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">è¡Œè€…  å¸ˆçˆ¶  å…«æˆ’  ä¸‰è—  å¤§åœ£  ä¸çŸ¥  è©è¨  å¦–ç²¾  åªè§  é•¿è€  å›½ç‹  å´è¯´  å‘†å­  å¾’å¼Ÿ  å°å¦–  å‡ºæ¥  ä¸å¾—  ä¸è§  ä¸èƒ½  å¸ˆå¾’</span><br></pre></td></tr></table></figure><h3 id="è¯æ€§æ ‡æ³¨"><a href="#è¯æ€§æ ‡æ³¨" class="headerlink" title="è¯æ€§æ ‡æ³¨"></a>è¯æ€§æ ‡æ³¨</h3><ul><li>jieba.posseg.POSTokenizer(tokenizer=None) æ–°å»ºè‡ªå®šä¹‰åˆ†è¯å™¨ï¼Œtokenizer å‚æ•°å¯æŒ‡å®šå†…éƒ¨ä½¿ç”¨çš„ jieba.Tokenizer åˆ†è¯å™¨ã€‚jieba.posseg.dt ä¸ºé»˜è®¤è¯æ€§æ ‡æ³¨åˆ†è¯å™¨ã€‚</li><li>æ ‡æ³¨å¥å­åˆ†è¯åæ¯ä¸ªè¯çš„è¯æ€§ï¼Œé‡‡ç”¨å’Œ ictclas å…¼å®¹çš„æ ‡è®°æ³•ã€‚</li><li>å…·ä½“çš„è¯æ€§å¯¹ç…§è¡¨å‚è§<a href="http://ictclas.nlpir.org/nlpir/html/readme.htm" target="_blank" rel="noopener">è®¡ç®—æ‰€æ±‰è¯­è¯æ€§æ ‡è®°é›†</a></li></ul><p>In [10]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba.posseg <span class="keyword">as</span> pseg</span><br><span class="line">words = pseg.cut(<span class="string">"æˆ‘çˆ±è‡ªç„¶è¯­è¨€å¤„ç†"</span>)</span><br><span class="line"><span class="keyword">for</span> word, flag <span class="keyword">in</span> words:</span><br><span class="line">    print(<span class="string">'%s %s'</span> % (word, flag))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">æˆ‘ r</span><br><span class="line">çˆ± v</span><br><span class="line">è‡ªç„¶è¯­è¨€ l</span><br><span class="line">å¤„ç† v</span><br></pre></td></tr></table></figure><h3 id="å¹¶è¡Œåˆ†è¯"><a href="#å¹¶è¡Œåˆ†è¯" class="headerlink" title="å¹¶è¡Œåˆ†è¯"></a>å¹¶è¡Œåˆ†è¯</h3><p>åŸç†ï¼šå°†ç›®æ ‡æ–‡æœ¬æŒ‰è¡Œåˆ†éš”åï¼ŒæŠŠå„è¡Œæ–‡æœ¬åˆ†é…åˆ°å¤šä¸ª Python è¿›ç¨‹å¹¶è¡Œåˆ†è¯ï¼Œç„¶åå½’å¹¶ç»“æœï¼Œä»è€Œè·å¾—åˆ†è¯é€Ÿåº¦çš„å¯è§‚æå‡ åŸºäº python è‡ªå¸¦çš„ multiprocessing æ¨¡å—ï¼Œç›®å‰æš‚ä¸æ”¯æŒ Windows</p><p>ç”¨æ³•ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">jieba.enable_parallel(<span class="number">4</span>) <span class="comment"># å¼€å¯å¹¶è¡Œåˆ†è¯æ¨¡å¼ï¼Œå‚æ•°ä¸ºå¹¶è¡Œè¿›ç¨‹æ•°</span></span><br><span class="line">jieba.disable_parallel() <span class="comment"># å…³é—­å¹¶è¡Œåˆ†è¯æ¨¡å¼</span></span><br></pre></td></tr></table></figure><p>å®éªŒç»“æœï¼šåœ¨ 4 æ ¸ 3.4GHz Linux æœºå™¨ä¸Šï¼Œå¯¹é‡‘åº¸å…¨é›†è¿›è¡Œç²¾ç¡®åˆ†è¯ï¼Œè·å¾—äº† 1MB/s çš„é€Ÿåº¦ï¼Œæ˜¯å•è¿›ç¨‹ç‰ˆçš„ 3.3 å€ã€‚</p><p>æ³¨æ„ï¼šå¹¶è¡Œåˆ†è¯ä»…æ”¯æŒé»˜è®¤åˆ†è¯å™¨ jieba.dt å’Œ jieba.posseg.dtã€‚</p><p>In [11]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line">jieba.enable_parallel()</span><br><span class="line">content = open(<span class="string">u'è¥¿æ¸¸è®°.txt'</span>,<span class="string">"r"</span>).read()</span><br><span class="line">t1 = time.time()</span><br><span class="line">words = <span class="string">"/ "</span>.join(jieba.cut(content))</span><br><span class="line">t2 = time.time()</span><br><span class="line">tm_cost = t2-t1</span><br><span class="line">print(<span class="string">'å¹¶è¡Œåˆ†è¯é€Ÿåº¦ä¸º %s bytes/second'</span> % (len(content)/tm_cost))</span><br><span class="line"></span><br><span class="line">jieba.disable_parallel()</span><br><span class="line">content = open(<span class="string">u'è¥¿æ¸¸è®°.txt'</span>,<span class="string">"r"</span>).read()</span><br><span class="line">t1 = time.time()</span><br><span class="line">words = <span class="string">"/ "</span>.join(jieba.cut(content))</span><br><span class="line">t2 = time.time()</span><br><span class="line">tm_cost = t2-t1</span><br><span class="line">print(<span class="string">'éå¹¶è¡Œåˆ†è¯é€Ÿåº¦ä¸º %s bytes/second'</span> % (len(content)/tm_cost))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">å¹¶è¡Œåˆ†è¯é€Ÿåº¦ä¸º 830619.50933 bytes/second</span><br><span class="line">éå¹¶è¡Œåˆ†è¯é€Ÿåº¦ä¸º 259941.448353 bytes/second</span><br></pre></td></tr></table></figure><h3 id="Tokenizeï¼šè¿”å›è¯è¯­åœ¨åŸæ–‡çš„èµ·æ­¢ä½ç½®"><a href="#Tokenizeï¼šè¿”å›è¯è¯­åœ¨åŸæ–‡çš„èµ·æ­¢ä½ç½®" class="headerlink" title="Tokenizeï¼šè¿”å›è¯è¯­åœ¨åŸæ–‡çš„èµ·æ­¢ä½ç½®"></a>Tokenizeï¼šè¿”å›è¯è¯­åœ¨åŸæ–‡çš„èµ·æ­¢ä½ç½®</h3><p>æ³¨æ„ï¼Œè¾“å…¥å‚æ•°åªæ¥å— unicode</p><p>In [12]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> <span class="string">"è¿™æ˜¯é»˜è®¤æ¨¡å¼çš„tokenize"</span></span><br><span class="line">result = jieba.tokenize(<span class="string">u'è‡ªç„¶è¯­è¨€å¤„ç†éå¸¸æœ‰ç”¨'</span>)</span><br><span class="line"><span class="keyword">for</span> tk <span class="keyword">in</span> result:</span><br><span class="line">    print(<span class="string">"%s\t\t start: %d \t\t end:%d"</span> % (tk[<span class="number">0</span>],tk[<span class="number">1</span>],tk[<span class="number">2</span>]))</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> <span class="string">"\n-----------æˆ‘æ˜¯ç¥å¥‡çš„åˆ†å‰²çº¿------------\n"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> <span class="string">"è¿™æ˜¯æœç´¢æ¨¡å¼çš„tokenize"</span></span><br><span class="line">result = jieba.tokenize(<span class="string">u'è‡ªç„¶è¯­è¨€å¤„ç†éå¸¸æœ‰ç”¨'</span>, mode=<span class="string">'search'</span>)</span><br><span class="line"><span class="keyword">for</span> tk <span class="keyword">in</span> result:</span><br><span class="line">    print(<span class="string">"%s\t\t start: %d \t\t end:%d"</span> % (tk[<span class="number">0</span>],tk[<span class="number">1</span>],tk[<span class="number">2</span>]))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">è¿™æ˜¯é»˜è®¤æ¨¡å¼çš„tokenize</span><br><span class="line">è‡ªç„¶è¯­è¨€ start: <span class="number">0</span>  end:<span class="number">4</span></span><br><span class="line">å¤„ç† start: <span class="number">4</span>  end:<span class="number">6</span></span><br><span class="line">éå¸¸ start: <span class="number">6</span>  end:<span class="number">8</span></span><br><span class="line">æœ‰ç”¨ start: <span class="number">8</span>  end:<span class="number">10</span></span><br><span class="line"></span><br><span class="line">-----------æˆ‘æ˜¯ç¥å¥‡çš„åˆ†å‰²çº¿------------</span><br><span class="line"></span><br><span class="line">è¿™æ˜¯æœç´¢æ¨¡å¼çš„tokenize</span><br><span class="line">è‡ªç„¶ start: <span class="number">0</span>  end:<span class="number">2</span></span><br><span class="line">è¯­è¨€ start: <span class="number">2</span>  end:<span class="number">4</span></span><br><span class="line">è‡ªç„¶è¯­è¨€ start: <span class="number">0</span>  end:<span class="number">4</span></span><br><span class="line">å¤„ç† start: <span class="number">4</span>  end:<span class="number">6</span></span><br><span class="line">éå¸¸ start: <span class="number">6</span>  end:<span class="number">8</span></span><br><span class="line">æœ‰ç”¨ start: <span class="number">8</span>  end:<span class="number">10</span></span><br></pre></td></tr></table></figure><h3 id="ChineseAnalyzer-for-Whoosh-æœç´¢å¼•æ“"><a href="#ChineseAnalyzer-for-Whoosh-æœç´¢å¼•æ“" class="headerlink" title="ChineseAnalyzer for Whoosh æœç´¢å¼•æ“"></a>ChineseAnalyzer for Whoosh æœç´¢å¼•æ“</h3><ul><li><code>from jieba.analyse import ChineseAnalyzer</code></li></ul><p>In [16]:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> unicode_literals</span><br><span class="line"><span class="keyword">import</span> sys,os</span><br><span class="line">sys.path.append(<span class="string">"../"</span>)</span><br><span class="line"><span class="keyword">from</span> whoosh.index <span class="keyword">import</span> create_in,open_dir</span><br><span class="line"><span class="keyword">from</span> whoosh.fields <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> whoosh.qparser <span class="keyword">import</span> QueryParser</span><br><span class="line"></span><br><span class="line">analyzer = jieba.analyse.ChineseAnalyzer()</span><br><span class="line">schema = Schema(title=TEXT(stored=<span class="literal">True</span>), path=ID(stored=<span class="literal">True</span>), content=TEXT(stored=<span class="literal">True</span>, analyzer=analyzer))</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">"tmp"</span>):</span><br><span class="line">    os.mkdir(<span class="string">"tmp"</span>)</span><br><span class="line"></span><br><span class="line">ix = create_in(<span class="string">"tmp"</span>, schema) <span class="comment"># for create new index</span></span><br><span class="line"><span class="comment">#ix = open_dir("tmp") # for read only</span></span><br><span class="line">writer = ix.writer()</span><br><span class="line"></span><br><span class="line">writer.add_document(</span><br><span class="line">    title=<span class="string">"document1"</span>,</span><br><span class="line">    path=<span class="string">"/a"</span>,</span><br><span class="line">    content=<span class="string">"This is the first document weâ€™ve added!"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">writer.add_document(</span><br><span class="line">    title=<span class="string">"document2"</span>,</span><br><span class="line">    path=<span class="string">"/b"</span>,</span><br><span class="line">    content=<span class="string">"The second one ä½  ä¸­æ–‡æµ‹è¯•ä¸­æ–‡ is even more interesting! åƒæ°´æœ"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">writer.add_document(</span><br><span class="line">    title=<span class="string">"document3"</span>,</span><br><span class="line">    path=<span class="string">"/c"</span>,</span><br><span class="line">    content=<span class="string">"ä¹°æ°´æœç„¶åæ¥ä¸–åšå›­ã€‚"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">writer.add_document(</span><br><span class="line">    title=<span class="string">"document4"</span>,</span><br><span class="line">    path=<span class="string">"/c"</span>,</span><br><span class="line">    content=<span class="string">"å·¥ä¿¡å¤„å¥³å¹²äº‹æ¯æœˆç»è¿‡ä¸‹å±ç§‘å®¤éƒ½è¦äº²å£äº¤ä»£24å£äº¤æ¢æœºç­‰æŠ€æœ¯æ€§å™¨ä»¶çš„å®‰è£…å·¥ä½œ"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">writer.add_document(</span><br><span class="line">    title=<span class="string">"document4"</span>,</span><br><span class="line">    path=<span class="string">"/c"</span>,</span><br><span class="line">    content=<span class="string">"å’±ä¿©äº¤æ¢ä¸€ä¸‹å§ã€‚"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">writer.commit()</span><br><span class="line">searcher = ix.searcher()</span><br><span class="line">parser = QueryParser(<span class="string">"content"</span>, schema=ix.schema)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> keyword <span class="keyword">in</span> (<span class="string">"æ°´æœä¸–åšå›­"</span>,<span class="string">"ä½ "</span>,<span class="string">"first"</span>,<span class="string">"ä¸­æ–‡"</span>,<span class="string">"äº¤æ¢æœº"</span>,<span class="string">"äº¤æ¢"</span>):</span><br><span class="line">    print(keyword+<span class="string">"çš„ç»“æœä¸ºå¦‚ä¸‹ï¼š"</span>)</span><br><span class="line">    q = parser.parse(keyword)</span><br><span class="line">    results = searcher.search(q)</span><br><span class="line">    <span class="keyword">for</span> hit <span class="keyword">in</span> results:</span><br><span class="line">        print(hit.highlights(<span class="string">"content"</span>))</span><br><span class="line">    print(<span class="string">"\n--------------æˆ‘æ˜¯ç¥å¥‡çš„åˆ†å‰²çº¿--------------\n"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> analyzer(<span class="string">"æˆ‘çš„å¥½æœ‹å‹æ˜¯ææ˜;æˆ‘çˆ±åŒ—äº¬å¤©å®‰é—¨;IBMå’ŒMicrosoft; I have a dream. this is intetesting and interested me a lot"</span>):</span><br><span class="line">    print(t.text)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">æ°´æœä¸–åšå›­çš„ç»“æœä¸ºå¦‚ä¸‹ï¼š</span><br><span class="line">ä¹°&lt;b class="match term0"&gt;æ°´æœ&lt;/b&gt;ç„¶åæ¥&lt;b class="match term1"&gt;ä¸–åšå›­&lt;/b&gt;</span><br><span class="line"></span><br><span class="line">--------------æˆ‘æ˜¯ç¥å¥‡çš„åˆ†å‰²çº¿--------------</span><br><span class="line"></span><br><span class="line">ä½ çš„ç»“æœä¸ºå¦‚ä¸‹ï¼š</span><br><span class="line">second one &lt;b class="match term0"&gt;ä½ &lt;/b&gt; ä¸­æ–‡æµ‹è¯•ä¸­æ–‡ is even more interesting</span><br><span class="line"></span><br><span class="line">--------------æˆ‘æ˜¯ç¥å¥‡çš„åˆ†å‰²çº¿--------------</span><br><span class="line"></span><br><span class="line">firstçš„ç»“æœä¸ºå¦‚ä¸‹ï¼š</span><br><span class="line">&lt;b class="match term0"&gt;first&lt;/b&gt; document weâ€™ve added</span><br><span class="line"></span><br><span class="line">--------------æˆ‘æ˜¯ç¥å¥‡çš„åˆ†å‰²çº¿--------------</span><br><span class="line"></span><br><span class="line">ä¸­æ–‡çš„ç»“æœä¸ºå¦‚ä¸‹ï¼š</span><br><span class="line">second one ä½  &lt;b class="match term0"&gt;ä¸­æ–‡&lt;/b&gt;æµ‹è¯•&lt;b class="match term0"&gt;ä¸­æ–‡&lt;/b&gt; is even more interesting</span><br><span class="line"></span><br><span class="line">--------------æˆ‘æ˜¯ç¥å¥‡çš„åˆ†å‰²çº¿--------------</span><br><span class="line"></span><br><span class="line">äº¤æ¢æœºçš„ç»“æœä¸ºå¦‚ä¸‹ï¼š</span><br><span class="line">å¹²äº‹æ¯æœˆç»è¿‡ä¸‹å±ç§‘å®¤éƒ½è¦äº²å£äº¤ä»£24å£&lt;b class="match term0"&gt;äº¤æ¢æœº&lt;/b&gt;ç­‰æŠ€æœ¯æ€§å™¨ä»¶çš„å®‰è£…å·¥ä½œ</span><br><span class="line"></span><br><span class="line">--------------æˆ‘æ˜¯ç¥å¥‡çš„åˆ†å‰²çº¿--------------</span><br><span class="line"></span><br><span class="line">äº¤æ¢çš„ç»“æœä¸ºå¦‚ä¸‹ï¼š</span><br><span class="line">å’±ä¿©&lt;b class="match term0"&gt;äº¤æ¢&lt;/b&gt;ä¸€ä¸‹å§</span><br><span class="line">å¹²äº‹æ¯æœˆç»è¿‡ä¸‹å±ç§‘å®¤éƒ½è¦äº²å£äº¤ä»£24å£&lt;b class="match term0"&gt;äº¤æ¢&lt;/b&gt;æœºç­‰æŠ€æœ¯æ€§å™¨ä»¶çš„å®‰è£…å·¥ä½œ</span><br><span class="line"></span><br><span class="line">--------------æˆ‘æ˜¯ç¥å¥‡çš„åˆ†å‰²çº¿--------------</span><br><span class="line"></span><br><span class="line">æˆ‘</span><br><span class="line">å¥½</span><br><span class="line">æœ‹å‹</span><br><span class="line">æ˜¯</span><br><span class="line">ææ˜</span><br><span class="line">æˆ‘</span><br><span class="line">çˆ±</span><br><span class="line">åŒ—äº¬</span><br><span class="line">å¤©å®‰</span><br><span class="line">å¤©å®‰é—¨</span><br><span class="line">ibm</span><br><span class="line">microsoft</span><br><span class="line">dream</span><br><span class="line">intetest</span><br><span class="line">interest</span><br><span class="line">me</span><br><span class="line">lot</span><br></pre></td></tr></table></figure><h3 id="å‘½ä»¤è¡Œåˆ†è¯"><a href="#å‘½ä»¤è¡Œåˆ†è¯" class="headerlink" title="å‘½ä»¤è¡Œåˆ†è¯"></a>å‘½ä»¤è¡Œåˆ†è¯</h3><p>ä½¿ç”¨ç¤ºä¾‹ï¼š<code>python -m jieba news.txt &gt; cut_result.txt</code></p><p>å‘½ä»¤è¡Œé€‰é¡¹ï¼ˆç¿»è¯‘ï¼‰ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">ä½¿ç”¨: python -m jieba [options] filename</span><br><span class="line"></span><br><span class="line">ç»“å·´å‘½ä»¤è¡Œç•Œé¢ã€‚</span><br><span class="line"></span><br><span class="line">å›ºå®šå‚æ•°:</span><br><span class="line">  filename              è¾“å…¥æ–‡ä»¶</span><br><span class="line"></span><br><span class="line">å¯é€‰å‚æ•°:</span><br><span class="line">  -h, --help            æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯å¹¶é€€å‡º</span><br><span class="line">  -d [DELIM], --delimiter [DELIM]</span><br><span class="line">                        ä½¿ç”¨ DELIM åˆ†éš”è¯è¯­ï¼Œè€Œä¸æ˜¯ç”¨é»˜è®¤çš„<span class="string">' / '</span>ã€‚</span><br><span class="line">                        è‹¥ä¸æŒ‡å®š DELIMï¼Œåˆ™ä½¿ç”¨ä¸€ä¸ªç©ºæ ¼åˆ†éš”ã€‚</span><br><span class="line">  -p [DELIM], --pos [DELIM]</span><br><span class="line">                        å¯ç”¨è¯æ€§æ ‡æ³¨ï¼›å¦‚æœæŒ‡å®š DELIMï¼Œè¯è¯­å’Œè¯æ€§ä¹‹é—´</span><br><span class="line">                        ç”¨å®ƒåˆ†éš”ï¼Œå¦åˆ™ç”¨ _ åˆ†éš”</span><br><span class="line">  -D DICT, --dict DICT  ä½¿ç”¨ DICT ä»£æ›¿é»˜è®¤è¯å…¸</span><br><span class="line">  -u USER_DICT, --user-dict USER_DICT</span><br><span class="line">                        ä½¿ç”¨ USER_DICT ä½œä¸ºé™„åŠ è¯å…¸ï¼Œä¸é»˜è®¤è¯å…¸æˆ–è‡ªå®šä¹‰è¯å…¸é…åˆä½¿ç”¨</span><br><span class="line">  -a, --cut-all         å…¨æ¨¡å¼åˆ†è¯ï¼ˆä¸æ”¯æŒè¯æ€§æ ‡æ³¨ï¼‰</span><br><span class="line">  -n, --no-hmm          ä¸ä½¿ç”¨éšå«é©¬å°”å¯å¤«æ¨¡å‹</span><br><span class="line">  -q, --quiet           ä¸è¾“å‡ºè½½å…¥ä¿¡æ¯åˆ° STDERR</span><br><span class="line">  -V, --version         æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯å¹¶é€€å‡º</span><br><span class="line"></span><br><span class="line">å¦‚æœæ²¡æœ‰æŒ‡å®šæ–‡ä»¶åï¼Œåˆ™ä½¿ç”¨æ ‡å‡†è¾“å…¥ã€‚</span><br></pre></td></tr></table></figure><p><code>--help</code> é€‰é¡¹è¾“å‡ºï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">$&gt; python -m jieba --help</span><br><span class="line">Jieba command line interface.</span><br><span class="line"></span><br><span class="line">positional arguments:</span><br><span class="line">  filename              input file</span><br><span class="line"></span><br><span class="line">optional arguments:</span><br><span class="line">  -h, --help            show this help message <span class="keyword">and</span> exit</span><br><span class="line">  -d [DELIM], --delimiter [DELIM]</span><br><span class="line">                        use DELIM instead of <span class="string">' / '</span> <span class="keyword">for</span> word delimiter; <span class="keyword">or</span> a</span><br><span class="line">                        space <span class="keyword">if</span> it <span class="keyword">is</span> used without DELIM</span><br><span class="line">  -p [DELIM], --pos [DELIM]</span><br><span class="line">                        enable POS tagging; <span class="keyword">if</span> DELIM <span class="keyword">is</span> specified, use DELIM</span><br><span class="line">                        instead of <span class="string">'_'</span> <span class="keyword">for</span> POS delimiter</span><br><span class="line">  -D DICT, --dict DICT  use DICT <span class="keyword">as</span> dictionary</span><br><span class="line">  -u USER_DICT, --user-dict USER_DICT</span><br><span class="line">                        use USER_DICT together <span class="keyword">with</span> the default dictionary <span class="keyword">or</span></span><br><span class="line">                        DICT (<span class="keyword">if</span> specified)</span><br><span class="line">  -a, --cut-all         full pattern cutting (ignored <span class="keyword">with</span> POS tagging)</span><br><span class="line">  -n, --no-hmm          don<span class="string">'t use the Hidden Markov Model</span></span><br><span class="line"><span class="string">  -q, --quiet           don'</span>t <span class="keyword">print</span> loading messages to stderr</span><br><span class="line">  -V, --version         show program<span class="string">'s version number and exit</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">If no filename specified, use STDIN instead.</span></span><br></pre></td></tr></table></figure><p>In [ ]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> åˆ†è¯ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jieba </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
